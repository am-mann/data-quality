---
title: "Mapping Notebook"
output: html_notebook
---

Temporality stable groupings
```{r}
# ──────────────────────────────────────────────────────────────
# 5-year average maps by temporally-stable IHME groups 
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2","here","scales","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))
options(tigris_use_cache = TRUE, tigris_class = "sf")

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Variables to map (no transformations will be applied)
vars_to_map <- c(
  "prop_garbage", "DQ_rec_ig_frac_mean_garbage", "DQ_overall", "DQ_rec_ig_abs_mean", "foreman_garbage", "RI"
)

# 2) Load your county-year data (as-is); add time windows only
dq <- readr::read_csv(here::here("data","county_year_quality_metrics.csv"), show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = as.integer(year),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999–2005",
      year >= 2006 & year <= 2012 ~ "2006–2012",
      year >= 2013 & year <= 2019 ~ "2013–2019",
      year >= 2020 & year <= 2022 ~ "2020–2022",
      TRUE ~ NA_character_
    )
  )

# Keep only variables that actually exist; no conversions
vars_present <- intersect(vars_to_map, names(dq))
if (!length(vars_present)) stop("None of vars_to_map exist in dq. Check column names.")
vars_missing <- setdiff(vars_to_map, vars_present)
if (length(vars_missing)) message("Skipping missing vars: ", paste(vars_missing, collapse = ", "))

# 3) 5-year averages by temporally-stable group (means of existing cols only)
dq_avg <- dq %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(
    dplyr::across(dplyr::all_of(vars_present), ~ mean(.x, na.rm = TRUE)),
    n_years = dplyr::n(),
    .groups = "drop"
  )

# 4) Crosswalk for temporality-stable shapes (dissolve multi-GEOID groups)
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(orig_fips, 5, pad = "0"),
    county_ihme = stringr::str_pad(ihme_fips, 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 5) Build shapes per period & join averages
crs_proj <- 2163
shapefile_years <- c("1999–2005"=2000, "2006–2012"=2010, "2013–2019"=2019, "2020–2022"=2020)

st_shift <- function(x, offset) { sf::st_geometry(x) <- sf::st_geometry(x) + offset; x }
st_scale <- function(x, factor) { ctr <- sf::st_centroid(sf::st_union(x)); sf::st_geometry(x) <- (sf::st_geometry(x) - ctr) * factor + ctr; x }

# ——— Normalizer: ensure a 5-digit GEOID exists, with robust fallbacks ———
normalize_geoid <- function(sf, year) {
  nms <- names(sf)

  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    message("[", year, "] Using GEOID column: ", geoid_col)
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(geoid_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }

  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    message("[", year, "] Constructing GEOID from ", state_col, " + ", county_col)
    sf$GEOID <- paste0(
      stringr::str_pad(as.character(sf[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sf[[county_col]]), 3, pad = "0")
    )
    return(sf)
  }

  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    message("[", year, "] Using combined ID column: ", combo_col, " as GEOID")
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(combo_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }

  stop("No GEOID-compatible columns found in shapefile for year ", year,
       ". Columns were: ", paste(nms, collapse = ", "))
}

# ——— Build groups: normalize → transform → dissolve by county_ihme ———
build_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM")

  counties_norm <- normalize_geoid(counties_raw, year) %>%  # ← normalize FIRST
    sf::st_transform(crs_proj)

  groups_sf <- counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")  # st_union here

  # AK / HI layout (unchanged)
  alaska   <- groups_sf %>% dplyr::filter(substr(county_ihme,1,2)=="02") %>%
    { ctr <- sf::st_centroid(sf::st_union(.)); sf::st_geometry(.) <- (sf::st_geometry(.) - ctr)*0.40 + ctr; . } %>%
    { sf::st_geometry(.) <- sf::st_geometry(.) + c(1300000, -4900000); . } %>%
    sf::st_set_crs(crs_proj)
  hawaii   <- groups_sf %>% dplyr::filter(substr(county_ihme,1,2)=="15") %>%
    { ctr <- sf::st_centroid(sf::st_union(.)); sf::st_geometry(.) <- (sf::st_geometry(.) - ctr)*1.50 + ctr; . } %>%
    { sf::st_geometry(.) <- sf::st_geometry(.) + c(5200000, -1400000); . } %>%
    sf::st_set_crs(crs_proj)
  mainland <- groups_sf %>% dplyr::filter(!substr(county_ihme,1,2) %in% c("02","15"))

  dplyr::bind_rows(mainland, alaska, hawaii)
}

joined_by_period <- purrr::imap(
  shapefile_years,
  function(year, window) {
    shape_all <- build_groups_sf(year)
    dplyr::left_join(shape_all, dplyr::filter(dq_avg, time_window == window), by = "county_ihme")
  }
)

# 6) make_map — now shows titles; we pass ONLY period strings when calling
make_map <- function(sf_data, var, title = NULL, palette = "RdBu") {
  states <- tigris::states(cb = TRUE, class = "sf") |> st_transform(2163)

  fill_scale <- if (var == "prop_garbage") {
    scale_fill_distiller(palette = palette, limits = c(0.15, 0.4), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "prop_light") {
    scale_fill_distiller(palette = palette, limits = c(0.20, 0.40), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_overd_miss") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.75), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "direction_score") {
    scale_fill_distiller(palette = palette, limits = c(-1,1.5), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "DQ_overall") {
    scale_fill_distiller(palette = palette, limits = c(0,0.9), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "pct_acc_miss") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.75), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_mandeath_comp_k") {
    scale_fill_distiller(palette = palette, limits = c(5, 20), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var %in% c("pct_age_comp_k", "pct_sex_comp_k", "pct_race_comp_k")) {
    scale_fill_distiller(palette = palette, limits = c(99.5, 100), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "RI") {
    scale_fill_distiller(palette = palette, limits = c(0.15, 0.3), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "pct_gc_N19") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.025), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_gc_J80") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.005), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (startsWith(var, "pct_") || var == "overall_completeness_pct") {
    scale_fill_distiller(palette = palette, limits = c(0, 100), oob = scales::squish, direction = 1, na.value = "grey90")
  } else {
    scale_fill_distiller(palette = palette, oob = scales::squish, na.value = "grey90", direction = -1)
  }

  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    fill_scale +
    coord_sf(xlim = c(-2500000, 2500000),
             ylim = c(-2200000, 730000),
             expand = FALSE) +
    labs(title = title %||% "", fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),  # ← SHOW titles
      legend.text = element_text(size = 9)
    )
}

# 7) Save ONLY 4-panel maps (one panel per time window)
output_dir <- here::here("figures","5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

purrr::walk(vars_present, function(var) {
  p_1999 <- make_map(joined_by_period[["1999–2005"]], var, "1999–2005")
  p_2006 <- make_map(joined_by_period[["2006–2012"]], var, "2006–2012")
  p_2013 <- make_map(joined_by_period[["2013–2019"]], var, "2013–2019")
  p_2020 <- make_map(joined_by_period[["2020–2022"]], var, "2020–2022")

  combined <- (p_1999 | p_2006) / (p_2013 | p_2020)

  ggsave(filename = file.path(output_dir, paste0(var, "_4panel.png")),
         plot = combined, width = 12, height = 9, dpi = 320)
})

message("✓ Done. 4-panel maps saved to: ", output_dir)

```
Map RI scores with light clustering
```{r}
# ──────────────────────────────────────────────────────────────
# Map RI, RI_post_only, and RI_jsd (if available) with light clusters
#   • Clustering uses n_cert as the "garbage count" proxy
#   • Robust min across 4 windows; min per-cluster threshold = 150
#   • Alaska & Hawaii included via state outlines
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2",
              "here","scales","igraph","tidyr","tibble","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))

options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Windows & inputs
periods_vec <- c("1999_2005","2006_2012","2013_2019","2020_2022")
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

metrics_path_gz <- here::here("data","county_year_quality_metrics.csv.gz")
metrics_path    <- if (file.exists(metrics_path_gz)) metrics_path_gz else here::here("data","county_year_quality_metrics.csv")

dq <- readr::read_csv(metrics_path, show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = suppressWarnings(as.integer(year)),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2006 & year <= 2012 ~ "2006_2012",
      year >= 2013 & year <= 2019 ~ "2013_2019",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    ),
    time_window = stringr::str_replace_all(time_window, "[\u2013\u2014]", "_")
  )

# Required columns for this mapping step
req_cols <- c("RI","RI_post_only","n_cert")
stopifnot(all(req_cols %in% names(dq)))

has_jsd <- "RI_jsd" %in% names(dq)
if (!has_jsd) message("ℹ 'RI_jsd' not found in input; JSD maps will be skipped.")

# Use n_cert as garbage proxy
dq$gb_n <- suppressWarnings(as.numeric(dq$n_cert))
dq$gb_n[is.na(dq$gb_n)] <- 0

# 2) IHME crosswalk
load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 3) Robust n_cert totals across windows (min across 4)
gb_by_window <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(gb = sum(gb_n, na.rm = TRUE), .groups = "drop")

gb_wide <- gb_by_window %>%
  tidyr::pivot_wider(names_from = time_window, values_from = gb, values_fill = 0)
for (w in periods_vec) if (!w %in% names(gb_wide)) gb_wide[[w]] <- 0

robust_tbl <- gb_wide %>%
  dplyr::mutate(robust_gb = pmin(`1999_2005`,`2006_2012`,`2013_2019`,`2020_2022`, na.rm = TRUE)) %>%
  dplyr::transmute(county_ihme, robust_gb = as.numeric(robust_gb))

# 4) Shapefiles
crs_proj <- 2163
albers_5070 <- 5070

normalize_geoid <- function(sfobj, year) {
  nms <- names(sfobj)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    sfobj <- dplyr::rename(sfobj, GEOID = !!rlang::sym(geoid_col))
    sfobj$GEOID <- stringr::str_pad(as.character(sfobj$GEOID), 5, pad = "0")
    return(sfobj)
  }
  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    sfobj$GEOID <- paste0(
      stringr::str_pad(as.character(sfobj[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sfobj[[county_col]]), 3, pad = "0")
    )
    return(sfobj)
  }
  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    sfobj <- dplyr::rename(sfobj, GEOID = !!rlang::sym(combo_col))
    sfobj$GEOID <- stringr::str_pad(as.character(sfobj$GEOID), 5, pad = "0")
    return(sfobj)
  }
  stop("No GEOID-compatible columns found in shapefile for year ", year)
}

build_ihme_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM") %>%
    sf::st_make_valid()
  counties_norm <- normalize_geoid(counties_raw, year) %>%
    sf::st_transform(crs_proj) %>%
    sf::st_make_valid()
  counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")
}

# 5) Light clustering (min_gb = 150)
ihme2020 <- build_ihme_groups_sf(2020) %>% sf::st_transform(albers_5070)
adj_list <- sf::st_touches(ihme2020)
neighbors_of <- setNames(lapply(seq_len(nrow(ihme2020)), function(i) ihme2020$county_ihme[adj_list[[i]]]),
                         ihme2020$county_ihme)

min_gb <- 2000L   # LIGHT threshold

nodes_tbl <- ihme2020 %>%
  sf::st_drop_geometry() %>%
  dplyr::select(county_ihme) %>%
  dplyr::left_join(robust_tbl, by = "county_ihme") %>%
  dplyr::mutate(robust_gb = dplyr::coalesce(robust_gb, 0))

gb_vec    <- setNames(nodes_tbl$robust_gb, nodes_tbl$county_ihme)
to_assign <- names(gb_vec)
clusters  <- setNames(rep(NA_character_, length(gb_vec)), to_assign)
cid <- 1L

while (length(to_assign) > 0) {
  seed  <- to_assign[which.max(gb_vec[to_assign])]
  cur   <- seed
  total <- gb_vec[seed]
  avail <- setdiff(to_assign, seed)

  repeat {
    nbrs <- unique(unlist(neighbors_of[cur], use.names = FALSE))
    nbrs <- setdiff(intersect(nbrs, avail), cur)
    if (!length(nbrs)) break
    cand_totals <- total + gb_vec[nbrs]
    # Grow toward threshold; if still under threshold, take the best grower; else take the closest to threshold
    best_idx <- if (any(cand_totals < min_gb)) which.max(cand_totals) else which.min(abs(cand_totals - min_gb))
    best <- nbrs[best_idx]
    new_total <- total + gb_vec[best]
    if (is.na(new_total)) break
    if (new_total <= min_gb * 1.6 || total < min_gb) {
      cur   <- c(cur, best)
      total <- new_total
      avail <- setdiff(avail, best)
      if (total >= min_gb) break
    } else break
  }

  clusters[cur] <- paste0("CL", cid)
  to_assign <- setdiff(to_assign, cur)
  cid <- cid + 1L
}

cluster_map <- tibble::tibble(county_ihme = names(clusters), cluster_id = unname(clusters))

# 6) Aggregate metrics (cluster × period means)
agg_metric <- function(varname) {
  dq %>%
    dplyr::filter(!is.na(time_window)) %>%
    dplyr::inner_join(cluster_map, by = "county_ihme") %>%
    dplyr::group_by(cluster_id, time_window) %>%
    dplyr::summarise(val = mean(.data[[varname]], na.rm = TRUE),
                     n_counties = dplyr::n_distinct(county_ihme),
                     .groups = "drop") %>%
    tidyr::complete(cluster_id, time_window = periods_vec,
                    fill = list(val = NA_real_, n_counties = 0L))
}

dq_cluster_RI   <- agg_metric("RI") %>% dplyr::rename(RI = val)
dq_cluster_post <- agg_metric("RI_post_only") %>% dplyr::rename(RI_post_only = val)
dq_cluster_jsd  <- if (has_jsd) agg_metric("RI_jsd") %>% dplyr::rename(RI_jsd = val) else NULL

# 7) Shapes per period
build_clusters_sf <- function(year) {
  base <- build_ihme_groups_sf(year)
  base %>%
    dplyr::left_join(cluster_map, by = "county_ihme") %>%
    dplyr::filter(!is.na(cluster_id)) %>%
    dplyr::group_by(cluster_id) %>%
    dplyr::summarise(.groups = "drop") %>%
    sf::st_transform(crs_proj) %>%
    sf::st_make_valid()
}

join_shapes <- function(metric_df) {
  lapply(names(shapefile_years), function(window) {
    year <- unname(shapefile_years[[window]])
    shape_all <- build_clusters_sf(year)
    dplyr::left_join(shape_all, dplyr::filter(metric_df, time_window == window), by = "cluster_id")
  }) %>% setNames(names(shapefile_years))
}

joined_by_period_RI   <- join_shapes(dq_cluster_RI)
joined_by_period_post <- join_shapes(dq_cluster_post)
joined_by_period_jsd  <- if (!is.null(dq_cluster_jsd)) join_shapes(dq_cluster_jsd) else NULL

# 8) Map helpers (fixed limits)
states_outline <- tigris::states(cb = TRUE, class = "sf") |>
  sf::st_transform(crs_proj) |>
  sf::st_make_valid()

make_map_numeric <- function(sf_data, fill_col, limits, title) {
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_outline, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", limits = limits,
                         oob = scales::squish, direction = 1,
                         na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = title, fill = NULL) +
    theme_void() +
    theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
          legend.text = element_text(size = 9))
}

make_map_RI   <- function(sf_data, title) make_map_numeric(sf_data, "RI", c(0.02, 0.05), title)
make_map_post <- function(sf_data, title) make_map_numeric(sf_data, "RI_post_only", c(0.08, 0.12), title)
make_map_jsd  <- function(sf_data, title) make_map_numeric(sf_data, "RI_jsd", c(0.02, 0.04), title)  # tweak if needed

# 9) Save maps
output_dir <- here::here("figures", "5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# RI maps
p_1999_RI <- make_map_RI(joined_by_period_RI[["1999_2005"]], "1999_2005")
p_2006_RI <- make_map_RI(joined_by_period_RI[["2006_2012"]], "2006_2012")
p_2013_RI <- make_map_RI(joined_by_period_RI[["2013_2019"]], "2013_2019")
p_2020_RI <- make_map_RI(joined_by_period_RI[["2020_2022"]], "2020_2022")
combined_RI <- (p_1999_RI | p_2006_RI) / (p_2013_RI | p_2020_RI)
ggsave(file.path(output_dir, "RI_clustered_garbage150_4panel.png"),
       plot = combined_RI, width = 12, height = 9, dpi = 320)

# RI_post_only maps
p_1999_post <- make_map_post(joined_by_period_post[["1999_2005"]], "1999_2005")
p_2006_post <- make_map_post(joined_by_period_post[["2006_2012"]], "2006_2012")
p_2013_post <- make_map_post(joined_by_period_post[["2013_2019"]], "2013_2019")
p_2020_post <- make_map_post(joined_by_period_post[["2020_2022"]], "2020_2022")
combined_post <- (p_1999_post | p_2006_post) / (p_2013_post | p_2020_post)
ggsave(file.path(output_dir, "RI_post_only_clustered_garbage150_4panel.png"),
       plot = combined_post, width = 12, height = 9, dpi = 320)

# RI_jsd maps (if available)
if (!is.null(joined_by_period_jsd)) {
  p_1999_jsd <- make_map_jsd(joined_by_period_jsd[["1999_2005"]], "1999_2005")
  p_2006_jsd <- make_map_jsd(joined_by_period_jsd[["2006_2012"]], "2006_2012")
  p_2013_jsd <- make_map_jsd(joined_by_period_jsd[["2013_2019"]], "2013_2019")
  p_2020_jsd <- make_map_jsd(joined_by_period_jsd[["2020_2022"]], "2020_2022")
  combined_jsd <- (p_1999_jsd | p_2006_jsd) / (p_2013_jsd | p_2020_jsd)
  ggsave(file.path(output_dir, "RI_jsd_clustered_garbage150_4panel.png"),
         plot = combined_jsd, width = 12, height = 9, dpi = 320)
} else {
  message("⚠ Skipping JSD maps: 'RI_jsd' not present in input file.")
}

message("✓ Done. Maps saved to: ", output_dir)

```
Average KL-divergence overtime
```{r}
metrics_path_gz <- here::here("data","county_year_quality_metrics.csv.gz")
metrics_path    <- if (file.exists(metrics_path_gz)) metrics_path_gz else here::here("data","county_year_quality_metrics.csv")
dq <- readr::read_csv(metrics_path, show_col_types = FALSE)


.wmean <- function(x, w) {
  w <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(w)) || sum(w, na.rm = TRUE) == 0) return(NA_real_)
  stats::weighted.mean(x, w, na.rm = TRUE)
}

ri_ts <- dq %>%
  dplyr::filter(!is.na(year), year >= 1999, year <= 2022, is.finite(RI)) %>%
  dplyr::group_by(year) %>%
  dplyr::summarise(
    wmean_RI  = .wmean(RI, N_garb_g1g2g4g5g6g7),  # weight by targeted garbage bins
    n_ctyyr   = dplyr::n(),
    .groups = "drop"
  )

# Save the underlying series
readr::write_csv(ri_ts, file.path(output_dir, "RI_time_series_1999_2022.csv"))

# Plot (weighted mean only)
p_ri_ts <- ggplot(ri_ts, aes(x = year, y = wmean_RI)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.7) +
  labs(
    x = NULL, y = "Normalized K-L Divergence"
  ) +
  scale_x_continuous(breaks = seq(2000, 2022, by = 2)) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  )

# Save figure
ggsave(file.path(output_dir, "RI_time_series_1999_2022.png"),
       plot = p_ri_ts, width = 8.5, height = 4.8, dpi = 320)

p_ri_ts

```
Make map of percentage missing overdoses with clusters (four panels)
```{r}
# ──────────────────────────────────────────────────────────────
# Map pct_overd_miss with temporally-stable clusters (IHME groups)
# Changes requested:
#   • min_overd = 30
#   • Prefer in-state neighbors; cross state only if needed
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2",
              "here","scales","igraph","tidyr","tibble","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))
options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

`%||%` <- function(a, b) if (!is.null(a)) a else b

# Small helper to get a simple mode (most frequent value)
mode_val <- function(x) {
  ux <- na.omit(x)
  if (!length(ux)) return(NA_character_)
  names(sort(table(ux), decreasing = TRUE))[1]
}

# 1) Windows & inputs
periods_list <- list(
  "1999_2005" = 1999:2005,
  "2006_2012" = 2006:2012,
  "2013_2019" = 2013:2019,
  "2020_2022" = 2020:2022
)
periods_vec <- names(periods_list)

dq <- readr::read_csv(here::here("data","county_year_quality_metrics.csv"),
                      show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = as.integer(year),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2006 & year <= 2012 ~ "2006_2012",
      year >= 2013 & year <= 2019 ~ "2013_2019",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    )
  )

stopifnot(all(c("overd_n","pct_overd_miss") %in% names(dq)))

# 2) IHME crosswalk (temporality-stable groups)
load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 3) Robust overdose totals per IHME group
overd_by_window <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(overd = sum(overd_n, na.rm = TRUE), .groups = "drop")

overd_wide <- overd_by_window %>%
  tidyr::pivot_wider(names_from = time_window, values_from = overd, values_fill = 0)

for (w in periods_vec) if (!w %in% names(overd_wide)) overd_wide[[w]] <- 0

robust_tbl <- overd_wide %>%
  dplyr::mutate(
    robust_overd = pmin(`1999_2005`,`2006_2012`,`2013_2019`,`2020_2022`, na.rm = TRUE)
  ) %>%
  dplyr::transmute(county_ihme, robust_overd = as.numeric(robust_overd))

# 4) Shapefile helpers
crs_proj <- 2163
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

normalize_geoid <- function(sf, year) {
  nms <- names(sf)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(geoid_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    sf$GEOID <- paste0(
      stringr::str_pad(as.character(sf[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sf[[county_col]]), 3, pad = "0")
    )
    return(sf)
  }
  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(combo_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  stop("No GEOID-compatible columns found in shapefile for year ", year)
}

# Build IHME group polygons and keep a dominant state per group
build_ihme_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM")
  counties_norm <- normalize_geoid(counties_raw, year) %>%
    sf::st_transform(crs_proj)

  counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(
      county_ihme = dplyr::coalesce(county_ihme, GEOID),
      STATEFP = as.character(STATEFP)
    ) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(
      state = mode_val(STATEFP),   # dominant state by membership count
      .groups = "drop"
    )
}

# 5) Adjacency & greedy clustering (state-aware; min_overd = 30)
ihme2020 <- build_ihme_groups_sf(2020) %>% sf::st_transform(5070)
adj_list <- sf::st_touches(ihme2020)
neighbors_of <- setNames(
  lapply(seq_len(nrow(ihme2020)), function(i) ihme2020$county_ihme[adj_list[[i]]]),
  ihme2020$county_ihme
)

# Lookup of dominant state per IHME group
state_of <- setNames(ihme2020$state, ihme2020$county_ihme)

# Lower threshold as requested
min_overd <- 50L

nodes_tbl <- ihme2020 %>%
  sf::st_drop_geometry() %>%
  dplyr::select(county_ihme, state) %>%
  dplyr::left_join(robust_tbl, by = "county_ihme") %>%
  dplyr::mutate(robust_overd = dplyr::coalesce(robust_overd, 0))

overd_vec <- setNames(nodes_tbl$robust_overd, nodes_tbl$county_ihme)
to_assign <- names(overd_vec)
clusters  <- setNames(rep(NA_character_, length(overd_vec)), to_assign)
cid <- 1L

while (length(to_assign) > 0) {
  seed       <- to_assign[which.max(overd_vec[to_assign])]
  home_state <- state_of[seed]
  cur        <- seed
  total      <- overd_vec[seed]
  avail      <- setdiff(to_assign, seed)

  repeat {
    nbrs_all <- unique(unlist(neighbors_of[cur], use.names = FALSE))
    nbrs_all <- setdiff(intersect(nbrs_all, avail), cur)

    if (!length(nbrs_all)) break

    # Prefer in-state neighbors; cross only if no in-state remain and we're still < min_overd
    nbrs_in_state   <- nbrs_all[state_of[nbrs_all] == home_state]
    nbrs_candidates <- if (length(nbrs_in_state)) nbrs_in_state else nbrs_all

    cand_totals <- total + overd_vec[nbrs_candidates]

    # If still below target, maximize growth; else, minimize overshoot
    if (all(cand_totals < min_overd)) {
      best <- nbrs_candidates[which.max(cand_totals)]
    } else {
      best <- nbrs_candidates[which.min(abs(cand_totals - min_overd))]
    }

    new_total <- total + overd_vec[best]
    if (is.na(new_total)) break

    allow_cross <- (!length(nbrs_in_state)) && (total < min_overd)

    # Guard against runaway growth (1.6× tolerance), but allow while under target or allowed to cross
    if (new_total <= min_overd * 1.6 || total < min_overd || allow_cross) {
      cur   <- c(cur, best)
      total <- new_total
      avail <- setdiff(avail, best)
      if (total >= min_overd) break
    } else break
  }

  clusters[cur] <- paste0("CL", cid)
  to_assign <- setdiff(to_assign, cur)
  cid <- cid + 1L
}

# 6) Post-processing: absorb undersized clusters, preferring same-state
centroids <- sf::st_centroid(ihme2020) %>%
  dplyr::mutate(county_ihme = ihme2020$county_ihme)
xy <- sf::st_coordinates(centroids)[,c("X","Y"), drop=FALSE]; rownames(xy) <- centroids$county_ihme

cluster_sum <- tapply(overd_vec[names(clusters)], clusters, sum, na.rm = TRUE)
small <- names(cluster_sum)[cluster_sum < min_overd]
big   <- names(cluster_sum)[cluster_sum >= min_overd]

# Dominant state per cluster (by member count)
cluster_state <- vapply(unique(na.omit(clusters)), function(clid) {
  memb_states <- state_of[names(clusters)[clusters == clid]]
  mode_val(memb_states)
}, FUN.VALUE = character(1L))
names(cluster_state) <- unique(na.omit(clusters))

if (length(small) && length(big)) {
  get_center <- function(cid) {
    memb <- names(clusters)[clusters == cid]
    colMeans(xy[memb,,drop=FALSE])
  }
  small_xy <- t(vapply(small, get_center, numeric(2L)))
  big_xy   <- t(vapply(big,   get_center, numeric(2L)))

  choose_target <- function(candidates, i_row) {
    if (!length(candidates)) return(NA_character_)
    dif <- t(big_xy[, candidates, drop = FALSE]) -
      matrix(small_xy[i_row, ], nrow = length(candidates), ncol = 2, byrow = TRUE)
    candidates[which.min(rowSums(dif * dif))]
  }

  for (i in seq_along(small)) {
    s_id    <- small[i]
    s_state <- cluster_state[s_id]
    same_state_big <- big[cluster_state[big] == s_state]
    target <- choose_target(same_state_big, i)
    if (is.na(target)) target <- choose_target(big, i)  # fallback: any state
    members <- names(clusters)[clusters == s_id]
    clusters[members] <- target
  }
}

cluster_map <- tibble::tibble(
  county_ihme = names(clusters),
  cluster_id  = unname(clusters)
)

# 7) Check threshold per window (reflects 30)
check_df <- overd_by_window %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(overdoses = sum(overd, na.rm = TRUE), .groups = "drop")
if (any(check_df$overdoses < min_overd, na.rm = TRUE)) {
  warning("Some clusters are still < 30 overdoses in a window. Consider tweaking heuristics.")
}

# 8) Aggregate pct_overd_miss to cluster×window with NA→0 (same as your original)
dq_cluster <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(
    pct_overd_miss = mean(tidyr::replace_na(pct_overd_miss, 0)),
    n_counties     = dplyr::n_distinct(county_ihme),
    .groups = "drop"
  ) %>%
  tidyr::complete(cluster_id, time_window = periods_vec,
                  fill = list(pct_overd_miss = 0, n_counties = 0L))

# 9) Shapes per period (group polygons by cluster for each year-vintage)
build_clusters_sf <- function(year) {
  base <- build_ihme_groups_sf(year)
  base %>%
    dplyr::left_join(cluster_map, by = "county_ihme") %>%
    dplyr::filter(!is.na(cluster_id)) %>%
    dplyr::group_by(cluster_id) %>%
    dplyr::summarise(.groups = "drop") %>%
    sf::st_transform(crs_proj)
}

joined_by_period <- purrr::imap(shapefile_years, function(year, window) {
  shape_all <- build_clusters_sf(year)
  dplyr::left_join(shape_all,
                   dplyr::filter(dq_cluster, time_window == window),
                   by = "cluster_id")
})

# 10) Map helper — preserves your “pretty” title style
make_map <- function(sf_data, var = "pct_overd_miss", title = NULL, palette = "RdBu") {
  states <- tigris::states(cb = TRUE, class = "sf") |> sf::st_transform(crs_proj)
  fill_scale <- scale_fill_distiller(
    palette = palette,
    limits = if (var == "pct_overd_miss") c(0, 0.6) else NULL,
    oob = scales::squish,
    direction = -1,
    na.value = "grey90"
  )
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    fill_scale +
    coord_sf(xlim = c(-2500000, 2500000),
             ylim = c(-2200000, 730000),
             expand = FALSE) +
    labs(title = title %||% "", fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 9)
    )
}

# 11) Save combined 2×2 with PERIOD-ONLY panel titles
output_dir <- here::here("figures", "5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

p_1999 <- make_map(joined_by_period[["1999_2005"]], "pct_overd_miss", "1999_2005")
p_2006 <- make_map(joined_by_period[["2006_2012"]], "pct_overd_miss", "2006_2012")
p_2013 <- make_map(joined_by_period[["2013_2019"]], "pct_overd_miss", "2013_2019")
p_2020 <- make_map(joined_by_period[["2020_2022"]], "pct_overd_miss", "2020_2022")

combined <- (p_1999 | p_2006) / (p_2013 | p_2020)

ggsave(filename = file.path(output_dir, "pct_overd_miss_4panel.png"),
       plot = combined, width = 12, height = 9, dpi = 320)

message("✓ Done. Single 4-panel map saved to: ",
        file.path(output_dir, "pct_overd_miss_4panel.png"))

```
Make map of z-scores
```{r}
# ──────────────────────────────────────────────────────────────
# Cluster z-scores & maps (overdose-unspecified, prop_garbage, RI, Philips)
#   • Robust to: membership duplicates, Philips column names, odd period labels
#   • Outputs:
#       - output/cluster_scores/cluster_zscores_overdose_philips_RI_propgarbage.csv
#       - figures/5yr_avg_stable/z_<metric>_4panel.png  (+ direction_score_4panel.png)
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(purrr)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ PATHS ------------------------
data_file       <- here("data",   "county_year_quality_metrics.csv")
membership_file <- here("output", "county_cluster_membership.csv.gz")
philips_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
out_dir_figs    <- here("figures","5yr_avg_stable")
out_dir_scores  <- here("output", "cluster_scores")
dir.create(out_dir_figs,   recursive = TRUE, showWarnings = FALSE)
dir.create(out_dir_scores, recursive = TRUE, showWarnings = FALSE)

# --------------------- periods & helpers -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
safe_div <- function(num, den) ifelse(is.finite(num) & is.finite(den) & den > 0, num / den, NA_real_)
compute_limits_symmetric <- function(x) {
  x <- x[is.finite(x)]; if (!length(x)) return(c(-1,1))
  L <- as.numeric(stats::quantile(abs(x), 0.98, na.rm = TRUE, names = FALSE))
  if (!is.finite(L) || L == 0) L <- 1
  c(-L, L)
}
sanitize <- function(x) { x %>% str_replace_all("[^A-Za-z0-9]+","_") %>% str_replace_all("^_+|_+$","") %>% tolower() }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }

# -------------------- projection & geometry helpers -------------------
crs_proj <- 2163
st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) { ctr <- st_centroid(st_union(sf_obj)); st_geometry(sf_obj) <- (st_geometry(sf_obj) - ctr) * scale + ctr; sf_obj }
build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)
  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> dplyr::rename(fips = GEOID, statefp = STATEFP) |> sf::st_make_valid()
}
build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)
  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> sf::st_make_valid()
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()

# ------------------------- load membership (dedupe) --------------------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        fips   = stringr::str_pad(as.character(fips), 5, pad = "0"),
        period = standardize_period(as.character(period)),
        cluster= as.character(cluster)
      ) %>%
      dplyr::left_join(ihme_map, by = "fips") %>%
      dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips)) %>%
      dplyr::select(county_ihme, period, cluster)
  } else stop("membership_file must contain 'county_ihme' or 'fips'.")

# dedupe to one row per county_ihme × period (mode if needed)
membership <- membership %>%
  dplyr::filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  dplyr::distinct(county_ihme, period, cluster)
dups <- membership %>% dplyr::count(county_ihme, period, name="n") %>% dplyr::filter(n > 1)
if (nrow(dups) > 0) message("Resolving ", nrow(dups), " county×period with multiple clusters (using modal cluster).")
membership <- membership %>%
  dplyr::group_by(county_ihme, period) %>%
  dplyr::summarise(cluster = mode_str(cluster), .groups="drop")

# --------------------- load county-year data -------------------
stopifnot(file.exists(data_file))
dy0 <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  dplyr::mutate(year = suppressWarnings(as.integer(year)),
                period = period_of_year(year))

if ("county_ihme" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
} else if ("fips" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0")) %>%
    dplyr::left_join(ihme_map, by = "fips") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))
} else stop("data_file must contain 'county_ihme' or 'fips'.")

# --- ensure N_garbage & garb_k exist before checks ---
nms <- names(dy)
col_n_cert <- pick_col(nms, c("n_cert","deaths","total","N"))
col_prop_g <- pick_col(nms, c("foreman_garbage","prop_garbage"))
if (!("N_garbage" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating N_garbage = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(N_garbage = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("garb_k" %in% nms) {
    message("Using garb_k as N_garbage"); dy <- dy %>% dplyr::mutate(N_garbage = garb_k)
  } else stop("Missing N_garbage and cannot construct it.")
}
if (!("garb_k" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating garb_k = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(garb_k = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("N_garbage" %in% names(dy)) {
    message("Creating garb_k from N_garbage"); dy <- dy %>% dplyr::mutate(garb_k = N_garbage)
  } else stop("Cannot create garb_k.")
}

# Required vars
need_vars <- c("county_ihme","period","overd_n","overd_miss_k","garb_k","n_cert","N_garbage","RI_post_only")
miss <- setdiff(need_vars, names(dy))
if (length(miss)) stop("Missing required columns in data_file: ", paste(miss, collapse=", "))

# ---------------- aggregate county → cluster×period -------------
cluster_core <- dy %>%
  dplyr::select(dplyr::all_of(need_vars)) %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::inner_join(membership, by = c("county_ihme","period")) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    sum_overd_miss_k = sum(overd_miss_k, na.rm = TRUE),
    sum_overd_n      = sum(overd_n,      na.rm = TRUE),
    sum_garb_k       = sum(garb_k,       na.rm = TRUE),
    sum_n_cert       = sum(n_cert,       na.rm = TRUE),
    sum_N_garbage    = sum(N_garbage,    na.rm = TRUE),
    num_RI_weighted  = sum(n_cert * RI_post_only, na.rm = TRUE),
    prop_overd_unspec = safe_div(sum_overd_miss_k, sum_overd_n),
    prop_garbage      = safe_div(sum_garb_k,       sum_n_cert),
    RI_cluster        = safe_div(num_RI_weighted,  sum_N_garbage),
    .groups = "drop"
  )

# ---------------- bring in Philips (CSTD; tolerant) ------------
stopifnot(file.exists(philips_file))
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
# normalize column names to lowercase for matching
names(ph0) <- tolower(names(ph0))

# ensure period
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% dplyr::mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% dplyr::mutate(period = standardize_period(period))
}

# normalize IDs to cluster-level
if ("cluster" %in% names(ph0)) {
  ph_norm <- ph0 %>% dplyr::mutate(cluster = as.character(cluster))
} else if ("county_ihme" %in% names(ph0) || "fips" %in% names(ph0)) {
  tmp <- ph0
  if ("fips" %in% names(tmp) && !("county_ihme" %in% names(tmp))) {
    tmp <- tmp %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad="0")) %>%
      dplyr::left_join(ihme_map, by="fips")
  }
  if (!("county_ihme" %in% names(tmp))) stop("Philips file lacks id columns (cluster/county_ihme/fips).")
  ph_norm <- tmp %>%
    dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad="0")) %>%
    dplyr::inner_join(membership, by = c("county_ihme","period"))
} else stop("Philips file must contain 'cluster' or county id (county_ihme/fips).")

# pick cstd & weights robustly
ph_col <- pick_col(names(ph_norm), c("detail_ucod_icd4_cstd","cstd_ucr39","cstd","phillips_detail","philips_detail","cod_cstd","cod_cstd_ucr39"))
if (is.na(ph_col)) stop("Philips source missing CSTD column (tried philips_cstd/cstd_ucr39/cstd/phillips_detail/philips_detail/cod_cstd/...).")
w_col  <- pick_col(names(ph_norm), c("n_cert","deaths","total","n"))

philips_clu <- ph_norm %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::mutate(cluster = as.character(cluster)) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    w   = if (!is.na(w_col)) sum(.data[[w_col]], na.rm=TRUE) else NA_real_,
    num = if (!is.na(w_col)) sum(.data[[w_col]] * .data[[ph_col]], na.rm=TRUE) else sum(.data[[ph_col]], na.rm=TRUE),
    den = if (!is.na(w_col)) w else sum(!is.na(.data[[ph_col]])),
    philips_cstd = safe_div(num, den),
    .groups = "drop"
  ) %>%
  dplyr::filter(!is.na(philips_cstd))

# ---------------- merge & Z-scores -----------------------------
metrics_clu <- cluster_core %>%
  dplyr::inner_join(philips_clu, by = c("period","cluster")) %>%
  dplyr::filter(period %in% period_levels) %>%
  dplyr::arrange(period, cluster) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

score_vars  <- c("prop_overd_unspec","philips_cstd","RI_cluster","prop_garbage")
global_means <- vapply(score_vars, function(v) mean(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds   <- vapply(score_vars, function(v)  sd(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds[!is.finite(global_sds) | global_sds == 0] <- NA_real_

z_tbl <- metrics_clu %>%
  dplyr::mutate(dplyr::across(
    dplyr::all_of(score_vars),
    \(x, nm=cur_column()) if (is.na(global_sds[[nm]])) NA_real_ else (x - global_means[[nm]]) / global_sds[[nm]],
    .names = "z_{.col}"
  )) %>%
  # Flip signs: higher z = better (less garbage / fewer unspecified overdoses)
  dplyr::mutate(
    z_prop_garbage      = -z_prop_garbage,
    z_prop_overd_unspec = -z_prop_overd_unspec
  ) %>%
  dplyr::mutate(
    direction_score = rowMeans(dplyr::across(starts_with("z_")), na.rm = TRUE)
  ) %>%
  dplyr::arrange(period, cluster)

readr::write_csv(z_tbl, file.path(out_dir_scores, "cluster_zscores_overdose_philips_RI_propgarbage.csv"))

# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))

build_cluster_sf <- function(period_key, membership_df, counties_sf_aug) {
  mm <- membership_df %>% dplyr::filter(.data$period == period_key) %>% dplyr::transmute(county_ihme = as.character(county_ihme), cluster = as.character(cluster)) %>% dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)
  counties_sf_aug %>%
    dplyr::inner_join(mm, by = "county_ihme") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ---------------- 4-panel maps of Z-scores --------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, states_sf) {
  ggplot2::ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1, limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(fill = NULL) + facet_wrap(~ period, ncol = 2) + theme_void() +
    theme(strip.text = element_text(size = 12, face = "bold"), legend.text = element_text(size = 9), plot.title = element_blank())
}

to_map <- c("z_RI_cluster","z_prop_overd_unspec","z_prop_garbage","z_philips_cstd","direction_score")

for (mcol in to_map) {
  message("Assembling 4-panel for metric: ", mcol)
  stacked_sf <- purrr::map_dfr(period_levels, function(win){
    cl_sf <- build_cluster_sf(win, membership, counties_aug)
    dat   <- z_tbl %>% dplyr::filter(period==win) %>% dplyr::select(cluster, !!rlang::sym(mcol)) %>% dplyr::rename(value = !!rlang::sym(mcol))
    out   <- cl_sf %>% dplyr::left_join(dat, by="cluster"); out$period <- win; out
  }) %>% dplyr::mutate(period=factor(period, levels=period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals))==1) { message("  Skipping ", mcol, " (no variance)"); next }

  lims_sym <- compute_limits_symmetric(vals)  # symmetric for z-scores (centered at 0)
  p <- make_faceted_map(stacked_sf, "value", lims_sym, states_tf)

  base <- if (mcol == "direction_score") "direction_score" else sanitize(mcol)
  ggsave(file.path(out_dir_figs, paste0(base, "_4panel.png")), p, width=10, height=7.5, dpi=320)
}

message("✓ Done. Z-score CSV in: ", out_dir_scores, "  |  maps in: ", out_dir_figs)

```
Make new aggregate data quality index map with box plot
```{r}
# ──────────────────────────────────────────────────────────────
# Two maps (1999–2005, 2020–2022) + county-by-state boxplot
#   • Uses a single metric from z_tbl (default = "direction_score")
#   • Saves: figures/5yr_avg_stable/two_maps_box_<metric>.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({ library(patchwork) })

# ---- choose which metric to show (must exist in z_tbl)
metric_to_plot <- "direction_score" 
# examples: "direction_score", "z_prop_garbage", "z_prop_overd_unspec", "z_philips_cstd", "z_RI_cluster"

metric_label <- dplyr::case_when(
  metric_to_plot == "direction_score"      ~ "Aggregate data quality index (z)",
  metric_to_plot == "z_prop_garbage"       ~ "Proportion garbage (z, higher is better)",
  metric_to_plot == "z_prop_overd_unspec"  ~ "Overdose unspecified (z, higher is better)",
  metric_to_plot == "z_philips_cstd"       ~ "Philips CSTD (z, higher is better)",
  metric_to_plot == "z_RI_cluster"         ~ "RI (z, higher is better)",
  TRUE ~ metric_to_plot
)

# ---------------- single-period map helper ----------------
make_single_map <- function(period_key, mcol, lims, states_sf, membership_df, counties_sf_aug) {
  cl_sf <- build_cluster_sf(period_key, membership_df, counties_sf_aug)
  dat   <- z_tbl %>%
    dplyr::filter(period == period_key) %>%
    dplyr::select(cluster, value = !!rlang::sym(mcol))
  map_sf <- cl_sf %>% dplyr::left_join(dat, by = "cluster")

  ggplot2::ggplot() +
    geom_sf(data = map_sf, aes(fill = value), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1,
                         limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = gsub("_", "–", period_key), fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

# ---------------- build common map limits (both periods) -------------
periods_two <- c("1999_2005","2020_2022")
vals_two <- purrr::map_dbl(1, ~0) # placeholder to appease R CMD check
map_vals <- purrr::map_dfr(periods_two, function(win){
  cl_sf <- build_cluster_sf(win, membership, counties_aug)
  dat   <- z_tbl %>%
    dplyr::filter(period == win) %>%
    dplyr::select(cluster, value = !!rlang::sym(metric_to_plot))
  cl_sf %>% dplyr::left_join(dat, by="cluster") %>% dplyr::transmute(value)
})
lims_sym <- compute_limits_symmetric(map_vals$value)

# ---------------- make the two maps -----------------------
pA <- make_single_map("1999_2005", metric_to_plot, lims_sym, states_tf, membership, counties_aug)
pB <- make_single_map("2020_2022", metric_to_plot, lims_sym, states_tf, membership, counties_aug)

# ---------------- county-level boxplot by state -----------
# Lookup for state abbreviations
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
  sf::st_drop_geometry() |>
  dplyr::select(STATEFP, STUSPS) %>% dplyr::rename(statefp = STATEFP, state = STUSPS)

counties_lite <- counties_aug %>% sf::st_drop_geometry() %>% dplyr::select(county_ihme, statefp)
counties_lite <- counties_lite %>%
  rename(county_ihme = fips) %>%
  mutate(
    county_ihme = str_pad(as.character(county_ihme), 5, pad = "0"),
    statefp     = str_pad(as.character(statefp), 2, pad = "0")
  )

# 2) Quick sanity checks (optional but useful)
cat("counties_lite names: ", paste(names(counties_lite), collapse = ", "), "\n")
cat("example counties_lite rows:\n"); print(head(counties_lite))
cat("Sample county_ihme in cluster_map but not in counties_lite (should be empty or small):\n")
print(setdiff(cluster_map$county_ihme, counties_lite$county_ihme)[1:10])


# Build a county-level table for both periods by assigning each county its cluster's metric value
build_county_values <- function(per){
  mm <- membership %>% dplyr::filter(period == per) %>% dplyr::select(county_ihme, cluster)
  zv <- z_tbl %>% dplyr::filter(period == per) %>% dplyr::select(cluster, value = !!rlang::sym(metric_to_plot))
  mm %>%
    dplyr::left_join(zv, by = "cluster") %>%
    dplyr::left_join(counties_lite, by = "county_ihme") %>%
    dplyr::left_join(states_info, by = "statefp") %>%
    dplyr::mutate(period = per) %>%
    dplyr::filter(!is.na(state), is.finite(value)) %>%
    dplyr::select(state, county_ihme, period, value)
}
bx_df <- dplyr::bind_rows(build_county_values("1999_2005"),
                          build_county_values("2020_2022"))

# Rank states by declining post-period median
state_order <- bx_df %>%
  dplyr::filter(period == "2020_2022") %>%
  dplyr::group_by(state) %>%
  dplyr::summarise(med = median(value, na.rm=TRUE), .groups="drop") %>%
  dplyr::arrange(dplyr::desc(med)) %>% dplyr::pull(state)

territories <- c("PR","GU","VI","AS","MP")

bx_df <- bx_df %>%
  dplyr::filter(!state %in% territories)

bx_df <- bx_df %>% dplyr::mutate(
  state = factor(state, levels = state_order),
  period = factor(period, levels = c("1999_2005","2020_2022"),
                  labels = c("1999–2005","2020–2022"))
)

ylims_box <- c(-2, 2)

pC <- ggplot2::ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  coord_cartesian(ylim = ylims_box) +
  scale_fill_manual(values = c("#94bedf","#f2c879")) +
  labs(x = "States (ranked by declining median county-level 2020-2022 aggregate data quality index)",
       y = metric_label) +
  theme_bw(base_size = 10) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    panel.grid.minor = element_blank()
  )

combined <- (pA | pB) / pC + plot_layout(guides = "collect") +
  plot_annotation(tag_levels = "A")

base <- if (metric_to_plot == "direction_score") "direction_score" else sanitize(metric_to_plot)
outfile <- file.path(out_dir_figs, paste0("two_maps_box_", base, ".png"))
ggsave(outfile, combined, width = 11, height = 8.5, dpi = 320)
```
Make new overdose maps with box plot
```{r}
# ──────────────────────────────────────────────────────────────
# Two maps (1999–2005, 2020–2022) + box plot for pct_overd_miss
#   • Uses your temporally-stable clusters in `cluster_map` (county_ihme → cluster_id)
#   • EXACT FIPS→IHME processing (ihme_fips.rda; coalesce(county_ihme, fips))
#   • AK/HI identical to your aggregate maps (uses counties_aug & states_tf)
#   • Viridis "D"; fixed limits 0–60%
#   • Fills missing cluster×period values to avoid grey patches
#   • Saves → figures/5yr_avg_stable/two_maps_box_pct_overd_miss.png
# Prereqs in memory: dq (with time_window & pct_overd_miss), cluster_map, counties_aug, states_tf
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(sf); library(scales)
  library(patchwork); library(here); library(stringr); library(readr); library(tidyr); library(tigris)
})

options(tigris_use_cache = TRUE, tigris_class = "sf")

# ---- sanity checks for required objects ----
if (!exists("dq"))          stop("Object `dq` not found (needs columns county_ihme, time_window, pct_overd_miss).")
if (!exists("cluster_map")) stop("Object `cluster_map` not found (must have columns county_ihme, cluster_id).")
if (!exists("counties_aug"))stop("Object `counties_aug` not found (AK/HI-shifted county polygons used in your maps).")
if (!exists("states_tf"))   stop("Object `states_tf` not found (AK/HI-shifted state polygons used in your maps).")

periods_two <- c("1999_2005","2020_2022")
territories <- c("PR","GU","VI","AS","MP")
lims_map <- c(0, 0.60)

# ── 0) IHME crosswalk: orig county FIPS (GEOID) -> IHME group (county_ihme) ──
#     This mirrors your working code (ihme_fips.rda → ihme_map with GEOID & county_ihme).
load(here::here("data_raw","ihme_fips.rda"))  # provides: ihme_fips
ihme_map <- ihme_fips %>%
  transmute(
    GEOID       = str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  distinct()

# ── 1) Harmonize counties_aug keys and add IHME group like your code does ──
#     Expect counties_aug to have `fips` and `statefp`; fallbacks if needed.
counties_aug_fixed <- counties_aug

# ensure we have a 5-digit FIPS column
if ("fips" %in% names(counties_aug_fixed)) {
  counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(fips), 5, pad = "0"))
} else if ("GEOID" %in% names(counties_aug_fixed)) {
  counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(GEOID), 5, pad = "0"))
} else {
  stop("`counties_aug` must have either 'fips' or 'GEOID'.")
}

# ensure we have statefp as 2-char
if (!"statefp" %in% names(counties_aug_fixed)) {
  if ("STATEFP" %in% names(counties_aug_fixed)) {
    counties_aug_fixed <- counties_aug_fixed %>% mutate(statefp = as.character(STATEFP))
  } else stop("`counties_aug` must have 'statefp' or 'STATEFP'.")
}
counties_aug_fixed <- counties_aug_fixed %>%
  mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

counties_aug_fixed <- counties_aug_fixed %>%
  left_join(ihme_map, by = c("fips" = "GEOID"), suffix = c(".orig", ".map")) %>%
  mutate(
    county_ihme = coalesce(county_ihme.orig, county_ihme.map, fips)
  ) %>%
  select(-county_ihme.orig, -county_ihme.map)

# ── 2) Build cluster polygons from counties_aug_fixed → IHME → cluster_id ──
clusters_aug_sf <- counties_aug_fixed %>%
  inner_join(cluster_map, by = "county_ihme") %>%     # county_ihme -> cluster_id
  group_by(cluster_id) %>%
  summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
  sf::st_make_valid()

# warn if any clusters in cluster_map still lack polygons
cl_missing_poly <- setdiff(sort(unique(cluster_map$cluster_id)),
                           sort(unique(clusters_aug_sf$cluster_id)))
if (length(cl_missing_poly)) {
  warning("No polygons for ", length(cl_missing_poly), " clusters (e.g., ",
          paste(utils::head(cl_missing_poly, 5), collapse = ", "),
          "). Check crosswalk and counties_aug coverage.")
}

# ── 3) Compute cluster×period values and COMPLETE missing cells to avoid grey ──
all_clusters <- sort(unique(cluster_map$cluster_id))
pct_cluster <- dq %>%
  filter(!is.na(time_window)) %>%
  select(county_ihme, time_window, pct_overd_miss) %>%
  inner_join(cluster_map, by = "county_ihme") %>%            # keep only IHME in clusters
  group_by(cluster_id, time_window) %>%
  summarise(pct_overd_miss = mean(pct_overd_miss, na.rm = TRUE), .groups = "drop") %>%
  tidyr::complete(
    cluster_id = all_clusters,
    time_window = periods_two,
    fill = list(pct_overd_miss = 0)                           # fill to guarantee coverage
  )

# ── 4) Build map layers (double-guard NA→0 after join) ──
map_1999 <- clusters_aug_sf %>%
  left_join(filter(pct_cluster, time_window == "1999_2005"), by = "cluster_id") %>%
  mutate(pct_overd_miss = coalesce(pct_overd_miss, 0))

map_2020 <- clusters_aug_sf %>%
  left_join(filter(pct_cluster, time_window == "2020_2022"), by = "cluster_id") %>%
  mutate(pct_overd_miss = coalesce(pct_overd_miss, 0))

# ── 5) Plot helpers ──
make_map <- function(map_sf, title, lims) {
  ggplot() +
    geom_sf(data = map_sf, aes(fill = pct_overd_miss), colour = NA) +
    geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.3) +  # EXACT overlay, AK/HI included
    scale_fill_viridis_c(
      option = "D", limits = lims, oob = scales::squish, na.value = "grey90",direction=-1,
      labels = scales::percent_format(accuracy = 1)
    ) +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = title, fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

pA <- make_map(map_1999, "1999–2005", lims_map)
pB <- make_map(map_2020, "2020–2022", lims_map)

# ── 6) Box plot: assign each county its cluster’s period value, then aggregate by state ──
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") %>%
  st_drop_geometry() %>%
  select(STATEFP, STUSPS) %>%
  rename(statefp = STATEFP, state = STUSPS) %>%
  mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

counties_lite <- counties_aug_fixed %>%
  st_drop_geometry() %>%
  select(county_ihme, statefp)

build_county_values <- function(per) {
  zv <- pct_cluster %>%
    filter(time_window == per) %>%
    select(cluster_id, value = pct_overd_miss)
  cluster_map %>%                                # county_ihme -> cluster_id
    left_join(zv, by = "cluster_id") %>%
    left_join(counties_lite, by = "county_ihme") %>%
    left_join(states_info,  by = "statefp") %>%
    transmute(state, county_ihme, period = per, value) %>%
    filter(!is.na(state), is.finite(value))
}

bx_df <- bind_rows(
  build_county_values("1999_2005"),
  build_county_values("2020_2022")
) %>% filter(!state %in% territories)

state_order <- bx_df %>%
  filter(period == "2020_2022") %>%
  group_by(state) %>%
  summarise(med = median(value, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(med)) %>% pull(state)

bx_df <- bx_df %>%
  mutate(
    state  = factor(state, levels = state_order),
    period = factor(period, levels = c("1999_2005","2020_2022"),
                    labels = c("1999–2005","2020–2022"))
  )

pC <- ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  coord_cartesian(ylim = lims_map) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("#94bedf","#f2c879")) +
  labs(x = "States (ranked by declining median county-level 2020–2022 % missing overdoses)",
       y = "Percent missing overdoses") +
  theme_bw(base_size = 10) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        panel.grid.minor = element_blank())

# ── 7) Save figure ──
dir.create(here::here("figures","5yr_avg_stable"), recursive = TRUE, showWarnings = FALSE)
combined <- (pA | pB) / pC + plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
ggsave(here::here("figures","5yr_avg_stable","two_maps_box_pct_overd_miss.png"),
       combined, width = 11, height = 8.5, dpi = 320)

```
Make new level of detail maps with box plots
```{r}
# ──────────────────────────────────────────────────────────────
# Two maps (1999–2005, 2020–2022) + box plot
# COD standardized diversity — UCOD 4-digit (detail_ucod_icd4_cstd)
#   • Clustering EXACTLY like your COD script: membership (fips, cluster, period)
#   • AK/HI resized & shifted (same helpers as your script)
#   • Viridis "D"; common limits across the two periods from 2–98% quantiles
#   • NO imputation/backup fills — if a cluster-period is missing, it will be NA
#   • Saves → figures/5yr_avg_stable/two_maps_box_detail_ucod_icd4_cstd.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(tibble)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
  library(purrr);   library(patchwork)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ paths -------------------------------
metrics_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
out_dir_base    <- here("figures", "5yr_avg_stable")
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)

# -------------------- projection ------------------------------
crs_proj <- 2163

# --------------------- stable periods -------------------------
# Use the same labels as your working scripts
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
periods_two   <- c("1999_2005","2020_2022")
territories   <- c("PR","GU","VI","AS","MP")

# ------------------------ helpers -----------------------------
sanitize <- function(x) {
  x %>% str_replace_all("[^A-Za-z0-9]+", "_") %>%
    str_replace_all("^_+|_+$", "") %>% tolower()
}

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

# Build cluster polygons exactly like your COD script: per-period membership → union by cluster
build_cluster_sf <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df %>%
    dplyr::filter(.data$period == period_key) %>%
    dplyr::transmute(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                     cluster = as.character(cluster)) %>%
    dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)

  counties_sf %>%
    dplyr::inner_join(mm, by = "fips") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ------------------------- load data --------------------------
message("Reading metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading membership: ", membership_file)
membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster),
                period  = as.character(period),
                fips    = stringr::str_pad(as.character(fips), 5, pad = "0"))

# Prepare transformed geographies ONCE (AK/HI resized exactly like your script)
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

# ---------------------- select the UCOD metric ----------------
# Column name provided by you
ucod_col <- "detail_ucod_icd4_cstd"
if (!ucod_col %in% names(metrics)) {
  stop("Column 'detail_ucod_icd4_cstd' not found in metrics. Available: ", paste(names(metrics), collapse = ", "))
}

# Keep only periods we need, preserve labels
metrics_two <- metrics %>%
  dplyr::filter(period %in% periods_two) %>%
  dplyr::select(cluster, period, !!rlang::sym(ucod_col)) %>%
  dplyr::rename(value = !!rlang::sym(ucod_col))

# ----------------- common limits across the two periods -----------------
lims_info <- {
  vals <- metrics_two$value[is.finite(metrics_two$value)]
  if (length(vals) >= 3) {
    stats::quantile(vals, c(0.02, 0.98), na.rm = TRUE, names = FALSE)
  } else {
    range(vals, na.rm = TRUE)
  }
}

# ------------------------- make the two maps ----------------------------
make_single_map <- function(period_key, lims, states_sf, membership_df, counties_sf, metrics_df) {
  cl_sf <- build_cluster_sf(period_key, membership_df, counties_sf)

  dat <- metrics_df %>%
    dplyr::filter(period == period_key) %>%
    dplyr::select(cluster, value)

  map_sf <- cl_sf %>% dplyr::left_join(dat, by = "cluster")

ggplot2::ggplot() +
  geom_sf(data = map_sf, aes(fill = value), colour = NA) +
  geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
  scale_fill_distiller(palette = "Reds", direction = -1,
                       limits = lims, oob = scales::squish, na.value = "grey90") +
  coord_sf(xlim = c(-2500000, 2500000),
           ylim = c(-2200000,  730000),
           expand = FALSE) +
  labs(title = gsub("_", "–", period_key), fill = NULL) +
  theme_void(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

pA <- make_single_map("1999_2005", lims_info, states_tf, membership, counties_tf, metrics_two)
pB <- make_single_map("2020_2022", lims_info, states_tf, membership, counties_tf, metrics_two)

# ----------------------- box plot (by state) ----------------------------
# For each period:
#   membership (fips -> cluster) ⟶ join cluster value ⟶ attach state via counties_tf ⟶ box by STUSPS
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
  sf::st_drop_geometry() |>
  dplyr::select(STATEFP, STUSPS) |>
  dplyr::rename(statefp = STATEFP, state = STUSPS) |>
  dplyr::mutate(statefp = stringr::str_pad(as.character(statefp), 2, pad = "0"))

counties_lite <- counties_tf %>%
  sf::st_drop_geometry() %>%
  dplyr::select(fips, statefp) %>%
  dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                statefp = stringr::str_pad(as.character(statefp), 2, pad = "0"))

build_county_values <- function(per) {
  mm <- membership %>%
    dplyr::filter(period == per) %>%
    dplyr::select(fips, cluster)

  zv <- metrics_two %>%
    dplyr::filter(period == per) %>%
    dplyr::select(cluster, value)

  mm %>%
    dplyr::left_join(zv, by = "cluster") %>%
    dplyr::left_join(counties_lite, by = c("fips" = "fips")) %>%
    dplyr::left_join(states_info,  by = "statefp") %>%
    dplyr::transmute(state, fips, period = per, value) %>%
    dplyr::filter(!is.na(state), is.finite(value))
}

bx_df <- dplyr::bind_rows(
  build_county_values("1999_2005"),
  build_county_values("2020_2022")
) %>% dplyr::filter(!state %in% territories)

# Order states by declining median of 2020–2022
state_order <- bx_df %>%
  dplyr::filter(period == "2020_2022") %>%
  dplyr::group_by(state) %>%
  dplyr::summarise(med = median(value, na.rm = TRUE), .groups = "drop") %>%
  dplyr::arrange(dplyr::desc(med)) %>% dplyr::pull(state)

bx_df <- bx_df %>%
  dplyr::mutate(
    state  = factor(state, levels = state_order),
    period = factor(period, levels = c("1999_2005","2020_2022"),
                    labels = c("1999–2005","2020–2022"))
  )

pC <- ggplot2::ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
    scale_y_continuous(limits = c(48, 60)) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  # UCOD diversity is not necessarily 0–1; let ggplot choose sensible y scaling
  labs(x = "States (ranked by declining median county-level 2020–2022 UCOD 4-digit standardized diversity)",
       y = "UCOD 4-digit standardized diversity") +
  theme_bw(base_size = 10) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    panel.grid.minor = element_blank()
  )

# ----------------------- assemble & save ----------------------
combined <- (pA | pB) / pC + plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
outfile <- file.path(out_dir_base, "two_maps_box_detail_ucod_icd4_cstd.png")
ggsave(outfile, combined, width = 11, height = 8.5, dpi = 320)
message("✓ Saved: ", outfile)

```
Make new RI and prop_garabge maps with box plot
```{r}
# ──────────────────────────────────────────────────────────────
# Three-period maps + box plot for RI and prop_garbage
#   • Periods: 1999–2005, 2013–2019, 2020–2022
#   • Uses temporally-stable clusters in `cluster_map`
#   • AK/HI identical to aggregate maps (uses counties_aug & states_tf; falls back if needed)
#   • Viridis "D" (inverted for prop_garbage)
#   • Custom box plot y-limits
#   • Box-plot legend centered above the panel
#   • Outputs → figures/5yr_avg_stable/two_maps_box_<metric>.png
# Prereqs expected in memory (if present): dq (with time_window & metrics), cluster_map, counties_aug, states_tf
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(sf); library(scales)
  library(patchwork); library(here); library(stringr); library(readr)
  library(tidyr); library(tigris)
})

options(tigris_use_cache = TRUE, tigris_class = "sf")

# ---- Periods & constants ----
periods_three <- c("1999_2005","2013_2019","2020_2022")
territories   <- c("PR","GU","VI","AS","MP")

# ──────────────────────────────────────────────────────────────
# Fallback builders (only run if needed)
# ──────────────────────────────────────────────────────────────

# 0) Build AK/HI-shifted county/state layers if not supplied (same recipe as your aggregate maps)
crs_proj <- 2163

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

# 1) Ensure we have states_tf
if (!exists("states_tf")) {
  states_tf <- build_states_2163_resized()
}

# 2) Ensure counties_aug_fixed with county_ihme & statefp (IHME crosswalk) + clusters_aug_sf
if (!exists("clusters_aug_sf") || !exists("counties_lite")) {
  if (!exists("counties_aug")) stop("Please provide `counties_aug` or precomputed `clusters_aug_sf`.")

  # IHME crosswalk
  load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
  ihme_map <- ihme_fips %>%
    transmute(
      GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
      county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
    ) %>% distinct()

  counties_aug_fixed <- counties_aug
  if ("fips" %in% names(counties_aug_fixed)) {
    counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(fips), 5, pad = "0"))
  } else if ("GEOID" %in% names(counties_aug_fixed)) {
    counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(GEOID), 5, pad = "0"))
  } else stop("`counties_aug` must have either 'fips' or 'GEOID'.")

  if (!"statefp" %in% names(counties_aug_fixed)) {
    if ("STATEFP" %in% names(counties_aug_fixed)) {
      counties_aug_fixed <- counties_aug_fixed %>% mutate(statefp = as.character(STATEFP))
    } else stop("`counties_aug` must have 'statefp' or 'STATEFP'.")
  }
  counties_aug_fixed <- counties_aug_fixed %>% mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

counties_aug_fixed <- counties_aug_fixed %>%
  left_join(ihme_map, by = c("fips" = "GEOID"), suffix = c(".orig", ".map")) %>%
  mutate(
    county_ihme = coalesce(county_ihme.orig, county_ihme.map, fips)
  ) %>%
  select(-county_ihme.orig, -county_ihme.map)

  if (!exists("cluster_map")) stop("`cluster_map` (county_ihme -> cluster_id) is required.")

  clusters_aug_sf <- counties_aug_fixed %>%
    select(county_ihme, geometry) %>%
    inner_join(cluster_map, by = "county_ihme.x") %>%
    group_by(cluster_id) %>%
    summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()

  counties_lite <- counties_aug_fixed %>%
    sf::st_drop_geometry() %>%
    select(county_ihme, statefp)
  library(dplyr)
library(stringr)

# 1) Rename and normalise counties_lite so it contains county_ihme and 2-digit statefp
counties_lite <- counties_lite %>%
  rename(county_ihme = fips) %>%
  mutate(
    county_ihme = str_pad(as.character(county_ihme), 5, pad = "0"),
    statefp     = str_pad(as.character(statefp), 2, pad = "0")
  )

# 2) Quick sanity checks (optional but useful)
cat("counties_lite names: ", paste(names(counties_lite), collapse = ", "), "\n")
cat("example counties_lite rows:\n"); print(head(counties_lite))
cat("Sample county_ihme in cluster_map but not in counties_lite (should be empty or small):\n")
print(setdiff(cluster_map$county_ihme, counties_lite$county_ihme)[1:10])

}

# 3) State labels (for box plot)
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") %>%
  sf::st_drop_geometry() %>%
  select(STATEFP, STUSPS) %>%
  rename(statefp = STATEFP, state = STUSPS) %>%
  mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

# ──────────────────────────────────────────────────────────────
# Plot helpers
# ──────────────────────────────────────────────────────────────

make_map <- function(map_sf, fill_col, title, lims, states_sf, reverse = FALSE) {
  ggplot() +
    geom_sf(data = map_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(
      palette = "Reds",
      limits = lims,
      oob = scales::squish,
      direction = 1,
      na.value = "grey90"
    ) +
    coord_sf(
      xlim = c(-2500000, 2500000),
      ylim = c(-2200000,  730000),
      expand = FALSE
    ) +
    labs(title = title, fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

# Box plot helper — legend centered **above** the panel
make_boxplot <- function(bx_df, y_lab, percent_scale = FALSE, fixed_ylim = NULL) {
  p <- ggplot(bx_df, aes(x = state, y = value, fill = period)) +
    geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
    geom_boxplot(width = 0.7, outlier.alpha = 0.4,
                 position = position_dodge2(width = 0.75, preserve = "single")) +
    labs(x = "States (ranked by declining median county-level 2020–2022)",
         y = y_lab) +
    # Center the legend over the panel area
    coord_cartesian(ylim = fixed_ylim, clip = "off") +
    theme_bw(base_size = 10) +
    theme(
      legend.position      = c(0.5, 1.05),   # center horizontally, slightly above panel
      legend.justification = c(0.5, 0),      # anchor from center-bottom
      legend.direction     = "horizontal",
      legend.box           = "horizontal",
      legend.title         = element_blank(),
      plot.margin          = margin(t = 18, r = 5, b = 5, l = 5),
      axis.text.x          = element_text(angle = 90, vjust = 0.5, hjust = 1),
      panel.grid.minor     = element_blank()
    ) +
    guides(fill = guide_legend(nrow = 1, byrow = TRUE))
  if (percent_scale) p <- p + scale_y_continuous(labels = percent_format(accuracy = 1))
  p
}

# Wrapper to make the figure for one metric
make_three_period_map_box <- function(metric_col,
                                      file_tag,
                                      pretty_y_label,
                                      percent_scale  = FALSE,
                                      fixed_ylim     = NULL,
                                      reverse_fill   = FALSE) {
  if (!exists("dq")) stop("`dq` not found. It must include `county_ihme`, `time_window`, and the metric column.")

  all_clusters <- sort(unique(cluster_map$cluster_id))

  cl_df <- dq %>%
    filter(!is.na(time_window), time_window %in% periods_three) %>%
    select(county_ihme, time_window, !!sym(metric_col)) %>%
    rename(value = !!sym(metric_col)) %>%
    inner_join(cluster_map, by = "county_ihme") %>%
    group_by(cluster_id, time_window) %>%
    summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
    tidyr::complete(cluster_id = all_clusters,
                    time_window = periods_three,
                    fill = list(value = NA_real_))   # do NOT force zeros; keep NA if a cluster truly missing

  # colourbar limits across the three periods (2–98% to avoid extreme outliers)
  vals <- cl_df$value[is.finite(cl_df$value)]
  lims <- if (length(vals) >= 10) stats::quantile(vals, c(0.02, 0.98), na.rm = TRUE) else range(vals, na.rm = TRUE)

  # build maps (no NA->0 for maps; leave grey if truly missing)
  mp_1999 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "1999_2005"), by = "cluster_id")
  mp_2013 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "2013_2019"), by = "cluster_id")
  mp_2020 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "2020_2022"), by = "cluster_id")

  pA <- make_map(mp_1999, "value", "1999–2005", lims, states_tf, reverse_fill)
  pB <- make_map(mp_2013, "value", "2013–2019", lims, states_tf, reverse_fill)
  pC_map <- make_map(mp_2020, "value", "2020–2022", lims, states_tf, reverse_fill)

  # box plot data
  build_bx_df <- function(per) {
    zv <- cl_df %>% filter(time_window == per) %>% select(cluster_id, value)
    cluster_map %>%
      left_join(zv, by = "cluster_id") %>%
      left_join(counties_lite, by = "county_ihme") %>%
      left_join(states_info,  by = "statefp") %>%
      transmute(state, county_ihme, period = per, value) %>%
      filter(!is.na(state), is.finite(value))
  }
  bx_df <- bind_rows(
    build_bx_df("1999_2005"),
    build_bx_df("2020_2022")
  ) %>% filter(!state %in% territories)

  # order states by 2020–2022 median
  state_order <- bx_df %>%
    filter(period == "2020_2022") %>%
    group_by(state) %>%
    summarise(med = median(value, na.rm=TRUE), .groups = "drop") %>%
    arrange(desc(med)) %>% pull(state)

  bx_df <- bx_df %>%
    mutate(state  = factor(state, levels = state_order),
           period = factor(period, levels = periods_three,
                           labels = c("1999–2005","2013–2019","2020–2022")))

  p_box <- make_boxplot(bx_df, pretty_y_label, percent_scale, fixed_ylim)

  combined <- (pA | pB | pC_map) / p_box +
    plot_layout(heights = c(2, 1), guides = "keep") +
    plot_annotation(tag_levels = "A")

  dir.create(here::here("figures","5yr_avg_stable"), recursive = TRUE, showWarnings = FALSE)
  outfile <- here::here("figures","5yr_avg_stable", paste0("two_maps_box_", file_tag, ".png"))
  ggsave(outfile, combined, width = 13, height = 9, dpi = 320)
  message("✓ Saved: ", outfile)
}

# ──────────────────────────────────────────────────────────────
# RUN: RI (box plot limits 0.025–0.05; maps not inverted)
make_three_period_map_box(
  metric_col      = "RI_post_only",     # ensure this column exists in `dq`
  file_tag        = "RI_post_only",
  pretty_y_label  = "Reassignment Index (RI)",
  percent_scale   = FALSE,
  fixed_ylim      = c(0.07, 0.13),
  reverse_fill    = FALSE
)

# RUN: prop_garbage (box plot limits 15%–50%; maps inverted)
make_three_period_map_box(
  metric_col      = "prop_garbage",   # ensure this column exists in `dq`
  file_tag        = "prop_garbage",
  pretty_y_label  = "Percentage of deaths that are garbage coded (%)",
  percent_scale   = TRUE,
  fixed_ylim      = c(0.15, 0.50),
  reverse_fill    = TRUE
)

```
Build public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# Build `fin_all` from fixed-width FinEstDAT (2017/2022) + PID crosswalk
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr); library(here)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# ---- 1) Parser for FinEst Individual Unit fixed-width file ----
# Layout (robustly inferred):
# [govt_id (14 chars)] [item_code (3 chars)] [amount (digits, right-justified)] [year (4)] [flag (1)]
# We parse from the RIGHT to avoid depending on space counts.
parse_finest_fixed <- function(path) {
  stopifnot(file.exists(path))
  lines <- read_lines(path, progress = FALSE)
  # drop blanks
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(tibble())

  # RIGHT-anchored extraction
  year  <- as.integer(str_sub(lines, -5, -2))
  flag  <- str_sub(lines, -1, -1)
  left1 <- str_sub(lines,  1, -6)                       # everything before year+flag
  # amount is trailing digits on left1
  m <- regexpr("(\\d+)\\s*$", left1, perl = TRUE)
  amt_str <- ifelse(m > 0, regmatches(left1, m), NA_character_)
  amount  <- suppressWarnings(as.numeric(amt_str))
  left2   <- ifelse(m > 0, substr(left1, 1, m - 1L), left1)
  left2   <- rtrim <- sub("\\s+$", "", left2)           # trim right spaces

  # last 3 chars of left2 are the raw item code (alpha+2digits OR 2digits+alpha)
  raw_item <- str_sub(left2, -3, -1)
  govt_id  <- str_sub(left2,  1, -4)

  # Normalize item code to LETTER+2DIGITS (e.g., "E32", "T01")
  item_code <- ifelse(grepl("^[A-Z][0-9]{2}$", raw_item, ignore.case = TRUE),
                      toupper(raw_item),
               ifelse(grepl("^[0-9]{2}[A-Z]$", raw_item, ignore.case = TRUE),
                      paste0(toupper(str_sub(raw_item, -1, -1)), str_sub(raw_item, 1, 2)),
                      toupper(raw_item)))

  tibble(
    govt_id  = govt_id,
    item_code = item_code,
    amount   = amount,
    year     = year,
    flag     = flag
  ) %>%
    filter(!is.na(amount), !is.na(year), nchar(govt_id) >= 10)
}

# ---- 2) PID crosswalk (maps govt_id → county FIPS if available) ----
# PID files vary; try TSV/CSV; look for columns like GOVTID/GOVT_ID and FIPS/GEOID/COUNTYFIPS.
# ──────────────────────────────────────────────────────────────
# Robust PID crosswalk for fixed‑width PID (e.g., Fin_PID_2022.txt)
# Extracts: govt_id (leading digits), county_ihme (stateFIPS + county)
# Lines look like:
# 011003160514BALDWIN COUNTY … 99003   22928722             093022
# ──────────────────────────────────────────────────────────────
read_pid_xwalk <- function(path) {
  if (!file.exists(path)) return(NULL)
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(NULL)

  # helper: leading digits = GOVTID
  lead_digits <- function(x) sub("^([0-9]+).*$", "\\1", x)

  # find the right-most 5-digit token that starts with "99" (e.g., 99015)
  find_99_code <- function(x) {
    m <- gregexpr("\\b99\\d{3}\\b", x, perl = TRUE)
    if (m[[1]][1] == -1) return(NA_character_)
    # take the last match on the line
    ix <- tail(m[[1]], 1)
    substr(x, ix, ix + attr(m[[1]], "match.length")[length(m[[1]])] - 1)
  }

  tib <- tibble::tibble(raw = lines) %>%
    dplyr::mutate(
      govt_id_raw = lead_digits(raw),
      state_fips  = substr(govt_id_raw, 1, 2),
      code_99     = vapply(raw, find_99_code, character(1)),
      county_ihme = dplyr::if_else(
        !is.na(code_99),
        paste0(state_fips, substr(code_99, 3, 5)),
        NA_character_
      )
    ) %>%
    dplyr::filter(!is.na(county_ihme), nchar(county_ihme) == 5) %>%
    dplyr::transmute(
      govt_id = govt_id_raw,
      county_ihme = stringr::str_pad(county_ihme, 5, pad = "0")
    ) %>%
    dplyr::distinct()

  if (!nrow(tib)) return(NULL)
  tib
}
# ---- 3) Locate files and build fin_all ----
find_first <- function(fname) {
  c(here("data_raw/finance", fname), fname) |> {\(p) p[file.exists(p)][1]}()
}

fin2017_path <- find_first("2017FinEstDAT_09202024modp_pu.txt")
fin2022_path <- find_first("2022FinEstDAT_09202024modp_pu.txt")
pid2017_path <- find_first("Fin_PID_2017.txt")
pid2022_path <- find_first("Fin_PID_2022.txt")

fin_tbls <- list()
if (!is.na(fin2017_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2017_path)))
if (!is.na(fin2022_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2022_path)))
stopifnot(length(fin_tbls) > 0)

fin_raw <- bind_rows(fin_tbls)

# PID crosswalks (optional but recommended for county mapping)
pid_xw <- bind_rows(
  list(read_pid_xwalk(pid2017_path), read_pid_xwalk(pid2022_path)) |> compact()
) %>% distinct()

# ---- 4) Filter to Public Health Expenditures (E32) and summarize by county ----
# item_code "E32" = expenditures, function 32 (Public Health)
fin_e32 <- fin_raw %>% filter(item_code == "E32")

if (nrow(fin_e32) == 0) {
  stop("Parsed finance files but found ZERO rows with item_code == 'E32'. ",
       "Double-check files and item code list; if needed, print a sample of item_code counts.")
}

# Map to counties
if (!nrow(pid_xw)) {
  stop("PID crosswalk not found or had no usable (govt_id, FIPS) columns. ",
       "Please provide Fin_PID_2017.txt / Fin_PID_2022.txt (or their actual paths).")
}

fin_all <- fin_e32 %>%
  left_join(pid_xw, by = "govt_id") %>%
  filter(!is.na(county_ihme)) %>%
  transmute(
    county_ihme = county_ihme,
    fin_year    = as.integer(year),
    ph_exp_total = as.numeric(amount)
  ) %>%
  group_by(county_ihme, fin_year) %>%
  summarise(ph_exp_total = sum(ph_exp_total, na.rm = TRUE), .groups = "drop")

# Sanity check
cat("# fin_all rows:", nrow(fin_all), "\n")
print(fin_all %>% count(fin_year, sort = TRUE))
```
Build pop and other needed things for next chunk
```{r}
# ──────────────────────────────────────────────────────────────
# REPAIR BLOCK — ensure components + build pop_join
# Run this ONCE before the PH-spend plotting code
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(purrr)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
as_county_ihme <- function(df) {
  nm <- names(df)
  id_col <- dplyr::case_when(
    "county_ihme" %in% nm ~ "county_ihme",
    "GEOID"       %in% nm ~ "GEOID",
    "fips"        %in% nm ~ "fips",
    "FIPS"        %in% nm ~ "FIPS",
    "countyrs"    %in% nm ~ "countyrs",
    TRUE ~ NA_character_
  )
  if (is.na(id_col)) stop("No county ID column found. Expect one of county_ihme/GEOID/fips/FIPS/countyrs.")
  df %>% mutate(county_ihme = std_fips(.data[[id_col]]))
}

# 1) Ensure direction_year has component z-cols
ensure_direction_components <- function(direction_year, df) {
  needed_comp <- c("z_DQ_prop_garbage","z_prop_light","z_pct_overd_miss","z_pct_acc_miss")
  if (all(needed_comp %in% names(direction_year))) return(direction_year)

  # We need the raw inputs in `df` to (re)compute z-scores
  req <- c("DQ_prop_garbage","prop_light","pct_overd_miss","pct_acc_miss","year")
  if (!exists("df") || !all(req %in% names(df))) {
    stop("direction_year lacks z-components and `df` is missing required columns: ",
         paste(setdiff(req, names(df)), collapse = ", "))
  }
  df <- as_county_ihme(df)

  # Compute global means/sds once
  gs <- df %>%
    summarise(across(
      c(DQ_prop_garbage, prop_light, pct_overd_miss, pct_acc_miss),
      list(mean = ~mean(.x, na.rm = TRUE), sd = ~sd(.x, na.rm = TRUE)),
      .names = "{.col}_{.fn}"
    ))
  z <- function(x, m, s) (x - m) / s

  # Join raw inputs to direction_year, then add missing z-cols
  direction_year %>%
    left_join(df %>% select(county_ihme, year,
                            DQ_prop_garbage, prop_light, pct_overd_miss, pct_acc_miss),
              by = c("county_ihme","year")) %>%
    mutate(
      z_prop_garbage =  z(prop_garbage, gs$prop_garbage_mean, gs$prop_garbage_sd)
                          else z_DQ_prop_garbage,
      z_prop_light      = if (!"z_prop_light" %in% names(direction_year))
                            z(prop_light, gs$prop_light_mean, gs$prop_light_sd)
                          else z_prop_light,
      z_pct_overd_miss  = if (!"z_pct_overd_miss" %in% names(direction_year))
                            z(pct_overd_miss, gs$pct_overd_miss_mean, gs$pct_overd_miss_sd)
                          else z_pct_overd_miss,
      z_pct_acc_miss    = if (!"z_pct_acc_miss" %in% names(direction_year))
                            z(pct_acc_miss, gs$pct_acc_miss_mean, gs$pct_acc_miss_sd)
                          else z_pct_acc_miss
    ) %>%
    select(-DQ_prop_garbage, -prop_light, -pct_overd_miss, -pct_acc_miss)
}

direction_year <- ensure_direction_components(direction_year, df)

# 2) Build pop_join (ACS preferred; pid_all fallback)
build_pop_join <- function(fin_years) {
  # Reuse if already valid
  if (exists("pop_join", inherits = TRUE)) {
    pj <- get("pop_join", inherits = TRUE)
    if (all(c("county_ihme","fin_year","pop") %in% names(pj))) return(pj)
  }

  # Try ACS via tidycensus
  if (requireNamespace("tidycensus", quietly = TRUE)) {
    message("Building pop_join from ACS (B01001_001, ACS5) …")
    out <- purrr::map_dfr(sort(unique(stats::na.omit(as.integer(fin_years)))), function(y) {
      yy <- max(2009L, min(2023L, as.integer(y)))  # ACS5 window
      tidycensus::get_acs(
        geography = "county", variables = "B01001_001",
        year = yy, survey = "acs5", cache_table = TRUE, show_call = FALSE
      ) %>%
        transmute(county_ihme = GEOID, fin_year = y, pop = estimate)
    })
    if (nrow(out)) return(out)
  }

  # Fallback: pid_all (must exist and have year/pop)
  if (exists("pid_all", inherits = TRUE)) {
    message("Falling back to pid_all for population …")
    pid <- get("pid_all", inherits = TRUE)
    stopifnot(all(c("county_ihme","year","pop") %in% names(pid)))
    return(pid %>% transmute(county_ihme, fin_year = as.integer(year), pop))
  }

  stop("Could not build pop_join: neither ACS nor pid_all available.")
}

# Need fin_years from fin_all
if (!exists("fin_all", inherits = TRUE)) stop("fin_all not found — run the finance builder first.")
fin_all <- as_county_ihme(fin_all)
stopifnot(all(c("county_ihme","fin_year","ph_exp_total") %in% names(fin_all)))

avail_fin_years <- sort(unique(stats::na.omit(as.integer(fin_all$fin_year))))
if (!length(avail_fin_years)) stop("No valid fin_year values in fin_all.")

pop_join <- build_pop_join(avail_fin_years)

# Finally: build ph_pc for downstream chunk
ph_pc <- fin_all %>%
  filter(!is.na(fin_year)) %>%
  left_join(pop_join, by = c("county_ihme","fin_year")) %>%
  mutate(ph_pc = ph_exp_total / pop) %>%
  filter(is.finite(ph_pc))
```
Build income (need for next chunk)
```{r}
# ──────────────────────────────────────────────────────────────
# Build income_all from the US Census API (ACS 5-year, B19013_001)
# • Output columns: county_ihme, acs_year, avg_income
# • Uses fin_years_actual if present; otherwise defaults to c(2017, 2022)
# • Requires: tidycensus (preferred). Falls back to censusapi if needed.
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(tidyr)
})

# Helper: install/load a package quietly
ensure_pkg <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  invisible(TRUE)
}

# Decide which ACS years to fetch.
# County-level ACS 5-year is available 2009+; you likely want finance years like 2017 & 2022.
acs_years <- if (exists("fin_years_actual") && length(fin_years_actual)) {
  unique(suppressWarnings(as.integer(fin_years_actual)))
} else {
  c(2017L, 2022L)
}
acs_years <- acs_years[is.finite(acs_years) & acs_years >= 2009L]
acs_years <- sort(unique(acs_years))

if (!length(acs_years)) stop("No valid ACS years to fetch (need >=2009).")

# Preferred path: tidycensus
have_tidycensus <- FALSE
if (ensure_pkg("tidycensus")) {
  # Only set a key if user already has one in env/options; otherwise tidycensus still works for many calls.
  # You can pre-set with: tidycensus::census_api_key("YOUR_KEY", install = FALSE, overwrite = FALSE)
  suppressWarnings({
    have_tidycensus <- requireNamespace("tidycensus", quietly = TRUE)
  })
}

pull_income_tidycensus <- function(years) {
  purrr::map_dfr(years, function(y) {
    df <- tidycensus::get_acs(
      geography = "county",
      variables = "B19013_001",  # Median household income (dollars)
      year = y,
      survey = "acs5",
      cache_table = TRUE,
      geometry = FALSE
    )
    tibble::tibble(
      county_ihme = df$GEOID,                   # 5-digit FIPS
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$estimate))
    )
  })
}

# Fallback path: censusapi (raw var names differ slightly but include "B19013_001E")
pull_income_censusapi <- function(years) {
  ensure_pkg("censusapi")
  purrr::map_dfr(years, function(y) {
    df <- censusapi::getCensus(
      name   = "acs/acs5",
      vintage= y,
      vars   = c("NAME", "B19013_001E"),
      region = "county:*",
      regionin = "state:*"
    )
    tibble::tibble(
      county_ihme = stringr::str_pad(paste0(df$state, df$county), 5, pad = "0"),
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$B19013_001E))
    )
  })
}

income_all <- tryCatch(
  if (have_tidycensus) pull_income_tidycensus(acs_years) else pull_income_censusapi(acs_years),
  error = function(e) {
    message("[income_all] tidycensus pull failed or unavailable; trying censusapi…\n", conditionMessage(e))
    pull_income_censusapi(acs_years)
  }
) %>%
  mutate(
    county_ihme = as.character(county_ihme),
    acs_year    = as.integer(acs_year),
    avg_income  = suppressWarnings(as.numeric(avg_income))
  ) %>%
  filter(!is.na(avg_income), is.finite(avg_income)) %>%
  arrange(acs_year, county_ihme)

# Optional: restrict to CONUS (drop PR/AK/HI) if your workflow expects that
# income_all <- income_all %>% filter(!stringr::str_sub(county_ihme, 1, 2) %in% c("02","15","72"))

# Sanity checks
message("[income_all] Years fetched: ", paste(unique(income_all$acs_year), collapse = ", "))
message("[income_all] Rows: ", nrow(income_all), " | Counties per year (median): ",
        stats::median(table(income_all$acs_year)))

# (Optional) If you want real (inflation-adjusted) dollars, bring your CPI deflator here and do:
# income_all <- income_all %>% left_join(cpi_tbl, by = c("acs_year" = "year")) %>%
#   mutate(avg_income_real_2022 = avg_income * deflator_to_2022)
# Then, in your plotting chunk, switch avg_income → avg_income_real_2022.
``` 
Validation: z-scores by reporting type, per capita healthcare expenditure, and income
```{r}
# ──────────────────────────────────────────────────────────────
# Validation (NEW): Aggregate index built from county–year z-scores
#   Index = mean( -Z(prop_garbage), -Z(pct_overd_miss), Z(RI_post_only), Z(Phillips detail) )
#   • Phillips detail pulled from cluster CSV, expanded to county–year
#   • Time series by Reporting Type, PH-spend quintile, Income quintile
# Saves:
#   figures/validation_zscore/direction_by_reporting.png
#   figures/validation_zscore/direction_by_spend_quintile.png
#   figures/validation_zscore/direction_by_income_quintile.png
#   figures/validation_zscore/direction_timeseries_3panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr);  library(tidyr);  library(ggplot2); library(scales)
  library(readr);  library(stringr); library(here);   library(purrr)
})

dir.create(here("figures","validation_zscore"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
pick_first <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# ---------- file paths (robust candidates) ----------
data_candidates <- c(here("data","county_year_quality_metrics.csv"),
                     here("data","county_year_quality_metrics.csv.gz"))
membership_candidates <- c(here("output","county_cluster_membership.csv.gz"),
                           here("output","county_cluster_membership.csv"),
                           "output/county_cluster_membership.csv.gz")
philips_candidates <- c(here("output","cluster_metrics_ucr39_cstd.csv.gz"),
                        here("output","cluster_metrics.csv.gz"),
                        "output/cluster_metrics_ucr39_cstd.csv.gz")
reporting_candidates <- c(
  here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
  here("data_raw","County-Death-Investigation-System-2018.csv"),
  "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv",
  "data_raw/County-Death-Investigation-System-2018.csv"
)
ph_pc_candidates <- c(                       # PH per-capita (county, finance years or tidy)
  here("output","ph_pc.csv"),
  here("output","ph_per_capita.csv"),
  here("data","ph_pc.csv"),
  "output/ph_pc.csv"
)
income_candidates <- c(                      # income (county, ACS)
  here("output","income_all.csv"),
  here("data","income_all.csv"),
  "output/income_all.csv",
  "data/income_all.csv"
)

data_file       <- pick_first(data_candidates)
membership_file <- pick_first(membership_candidates)
philips_file    <- pick_first(philips_candidates)
reporting_file  <- pick_first(reporting_candidates)
ph_pc_file      <- pick_first(ph_pc_candidates)
income_file     <- pick_first(income_candidates)

stopifnot(!is.na(data_file), !is.na(membership_file), !is.na(philips_file))

# ---------- optional IHME crosswalk if available ----------
ihme_map <- NULL
if (file.exists(here::here("data_raw","ihme_fips.rda"))) {
  load(here::here("data_raw","ihme_fips.rda"))
  if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
    ihme_map <- ihme_fips %>%
      transmute(fips = std_fips(orig_fips), county_ihme = std_fips(ihme_fips)) %>%
      distinct()
  }
}

# ---------- load membership (one modal cluster per county×period) ----------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      mutate(
        county_ihme = std_fips(county_ihme),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    m0 <- membership_raw %>%
      mutate(
        fips    = std_fips(fips),
        period  = standardize_period(as.character(period)),
        cluster = as.character(cluster)
      )
    if (!is.null(ihme_map)) {
      m0 <- m0 %>% left_join(ihme_map, by = "fips") %>%
        mutate(county_ihme = coalesce(county_ihme, fips)) %>%
        select(county_ihme, period, cluster)
    } else {
      m0 <- m0 %>% transmute(county_ihme = fips, period, cluster)
    }
    m0
  } else stop("membership file must contain county_ihme or fips")

# modal cluster if duplicates
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }
membership <- membership %>%
  filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  group_by(county_ihme, period) %>%
  summarise(cluster = mode_str(cluster), .groups="drop")

# ---------- load county-year data ----------
cy <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  mutate(year = suppressWarnings(as.integer(year)),
         period = period_of_year(year))

# normalize ids
if ("county_ihme" %in% names(cy)) {
  cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))
} else if ("fips" %in% names(cy)) {
  cy <- cy %>% mutate(fips = std_fips(fips))
  cy <- if (!is.null(ihme_map)) {
    cy %>% left_join(ihme_map, by = "fips") %>% mutate(county_ihme = coalesce(county_ihme, fips))
  } else {
    cy %>% mutate(county_ihme = fips)
  }
} else stop("data file must contain county_ihme or fips")

# ---------- ensure the FOUR components exist (county–year) ----------
# 1) prop_garbage
nms <- names(cy)
col_prop_g <- pick_col(nms, c("prop_garbage","foreman_garbage"))
if (is.na(col_prop_g)) stop("Need prop_garbage (or foreman_garbage) in county-year file.")

# 2) pct_overd_miss  (if missing, derive from counts if available)
if (!("pct_overd_miss" %in% nms)) {
  k <- pick_col(nms, c("overd_miss_k","overdose_unspecified_k","overdose_unspec_k","od_unspec_k"))
  N <- pick_col(nms, c("overd_n","overdose_total_n","od_total_n"))
  if (!is.na(k) && !is.na(N)) {
    cy <- cy %>% mutate(pct_overd_miss = ifelse(.data[[N]] > 0, .data[[k]] / .data[[N]], NA_real_))
  } else {
    stop("pct_overd_miss not found and cannot derive from counts.")
  }
}

# 3) RI_post_only
if (!("RI_post_only" %in% nms)) {
  alt <- pick_col(nms, c("RI","ri_post_only","ri"))
  if (!is.na(alt)) {
    cy <- cy %>% rename(RI_post_only = all_of(alt))
  } else stop("RI_post_only not found.")
}

# 4) Phillips detail from cluster CSV → expand to county–year
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
names(ph0) <- tolower(names(ph0))
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% mutate(period = standardize_period(period))
}
# choose a detail/CSTD column (fallbacks in order)
philips_col <- pick_col(names(ph0),
                        c("detail_ucod_icd4_cstd","detail_mcod_icd4_cstd",
                          "cod_diversity_cstd","cod_diversity_std","neff_cstd","richness_cstd"))
stopifnot(!is.na(philips_col))
# ensure cluster present (or map from county)
if (!("cluster" %in% names(ph0))) {
  # if provided at county level, map to cluster using membership
  idcol <- pick_col(names(ph0), c("county_ihme","fips","geoid"))
  stopifnot(!is.na(idcol))
  ph0 <- ph0 %>%
    mutate(county_ihme = if (idcol=="county_ihme") std_fips(county_ihme) else std_fips(.data[[idcol]])) %>%
    inner_join(membership, by = c("county_ihme","period"))
}
ph0 <- ph0 %>% mutate(cluster = as.character(cluster))

# build period endpoints & expand to years
get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) tibble(period = lbl, start = min(yrs[1], yrs[2]), end = max(yrs[1], yrs[2]))
  else tibble(period = lbl, start = NA_integer_, end = NA_integer_)
}
period_tbl <- unique(ph0$period) %>% sort() %>% map_dfr(parse_period) %>% filter(!is.na(start), !is.na(end))

ph_cy <- ph0 %>%
  select(cluster, period, value = all_of(philips_col)) %>%
  inner_join(membership, by = c("cluster","period")) %>%        # → county
  left_join(period_tbl, by = "period") %>%
  mutate(year = map2(start, end, seq)) %>%
  select(county_ihme, year, philips_detail = value) %>%
  unnest(year)

# ---------- join Phillips with county–year + compute z's ----------
# restrict to years we care about
cy <- cy %>% filter(!is.na(year), year >= 1999, year <= 2022)
cy4 <- cy %>%
  select(county_ihme, year, period,
         prop_garbage = all_of(col_prop_g),
         pct_overd_miss, RI_post_only)

cy4 <- cy4 %>%
  left_join(ph_cy, by = c("county_ihme","year"))

# global z's (across ALL county–years)
zcol <- function(x){ m <- mean(x, na.rm = TRUE); s <- sd(x, na.rm = TRUE); if (!is.finite(s) || s==0) return((x-x)*NA_real_); (x-m)/s }

cy4 <- cy4 %>%
  mutate(
    z_prop_garbage    = zcol(prop_garbage),
    z_pct_overd_miss  = zcol(pct_overd_miss),
    z_RI_post_only    = zcol(RI_post_only),
    z_phillips_detail = zcol(philips_detail)
  ) %>%
  # flip so that larger is always better
  mutate(
    z_prop_garbage    = -z_prop_garbage,
    z_pct_overd_miss  = -z_pct_overd_miss
  )

# aggregate index (county–year)
cy4 <- cy4 %>%
  mutate(
    direction_score = rowMeans(select(., z_prop_garbage, z_pct_overd_miss, z_RI_post_only, z_phillips_detail),
                               na.rm = TRUE)
  ) %>%
  mutate(direction_score = ifelse(is.nan(direction_score), NA_real_, direction_score))

# collapse to county–PERIOD means for plotting
dir_cp <- cy4 %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
  mutate(period = factor(period, levels = period_levels))

# =================================================================
# Reporting-type LOOKUP + panel
# =================================================================
normalize_reporting_type <- function(x) {
  y <- stringr::str_to_lower(stringr::str_squish(as.character(x)))
  dplyr::case_when(
    y %in% c("me","medical examiner") ~ "Medical Examiner",
    y %in% c("coroner")               ~ "Coroner",
    y %in% c("mixed","hybrid")        ~ "Mixed",
    grepl("other", y)                 ~ "Other County Official",
    y %in% c("na","n/a","unknown","") ~ NA_character_,
    TRUE                              ~ stringr::str_to_title(y)
  )
}
get_reporting_lookup <- function() {
  stopifnot(!is.na(reporting_file))
  rep_raw <- readr::read_csv(reporting_file, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, \(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_)
    nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5","county_ihme"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  out <- rep_raw %>%
    mutate(
      county_ihme = if (tolower(fips_col)=="county_ihme") std_fips(.data[[fips_col]]) else std_fips(.data[[fips_col]]),
      reporting_type = normalize_reporting_type(.data[[type_col]])
    ) %>%
    filter(nchar(county_ihme)==5, !is.na(reporting_type)) %>%
    distinct(county_ihme, reporting_type)
  out
}
rep_lookup <- get_reporting_lookup()

ts_reporting <- dir_cp %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  group_by(period, reporting_type) %>%
  summarise(mean_direction = mean(direction_score, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop")

p_rep <- ggplot(ts_reporting, aes(x = period, y = mean_direction, group = reporting_type, colour = reporting_type)) +
  geom_line(linewidth = 1.2) + geom_point(size = 2) +
  labs(title = "Aggregate data quality by reporting type",
       x = NULL, y = "Aggregate data quality (z)", colour = "Reporting type") +
  theme_bw(base_size = 12)

print(p_rep)
ggsave(here("figures","validation_zscore","direction_by_reporting.png"),
       p_rep, width = 9, height = 5.2, dpi = 320)
message("[REP] Saved reporting-type panel (rows=", nrow(ts_reporting), ").")

# =================================================================
# PH SPEND helpers + panel
# =================================================================
get_ph_any <- function() {
  # prefer in-memory ph_pc object
  if (exists("ph_pc", inherits = TRUE)) {
    pc <- get("ph_pc", inherits = TRUE)
    if (is.data.frame(pc)) {
      id  <- pick_col(names(pc), c("county_ihme","fips","geoid"))
      val <- pick_col(names(pc), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
      if (!is.na(id) && !is.na(val)) {
        return(
          pc %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
            filter(is.finite(ph_pc))
        )
      }
    }
  }
  # files
  f <- ph_pc_file
  if (!is.na(f) && file.exists(f)) {
    ph_raw <- readr::read_csv(f, show_col_types = FALSE)
    id  <- pick_col(names(ph_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(ph_raw), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
    if (!is.na(id) && !is.na(val)) {
      return(
        ph_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
          filter(is.finite(ph_pc))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
    )
  }
  NULL
}
get_ph_quintiles <- function() {
  qcol <- intersect(c("ph_quint","phspend_quint","ph_pc_quintile","ph_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[PH] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, ph_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  ph_any <- get_ph_any()
  if (is.null(ph_any) || !nrow(ph_any)) return(NULL)
  brks <- make_quintile_breaks(ph_any$ph_pc)
  ph_any %>%
    mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
}

ph_q <- get_ph_quintiles()
p_ph <- NULL
if (!is.null(ph_q) && nrow(ph_q)) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))

  p_ph <- ggplot(ts_ph, aes(period, mean_direction, group = ph_quint, colour = ph_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by public-health spending",
         x = NULL, y = "Aggregate data quality (z)", colour = "PH spend quintile") +
    theme_bw(base_size = 12)

  print(p_ph)
  out_path <- here("figures","validation_zscore","direction_by_spend_quintile.png")
  ggsave(out_path, p_ph, width = 9, height = 5.2, dpi = 320)
  message("[PH] Saved: ", out_path, "  (n rows=", nrow(ts_ph), ")")
} else {
  message("[PH] Panel skipped: could not derive PH quintiles.")
}

# =================================================================
# INCOME helpers + panel
# =================================================================
get_income_any <- function() {
  # prefer in-memory income_all
  if (exists("income_all", inherits = TRUE)) {
    ia <- get("income_all", inherits = TRUE)
    if (is.data.frame(ia)) {
      id  <- pick_col(names(ia), c("county_ihme","fips","geoid"))
      val <- pick_col(names(ia), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                   "income_pc","per_capita_income","pc_income","income"))
      if (!is.na(id) && !is.na(val)) {
        return(
          ia %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   income = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
            filter(is.finite(income))
        )
      }
    }
  }
  # from file
  if (!is.na(income_file) && file.exists(income_file)) {
    inc_raw <- readr::read_csv(income_file, show_col_types = FALSE)
    id  <- pick_col(names(inc_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(inc_raw), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                      "income_pc","per_capita_income","pc_income","income"))
    if (!is.na(id) && !is.na(val)) {
      return(
        inc_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 income = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
          filter(is.finite(income))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("avg_income","median_household_income","median_income","mhi","hh_income",
                      "income_pc","per_capita_income","pc_income","income","acs_income"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, income = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(income))
    )
  }
  NULL
}
get_income_quintiles <- function() {
  qcol <- intersect(c("inc_quint","income_quint","income_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[INC] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, inc_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  income_any <- get_income_any()
  if (is.null(income_any) || !nrow(income_any)) return(NULL)
  brks <- make_quintile_breaks(income_any$income)
  income_any %>%
    mutate(inc_quint = cut(income, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, inc_quint = factor(inc_quint, levels = labs_quint))
}

inc_q <- get_income_quintiles()
p_inc <- NULL
if (!is.null(inc_q) && nrow(inc_q)) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))

  p_inc <- ggplot(ts_inc, aes(period, mean_direction, group = inc_quint, colour = inc_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by income quintile",
         x = NULL, y = "Aggregate data quality (z)", colour = "Income quintile") +
    theme_bw(base_size = 12)

  print(p_inc)
  out_path <- here("figures","validation_zscore","direction_by_income_quintile.png")
  ggsave(out_path, p_inc, width = 9, height = 5.2, dpi = 320)
  message("[INC] Saved: ", out_path, "  (n rows=", nrow(ts_inc), ")")
} else {
  message("[INC] Panel skipped: could not derive income quintiles.")
}

# =================================================================
# Combined 3-panel (if at least two exist)
# =================================================================
panel_list <- list(
  "Reporting type"   = if (exists("p_rep") && inherits(p_rep, "gg")) p_rep else NULL,
  "PH spend quintile"= if (exists("p_ph")  && inherits(p_ph,  "gg")) p_ph  else NULL,
  "Income quintile"  = if (exists("p_inc") && inherits(p_inc, "gg")) p_inc else NULL
)
panel_list <- panel_list[ vapply(panel_list, inherits, logical(1), "gg") ]

if (length(panel_list) >= 2) {
  if (requireNamespace("patchwork", quietly = TRUE)) {
    p_all <- patchwork::wrap_plots(unname(panel_list), nrow = 1, guides = "collect") &
      theme(legend.position = "bottom")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel.")
  } else if (requireNamespace("cowplot", quietly = TRUE)) {
    p_all <- cowplot::plot_grid(plotlist = unname(panel_list), nrow = 1, align = "h")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel (cowplot).")
  } else {
    message("[ALL] Combined 3-panel skipped (patchwork/cowplot not available).")
  }
} else {
  message("[ALL] Not enough panels to create the combined summary; individual panels were saved.")
}

# ──────────────────────────────────────────────────────────────
# Compact 2-row table for the paper:
# Columns: Per capita public health spending | Reporting type | Income quintile
# Rows:    1999–2005, 2020–2022
# Saves → output/validation_zscore/aggregate_index_table_2periods.csv
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr); library(readr); library(here) })

out_dir_csv <- here::here("output","validation_zscore")
dir.create(out_dir_csv, recursive = TRUE, showWarnings = FALSE)

# ensure helpers from earlier exist
`%||%` <- function(a,b) if (!is.null(a)) a else b
labs_quint <- exists("labs_quint") %||% FALSE
if (identical(labs_quint, FALSE)) labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Recompute dir_cp (county × period aggregate index) if missing
if (!exists("dir_cp")) {
  stopifnot(exists("cy4"))
  period_levels2 <- c("1999_2005","2006_2012","2013_2019","2020_2022")
  dir_cp <- cy4 %>%
    filter(!is.na(period), period %in% period_levels2) %>%
    group_by(county_ihme, period) %>%
    summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
    mutate(period = factor(period, levels = period_levels2))
}

# (Re)build PH spend quintiles if needed
if (!exists("ph_q")) {
  make_quintile_breaks <- function(v) {
    v <- v[is.finite(v)]
    stopifnot(length(v) > 0)
    qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
    for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
    qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
  }
  # derive from cy4 if needed
  if (!exists("ph_q")) {
    cand <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                      names(cy4))
    if (length(cand)) {
      ph_any <- cy4 %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[cand[1]]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
      if (nrow(ph_any)) {
        brks <- make_quintile_breaks(ph_any$ph_pc)
        ph_q <- ph_any %>%
          mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
          transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
      }
    }
  }
}

# Recompute PH / Reporting / Income summaries if missing
if (!exists("ts_ph") && exists("ph_q")) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))
}
if (!exists("ts_reporting") && exists("rep_lookup")) {
  ts_reporting <- dir_cp %>%
    inner_join(rep_lookup, by = "county_ihme") %>%
    group_by(period, reporting_type) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop")
}
if (!exists("ts_inc") && exists("inc_q")) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))
}

# ------- formatting helpers (period-scoped “label: value” strings) -------
fmt_pairs <- function(df, period_key, group_col, value_col = "mean_direction", levels = NULL, digits = 2, label_map = NULL) {
  if (is.null(df) || !nrow(df)) return(NA_character_)
  d <- df %>% filter(as.character(period) == period_key)
  if (!is.null(levels)) {
    d[[group_col]] <- factor(d[[group_col]], levels = levels)
    d <- d %>% arrange(.data[[group_col]])
  }
  if (!is.null(label_map)) {
    labs <- label_map(as.character(d[[group_col]]))
  } else {
    labs <- as.character(d[[group_col]])
  }
  vals <- round(d[[value_col]], digits = digits)
  # keep N if present
  if ("n" %in% names(d)) {
    paste0(labs, ": ", vals, " (n=", d$n, ")") %>% paste(collapse = "; ")
  } else {
    paste0(labs, ": ", vals) %>% paste(collapse = "; ")
  }
}

# Labels/order for reporting types
rt_levels <- c("Coroner","Other County Official","Mixed","Medical Examiner")
rt_label_map <- function(x) x  # already pretty

# Build the 2-row table
period_keep <- c("1999_2005","2020_2022")
period_label <- function(p) dplyr::recode(p, `1999_2005`="1999–2005", `2020_2022`="2020–2022", .default = p)

tbl_rows <- lapply(period_keep, function(pk) {
  tibble::tibble(
    Period = period_label(pk),
    `Per capita public health spending` =
      fmt_pairs(ts_ph %||% tibble(), pk, "ph_quint", levels = labs_quint),
    `Reporting type` =
      fmt_pairs(ts_reporting %||% tibble(), pk, "reporting_type", levels = rt_levels, label_map = rt_label_map),
    `Income quintile` =
      fmt_pairs(ts_inc %||% tibble(), pk, "inc_quint", levels = labs_quint)
  )
})
table_2rows <- dplyr::bind_rows(tbl_rows)

# Save CSV
out_csv <- file.path(out_dir_csv, "aggregate_index_table_2periods.csv")
readr::write_csv(table_2rows, out_csv)
message("[CSV] Saved compact 2-row table to: ", out_csv)

# (Optional) print to console
print(table_2rows)

```
R^2
```{r}
# ===================== Variance explained (weighted R²) =====================
# What this does
# • Builds a cluster×period metrics table (adds direction_score).
# • REPORTING TYPE: expands cluster metrics to counties, joins reporting type per county,
#   fits weighted models y ~ reporting_type with weights = county n_cert (within period).
# • INCOME & PH SPEND: computes cluster×period weighted averages from county values
#   (weights = county n_cert within period), then fits y ~ cluster_avg predictor
#   with cluster weight = sum_n_cert.
# • Prints one compact table per predictor: R² by metric (no files written).

suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr); library(rlang) })

# ---- Safety: small utils ----
wt_mean <- function(x, w) { w <- ifelse(is.finite(w), w, 0); if (sum(w) > 0) sum(w * x, na.rm=TRUE) / sum(w) else NA_real_ }
r2_weighted_from_lm <- function(fit){
  w <- if (!is.null(fit$weights)) fit$weights else rep(1, nrow(fit$model))
  y <- model.response(model.frame(fit))
  rss <- sum(w * stats::residuals(fit)^2, na.rm = TRUE)
  yb  <- stats::weighted.mean(y, w)
  tss <- sum(w * (y - yb)^2, na.rm = TRUE)
  if (tss > 0) 1 - rss/tss else NA_real_
}
safe_print_matrix <- function(title, mat){
  cat("\n[R2] ", title, " (weighted)\n", sep = "")
  base::print.data.frame(as.data.frame(mat), row.names = FALSE)
}

# ---- 1) Metrics at cluster×period, incl. z-score sum ----
stopifnot(exists("metrics_clu"), exists("z_tbl"))  # created in your script above

metrics_all <- metrics_clu %>%
  inner_join(z_tbl %>% select(period, cluster, direction_score),
             by = c("period","cluster")) %>%
  # Keep a cluster weight (sum certificates) for continuous models
  mutate(w_cluster = replace_na(sum_n_cert, 0)) %>%
  filter(is.finite(w_cluster))

metric_cols <- c("prop_overd_unspec", "philips_cstd", "RI_cluster", "prop_garbage", "direction_score")

# ---- 2) County×period weights (for expansion) ----
stopifnot(exists("cy"))
cw <- cy %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(w_cnty = sum(n_cert, na.rm = TRUE), .groups = "drop") %>%
  mutate(w_cnty = ifelse(is.finite(w_cnty) & w_cnty > 0, w_cnty, NA_real_))

# ---- 3) REPORTING TYPE R² (categorical) ----
# Ensure reporting lookup available
if (!exists("rep_lookup")) {
  rep_lookup <- tryCatch(
    get_reporting_lookup() %>%
      mutate(reporting_type = normalize_reporting_type(reporting_type)) %>%
      filter(!is.na(reporting_type)),
    error = function(e) NULL
  )
}
r2_by_reporting <- NULL
if (!is.null(rep_lookup) && nrow(rep_lookup)) {
  # Expand cluster metrics down to counties (carry metric values), attach reporting type & weights
  met_cnty <- metrics_all %>%
    inner_join(membership %>% select(county_ihme, period, cluster), by = c("period","cluster")) %>%
    inner_join(rep_lookup, by = "county_ihme") %>%
    inner_join(cw, by = c("county_ihme","period")) %>%
    filter(is.finite(w_cnty)) %>%
    mutate(reporting_type = factor(reporting_type))

  r2_vals <- lapply(metric_cols, function(m) {
    df <- met_cnty %>% select(y = all_of(m), reporting_type, w_cnty) %>%
      filter(is.finite(y), !is.na(reporting_type), is.finite(w_cnty))
    if (!nrow(df)) return(NA_real_)
    fit <- stats::lm(y ~ reporting_type, data = df, weights = w_cnty)
    r2_weighted_from_lm(fit)
  })
  r2_by_reporting <- tibble::tibble(metric = metric_cols, R2_reporting_type = unlist(r2_vals))
  safe_print_matrix("Variance explained by REPORTING TYPE",
                    transform(r2_by_reporting, R2_reporting_type = round(R2_reporting_type, 3)))
} else {
  cat("\n[R2] Reporting-type lookup not available; skipping REPORTING TYPE R².\n")
}

# ---- 4) Cluster-average INCOME & PH SPEND predictors (continuous) ----
# Build county-level income & PH datasets
income_any <- tryCatch(get_income_any(), error = function(e) NULL)
ph_any     <- tryCatch(get_ph_any(),     error = function(e) NULL)

# Compute cluster×period weighted averages from county values (weights = county n_cert within period)
cl_preds <- membership %>%
  inner_join(cw, by = c("county_ihme","period")) %>%
  { df <- .;
    # Income
    inc_cl <- NULL
    if (!is.null(income_any) && nrow(income_any)) {
      inc_cl <- df %>% inner_join(income_any, by = "county_ihme") %>%
        group_by(period, cluster) %>%
        summarise(cluster_avg_income = wt_mean(income, w_cnty), .groups = "drop")
    }
    # PH per-capita
    ph_cl <- NULL
    if (!is.null(ph_any) && nrow(ph_any)) {
      ph_cl <- df %>% inner_join(ph_any, by = "county_ihme") %>%
        group_by(period, cluster) %>%
        summarise(cluster_ph_pc = wt_mean(ph_pc, w_cnty), .groups = "drop")
    }
    full_join(inc_cl, ph_cl, by = c("period","cluster"))
  }

metrics_with_preds <- metrics_all %>% left_join(cl_preds, by = c("period","cluster"))

# Helper to fit y ~ x with cluster weights
fit_r2_cont <- function(y_col, x_col) {
  df <- metrics_with_preds %>%
    select(y = all_of(y_col), x = all_of(x_col), w = w_cluster) %>%
    filter(is.finite(y), is.finite(x), is.finite(w), w > 0)
  if (!nrow(df)) return(NA_real_)
  fit <- stats::lm(y ~ x, data = df, weights = w)
  r2_weighted_from_lm(fit)
}

# ---- 4a) R² by cluster-average INCOME ----
r2_by_income <- NULL
if ("cluster_avg_income" %in% names(metrics_with_preds)) {
  r2_vals_inc <- vapply(metric_cols, function(m) fit_r2_cont(m, "cluster_avg_income"), numeric(1))
  r2_by_income <- tibble::tibble(metric = metric_cols, R2_cluster_avg_income = r2_vals_inc)
  safe_print_matrix("Variance explained by CLUSTER AVERAGE INCOME",
                    transform(r2_by_income, R2_cluster_avg_income = round(R2_cluster_avg_income, 3)))
} else {
  cat("\n[R2] Income data not available; skipping INCOME R².\n")
}

# ---- 4b) R² by per-capita PUBLIC-HEALTH SPENDING ----
r2_by_ph <- NULL
if ("cluster_ph_pc" %in% names(metrics_with_preds)) {
  r2_vals_ph <- vapply(metric_cols, function(m) fit_r2_cont(m, "cluster_ph_pc"), numeric(1))
  r2_by_ph <- tibble::tibble(metric = metric_cols, R2_ph_per_capita = r2_vals_ph)
  safe_print_matrix("Variance explained by PH PER-CAPITA SPENDING",
                    transform(r2_by_ph, R2_ph_per_capita = round(R2_ph_per_capita, 3)))
} else {
  cat("\n[R2] PH per-capita not available; skipping PH-SPEND R².\n")
}

# ---- 5) Optional: compact summary table (print if multiple available) ----
if (!is.null(r2_by_reporting) || !is.null(r2_by_income) || !is.null(r2_by_ph)) {
  summary_tbl <- tibble::tibble(metric = metric_cols)
  if (!is.null(r2_by_reporting)) summary_tbl <- summary_tbl %>% left_join(r2_by_reporting, by = "metric")
  if (!is.null(r2_by_income))    summary_tbl <- summary_tbl %>% left_join(r2_by_income,    by = "metric")
  if (!is.null(r2_by_ph))        summary_tbl <- summary_tbl %>% left_join(r2_by_ph,        by = "metric")
  summary_tbl <- summary_tbl %>% mutate(across(where(is.numeric), ~round(.x, 3)))
  safe_print_matrix("SUMMARY — R² by predictor and metric", summary_tbl)
}
# ===========================================================================

```
Correlation between the 4 metrics
```{r}
# ──────────────────────────────────────────────────────────────
# PRINT-ONLY CORRELATIONS (no CSVs)
#   Metrics: z_prop_overd_unspec, z_philips_cstd, z_RI_cluster, z_prop_garbage
#   Levels: overall; by reporting type (if rep_lookup);
#           by PH-spend quintile (if ph_q); by income quintile (if inc_q)
#   Notes:
#     • Weighted = death-weighted (sum_n_cert) at cluster×period
#     • Also prints unweighted
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(tibble)
})

options(pillar.max_cols = Inf)  # show all columns

# ---- Inputs expected from earlier chunks ----
stopifnot(exists("z_tbl"), exists("cluster_core"), exists("membership"), exists("cy"))

# ---- Select z-variables & weights at cluster×period ----
zvars <- c("z_prop_overd_unspec","z_philips_cstd","z_RI_cluster","z_prop_garbage")
present_z <- intersect(zvars, names(z_tbl))
if (length(present_z) != length(zvars)) {
  stop("Missing z-variables in z_tbl: ", paste(setdiff(zvars, present_z), collapse = ", "))
}

z_cluster <- z_tbl %>%
  select(period, cluster, all_of(zvars)) %>%
  inner_join(cluster_core %>% select(period, cluster, sum_n_cert),
             by = c("period","cluster")) %>%
  filter(if_all(all_of(zvars), ~ is.finite(.x)),
         is.finite(sum_n_cert) & sum_n_cert > 0)

# ---- Correlation helpers ----
weighted_cor_mat <- function(df, vars, wcol = NULL, method = c("pearson","spearman")) {
  method <- match.arg(method)
  X <- df %>% dplyr::select(dplyr::all_of(vars))
  w <- if (!is.null(wcol) && wcol %in% names(df)) df[[wcol]] else NULL

  # listwise complete rows; handle weights safely
  if (is.null(w)) keep <- stats::complete.cases(X) else keep <- stats::complete.cases(X) & is.finite(w) & w > 0
  if (!length(keep)) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = 0))
  }

  X <- as.matrix(X[keep, , drop = FALSE])
  w <- if (is.null(w)) NULL else as.numeric(w[keep])
  n_used <- nrow(X)
  if (n_used < 3) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = n_used))
  }

  if (method == "spearman") X <- apply(X, 2, rank, ties.method = "average")

  if (is.null(w)) {
    C <- stats::cov(X)
  } else {
    w <- w / sum(w)
    C <- stats::cov.wt(X, wt = w, method = "ML")$cov
  }

  s <- sqrt(diag(C)); s[!is.finite(s) | s == 0] <- NA_real_
  R <- C / (s %o% s)
  dimnames(R) <- list(colnames(X), colnames(X))
  list(cor = R, n = n_used)
}

mat_to_tidy <- function(corlst, method, group_type, group_value, weighted, include_group = TRUE) {
  R <- corlst$cor; n_used <- corlst$n; vars <- colnames(R)
  if (is.null(vars)) vars <- zvars
  comb <- t(combn(vars, 2))
  out <- tibble(
    group_type = group_type,
    method     = method,
    weighted   = weighted,
    n_used     = n_used,
    var1       = comb[,1],
    var2       = comb[,2],
    correlation= mapply(function(a,b) R[a,b], comb[,1], comb[,2])
  )
  if (isTRUE(include_group)) {
    gv <- if (length(group_value)) as.character(group_value)[1] else NA_character_
    out <- out |> dplyr::mutate(group = gv, .before = method)
  }
  out
}

compute_all_methods <- function(df, label_type, label_val, wcol = NULL, include_group = TRUE) {
  dplyr::bind_rows(
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "pearson"),
                "pearson",  label_type, label_val, !is.null(wcol), include_group),
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "spearman"),
                "spearman", label_type, label_val, !is.null(wcol), include_group)
  )
}

# Pretty printer (forces full width, shows key cols first)
pp <- function(x, title) {
  cat("\n", strrep("=", nchar(title)+4), "\n", "= ", title, " =\n",
      strrep("=", nchar(title)+4), "\n", sep = "")

  grpcol <- intersect(names(x),
                      c("reporting_type","ph_spend_quintile","income_quintile","group"))[1]
  x2 <- x %>%
    mutate(correlation = round(correlation, 3)) %>%
    arrange(desc(weighted), method, var1, var2)

  if (length(grpcol)) {
    x2 <- x2 %>% select(group_type, all_of(grpcol), method, weighted, n_used, var1, var2, correlation)
  } else {
    x2 <- x2 %>% select(group_type, method, weighted, n_used, var1, var2, correlation)
  }

  print(x2, n = Inf, width = Inf)
  invisible(NULL)
}

# ---- 1) OVERALL correlations (weighted & unweighted) ----
corr_overall <- bind_rows(
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = "sum_n_cert"),
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = NULL)
)
pp(corr_overall, "Overall correlations (Pearson & Spearman; weighted & unweighted)")

# ---- 2) Build county weights for modal grouping at cluster×period ----
county_w <- cy %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(w = sum(n_cert, na.rm = TRUE), .groups = "drop") %>%
  mutate(w = ifelse(is.finite(w) & w > 0, w, 1))

modal_group <- function(lookup_df, value_col) {
  req_cols <- c("county_ihme", value_col)
  if (is.null(lookup_df) || !all(req_cols %in% names(lookup_df))) return(NULL)

  membership %>%
    left_join(lookup_df %>% select(county_ihme, !!rlang::sym(value_col)), by = "county_ihme") %>%
    left_join(county_w, by = c("county_ihme","period")) %>%
    filter(!is.na(.data[[value_col]])) %>%
    mutate(w = ifelse(is.finite(w) & w > 0, w, 1)) %>%
    group_by(period, cluster, .data[[value_col]]) %>%
    summarise(w = sum(w, na.rm = TRUE), .groups = "drop") %>%
    group_by(period, cluster) %>%
    slice_max(order_by = w, n = 1, with_ties = FALSE) %>%
    ungroup() %>%
    rename(group = !!rlang::sym(value_col))
}

# ---- 3a) By REPORTING TYPE (if available) ----
if (exists("rep_lookup") && is.data.frame(rep_lookup)) {
  cl_rep <- modal_group(rep_lookup %>% mutate(reporting_type = as.character(reporting_type)),
                        "reporting_type")
  if (!is.null(cl_rep) && nrow(cl_rep)) {
    corr_by_reporting <- bind_rows(
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_reporting %>% rename(reporting_type = group),
       "By reporting type (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Reporting-type lookup present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Reporting-type lookup not found; skipping by-reporting correlations.\n")
}

# ---- 3b) By PH SPEND quintile (if available) ----
if (exists("ph_q") && is.data.frame(ph_q) && nrow(ph_q)) {
  cl_ph <- modal_group(ph_q %>% mutate(ph_quint = as.character(ph_quint)), "ph_quint")
  if (!is.null(cl_ph) && nrow(cl_ph)) {
    corr_by_ph <- bind_rows(
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_ph %>% rename(ph_spend_quintile = group),
       "By PH-spend quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] PH spend quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] PH spend quintiles not available; skipping.\n")
}

# ---- 3c) By INCOME quintile (if available) ----
if (exists("inc_q") && is.data.frame(inc_q) && nrow(inc_q)) {
  cl_inc <- modal_group(inc_q %>% mutate(inc_quint = as.character(inc_quint)), "inc_quint")
  if (!is.null(cl_inc) && nrow(cl_inc)) {
    corr_by_inc <- bind_rows(
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_inc %>% rename(income_quintile = group),
       "By income quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Income quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Income quintiles not available; skipping.\n")
}

```
COD standardized diversity maps
```{r}
# ──────────────────────────────────────────────────────────────
# COD standardized diversity — clusters (ONE 4-panel per metric)
#   • Panels: 1999–2004, 2005–2010, 2011–2017, 2018–2022
#   • AK/HI resized & shifted
#   • No top title; facet strips show period
#   • Outputs → figures/5yr_avg_stable/<metric>_4panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(tibble)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
  library(purrr)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ paths -------------------------------
metrics_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
out_dir_base    <- here("figures", "5yr_avg_stable")  # <-- flat output here
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)

# -------------------- projection ------------------------------
crs_proj <- 2163

# --------------------- stable periods -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")

# ------------------------ helpers -----------------------------
compute_limits <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return(list(lims = c(0, 1), diverging = FALSE))
  q <- stats::quantile(x, c(0.02, 0.98), na.rm = TRUE, names = FALSE)
  if (q[1] < 0 && q[2] > 0) {
    L <- max(abs(q))
    list(lims = c(-L, L), diverging = TRUE)
  } else {
    list(lims = c(q[1], q[2]), diverging = FALSE)
  }
}

sanitize <- function(x) {
  x %>% str_replace_all("[^A-Za-z0-9]+", "_") %>% str_replace_all("^_+|_+$", "") %>% tolower()
}

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

build_cluster_sf <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df %>%
    dplyr::filter(.data$period == period_key) %>%
    dplyr::transmute(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                     cluster = as.character(cluster)) %>%
    dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)

  counties_sf %>%
    dplyr::inner_join(mm, by = "fips") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ------------------------- load data --------------------------
message("Reading metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading membership: ", membership_file)
membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster),
                period  = as.character(period),
                fips    = stringr::str_pad(as.character(fips), 5, pad = "0"))

# Prepare transformed geographies ONCE
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

# Metric columns & usable periods
metric_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
metric_cols <- setdiff(metric_cols, c("fips", "GEOID", "STATEFP", "COUNTYFP"))
periods_all <- intersect(period_levels, unique(metrics$period))

# ----------------------- faceted maps -------------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, diverging, states_sf) {
  ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(
      palette = "RdBu",
      direction = 1,
      limits = lims,
      oob = scales::squish,
      na.value = "grey90"
    ) +
    coord_sf(
      xlim = c(-2500000, 2500000),
      ylim = c(-2200000,  730000),
      expand = FALSE
    ) +
    labs(fill = NULL) +                # no legend title
    facet_wrap(~ period, ncol = 2) +   # 4 panels labeled by period
    theme_void() +
    theme(
      strip.text = element_text(size = 12, face = "bold"),
      legend.text = element_text(size = 9),
      plot.title = element_blank()     # <-- ensure no top title
    )
}

# For each metric: stack 4 periods → one 4-panel PNG
for (mcol in metric_cols) {
  message("Assembling 4-panel for metric: ", mcol)

  lims_info <- compute_limits(metrics[[mcol]])

  # Build cluster polygons per period, join metric, and stack
  stacked_sf <- map_dfr(periods_all, function(win) {
    cl_sf <- build_cluster_sf(win, membership, counties_tf)

    dat <- metrics %>%
      dplyr::filter(period == win) %>%
      dplyr::select(cluster, !!rlang::sym(mcol)) %>%
      dplyr::rename(value = !!rlang::sym(mcol))

    sf_cl <- cl_sf %>% dplyr::left_join(dat, by = "cluster")
    sf_cl$period <- win
    sf_cl
  }) %>%
    dplyr::mutate(period = factor(period, levels = period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals)) == 1) {
    message("  Skipping ", mcol, ": no finite variance across periods.")
    next
  }

  p <- make_faceted_map(
    stacked_sf = stacked_sf,
    fill_col   = "value",
    lims       = lims_info$lims,
    diverging  = lims_info$diverging,
    states_sf  = states_tf
  )

  fout <- file.path(out_dir_base, paste0(sanitize(mcol), "_4panel.png"))
  ggsave(fout, p, width = 10, height = 7.5, dpi = 320)
  message("  Saved: ", fout)
}

message("Done. 4-panel maps in: ", out_dir_base)

```
Scores by reporting type and public health spending for diversity metrics
```{r}
# ──────────────────────────────────────────────────────────────
# Phillips detail metrics vs reporting type & PH spend — FINAL+
# (period normalization, de-dup membership, robust fin-year snapping)
# + One time series per metric with 5 lines for PH-spend quintiles
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(tidyr); library(stringr)
  library(purrr); library(ggplot2); library(scales); library(here)
})

dir.create(here("figures","phillips_detail"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)

# ---- helpers --------------------------------------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

norm_period <- function(x) {
  # normalize "1999–2005", "1999-2005", "1999 — 2005", etc. → "1999_2005"
  x <- gsub("\u2013|\u2014|—|-", "_", x)  # en/em dash/hyphen → underscore
  x <- gsub("\\s+", "", x)                # drop spaces
  re <- regmatches(x, gregexpr("\\d{4}", x))
  out <- mapply(function(lbl, yrs) {
    if (length(yrs) >= 2) {
      y1 <- min(as.integer(yrs[1]), as.integer(yrs[2]))
      y2 <- max(as.integer(yrs[1]), as.integer(yrs[2]))
      paste0(y1, "_", y2)
    } else lbl
  }, x, re, USE.NAMES = FALSE)
  out
}

get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) {
    y1 <- min(yrs[1], yrs[2]); y2 <- max(yrs[1], yrs[2]); mid <- floor((y1 + y2)/2)
    tibble(period = lbl, start = y1, end = y2, mid = mid)
  } else tibble(period = lbl, start = NA_integer_, end = NA_integer_, mid = NA_integer_)
}
nearest_fin_year <- function(y, avail) if (!length(avail) || is.na(y)) NA_integer_ else avail[which.min(abs(avail - y))]

# ---- load cluster metrics + membership -----------------------
metrics_file_candidates <- c(
  here("output","cluster_metrics_ucr39_cstd.csv.gz"),
  here("output","cluster_metrics.csv.gz"),
  "output/cluster_metrics_ucr39_cstd.csv.gz",
  "output/cluster_metrics.csv.gz",
  "cluster_metrics_ucr39_cstd.csv.gz",
  "cluster_metrics.csv.gz"
)
membership_file_candidates <- c(
  here("output","county_cluster_membership.csv.gz"),
  "output/county_cluster_membership.csv.gz",
  "county_cluster_membership.csv.gz"
)
metrics_file    <- metrics_file_candidates[file.exists(metrics_file_candidates)][1]
membership_file <- membership_file_candidates[file.exists(membership_file_candidates)][1]
stopifnot(!is.na(metrics_file), !is.na(membership_file))

metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster),
         period  = norm_period(as.character(period)))

membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  mutate(cluster     = as.character(cluster),
         period      = norm_period(as.character(period)),
         county_ihme = std_fips(if ("fips" %in% names(.)) fips else if ("GEOID" %in% names(.)) GEOID else fips)) %>%
  filter(grepl("^[0-9]{5}$", county_ihme)) %>%
  distinct(cluster, period, county_ihme, .keep_all = FALSE)    # one row per key

# ---- pick 4 Phillips metrics ---------------------------------
num_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
preferred <- c(
  "detail_mcod_root3_cstd","detail_mcod_icd4_cstd","detail_ucod_root3_cstd","detail_ucod_icd4_cstd",
  "detail_d95","detail_d2000","detail_2000","detail_ref2000",
  "cod_diversity_cstd","cod_diversity_std","cod_diversity",
  "neff_cause","richness_cause","richness_cstd","neff_cstd"
)
present_pref <- intersect(preferred, num_cols)
if (length(present_pref) < 4) {
  extra <- setdiff(num_cols, present_pref)
  cand  <- extra[grepl("detail|divers|rich|neff|d95", extra, ignore.case = TRUE)]
  present_pref <- unique(c(present_pref, cand))
}
detail_cols <- unique(present_pref)[1:min(4, length(unique(present_pref)))]
stopifnot(length(detail_cols) > 0)
message("Using Phillips detail metrics: ", paste(detail_cols, collapse = " | "))

# ---- diagnostics: period coverage BEFORE expansion -----------
cat("\n# Period counts (metrics):\n")
print(metrics %>% count(period, name = "clusters_in_metrics") %>% arrange(period))
cat("\n# Period counts (membership):\n")
print(membership %>% count(period, name = "counties_in_membership") %>% arrange(period))

# ---- expand cluster→county -----------------------------------
detail_long <- metrics %>%
  select(cluster, period, all_of(detail_cols)) %>%
  pivot_longer(cols = all_of(detail_cols), names_to = "metric", values_to = "value") %>%
  inner_join(membership %>% select(cluster, period, county_ihme),
             by = c("cluster","period"),
             relationship = "many-to-many") %>%
  filter(is.finite(value))

cat("\n# After expansion: rows by period & metric\n")
print(detail_long %>% count(period, metric, name = "rows") %>% arrange(metric, period))

# ---- reporting-type lookup (or build) ------------------------
if (!exists("rep_lu")) {
  reporting_path_opts <- c(
    here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    "/mnt/data/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  reporting_path <- reporting_path_opts[file.exists(reporting_path_opts)][1]
  stopifnot(!is.na(reporting_path))
  rep_raw <- readr::read_csv(reporting_path, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df)
    hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_) else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  rep_lu <- rep_raw %>%
    mutate(county_ihme = std_fips(.data[[fips_col]]),
           reporting_type = trimws(as.character(.data[[type_col]]))) %>%
    filter(grepl("^[0-9]{5}$", county_ihme), !is.na(reporting_type), reporting_type != "") %>%
    mutate(reporting_type = dplyr::recode(tolower(reporting_type),
      "medical examiner"="Medical Examiner","me"="Medical Examiner",
      "coroner"="Coroner","mixed"="Mixed","hybrid"="Mixed",
      .default = stringr::str_to_title(reporting_type))) %>%
    select(county_ihme, reporting_type) %>% distinct()
}
cat("\n# Reporting-type coverage (distinct counties):\n")
print(rep_lu %>% count(reporting_type) %>% mutate(total = sum(n)))

# ---- finance-year snapping (+ fallback) — ROBUST --------------
# Make sure fin_year is integer for joins; be tolerant if fin_all missing
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")

# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))

# Main PH-per-period using nearest AVAILABLE finance year
ph_period_main <- period_info %>%
  dplyr::select(period, fin_year) %>%
  dplyr::inner_join(
    ph_pc %>% dplyr::select(county_ihme, fin_year, ph_pc),
    by = "fin_year", relationship = "many-to-many"
  ) %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6))) %>%
  dplyr::select(county_ihme, period, ph_pc, log_ph_pc)

# Fallback (periods without a mapped fin_year row will use county median spend)
ph_any <- ph_pc %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups = "drop") %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6)))

need_fallback <- setdiff(period_info$period, unique(ph_period_main$period))
ph_period_fb <- if (length(need_fallback)) {
  tidyr::crossing(county_ihme = unique(membership$county_ihme), period = need_fallback) %>%
    dplyr::left_join(ph_any, by = "county_ihme")
} else tibble(county_ihme = character(), period = character(), ph_pc = numeric(), log_ph_pc = numeric())

ph_period <- dplyr::bind_rows(ph_period_main, ph_period_fb)

cat("\n# Period→finance-year map (forced to available years)\n")
print(period_info %>% dplyr::mutate(fin_year = as.character(fin_year)))
cat("\n# PH spend rows by period (should be large)\n")
print(ph_period %>% dplyr::count(period, name = "rows") %>% dplyr::arrange(period))
cat("\n# ph_pc rows by fin_year\n")
print(ph_pc %>% dplyr::count(fin_year, name = "rows") %>% dplyr::arrange(fin_year))

# ---- A) Means by reporting type across periods ----------------
detail_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, reporting_type, metric) %>%
  summarise(avg_value = mean(value, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop") %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)]))

if (nrow(detail_rep) > 0) {
  g_detail_rep <- ggplot(detail_rep, aes(period_ord, avg_value, group = reporting_type, colour = reporting_type)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, scales = "free_y", ncol = 2) +
    labs(title = "Phillips detail metrics by reporting type (cluster→county, period means)",
         x = NULL, y = "Mean value", colour = "Reporting type") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_by_reporting_type_timeseries.png"),
         g_detail_rep, width = 9, height = 6.5, dpi = 300)
  print(g_detail_rep)
} else {
  message("No rows for reporting-type timeseries — skipping the plot.")
}

# ---- B) R²: metric ~ reporting_type (per period) --------------
r2_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || n_distinct(d$reporting_type) < 2) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ reporting_type, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ reporting_type (by period)\n")
print(r2_rep %>% arrange(metric, period))

# ---- C) R²: metric ~ log10(PH spend) (per period) -------------
r2_spend <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || !any(is.finite(d$log_ph_pc))) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ log_ph_pc, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ log10(PH spend per capita) (by period)\n")
print(r2_spend %>% arrange(metric, period))

# ---- D) Scatter (guarded) ------------------------------------
scatter_sample <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)])) %>%
  filter(is.finite(value), is.finite(log_ph_pc))

if (nrow(scatter_sample) > 0) {
  g_detail_spend <- ggplot(scatter_sample, aes(log_ph_pc, value)) +
    geom_point(alpha = 0.35, size = 1) +
    geom_smooth(method = "lm", se = FALSE, linewidth = 0.8) +
    facet_grid(metric ~ period_ord, scales = "free_y") +
    labs(title = "Phillips detail metrics vs log10(PH spend per capita)",
         x = "log10(PH spend per capita)", y = "Metric value") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_vs_ph_spend_scatter.png"),
         g_detail_spend, width = 12, height = 7.5, dpi = 300)
  print(g_detail_spend)
} else {
  message("No rows for spend vs metrics scatter — skipping the plot.")
}

# ---- E) NEW: Time series with multiple lines for PH-spend quintiles ----
# Quintiles computed GLOBALLY from each county's median PH spend (ph_any),
# so periods with sparse PH coverage still get full quintile lines.
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Build monotone breaks even if there are ties
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  # enforce strictly increasing breaks
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9
  qs[length(qs)] <- max(v) + 1e-9
  qs
}

quint_breaks <- make_quintile_breaks(ph_any$ph_pc)

county_quintile <- ph_any %>%
  mutate(spend_quintile = cut(ph_pc, breaks = quint_breaks, include.lowest = TRUE,
                              right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_quintile)

period_levels <- period_info$period[order(period_info$start)]

detail_with_quint <- detail_long %>%
  left_join(county_quintile, by = "county_ihme") %>%
  filter(!is.na(spend_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

# Summarize mean metric per period × quintile
ts_quint <- detail_with_quint %>%
  group_by(metric, period_ord, spend_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = dplyr::n(), .groups = "drop")

cat("\n# Rows per period × quintile (any metric):\n")
print(
  detail_with_quint %>%
    count(period_ord, spend_quintile, name = "rows") %>%
    tidyr::complete(period_ord = period_levels, spend_quintile = labs_quint, fill = list(rows = 0)) %>%
    arrange(period_ord, spend_quintile)
)

# Plot (guarded)
if (nrow(ts_quint) > 0) {
  g_quint <- ggplot(ts_quint,
                    aes(x = period_ord, y = avg_value,
                        group = spend_quintile, colour = spend_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(
      title = "Phillips detail metrics over time by public-health spend quintile",
      x = NULL, y = "Mean metric value", colour = "PH spend (per-capita) quintile"
    ) +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_spend_quintile.png"),
         g_quint, width = 10, height = 6.5, dpi = 300)
  print(g_quint)
} else {
  message("No rows for time-series-by-quintile — skipping the plot.")
}

# ---- F) Correlations with direction score (by period) ---------
assign_period <- function(y, info) {
  with(info, {
    p <- period[y >= start & y <= end]
    ifelse(length(p) >= 1, p[1], NA_character_)
  })
}
stopifnot(exists("direction_year"))
direction_period <- direction_year %>%
  mutate(period = vapply(year, assign_period, character(1), info = period_info)) %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop")

detail_wide <- detail_long %>%
  select(county_ihme, period, metric, value) %>%
  distinct() %>%
  pivot_wider(names_from = metric, values_from = value)

corr_tbl <- direction_period %>%
  inner_join(detail_wide, by = c("county_ihme","period"))

cols_metrics <- setdiff(names(detail_wide), c("county_ihme","period"))
corr_out <- map_dfr(split(corr_tbl, corr_tbl$period), function(dd) {
  tibble(
    period = unique(dd$period),
    metric = cols_metrics,
    pearson_r = map_dbl(cols_metrics, ~ suppressWarnings(
      cor(dd$direction_score, dd[[.x]], use = "pairwise.complete.obs")
    )),
    n = nrow(dd)
  )
})
readr::write_csv(corr_out, here("output","correlation_direction_vs_phillips_by_period.csv"))
cat("\nSaved correlations to: ", here("output","correlation_direction_vs_phillips_by_period.csv"), "\n")
print(corr_out %>% arrange(metric, period))
```
Check by income
```{r}
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")
# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))
# ---- G) Time series by INCOME quintiles ------------------------
safe_quintile <- function(x) {
  labs <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
  v <- x[is.finite(x)]
  if (length(v) < 5L || length(unique(v)) < 5L) {
    return(factor(rep(NA_character_, length(x)), levels = labs))
  }
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9
  cut(x, breaks = qs, include.lowest = TRUE, right = FALSE, labels = labs)
}

period_levels <- period_info$period[order(period_info$start)]

# Join detail with ACS income
detail_with_income <- detail_long %>%
  inner_join(income_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(avg_income)) %>%
  group_by(period) %>%
  mutate(income_quintile = safe_quintile(avg_income)) %>%
  ungroup() %>%
  filter(!is.na(income_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_income <- detail_with_income %>%
  group_by(metric, period_ord, income_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_income) > 0) {
  g_income <- ggplot(ts_income,
                     aes(x = period_ord, y = avg_value,
                         group = income_quintile, colour = income_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by INCOME quintile",
         x = NULL, y = "Mean metric value", colour = "Income quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_income_quintile.png"),
         g_income, width = 10, height = 6.5, dpi = 300)
  print(g_income)
} else {
  message("Income quintile time-series empty after guards — skipping.")
}


# ---- H) Time series by BA+ quintiles ---------------------------
detail_with_ba <- detail_long %>%
  inner_join(ba_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(ba_share)) %>%
  group_by(period) %>%
  mutate(ba_quintile = safe_quintile(ba_share)) %>%
  ungroup() %>%
  filter(!is.na(ba_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_ba <- detail_with_ba %>%
  group_by(metric, period_ord, ba_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_ba) > 0) {
  g_ba <- ggplot(ts_ba,
                 aes(x = period_ord, y = avg_value,
                     group = ba_quintile, colour = ba_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by BA+ share quintile",
         x = NULL, y = "Mean metric value", colour = "BA+ quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_ba_quintile.png"),
         g_ba, width = 10, height = 6.5, dpi = 300)
  print(g_ba)
} else {
  message("BA+ quintile time-series empty after guards — skipping.")
}

```
Pre-requisites
```{r}
# ---------- prerequisites ----------
if (!exists("prop_garbage_col") || !exists("overd_col")) {
  stop("Run the preamble that defines prop_garbage_col/overd_col and builds detail_year.")
}

# ---------- population weighting (robust & non-crashy) ----------
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) {
  as.character(pop_col)
} else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").")
        else "Population weighting OFF.")

# ---------- build base_sel (1999–2022), drop dummy FIPS ----------
base_sel <- cy %>%
  dplyr::mutate(
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    pg  = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    od  = suppressWarnings(as.numeric(.data[[overd_col]])),
    # create 'pop' ONLY if a population column is available; else NA
    pop = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  dplyr::filter(
    year >= 1999, year <= 2022,
    county_ihme != "00000", county_ihme != "0000"
  )

# ---------- temporally stable, safe weighted mean ----------
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)

# ---------- per-county temporally stable averages ----------
county_avg <- base_sel %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(
    prop_garbage = wmaybe(pg, pop),       # uses weights if present; else unweighted mean
    overd_unspec = wmaybe(od, pop),
    pop_wt       = if (pop_col_ok) mean(pop, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# ---------- detail averages from prebuilt detail_year ----------
detail_avg <- detail_year %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# PH spend quintiles (stable across finance years)
ph_any <- ph_pc %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  dplyr::filter(is.finite(ph_pc))

# Income quintiles (already pooled over time in your function)
income_quint <- income_quint %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000")


```
Validation: 4 metrics by public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# Time series by PUBLIC HEALTH SPENDING (4 plots incl. RI)
#   • X = year (1999–2022)
#   • Lines = PH-spend quintiles (county median of ph_pc across finance years)
#   • Weighted by population if available (fallback to n_cert)
# Saves:
#   figures/ph_spend_relationship/{prop_garbage,pct_overd_miss,detail_icd4,ri}_by_phspend_timeseries.png
#   figures/ph_spend_relationship/metrics_by_phspend_timeseries_4panel.png
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(here);  library(readr); library(stringr); library(patchwork)
})

dir.create(here("figures","ph_spend_relationship"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b

find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}

period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}

safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("ph_pc"))     # needs cy (county-year), ph_pc (finance)
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# Detect metric columns
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns in `cy`: prop_garbage (auto-detected) AND pct_overd_miss.")
}
ri_label <- "Reassignability Index (RI)"
have_ri  <- !is.na(ri_col)

# Population weights (prefer explicit pop_col; else fall back to n_cert if present)
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(pop_col_name)) pop_col_name <- if ("population" %in% names(cy)) "population" else NA_character_
weight_fallback <- NA_character_
if (is.na(pop_col_name)) {
  if ("n_cert" %in% names(cy)) { pop_col_name <- "n_cert"; weight_fallback <- "n_cert" }
}
pop_col_ok <- !is.na(pop_col_name)
message(
  if (pop_col_ok && is.na(weight_fallback)) paste0("Population weighting ON (", pop_col_name, ").")
  else if (pop_col_ok && weight_fallback == "n_cert") "Weighting by n_cert (fallback)."
  else "Population weighting OFF (no weights found)."
)

# ---------- PH spend quintiles (stable per county) ----------
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000", county_ihme != "0000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>%
  mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE, right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# ---------- detail_year (bring ICD-4 detail to year) ----------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit   <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric found in `detail_long`.")
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000", county_ihme != "0000") %>%
    distinct()
}

# ---------- assemble county-year series (with weights) ----------
base_sel <- cy %>%
  mutate(
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    weight         = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022,
         county_ihme != "00000", county_ihme != "0000") %>%
  select(county_ihme, year, prop_garbage, pct_overd_miss, ri, weight) %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(spend_quint,  by = "county_ihme")

# ---------- aggregate to year × PH-spend quintile (WEIGHTED) ----------
ts_spend <- base_sel %>%
  group_by(year, spend_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(spend_q = factor(spend_q, levels = labs_quint))

# ---------- plotting helper ----------
plot_metric_spend_ts <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no finite data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = spend_q)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("County means by PH-spend quintile (1999–2022)",
                        if (!is.na(weight_fallback)) paste0(", weighted by ", weight_fallback) else
                        if (pop_col_ok) ", population-weighted" else ", unweighted"),
      x = NULL, y = "Mean value", colour = "PH-spend quintile"
    ) +
    theme_bw(base_size = 12)
  ggsave(here("figures","ph_spend_relationship", file_out), p, width = 8.8, height = 5.2, dpi = 320)
  p
}

p1 <- plot_metric_spend_ts(ts_spend, "prop_garbage",   "Proportion garbage (UCOD)",           "prop_garbage_by_phspend_timeseries.png")
p2 <- plot_metric_spend_ts(ts_spend, "pct_overd_miss", "Overdose % missing",                   "pct_overd_miss_by_phspend_timeseries.png")
p3 <- plot_metric_spend_ts(ts_spend, "detail_icd4",    "Phillips detail (UCOD, ICD-4)",       "detail_icd4_by_phspend_timeseries.png")
p4 <- plot_metric_spend_ts(ts_spend, "ri",             ri_label,                               "ri_by_phspend_timeseries.png")

combined <- wrap_plots(p1, p2, p3, p4, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","ph_spend_relationship","metrics_by_phspend_timeseries_4panel.png"),
       combined, width = 9.5, height = 16, dpi = 320)

# Show in Viewer
p1; p2; p3; p4

```
Validation: 4 metrics by reporting type
```{r}
# ──────────────────────────────────────────────────────────────
# Time series by REPORTING TYPE (4 weighted plots incl. RI)
#   • X = year (1999–2022)
#   • Lines = reporting type
#   • Weights: pop_col > population > n_cert (fallback)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","reporting_type_timeseries"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# metrics
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) stop("Need prop_garbage + pct_overd_miss in `cy`.")
have_ri <- !is.na(ri_col)

# weights (pop_col > population > n_cert)
w_col <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(w_col) && "population" %in% names(cy)) w_col <- "population"
if (is.na(w_col) && "n_cert"     %in% names(cy)) w_col <- "n_cert"
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# reporting type lookup (incl. “Other County Official”)
get_reporting_lookup <- function() {
  if (exists("rep_lu")) {
    stopifnot(all(c("county_ihme","reporting_type") %in% names(rep_lu)))
    return(rep_lu %>% transmute(county_ihme = std_fips(county_ihme),
                                reporting_type = as.character(reporting_type)))
  }
  candidates <- c(
    here::here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    here::here("data_raw","County-Death-Investigation-System-2018.csv"),
    "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  path <- candidates[file.exists(candidates)][1]
  if (is.na(path)) stop("No reporting-type lookup found.")
  rep_raw <- readr::read_csv(path, show_col_types = FALSE)

  get_colname <- function(df, patterns) {
    nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) NA_character_ else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  if (is.na(fips_col) || is.na(type_col)) stop("Could not detect FIPS/type columns.")

  rep_raw %>%
    transmute(
      county_ihme = std_fips(.data[[fips_col]]),
      reporting_type = dplyr::recode(
        stringr::str_to_title(trimws(as.character(.data[[type_col]]))),
        "Me"="Medical Examiner","Medical Examiner"="Medical Examiner",
        "Coroner"="Coroner","Mixed"="Mixed","Hybrid"="Mixed",
        .default = stringr::str_to_title(trimws(as.character(.data[[type_col]])))
      )
    ) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000", reporting_type != "") %>%
    distinct()
}
rep_lookup <- get_reporting_lookup() %>%
  mutate(
    reporting_type = {
      y <- stringr::str_to_lower(stringr::str_squish(as.character(reporting_type)))
      dplyr::case_when(
        y %in% c("me","medical examiner") ~ "Medical Examiner",
        y %in% c("coroner")               ~ "Coroner",
        y %in% c("mixed","hybrid")        ~ "Mixed",
        grepl("other", y)                 ~ "Other County Official",
        TRUE                              ~ stringr::str_to_title(y)
      )
    },
    reporting_type = factor(reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
  ) %>% filter(!is.na(reporting_type))
rt_levels <- levels(rep_lookup$reporting_type)

# detail_year
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>% transmute(
      county_ihme,
      year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
    )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% dplyr::filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric in `detail_long`.")
    detail_year <- dl %>% transmute(
      county_ihme,
      year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(value))
    ) %>% group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>% filter(county_ihme != "00000") %>% distinct()
}

# assemble series with weights
base_sel <- cy %>%
  transmute(
    county_ihme, year,
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    weight         = if (!is.na(w_col)) suppressWarnings(as.numeric(.data[[w_col]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000")

series_rt <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  mutate(reporting_type = factor(reporting_type, levels = rt_levels))

# weighted aggregation
ts_rt <- series_rt %>%
  group_by(year, reporting_type) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  )

plot_metric_rt <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = reporting_type)) +
    geom_line(linewidth = 1.2) + geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means by reporting type (1999–2022)"),
      x = NULL, y = "Mean value", colour = "Reporting type"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","reporting_type_timeseries", file_out), p, width = 8.8, height = 5.2, dpi = 320)
  p
}

p1 <- plot_metric_rt(ts_rt, "prop_garbage",   "Proportion garbage (UCOD)",          "prop_garbage_by_reporting_timeseries.png")
p2 <- plot_metric_rt(ts_rt, "pct_overd_miss", "Overdose % missing",                  "pct_overd_miss_by_reporting_timeseries.png")
p3 <- plot_metric_rt(ts_rt, "detail_icd4",    "Phillips detail (UCOD, ICD-4)",       "detail_icd4_by_reporting_timeseries.png")
p4 <- plot_metric_rt(ts_rt, "ri",             ri_label,                               "ri_by_reporting_timeseries.png")

combined <- wrap_plots(p1, p2, p3, p4, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","reporting_type_timeseries","metrics_by_reporting_timeseries_4panel.png"),
       combined, width = 9.5, height = 16, dpi = 320)

p1; p2; p3; p4

```
Validation: 4 metrics by income
```{r}
# ──────────────────────────────────────────────────────────────
# Metrics by INCOME — weighted everywhere (incl. RI)
#   A) x = income quintile; lines = PH-spend quintiles
#      • County-level metric averaged across years USING WEIGHTS
#      • Group means weighted by county SUM of weights across years
#   B) Time series: x = year; lines = income quintiles
#      • Weighted by year-specific weights
# Weights: pop_col > population > n_cert (fallback)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","income_relationship"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("figures","income_timeseries"),   recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"), exists("ph_pc"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# metrics
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) stop("Need prop_garbage + pct_overd_miss in `cy`.")
have_ri <- !is.na(ri_col)

# weights (pop_col > population > n_cert)
w_col <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(w_col) && "population" %in% names(cy)) w_col <- "population"
if (is.na(w_col) && "n_cert"     %in% names(cy)) w_col <- "n_cert"
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# income quintiles (county-level, stable)
get_income_quintiles <- function(cy_df) {
  income_candidates <- c("median_household_income","median_income","mhi","hh_income",
                         "income_pc","per_capita_income","pc_income","income")
  inc_col <- income_candidates[income_candidates %in% names(cy_df)][1]
  if (!is.na(inc_col)) {
    inc_any <- cy_df %>%
      transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
      group_by(county_ihme) %>% summarise(income = median(income_val, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(income))
  } else {
    if (!requireNamespace("tidycensus", quietly = TRUE)) stop("No income in `cy` and {tidycensus} not installed.")
    inc_acs <- tidycensus::get_acs(geography = "county", variables = "B19013_001",
                                   year = 2022, survey = "acs5", cache_table = TRUE, show_call = FALSE)
    inc_any <- inc_acs %>% transmute(county_ihme = std_fips(GEOID), income = as.numeric(estimate)) %>%
      filter(is.finite(income), county_ihme != "00000")
  }
  qb_inc <- make_quintile_breaks(inc_any$income)
  inc_any %>% mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                                    right = FALSE, labels = labs_quint)) %>%
    transmute(county_ihme, income_q)
}
income_quint <- get_income_quintiles(cy)

# PH-spend quintiles (for panel A line colour)
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>% mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE,
                                               right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# detail_year (to year)
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
    )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% dplyr::filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric in `detail_long`.")
    detail_year <- dl %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(value))
    ) %>% group_by(county_ihme, year) %>% summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>% filter(county_ihme != "00000") %>% distinct()
}

# ---------- weights per county-year ----------
w_df <- cy %>%
  transmute(county_ihme, year,
            weight = if (!is.na(w_col)) suppressWarnings(as.numeric(.data[[w_col]])) else NA_real_) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-year series (with weights) ----------
base_sel <- cy %>%
  transmute(
    county_ihme = std_fips(county_ihme), year,
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_
  ) %>%
  left_join(w_df, by = c("county_ihme","year")) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-level STABLE averages (weighted across years) ----------
county_avg <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  group_by(county_ihme) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    wt_sum         = sum(weight, na.rm = TRUE),
    .groups = "drop"
  )

# ============================================================
# A) Metrics vs INCOME quintile (x = income_q; lines = PH-spend quintiles)
#     Group means weighted by county wt_sum
# ============================================================
comb_A <- county_avg %>%
  inner_join(income_quint, by = "county_ihme") %>%
  inner_join(spend_quint,  by = "county_ihme")

metrics_cols_A <- intersect(c("prop_garbage","pct_overd_miss","detail_icd4","ri"), names(comb_A))

by_q_income_x <- comb_A %>%
  pivot_longer(cols = all_of(metrics_cols_A), names_to = "metric", values_to = "value") %>%
  group_by(metric, income_q, spend_q) %>%
  summarise(mean_value = safe_wmean(value, wt_sum), n = dplyr::n(), .groups = "drop") %>%
  mutate(
    metric   = dplyr::recode(metric,
                  prop_garbage="Proportion garbage (UCOD)",
                  pct_overd_miss="Overdose % missing",
                  detail_icd4="Phillips detail (UCOD, ICD-4)",
                  ri=ri_label),
    income_q = factor(income_q, levels = labs_quint),
    spend_q  = factor(spend_q,  levels = labs_quint)
  )

plot_lines_income <- function(df, mname, title, file_out) {
  dd <- df %>% filter(metric == mname, is.finite(mean_value))
  if (!nrow(dd)) { message("Skipping (no data): ", mname); return(NULL) }
  p <- ggplot(dd, aes(x = income_q, y = mean_value, group = spend_q, colour = spend_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2.2) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means (1999–2022) · Lines = PH-spend quintiles"),
      x = "Income quintile (median HH income)", y = "Mean metric", colour = "PH-spend quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_relationship", file_out), p, width = 8.8, height = 5.4, dpi = 320)
  p
}

pA_garb  <- plot_lines_income(by_q_income_x, "Proportion garbage (UCOD)", "Proportion garbage (UCOD)",       "prop_garbage_lines.png")
pA_overd <- plot_lines_income(by_q_income_x, "Overdose % missing",        "Overdose % missing",              "pct_overd_miss_lines.png")
pA_det   <- plot_lines_income(by_q_income_x, "Phillips detail (UCOD, ICD-4)", "Phillips detail (UCOD, ICD-4)", "detail_icd4_lines.png")
pA_ri    <- plot_lines_income(by_q_income_x, ri_label, ri_label, "ri_lines.png")

combined_A <- wrap_plots(pA_garb, pA_overd, pA_det, pA_ri, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_relationship","metrics_vs_income_lines_4panel.png"),
       combined_A, width = 9.5, height = 16, dpi = 320)

# ============================================================
# B) Time series by INCOME quintile (x = year; lines = income quintiles)
#     Weighted by year-specific weights
# ============================================================
series_inc <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(income_quint, by = "county_ihme")

ts_income <- series_inc %>%
  group_by(year, income_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(income_q = factor(income_q, levels = labs_quint))

plot_metric_income_ts <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = income_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means by income quintile (1999–2022)"),
      x = NULL, y = "Mean value", colour = "Income quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_timeseries", file_out), p, width = 8.8, height = 5.2, dpi = 320)
  p
}

pB1 <- plot_metric_income_ts(ts_income, "prop_garbage",   "Proportion garbage (UCOD)",      "prop_garbage_by_income_timeseries.png")
pB2 <- plot_metric_income_ts(ts_income, "pct_overd_miss", "Overdose % missing",              "pct_overd_miss_by_income_timeseries.png")
pB3 <- plot_metric_income_ts(ts_income, "detail_icd4",    "Phillips detail (UCOD, ICD-4)",  "detail_icd4_by_income_timeseries.png")
pB4 <- plot_metric_income_ts(ts_income, "ri",             ri_label,                          "ri_by_income_timeseries.png")

combined_B <- wrap_plots(pB1, pB2, pB3, pB4, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_timeseries","metrics_by_income_timeseries_4panel.png"),
       combined_B, width = 9.5, height = 16, dpi = 320)

pA_garb; pA_overd; pA_det; pA_ri; pB1; pB2; pB3; pB4

```
Validation: 4 metrics by excess COVID-19 deaths
```{r}
# ---- diagnostics using per-capita measures ----
suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr)
})

# 1) find population source ---------------------------------------------------
# prefer an existing population column in `cy` or `est`; otherwise attempt tidycensus
pop_col <- NULL
if ("population" %in% names(cy)) pop_col <- "population"
if (is.null(pop_col) && exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) pop_col <- pop_col
# sometimes est has a population column
if (is.null(pop_col) && "population" %in% names(est)) pop_col <- "population"

# helper to fetch pop with tidycensus if needed (optional)
fetch_pop_tidycensus_if_needed <- function() {
  if (!requireNamespace("tidycensus", quietly = TRUE)) {
    stop("No population column found in data. Install 'tidycensus' and set CENSUS_API_KEY to fetch populations, or add a population column to `cy`/`est`.")
  }
  # user must have CENSUS_API_KEY set in environment; choose ACS variable B01003_001 (total population)
  message("Attempting to fetch county populations via tidycensus::get_acs (requires CENSUS_API_KEY and internet).")
  library(tidycensus)
  pops <- tidycensus::get_acs(geography = "county", variables = "B01003_001", year = 2019, geometry = FALSE,
                              cache_table = TRUE) %>%
    transmute(state = str_pad(GEOID, 5, pad = "0"), # GEOID is 5-digit FIPS
              pop = estimate) %>%
    rename(county_ihme = state)
  pops
}

# build a county-level population table (county_ihme, pop)
if (!is.null(pop_col)) {
  pop_by_county <- cy %>%
    transmute(county_ihme = std_fips(county_ihme),
              pop = as.numeric(.data[[pop_col]])) %>%
    group_by(county_ihme) %>%
    summarise(pop = mean(pop, na.rm = TRUE), .groups = "drop")
} else {
  # try est (maybe has population)
  if ("population" %in% names(est)) {
    pop_by_county <- est %>%
      transmute(county_ihme = std_fips(FIPSCode),
                pop = as.numeric(population)) %>%
      group_by(county_ihme) %>%
      summarise(pop = mean(pop, na.rm = TRUE), .groups = "drop")
  } else {
    # attempt tidycensus (will error with message if tidycensus not installed or no APIKEY)
    pop_by_county <- fetch_pop_tidycensus_if_needed()
  }
}

# 2) compute county averages of exc and covid (as before) and then per-capita ----
est_sub <- est %>%
  transmute(county_ihme = std_fips(FIPSCode),
            year = as.integer(year), month = as.integer(month),
            excDeaths = as.numeric(excDeathsMed),   # median excess
            COVIDDeaths = as.numeric(COVIDDeathsUCD)) %>%
  mutate(ym = year*100 + month) %>%
  filter(ym >= 202003, ym <= 202208)

counts_by_county <- est_sub %>%
  group_by(county_ihme) %>%
  summarise(exc_avg = mean(excDeaths, na.rm = TRUE),
            covid_avg = mean(COVIDDeaths, na.rm = TRUE),
            .groups = "drop")

# join population
check_df <- county_avg %>%
  left_join(counts_by_county, by = "county_ihme") %>%
  left_join(pop_by_county, by = "county_ihme")

# 3) compute per-capita measures (per 100k) and stabilized rates ----------------
# add small epsilon to avoid division issues when pop==0 or NA
eps_pop <- 1
check_df <- check_df %>%
  mutate(pop = ifelse(is.na(pop) | pop <= 0, NA_real_, pop),
         exc_per100k   = (exc_avg / pop) * 1e5,
         covid_per100k = (covid_avg / pop) * 1e5,
         nc_excess_per100k = ((exc_avg - covid_avg) / pop) * 1e5)

# 4) quick sanity print --------------------------------------------------------
message("Rows with missing population will be omitted from per-capita checks.")
print(check_df %>% select(county_ihme, wt_sum, pop, exc_avg, covid_avg, exc_per100k, covid_per100k, nc_excess_per100k) %>% 
        arrange(desc(wt_sum)) %>% head(20), n = 20)

# 5) correlations: metric vs ratio (original) and vs per-capita NC excess -------------

# Example for prop_garbage; you can loop over metrics as before
metric <- "prop_garbage"
df_metric <- check_df %>% filter(is.finite(.data[[metric]]), !is.na(nc_excess_per100k))

# unweighted correlations
cor_unw_nc  <- cor(df_metric[[metric]], df_metric$nc_excess_per100k, use = "complete.obs")
cor_unw_exc <- cor(df_metric[[metric]], df_metric$exc_per100k, use = "complete.obs")
cor_unw_cvd <- cor(df_metric[[metric]], df_metric$covid_per100k, use = "complete.obs")

# weighted correlations (use wt_sum as weight)
cor_w_nc  <- w_pearson(df_metric[[metric]], df_metric$nc_excess_per100k, df_metric$wt_sum)
cor_w_exc <- w_pearson(df_metric[[metric]], df_metric$exc_per100k, df_metric$wt_sum)
cor_w_cvd <- w_pearson(df_metric[[metric]], df_metric$covid_per100k, df_metric$wt_sum)

data.frame(
  metric = metric,
  cor_unweighted_nc_per100k = cor_unw_nc,
  cor_weighted_nc_per100k = cor_w_nc["r"],
  cor_unweighted_exc_per100k = cor_unw_exc,
  cor_weighted_exc_per100k = cor_w_exc["r"],
  cor_unweighted_covid_per100k = cor_unw_cvd,
  cor_weighted_covid_per100k = cor_w_cvd["r"]
)

# 6) optional: repeat for all metrics (prop_garbage, detail_icd4, ri) ------------
metrics <- c("prop_garbage","detail_icd4","ri")
out_list <- lapply(metrics, function(m) {
  dfm <- check_df %>% filter(is.finite(.data[[m]]), !is.na(nc_excess_per100k))
  if (nrow(dfm) < 4) return(NULL)
  w_ok <- any(is.finite(dfm$wt_sum) & dfm$wt_sum > 0)
  corr_nc <- if (w_ok) w_pearson(dfm[[m]], dfm$nc_excess_per100k, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$nc_excess_per100k, NULL)
  corr_exc <- if (w_ok) w_pearson(dfm[[m]], dfm$exc_per100k, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$exc_per100k, NULL)
  corr_cvd <- if (w_ok) w_pearson(dfm[[m]], dfm$covid_per100k, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$covid_per100k, NULL)
  data.frame(
    metric = m,
    n_counties = nrow(dfm),
    cor_nc_r = corr_nc["r"], cor_nc_p = corr_nc["p"], cor_nc_lo = corr_nc["lo"], cor_nc_hi = corr_nc["hi"],
    cor_exc_r = corr_exc["r"], cor_cvd_r = corr_cvd["r"]
  )
}) %>% bind_rows()

print(out_list)

```



