---
title: "Mapping Notebook"
output: html_notebook
---

Temporality stable groupings
```{r}
# ──────────────────────────────────────────────────────────────
# 5-year average maps by temporally-stable IHME groups — NO EXTRA PROCESSING
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2","here","scales","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))
options(tigris_use_cache = TRUE, tigris_class = "sf")

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Variables to map (no transformations will be applied)
vars_to_map <- c(
  "prop_garbage", "DQ_rec_ig_frac_mean_garbage", "DQ_overall", "DQ_rec_ig_abs_mean", "foreman_garbage", "RI"
)

# 2) Load your county-year data (as-is); add time windows only
dq <- readr::read_csv(here::here("data","county_year_quality_metrics.csv"), show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = as.integer(year),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999–2005",
      year >= 2006 & year <= 2012 ~ "2006–2012",
      year >= 2013 & year <= 2019 ~ "2013–2019",
      year >= 2020 & year <= 2022 ~ "2020–2022",
      TRUE ~ NA_character_
    )
  )

# Keep only variables that actually exist; no conversions
vars_present <- intersect(vars_to_map, names(dq))
if (!length(vars_present)) stop("None of vars_to_map exist in dq. Check column names.")
vars_missing <- setdiff(vars_to_map, vars_present)
if (length(vars_missing)) message("Skipping missing vars: ", paste(vars_missing, collapse = ", "))

# 3) 5-year averages by temporally-stable group (means of existing cols only)
dq_avg <- dq %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(
    dplyr::across(dplyr::all_of(vars_present), ~ mean(.x, na.rm = TRUE)),
    n_years = dplyr::n(),
    .groups = "drop"
  )

# 4) Crosswalk for temporality-stable shapes (dissolve multi-GEOID groups)
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(orig_fips, 5, pad = "0"),
    county_ihme = stringr::str_pad(ihme_fips, 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 5) Build shapes per period & join averages
crs_proj <- 2163
shapefile_years <- c("1999–2005"=2000, "2006–2012"=2010, "2013–2019"=2019, "2020–2022"=2020)

st_shift <- function(x, offset) { sf::st_geometry(x) <- sf::st_geometry(x) + offset; x }
st_scale <- function(x, factor) { ctr <- sf::st_centroid(sf::st_union(x)); sf::st_geometry(x) <- (sf::st_geometry(x) - ctr) * factor + ctr; x }

# ——— Normalizer: ensure a 5-digit GEOID exists, with robust fallbacks ———
normalize_geoid <- function(sf, year) {
  nms <- names(sf)

  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    message("[", year, "] Using GEOID column: ", geoid_col)
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(geoid_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }

  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    message("[", year, "] Constructing GEOID from ", state_col, " + ", county_col)
    sf$GEOID <- paste0(
      stringr::str_pad(as.character(sf[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sf[[county_col]]), 3, pad = "0")
    )
    return(sf)
  }

  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    message("[", year, "] Using combined ID column: ", combo_col, " as GEOID")
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(combo_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }

  stop("No GEOID-compatible columns found in shapefile for year ", year,
       ". Columns were: ", paste(nms, collapse = ", "))
}

# ——— Build groups: normalize → transform → dissolve by county_ihme ———
build_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM")

  counties_norm <- normalize_geoid(counties_raw, year) %>%  # ← normalize FIRST
    sf::st_transform(crs_proj)

  groups_sf <- counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")  # st_union here

  # AK / HI layout (unchanged)
  alaska   <- groups_sf %>% dplyr::filter(substr(county_ihme,1,2)=="02") %>%
    { ctr <- sf::st_centroid(sf::st_union(.)); sf::st_geometry(.) <- (sf::st_geometry(.) - ctr)*0.40 + ctr; . } %>%
    { sf::st_geometry(.) <- sf::st_geometry(.) + c(1300000, -4900000); . } %>%
    sf::st_set_crs(crs_proj)
  hawaii   <- groups_sf %>% dplyr::filter(substr(county_ihme,1,2)=="15") %>%
    { ctr <- sf::st_centroid(sf::st_union(.)); sf::st_geometry(.) <- (sf::st_geometry(.) - ctr)*1.50 + ctr; . } %>%
    { sf::st_geometry(.) <- sf::st_geometry(.) + c(5200000, -1400000); . } %>%
    sf::st_set_crs(crs_proj)
  mainland <- groups_sf %>% dplyr::filter(!substr(county_ihme,1,2) %in% c("02","15"))

  dplyr::bind_rows(mainland, alaska, hawaii)
}

joined_by_period <- purrr::imap(
  shapefile_years,
  function(year, window) {
    shape_all <- build_groups_sf(year)
    dplyr::left_join(shape_all, dplyr::filter(dq_avg, time_window == window), by = "county_ihme")
  }
)

# 6) make_map — now shows titles; we pass ONLY period strings when calling
make_map <- function(sf_data, var, title = NULL, palette = "RdBu") {
  states <- tigris::states(cb = TRUE, class = "sf") |> st_transform(2163)

  fill_scale <- if (var == "prop_garbage") {
    scale_fill_distiller(palette = palette, limits = c(0.15, 0.4), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "prop_light") {
    scale_fill_distiller(palette = palette, limits = c(0.20, 0.40), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_overd_miss") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.75), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "direction_score") {
    scale_fill_distiller(palette = palette, limits = c(-1,1.5), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "DQ_overall") {
    scale_fill_distiller(palette = palette, limits = c(0,0.9), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "pct_acc_miss") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.75), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_mandeath_comp_k") {
    scale_fill_distiller(palette = palette, limits = c(5, 20), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var %in% c("pct_age_comp_k", "pct_sex_comp_k", "pct_race_comp_k")) {
    scale_fill_distiller(palette = palette, limits = c(99.5, 100), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "RI") {
    scale_fill_distiller(palette = palette, limits = c(0.1, 0.3), oob = scales::squish, direction = 1, na.value = "grey90")
  } else if (var == "pct_gc_N19") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.025), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (var == "pct_gc_J80") {
    scale_fill_distiller(palette = palette, limits = c(0, 0.005), oob = scales::squish, direction = -1, na.value = "grey90")
  } else if (startsWith(var, "pct_") || var == "overall_completeness_pct") {
    scale_fill_distiller(palette = palette, limits = c(0, 100), oob = scales::squish, direction = 1, na.value = "grey90")
  } else {
    scale_fill_distiller(palette = palette, oob = scales::squish, na.value = "grey90", direction = -1)
  }

  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    fill_scale +
    coord_sf(xlim = c(-2500000, 2500000),
             ylim = c(-2200000, 730000),
             expand = FALSE) +
    labs(title = title %||% "", fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),  # ← SHOW titles
      legend.text = element_text(size = 9)
    )
}

# 7) Save ONLY 4-panel maps (one panel per time window)
output_dir <- here::here("figures","5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

purrr::walk(vars_present, function(var) {
  p_1999 <- make_map(joined_by_period[["1999–2005"]], var, "1999–2005")
  p_2006 <- make_map(joined_by_period[["2006–2012"]], var, "2006–2012")
  p_2013 <- make_map(joined_by_period[["2013–2019"]], var, "2013–2019")
  p_2020 <- make_map(joined_by_period[["2020–2022"]], var, "2020–2022")

  combined <- (p_1999 | p_2006) / (p_2013 | p_2020)

  ggsave(filename = file.path(output_dir, paste0(var, "_4panel.png")),
         plot = combined, width = 12, height = 9, dpi = 320)
})

message("✓ Done. 4-panel maps saved to: ", output_dir)

```
Map RI scores with light clustering
```{r}
# ──────────────────────────────────────────────────────────────
# Map RI with temporally-stable clusters built from Foreman-garbage counts
#   • Clustering logic mirrors the overdose script
#   • Robust FG count across windows; min threshold = 50 per cluster
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2",
              "here","scales","igraph","tidyr","tibble","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))
options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Windows & inputs
periods_list <- list(
  "1999_2005" = 1999:2005,
  "2006_2012" = 2006:2012,
  "2013_2019" = 2013:2019,
  "2020_2022" = 2020:2022
)
periods_vec <- names(periods_list)

dq <- readr::read_csv(here::here("data","county_year_quality_metrics.csv.gz"),
                      show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = as.integer(year),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2006 & year <= 2012 ~ "2006_2012",
      year >= 2013 & year <= 2019 ~ "2013_2019",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    )
  )

stopifnot("RI" %in% names(dq))

# 2) IHME crosswalk (temporality-stable groups)
load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 3) Robust Foreman-garbage totals per IHME group (to build clusters)
fg_n_col <- intersect(c("foreman_garbage_n","fg_n","n_foreman_garbage","foreman_garbage_count"),
                      names(dq))[1] %||% NA_character_
total_col <- intersect(c("total_deaths","deaths","n_deaths","N","n","total","num_deaths","all_deaths"),
                       names(dq))[1] %||% NA_character_

dq <- dq %>%
  dplyr::mutate(
    fg_n = if (!is.na(fg_n_col)) {
      as.numeric(.data[[fg_n_col]])
    } else if ("foreman_garbage" %in% names(dq) && !is.na(total_col)) {
      suppressWarnings(as.numeric(foreman_garbage) * as.numeric(.data[[total_col]]))
    } else NA_real_
  ) %>%
  dplyr::mutate(fg_n = tidyr::replace_na(fg_n, 0))

fg_by_window <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(fg = sum(fg_n, na.rm = TRUE), .groups = "drop")

fg_wide <- fg_by_window %>%
  tidyr::pivot_wider(names_from = time_window, values_from = fg, values_fill = 0)
for (w in periods_vec) if (!w %in% names(fg_wide)) fg_wide[[w]] <- 0

robust_tbl <- fg_wide %>%
  dplyr::mutate(robust_fg = pmin(`1999_2005`,`2006_2012`,`2013_2019`,`2020_2022`, na.rm = TRUE)) %>%
  dplyr::transmute(county_ihme, robust_fg = as.numeric(robust_fg))

# 4) Shapefile helpers
crs_proj <- 2163
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

normalize_geoid <- function(sf, year) {
  nms <- names(sf)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(geoid_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    sf$GEOID <- paste0(
      stringr::str_pad(as.character(sf[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sf[[county_col]]), 3, pad = "0")
    )
    return(sf)
  }
  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(combo_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  stop("No GEOID-compatible columns found in shapefile for year ", year)
}

build_ihme_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM")
  counties_norm <- normalize_geoid(counties_raw, year) %>% sf::st_transform(crs_proj)
  counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")
}

# 5) Adjacency & greedy clustering (MIMICS OVERDOSE SCRIPT)
ihme2020 <- build_ihme_groups_sf(2020) %>% sf::st_transform(5070)
adj_list <- sf::st_touches(ihme2020)
neighbors_of <- setNames(
  lapply(seq_len(nrow(ihme2020)), function(i) ihme2020$county_ihme[adj_list[[i]]]),
  ihme2020$county_ihme
)

min_fg <- 50L
nodes_tbl <- ihme2020 %>%
  sf::st_drop_geometry() %>%
  dplyr::select(county_ihme) %>%
  dplyr::left_join(robust_tbl, by = "county_ihme") %>%
  dplyr::mutate(robust_fg = dplyr::coalesce(robust_fg, 0))

fg_vec   <- setNames(nodes_tbl$robust_fg, nodes_tbl$county_ihme)
to_assign <- names(fg_vec)
clusters  <- setNames(rep(NA_character_, length(fg_vec)), to_assign)
cid <- 1L

while (length(to_assign) > 0) {
  seed  <- to_assign[which.max(fg_vec[to_assign])]
  cur   <- seed
  total <- fg_vec[seed]
  avail <- setdiff(to_assign, seed)

  repeat {
    nbrs <- unique(unlist(neighbors_of[cur], use.names = FALSE))
    nbrs <- setdiff(intersect(nbrs, avail), cur)
    if (!length(nbrs)) break
    cand_totals <- total + fg_vec[nbrs]
    best_idx <- if (any(cand_totals < min_fg)) which.max(cand_totals) else which.min(abs(cand_totals - min_fg))
    best <- nbrs[best_idx]
    new_total <- total + fg_vec[best]
    if (is.na(new_total)) break
    if (new_total <= min_fg * 1.6 || total < min_fg) {
      cur   <- c(cur, best)
      total <- new_total
      avail <- setdiff(avail, best)
      if (total >= min_fg) break
    } else break
  }

  clusters[cur] <- paste0("CL", cid)
  to_assign <- setdiff(to_assign, cur)
  cid <- cid + 1L
}

# Merge small clusters into nearest big one (centroid rule) — same as overdose
centroids <- sf::st_centroid(ihme2020) %>% dplyr::mutate(county_ihme = ihme2020$county_ihme)
xy <- sf::st_coordinates(centroids)[,c("X","Y"), drop=FALSE]; rownames(xy) <- centroids$county_ihme

cluster_sum <- tapply(fg_vec[names(clusters)], clusters, sum, na.rm = TRUE)
small <- names(cluster_sum)[cluster_sum < min_fg]
big   <- names(cluster_sum)[cluster_sum >= min_fg]

if (length(small) && length(big)) {
  get_center <- function(cid) {
    memb <- names(clusters)[clusters == cid]
    colMeans(xy[memb,,drop=FALSE])
  }
  small_xy <- t(vapply(small, get_center, numeric(2L)))
  big_xy   <- t(vapply(big,   get_center, numeric(2L)))
  assign_to <- vapply(seq_len(nrow(small_xy)), function(i) {
    dif <- t(big_xy) - small_xy[i,]; which.min(colSums(dif*dif))
  }, integer(1L))
  for (i in seq_along(small)) {
    members <- names(clusters)[clusters == small[i]]
    clusters[members] <- big[assign_to[i]]
  }
}

cluster_map <- tibble::tibble(
  county_ihme = names(clusters),
  cluster_id  = unname(clusters)
)

# 6) Check threshold per window (diagnostic only)
check_df <- fg_by_window %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(fg_total = sum(fg, na.rm = TRUE), .groups = "drop")
if (any(check_df$fg_total < min_fg, na.rm = TRUE)) {
  warning("Some clusters are still < 50 FG in a window. Consider tweaking heuristics.")
}

# 7) Aggregate RI to cluster×window (mean, mirroring overdose script’s approach)
dq_cluster <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(
    RI = mean(RI, na.rm = TRUE),
    n_counties = dplyr::n_distinct(county_ihme),
    .groups = "drop"
  ) %>%
  tidyr::complete(cluster_id, time_window = periods_vec,
                  fill = list(RI = NA_real_, n_counties = 0L))

# 8) Shapes per period
build_clusters_sf <- function(year) {
  base <- build_ihme_groups_sf(year)
  base %>%
    dplyr::left_join(cluster_map, by = "county_ihme") %>%
    dplyr::filter(!is.na(cluster_id)) %>%
    dplyr::group_by(cluster_id) %>%
    dplyr::summarise(.groups = "drop") %>%
    sf::st_transform(crs_proj)
}

joined_by_period <- purrr::imap(shapefile_years, function(year, window) {
  shape_all <- build_clusters_sf(year)
  dplyr::left_join(shape_all,
                   dplyr::filter(dq_cluster, time_window == window),
                   by = "cluster_id")
})

# 9) Map helper — same “pretty” style; RI palette/limits like before
make_map <- function(sf_data, var = "RI", title = NULL, palette = "RdBu") {
  states <- tigris::states(cb = TRUE, class = "sf") |> sf::st_transform(crs_proj)
  fill_scale <- scale_fill_distiller(
    palette = palette,
    limits = if (var == "RI") c(0.1, 0.3) else NULL,
    oob = scales::squish,
    direction = 1,               # RI: higher = better (flip direction)
    na.value = "grey90"
  )
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    fill_scale +
    coord_sf(xlim = c(-2500000, 2500000),
             ylim = c(-2200000, 730000),
             expand = FALSE) +
    labs(title = title %||% "", fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 9)
    )
}

# 10) Save combined 2×2 with PERIOD-ONLY panel titles
output_dir <- here::here("figures", "5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

p_1999 <- make_map(joined_by_period[["1999_2005"]], "RI", "1999_2005")
p_2006 <- make_map(joined_by_period[["2006_2012"]], "RI", "2006_2012")
p_2013 <- make_map(joined_by_period[["2013_2019"]], "RI", "2013_2019")
p_2020 <- make_map(joined_by_period[["2020_2022"]], "RI", "2020_2022")

combined <- (p_1999 | p_2006) / (p_2013 | p_2020)

ggsave(filename = file.path(output_dir, "RI_clustered_fg50_4panel.png"),
       plot = combined, width = 12, height = 9, dpi = 320)

message("✓ Done. Single 4-panel RI map saved to: ",
        file.path(output_dir, "RI_clustered_fg50_4panel.png"))

```
Make map of percentage missing overdoses with clusters (four panels)
```{r}
# ──────────────────────────────────────────────────────────────
# Map pct_overd_miss with temporally-stable clusters (IHME groups)
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2",
              "here","scales","igraph","tidyr","tibble","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))
options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Windows & inputs
periods_list <- list(
  "1999_2005" = 1999:2005,
  "2006_2012" = 2006:2012,
  "2013_2019" = 2013:2019,
  "2020_2022" = 2020:2022
)
periods_vec <- names(periods_list)

dq <- readr::read_csv(here::here("data","county_year_quality_metrics.csv.gz"),
                      show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = as.integer(year),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2006 & year <= 2012 ~ "2006_2012",
      year >= 2013 & year <= 2019 ~ "2013_2019",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    )
  )

stopifnot(all(c("overd_n","pct_overd_miss") %in% names(dq)))

# 2) IHME crosswalk (temporality-stable groups)
load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 3) Robust overdose totals per IHME group
overd_by_window <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(overd = sum(overd_n, na.rm = TRUE), .groups = "drop")

overd_wide <- overd_by_window %>%
  tidyr::pivot_wider(names_from = time_window, values_from = overd, values_fill = 0)

for (w in periods_vec) if (!w %in% names(overd_wide)) overd_wide[[w]] <- 0

robust_tbl <- overd_wide %>%
  dplyr::mutate(
    robust_overd = pmin(`1999_2005`,`2006_2012`,`2013_2019`,`2020_2022`, na.rm = TRUE)
  ) %>%
  dplyr::transmute(county_ihme, robust_overd = as.numeric(robust_overd))

# 4) Shapefile helpers
crs_proj <- 2163
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

normalize_geoid <- function(sf, year) {
  nms <- names(sf)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(geoid_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    sf$GEOID <- paste0(
      stringr::str_pad(as.character(sf[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sf[[county_col]]), 3, pad = "0")
    )
    return(sf)
  }
  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    sf <- dplyr::rename(sf, GEOID = !!rlang::sym(combo_col))
    sf$GEOID <- stringr::str_pad(as.character(sf$GEOID), 5, pad = "0")
    return(sf)
  }
  stop("No GEOID-compatible columns found in shapefile for year ", year)
}

build_ihme_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM")
  counties_norm <- normalize_geoid(counties_raw, year) %>% sf::st_transform(crs_proj)
  counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")
}

# 5) Adjacency & greedy clustering
ihme2020 <- build_ihme_groups_sf(2020) %>% sf::st_transform(5070)
adj_list <- sf::st_touches(ihme2020)
neighbors_of <- setNames(
  lapply(seq_len(nrow(ihme2020)), function(i) ihme2020$county_ihme[adj_list[[i]]]),
  ihme2020$county_ihme
)

min_overd <- 50L
nodes_tbl <- ihme2020 %>%
  sf::st_drop_geometry() %>%
  dplyr::select(county_ihme) %>%
  dplyr::left_join(robust_tbl, by = "county_ihme") %>%
  dplyr::mutate(robust_overd = dplyr::coalesce(robust_overd, 0))

overd_vec <- setNames(nodes_tbl$robust_overd, nodes_tbl$county_ihme)
to_assign <- names(overd_vec)
clusters  <- setNames(rep(NA_character_, length(overd_vec)), to_assign)
cid <- 1L

while (length(to_assign) > 0) {
  seed  <- to_assign[which.max(overd_vec[to_assign])]
  cur   <- seed
  total <- overd_vec[seed]
  avail <- setdiff(to_assign, seed)

  repeat {
    nbrs <- unique(unlist(neighbors_of[cur], use.names = FALSE))
    nbrs <- setdiff(intersect(nbrs, avail), cur)
    if (!length(nbrs)) break
    cand_totals <- total + overd_vec[nbrs]
    best_idx <- if (any(cand_totals < min_overd)) which.max(cand_totals) else which.min(abs(cand_totals - min_overd))
    best <- nbrs[best_idx]
    new_total <- total + overd_vec[best]
    if (is.na(new_total)) break
    if (new_total <= min_overd * 1.6 || total < min_overd) {
      cur   <- c(cur, best)
      total <- new_total
      avail <- setdiff(avail, best)
      if (total >= min_overd) break
    } else break
  }

  clusters[cur] <- paste0("CL", cid)
  to_assign <- setdiff(to_assign, cur)
  cid <- cid + 1L
}

centroids <- sf::st_centroid(ihme2020) %>% dplyr::mutate(county_ihme = ihme2020$county_ihme)
xy <- sf::st_coordinates(centroids)[,c("X","Y"), drop=FALSE]; rownames(xy) <- centroids$county_ihme

cluster_sum <- tapply(overd_vec[names(clusters)], clusters, sum, na.rm = TRUE)
small <- names(cluster_sum)[cluster_sum < min_overd]
big   <- names(cluster_sum)[cluster_sum >= min_overd]

if (length(small) && length(big)) {
  get_center <- function(cid) {
    memb <- names(clusters)[clusters == cid]
    colMeans(xy[memb,,drop=FALSE])
  }
  small_xy <- t(vapply(small, get_center, numeric(2L)))
  big_xy   <- t(vapply(big,   get_center, numeric(2L)))
  assign_to <- vapply(seq_len(nrow(small_xy)), function(i) {
    dif <- t(big_xy) - small_xy[i,]; which.min(colSums(dif*dif))
  }, integer(1L))
  for (i in seq_along(small)) {
    members <- names(clusters)[clusters == small[i]]
    clusters[members] <- big[assign_to[i]]
  }
}

cluster_map <- tibble::tibble(
  county_ihme = names(clusters),
  cluster_id  = unname(clusters)
)

# 7) Check threshold per window
overd_by_window <- overd_by_window  # already computed
check_df <- overd_by_window %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(overdoses = sum(overd, na.rm = TRUE), .groups = "drop")
if (any(check_df$overdoses < min_overd, na.rm = TRUE)) {
  warning("Some clusters are still < 50 overdoses in a window. Consider tweaking heuristics.")
}

# 8) Aggregate pct_overd_miss to cluster×window with NA→0
dq_cluster <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::inner_join(cluster_map, by = "county_ihme") %>%
  dplyr::group_by(cluster_id, time_window) %>%
  dplyr::summarise(
    pct_overd_miss = mean(replace_na(pct_overd_miss, 0)),
    n_counties     = dplyr::n_distinct(county_ihme),
    .groups = "drop"
  ) %>%
  tidyr::complete(cluster_id, time_window = periods_vec,
                  fill = list(pct_overd_miss = 0, n_counties = 0L))

# 9) Shapes per period
build_clusters_sf <- function(year) {
  base <- build_ihme_groups_sf(year)
  base %>%
    dplyr::left_join(cluster_map, by = "county_ihme") %>%
    dplyr::filter(!is.na(cluster_id)) %>%
    dplyr::group_by(cluster_id) %>%
    dplyr::summarise(.groups = "drop") %>%
    sf::st_transform(crs_proj)
}

joined_by_period <- purrr::imap(shapefile_years, function(year, window) {
  shape_all <- build_clusters_sf(year)
  dplyr::left_join(shape_all,
                   dplyr::filter(dq_cluster, time_window == window),
                   by = "cluster_id")
})

# 10) Map helper — keeps your “pretty” title style
make_map <- function(sf_data, var = "pct_overd_miss", title = NULL, palette = "RdBu") {
  states <- tigris::states(cb = TRUE, class = "sf") |> sf::st_transform(crs_proj)
  fill_scale <- scale_fill_distiller(
    palette = palette,
    limits = if (var == "pct_overd_miss") c(0, 0.6) else NULL,
    oob = scales::squish,
    direction = -1,
    na.value = "grey90"
  )
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    fill_scale +
    coord_sf(xlim = c(-2500000, 2500000),
             ylim = c(-2200000, 730000),
             expand = FALSE) +
    labs(title = title %||% "", fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),  # old pretty title
      legend.text = element_text(size = 9)
    )
}

# 11) Save combined 2×2 with PERIOD-ONLY panel titles
output_dir <- here::here("figures", "5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

p_1999 <- make_map(joined_by_period[["1999_2005"]], "pct_overd_miss", "1999_2005")
p_2006 <- make_map(joined_by_period[["2006_2012"]], "pct_overd_miss", "2006_2012")
p_2013 <- make_map(joined_by_period[["2013_2019"]], "pct_overd_miss", "2013_2019")
p_2020 <- make_map(joined_by_period[["2020_2022"]], "pct_overd_miss", "2020_2022")

combined <- (p_1999 | p_2006) / (p_2013 | p_2020)

ggsave(filename = file.path(output_dir, "pct_overd_miss_4panel.png"),
       plot = combined, width = 12, height = 9, dpi = 320)

message("✓ Done. Single 4-panel map saved to: ",
        file.path(output_dir, "pct_overd_miss_4panel.png"))

```
Make map of z-scores
```{r}
# ──────────────────────────────────────────────────────────────
# Cluster z-scores & maps (overdose-unspecified, prop_garbage, RI, Philips)
#   • Robust to: membership duplicates, Philips column names, odd period labels
#   • Outputs:
#       - output/cluster_scores/cluster_zscores_overdose_philips_RI_propgarbage.csv
#       - figures/5yr_avg_stable/z_<metric>_4panel.png  (+ direction_score_4panel.png)
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(purrr)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ PATHS ------------------------
data_file       <- here("data",   "county_year_quality_metrics.csv")
membership_file <- here("output", "county_cluster_membership.csv.gz")
philips_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
out_dir_figs    <- here("figures","5yr_avg_stable")
out_dir_scores  <- here("output", "cluster_scores")
dir.create(out_dir_figs,   recursive = TRUE, showWarnings = FALSE)
dir.create(out_dir_scores, recursive = TRUE, showWarnings = FALSE)

# --------------------- periods & helpers -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
safe_div <- function(num, den) ifelse(is.finite(num) & is.finite(den) & den > 0, num / den, NA_real_)
compute_limits_symmetric <- function(x) {
  x <- x[is.finite(x)]; if (!length(x)) return(c(-1,1))
  L <- as.numeric(stats::quantile(abs(x), 0.98, na.rm = TRUE, names = FALSE))
  if (!is.finite(L) || L == 0) L <- 1
  c(-L, L)
}
sanitize <- function(x) { x %>% str_replace_all("[^A-Za-z0-9]+","_") %>% str_replace_all("^_+|_+$","") %>% tolower() }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }

# -------------------- projection & geometry helpers -------------------
crs_proj <- 2163
st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) { ctr <- st_centroid(st_union(sf_obj)); st_geometry(sf_obj) <- (st_geometry(sf_obj) - ctr) * scale + ctr; sf_obj }
build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)
  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> dplyr::rename(fips = GEOID, statefp = STATEFP) |> sf::st_make_valid()
}
build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)
  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> sf::st_make_valid()
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()

# ------------------------- load membership (dedupe) --------------------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        fips   = stringr::str_pad(as.character(fips), 5, pad = "0"),
        period = standardize_period(as.character(period)),
        cluster= as.character(cluster)
      ) %>%
      dplyr::left_join(ihme_map, by = "fips") %>%
      dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips)) %>%
      dplyr::select(county_ihme, period, cluster)
  } else stop("membership_file must contain 'county_ihme' or 'fips'.")

# dedupe to one row per county_ihme × period (mode if needed)
membership <- membership %>%
  dplyr::filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  dplyr::distinct(county_ihme, period, cluster)
dups <- membership %>% dplyr::count(county_ihme, period, name="n") %>% dplyr::filter(n > 1)
if (nrow(dups) > 0) message("Resolving ", nrow(dups), " county×period with multiple clusters (using modal cluster).")
membership <- membership %>%
  dplyr::group_by(county_ihme, period) %>%
  dplyr::summarise(cluster = mode_str(cluster), .groups="drop")

# --------------------- load county-year data -------------------
stopifnot(file.exists(data_file))
dy0 <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  dplyr::mutate(year = suppressWarnings(as.integer(year)),
                period = period_of_year(year))

if ("county_ihme" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
} else if ("fips" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0")) %>%
    dplyr::left_join(ihme_map, by = "fips") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))
} else stop("data_file must contain 'county_ihme' or 'fips'.")

# --- ensure N_garbage & garb_k exist before checks ---
nms <- names(dy)
col_n_cert <- pick_col(nms, c("n_cert","deaths","total","N"))
col_prop_g <- pick_col(nms, c("foreman_garbage","prop_garbage"))
if (!("N_garbage" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating N_garbage = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(N_garbage = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("garb_k" %in% nms) {
    message("Using garb_k as N_garbage"); dy <- dy %>% dplyr::mutate(N_garbage = garb_k)
  } else stop("Missing N_garbage and cannot construct it.")
}
if (!("garb_k" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating garb_k = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(garb_k = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("N_garbage" %in% names(dy)) {
    message("Creating garb_k from N_garbage"); dy <- dy %>% dplyr::mutate(garb_k = N_garbage)
  } else stop("Cannot create garb_k.")
}

# Required vars
need_vars <- c("county_ihme","period","overd_n","overd_miss_k","garb_k","n_cert","N_garbage","RI")
miss <- setdiff(need_vars, names(dy))
if (length(miss)) stop("Missing required columns in data_file: ", paste(miss, collapse=", "))

# ---------------- aggregate county → cluster×period -------------
cluster_core <- dy %>%
  dplyr::select(dplyr::all_of(need_vars)) %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::inner_join(membership, by = c("county_ihme","period")) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    sum_overd_miss_k = sum(overd_miss_k, na.rm = TRUE),
    sum_overd_n      = sum(overd_n,      na.rm = TRUE),
    sum_garb_k       = sum(garb_k,       na.rm = TRUE),
    sum_n_cert       = sum(n_cert,       na.rm = TRUE),
    sum_N_garbage    = sum(N_garbage,    na.rm = TRUE),
    num_RI_weighted  = sum(N_garbage * RI, na.rm = TRUE),
    prop_overd_unspec = safe_div(sum_overd_miss_k, sum_overd_n),
    prop_garbage      = safe_div(sum_garb_k,       sum_n_cert),
    RI_cluster        = safe_div(num_RI_weighted,  sum_N_garbage),
    .groups = "drop"
  )

# ---------------- bring in Philips (CSTD; tolerant) ------------
stopifnot(file.exists(philips_file))
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
# normalize column names to lowercase for matching
names(ph0) <- tolower(names(ph0))

# ensure period
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% dplyr::mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% dplyr::mutate(period = standardize_period(period))
}

# normalize IDs to cluster-level
if ("cluster" %in% names(ph0)) {
  ph_norm <- ph0 %>% dplyr::mutate(cluster = as.character(cluster))
} else if ("county_ihme" %in% names(ph0) || "fips" %in% names(ph0)) {
  tmp <- ph0
  if ("fips" %in% names(tmp) && !("county_ihme" %in% names(tmp))) {
    tmp <- tmp %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad="0")) %>%
      dplyr::left_join(ihme_map, by="fips")
  }
  if (!("county_ihme" %in% names(tmp))) stop("Philips file lacks id columns (cluster/county_ihme/fips).")
  ph_norm <- tmp %>%
    dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad="0")) %>%
    dplyr::inner_join(membership, by = c("county_ihme","period"))
} else stop("Philips file must contain 'cluster' or county id (county_ihme/fips).")

# pick cstd & weights robustly
ph_col <- pick_col(names(ph_norm), c("detail_ucod_icd4_cstd","cstd_ucr39","cstd","phillips_detail","philips_detail","cod_cstd","cod_cstd_ucr39"))
if (is.na(ph_col)) stop("Philips source missing CSTD column (tried philips_cstd/cstd_ucr39/cstd/phillips_detail/philips_detail/cod_cstd/...).")
w_col  <- pick_col(names(ph_norm), c("n_cert","deaths","total","n"))

philips_clu <- ph_norm %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::mutate(cluster = as.character(cluster)) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    w   = if (!is.na(w_col)) sum(.data[[w_col]], na.rm=TRUE) else NA_real_,
    num = if (!is.na(w_col)) sum(.data[[w_col]] * .data[[ph_col]], na.rm=TRUE) else sum(.data[[ph_col]], na.rm=TRUE),
    den = if (!is.na(w_col)) w else sum(!is.na(.data[[ph_col]])),
    philips_cstd = safe_div(num, den),
    .groups = "drop"
  ) %>%
  dplyr::filter(!is.na(philips_cstd))

# ---------------- merge & Z-scores -----------------------------
metrics_clu <- cluster_core %>%
  dplyr::inner_join(philips_clu, by = c("period","cluster")) %>%
  dplyr::filter(period %in% period_levels) %>%
  dplyr::arrange(period, cluster) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

score_vars  <- c("prop_overd_unspec","philips_cstd","RI_cluster","prop_garbage")
global_means <- vapply(score_vars, function(v) mean(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds   <- vapply(score_vars, function(v)  sd(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds[!is.finite(global_sds) | global_sds == 0] <- NA_real_

z_tbl <- metrics_clu %>%
  dplyr::mutate(dplyr::across(
    dplyr::all_of(score_vars),
    \(x, nm=cur_column()) if (is.na(global_sds[[nm]])) NA_real_ else (x - global_means[[nm]]) / global_sds[[nm]],
    .names = "z_{.col}"
  )) %>%
  # Flip signs: higher z = better (less garbage / fewer unspecified overdoses)
  dplyr::mutate(
    z_prop_garbage      = -z_prop_garbage,
    z_prop_overd_unspec = -z_prop_overd_unspec
  ) %>%
  dplyr::mutate(
    direction_score = rowMeans(dplyr::across(starts_with("z_")), na.rm = TRUE)
  ) %>%
  dplyr::arrange(period, cluster)

readr::write_csv(z_tbl, file.path(out_dir_scores, "cluster_zscores_overdose_philips_RI_propgarbage.csv"))

# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))

build_cluster_sf <- function(period_key, membership_df, counties_sf_aug) {
  mm <- membership_df %>% dplyr::filter(.data$period == period_key) %>% dplyr::transmute(county_ihme = as.character(county_ihme), cluster = as.character(cluster)) %>% dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)
  counties_sf_aug %>%
    dplyr::inner_join(mm, by = "county_ihme") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ---------------- 4-panel maps of Z-scores --------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, states_sf) {
  ggplot2::ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1, limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(fill = NULL) + facet_wrap(~ period, ncol = 2) + theme_void() +
    theme(strip.text = element_text(size = 12, face = "bold"), legend.text = element_text(size = 9), plot.title = element_blank())
}

to_map <- c("z_RI_cluster","z_prop_overd_unspec","z_prop_garbage","z_philips_cstd","direction_score")

for (mcol in to_map) {
  message("Assembling 4-panel for metric: ", mcol)
  stacked_sf <- purrr::map_dfr(period_levels, function(win){
    cl_sf <- build_cluster_sf(win, membership, counties_aug)
    dat   <- z_tbl %>% dplyr::filter(period==win) %>% dplyr::select(cluster, !!rlang::sym(mcol)) %>% dplyr::rename(value = !!rlang::sym(mcol))
    out   <- cl_sf %>% dplyr::left_join(dat, by="cluster"); out$period <- win; out
  }) %>% dplyr::mutate(period=factor(period, levels=period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals))==1) { message("  Skipping ", mcol, " (no variance)"); next }

  lims_sym <- compute_limits_symmetric(vals)  # symmetric for z-scores (centered at 0)
  p <- make_faceted_map(stacked_sf, "value", lims_sym, states_tf)

  base <- if (mcol == "direction_score") "direction_score" else sanitize(mcol)
  ggsave(file.path(out_dir_figs, paste0(base, "_4panel.png")), p, width=10, height=7.5, dpi=320)
}

message("✓ Done. Z-score CSV in: ", out_dir_scores, "  |  maps in: ", out_dir_figs)

```
Build public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# Build `fin_all` from fixed-width FinEstDAT (2017/2022) + PID crosswalk
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr); library(here)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# ---- 1) Parser for FinEst Individual Unit fixed-width file ----
# Layout (robustly inferred):
# [govt_id (14 chars)] [item_code (3 chars)] [amount (digits, right-justified)] [year (4)] [flag (1)]
# We parse from the RIGHT to avoid depending on space counts.
parse_finest_fixed <- function(path) {
  stopifnot(file.exists(path))
  lines <- read_lines(path, progress = FALSE)
  # drop blanks
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(tibble())

  # RIGHT-anchored extraction
  year  <- as.integer(str_sub(lines, -5, -2))
  flag  <- str_sub(lines, -1, -1)
  left1 <- str_sub(lines,  1, -6)                       # everything before year+flag
  # amount is trailing digits on left1
  m <- regexpr("(\\d+)\\s*$", left1, perl = TRUE)
  amt_str <- ifelse(m > 0, regmatches(left1, m), NA_character_)
  amount  <- suppressWarnings(as.numeric(amt_str))
  left2   <- ifelse(m > 0, substr(left1, 1, m - 1L), left1)
  left2   <- rtrim <- sub("\\s+$", "", left2)           # trim right spaces

  # last 3 chars of left2 are the raw item code (alpha+2digits OR 2digits+alpha)
  raw_item <- str_sub(left2, -3, -1)
  govt_id  <- str_sub(left2,  1, -4)

  # Normalize item code to LETTER+2DIGITS (e.g., "E32", "T01")
  item_code <- ifelse(grepl("^[A-Z][0-9]{2}$", raw_item, ignore.case = TRUE),
                      toupper(raw_item),
               ifelse(grepl("^[0-9]{2}[A-Z]$", raw_item, ignore.case = TRUE),
                      paste0(toupper(str_sub(raw_item, -1, -1)), str_sub(raw_item, 1, 2)),
                      toupper(raw_item)))

  tibble(
    govt_id  = govt_id,
    item_code = item_code,
    amount   = amount,
    year     = year,
    flag     = flag
  ) %>%
    filter(!is.na(amount), !is.na(year), nchar(govt_id) >= 10)
}

# ---- 2) PID crosswalk (maps govt_id → county FIPS if available) ----
# PID files vary; try TSV/CSV; look for columns like GOVTID/GOVT_ID and FIPS/GEOID/COUNTYFIPS.
# ──────────────────────────────────────────────────────────────
# Robust PID crosswalk for fixed‑width PID (e.g., Fin_PID_2022.txt)
# Extracts: govt_id (leading digits), county_ihme (stateFIPS + county)
# Lines look like:
# 011003160514BALDWIN COUNTY … 99003   22928722             093022
# ──────────────────────────────────────────────────────────────
read_pid_xwalk <- function(path) {
  if (!file.exists(path)) return(NULL)
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(NULL)

  # helper: leading digits = GOVTID
  lead_digits <- function(x) sub("^([0-9]+).*$", "\\1", x)

  # find the right-most 5-digit token that starts with "99" (e.g., 99015)
  find_99_code <- function(x) {
    m <- gregexpr("\\b99\\d{3}\\b", x, perl = TRUE)
    if (m[[1]][1] == -1) return(NA_character_)
    # take the last match on the line
    ix <- tail(m[[1]], 1)
    substr(x, ix, ix + attr(m[[1]], "match.length")[length(m[[1]])] - 1)
  }

  tib <- tibble::tibble(raw = lines) %>%
    dplyr::mutate(
      govt_id_raw = lead_digits(raw),
      state_fips  = substr(govt_id_raw, 1, 2),
      code_99     = vapply(raw, find_99_code, character(1)),
      county_ihme = dplyr::if_else(
        !is.na(code_99),
        paste0(state_fips, substr(code_99, 3, 5)),
        NA_character_
      )
    ) %>%
    dplyr::filter(!is.na(county_ihme), nchar(county_ihme) == 5) %>%
    dplyr::transmute(
      govt_id = govt_id_raw,
      county_ihme = stringr::str_pad(county_ihme, 5, pad = "0")
    ) %>%
    dplyr::distinct()

  if (!nrow(tib)) return(NULL)
  tib
}
# ---- 3) Locate files and build fin_all ----
find_first <- function(fname) {
  c(here("data_raw/finance", fname), fname) |> {\(p) p[file.exists(p)][1]}()
}

fin2017_path <- find_first("2017FinEstDAT_09202024modp_pu.txt")
fin2022_path <- find_first("2022FinEstDAT_09202024modp_pu.txt")
pid2017_path <- find_first("Fin_PID_2017.txt")
pid2022_path <- find_first("Fin_PID_2022.txt")

fin_tbls <- list()
if (!is.na(fin2017_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2017_path)))
if (!is.na(fin2022_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2022_path)))
stopifnot(length(fin_tbls) > 0)

fin_raw <- bind_rows(fin_tbls)

# PID crosswalks (optional but recommended for county mapping)
pid_xw <- bind_rows(
  list(read_pid_xwalk(pid2017_path), read_pid_xwalk(pid2022_path)) |> compact()
) %>% distinct()

# ---- 4) Filter to Public Health Expenditures (E32) and summarize by county ----
# item_code "E32" = expenditures, function 32 (Public Health)
fin_e32 <- fin_raw %>% filter(item_code == "E32")

if (nrow(fin_e32) == 0) {
  stop("Parsed finance files but found ZERO rows with item_code == 'E32'. ",
       "Double-check files and item code list; if needed, print a sample of item_code counts.")
}

# Map to counties
if (!nrow(pid_xw)) {
  stop("PID crosswalk not found or had no usable (govt_id, FIPS) columns. ",
       "Please provide Fin_PID_2017.txt / Fin_PID_2022.txt (or their actual paths).")
}

fin_all <- fin_e32 %>%
  left_join(pid_xw, by = "govt_id") %>%
  filter(!is.na(county_ihme)) %>%
  transmute(
    county_ihme = county_ihme,
    fin_year    = as.integer(year),
    ph_exp_total = as.numeric(amount)
  ) %>%
  group_by(county_ihme, fin_year) %>%
  summarise(ph_exp_total = sum(ph_exp_total, na.rm = TRUE), .groups = "drop")

# Sanity check
cat("# fin_all rows:", nrow(fin_all), "\n")
print(fin_all %>% count(fin_year, sort = TRUE))
```
Build pop and other needed things for next chunk
```{r}
# ──────────────────────────────────────────────────────────────
# REPAIR BLOCK — ensure components + build pop_join
# Run this ONCE before the PH-spend plotting code
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(purrr)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
as_county_ihme <- function(df) {
  nm <- names(df)
  id_col <- dplyr::case_when(
    "county_ihme" %in% nm ~ "county_ihme",
    "GEOID"       %in% nm ~ "GEOID",
    "fips"        %in% nm ~ "fips",
    "FIPS"        %in% nm ~ "FIPS",
    "countyrs"    %in% nm ~ "countyrs",
    TRUE ~ NA_character_
  )
  if (is.na(id_col)) stop("No county ID column found. Expect one of county_ihme/GEOID/fips/FIPS/countyrs.")
  df %>% mutate(county_ihme = std_fips(.data[[id_col]]))
}

# 1) Ensure direction_year has component z-cols
ensure_direction_components <- function(direction_year, df) {
  needed_comp <- c("z_DQ_prop_garbage","z_prop_light","z_pct_overd_miss","z_pct_acc_miss")
  if (all(needed_comp %in% names(direction_year))) return(direction_year)

  # We need the raw inputs in `df` to (re)compute z-scores
  req <- c("DQ_prop_garbage","prop_light","pct_overd_miss","pct_acc_miss","year")
  if (!exists("df") || !all(req %in% names(df))) {
    stop("direction_year lacks z-components and `df` is missing required columns: ",
         paste(setdiff(req, names(df)), collapse = ", "))
  }
  df <- as_county_ihme(df)

  # Compute global means/sds once
  gs <- df %>%
    summarise(across(
      c(DQ_prop_garbage, prop_light, pct_overd_miss, pct_acc_miss),
      list(mean = ~mean(.x, na.rm = TRUE), sd = ~sd(.x, na.rm = TRUE)),
      .names = "{.col}_{.fn}"
    ))
  z <- function(x, m, s) (x - m) / s

  # Join raw inputs to direction_year, then add missing z-cols
  direction_year %>%
    left_join(df %>% select(county_ihme, year,
                            DQ_prop_garbage, prop_light, pct_overd_miss, pct_acc_miss),
              by = c("county_ihme","year")) %>%
    mutate(
      z_DQ_prop_garbage = if (!"z_DQ_prop_garbage" %in% names(direction_year))
                            z(DQ_prop_garbage, gs$DQ_prop_garbage_mean, gs$DQ_prop_garbage_sd)
                          else z_DQ_prop_garbage,
      z_prop_light      = if (!"z_prop_light" %in% names(direction_year))
                            z(prop_light, gs$prop_light_mean, gs$prop_light_sd)
                          else z_prop_light,
      z_pct_overd_miss  = if (!"z_pct_overd_miss" %in% names(direction_year))
                            z(pct_overd_miss, gs$pct_overd_miss_mean, gs$pct_overd_miss_sd)
                          else z_pct_overd_miss,
      z_pct_acc_miss    = if (!"z_pct_acc_miss" %in% names(direction_year))
                            z(pct_acc_miss, gs$pct_acc_miss_mean, gs$pct_acc_miss_sd)
                          else z_pct_acc_miss
    ) %>%
    select(-DQ_prop_garbage, -prop_light, -pct_overd_miss, -pct_acc_miss)
}

direction_year <- ensure_direction_components(direction_year, df)

# 2) Build pop_join (ACS preferred; pid_all fallback)
build_pop_join <- function(fin_years) {
  # Reuse if already valid
  if (exists("pop_join", inherits = TRUE)) {
    pj <- get("pop_join", inherits = TRUE)
    if (all(c("county_ihme","fin_year","pop") %in% names(pj))) return(pj)
  }

  # Try ACS via tidycensus
  if (requireNamespace("tidycensus", quietly = TRUE)) {
    message("Building pop_join from ACS (B01001_001, ACS5) …")
    out <- purrr::map_dfr(sort(unique(stats::na.omit(as.integer(fin_years)))), function(y) {
      yy <- max(2009L, min(2023L, as.integer(y)))  # ACS5 window
      tidycensus::get_acs(
        geography = "county", variables = "B01001_001",
        year = yy, survey = "acs5", cache_table = TRUE, show_call = FALSE
      ) %>%
        transmute(county_ihme = GEOID, fin_year = y, pop = estimate)
    })
    if (nrow(out)) return(out)
  }

  # Fallback: pid_all (must exist and have year/pop)
  if (exists("pid_all", inherits = TRUE)) {
    message("Falling back to pid_all for population …")
    pid <- get("pid_all", inherits = TRUE)
    stopifnot(all(c("county_ihme","year","pop") %in% names(pid)))
    return(pid %>% transmute(county_ihme, fin_year = as.integer(year), pop))
  }

  stop("Could not build pop_join: neither ACS nor pid_all available.")
}

# Need fin_years from fin_all
if (!exists("fin_all", inherits = TRUE)) stop("fin_all not found — run the finance builder first.")
fin_all <- as_county_ihme(fin_all)
stopifnot(all(c("county_ihme","fin_year","ph_exp_total") %in% names(fin_all)))

avail_fin_years <- sort(unique(stats::na.omit(as.integer(fin_all$fin_year))))
if (!length(avail_fin_years)) stop("No valid fin_year values in fin_all.")

pop_join <- build_pop_join(avail_fin_years)

# Finally: build ph_pc for downstream chunk
ph_pc <- fin_all %>%
  filter(!is.na(fin_year)) %>%
  left_join(pop_join, by = c("county_ihme","fin_year")) %>%
  mutate(ph_pc = ph_exp_total / pop) %>%
  filter(is.finite(ph_pc))
```
Build income (need for next chunk)
```{r}
# ──────────────────────────────────────────────────────────────
# Build income_all from the US Census API (ACS 5-year, B19013_001)
# • Output columns: county_ihme, acs_year, avg_income
# • Uses fin_years_actual if present; otherwise defaults to c(2017, 2022)
# • Requires: tidycensus (preferred). Falls back to censusapi if needed.
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(tidyr)
})

# Helper: install/load a package quietly
ensure_pkg <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  invisible(TRUE)
}

# Decide which ACS years to fetch.
# County-level ACS 5-year is available 2009+; you likely want finance years like 2017 & 2022.
acs_years <- if (exists("fin_years_actual") && length(fin_years_actual)) {
  unique(suppressWarnings(as.integer(fin_years_actual)))
} else {
  c(2017L, 2022L)
}
acs_years <- acs_years[is.finite(acs_years) & acs_years >= 2009L]
acs_years <- sort(unique(acs_years))

if (!length(acs_years)) stop("No valid ACS years to fetch (need >=2009).")

# Preferred path: tidycensus
have_tidycensus <- FALSE
if (ensure_pkg("tidycensus")) {
  # Only set a key if user already has one in env/options; otherwise tidycensus still works for many calls.
  # You can pre-set with: tidycensus::census_api_key("YOUR_KEY", install = FALSE, overwrite = FALSE)
  suppressWarnings({
    have_tidycensus <- requireNamespace("tidycensus", quietly = TRUE)
  })
}

pull_income_tidycensus <- function(years) {
  purrr::map_dfr(years, function(y) {
    df <- tidycensus::get_acs(
      geography = "county",
      variables = "B19013_001",  # Median household income (dollars)
      year = y,
      survey = "acs5",
      cache_table = TRUE,
      geometry = FALSE
    )
    tibble::tibble(
      county_ihme = df$GEOID,                   # 5-digit FIPS
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$estimate))
    )
  })
}

# Fallback path: censusapi (raw var names differ slightly but include "B19013_001E")
pull_income_censusapi <- function(years) {
  ensure_pkg("censusapi")
  purrr::map_dfr(years, function(y) {
    df <- censusapi::getCensus(
      name   = "acs/acs5",
      vintage= y,
      vars   = c("NAME", "B19013_001E"),
      region = "county:*",
      regionin = "state:*"
    )
    tibble::tibble(
      county_ihme = stringr::str_pad(paste0(df$state, df$county), 5, pad = "0"),
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$B19013_001E))
    )
  })
}

income_all <- tryCatch(
  if (have_tidycensus) pull_income_tidycensus(acs_years) else pull_income_censusapi(acs_years),
  error = function(e) {
    message("[income_all] tidycensus pull failed or unavailable; trying censusapi…\n", conditionMessage(e))
    pull_income_censusapi(acs_years)
  }
) %>%
  mutate(
    county_ihme = as.character(county_ihme),
    acs_year    = as.integer(acs_year),
    avg_income  = suppressWarnings(as.numeric(avg_income))
  ) %>%
  filter(!is.na(avg_income), is.finite(avg_income)) %>%
  arrange(acs_year, county_ihme)

# Optional: restrict to CONUS (drop PR/AK/HI) if your workflow expects that
# income_all <- income_all %>% filter(!stringr::str_sub(county_ihme, 1, 2) %in% c("02","15","72"))

# Sanity checks
message("[income_all] Years fetched: ", paste(unique(income_all$acs_year), collapse = ", "))
message("[income_all] Rows: ", nrow(income_all), " | Counties per year (median): ",
        stats::median(table(income_all$acs_year)))

# (Optional) If you want real (inflation-adjusted) dollars, bring your CPI deflator here and do:
# income_all <- income_all %>% left_join(cpi_tbl, by = c("acs_year" = "year")) %>%
#   mutate(avg_income_real_2022 = avg_income * deflator_to_2022)
# Then, in your plotting chunk, switch avg_income → avg_income_real_2022.
``` 
Validation: z-scores by reporting type, per capita healthcare expenditure, and income
```{r}
# ──────────────────────────────────────────────────────────────
# Validation: direction_score (sum of z-scores) — SELF-CONTAINED
#   • Recomputes z-scores (incl. sign flips) from raw inputs
#   • Expands to county level via membership
#   • Time series by: REPORTING TYPE, PH spend quintile, INCOME quintile
# Saves:
#   figures/validation_zscore/direction_by_reporting.png
#   figures/validation_zscore/direction_by_spend_quintile.png
#   figures/validation_zscore/direction_by_income_quintile.png
#   figures/validation_zscore/direction_timeseries_3panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr);  library(tidyr);  library(ggplot2); library(scales)
  library(readr);  library(stringr); library(here);   library(purrr)
})

dir.create(here("figures","validation_zscore"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
safe_div <- function(num, den) ifelse(is.finite(num) & is.finite(den) & den > 0, num / den, NA_real_)
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
pick_first <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# ---------- file paths (robust candidates) ----------
data_candidates <- c(here("data","county_year_quality_metrics.csv"),
                     here("data","county_year_quality_metrics.csv.gz"))
membership_candidates <- c(here("output","county_cluster_membership.csv.gz"),
                           here("output","county_cluster_membership.csv"),
                           "output/county_cluster_membership.csv.gz")
philips_candidates <- c(here("output","cluster_metrics_ucr39_cstd.csv.gz"),
                        here("output","cluster_metrics.csv.gz"),
                        "output/cluster_metrics_ucr39_cstd.csv.gz")
reporting_candidates <- c(
  here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
  here("data_raw","County-Death-Investigation-System-2018.csv"),
  "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv",
  "data_raw/County-Death-Investigation-System-2018.csv"
)
ph_pc_candidates <- c(                       # PH per-capita (county, finance years)
  here("output","ph_pc.csv"),
  here("output","ph_per_capita.csv"),
  here("data","ph_pc.csv"),
  "output/ph_pc.csv"
)
income_candidates <- c(                      # income (county, ACS)
  here("output","income_all.csv"),
  here("data","income_all.csv"),
  "output/income_all.csv",
  "data/income_all.csv"
)

data_file       <- pick_first(data_candidates)
membership_file <- pick_first(membership_candidates)
philips_file    <- pick_first(philips_candidates)
reporting_file  <- pick_first(reporting_candidates)
ph_pc_file      <- pick_first(ph_pc_candidates)
income_file     <- pick_first(income_candidates)

stopifnot(!is.na(data_file), !is.na(membership_file), !is.na(philips_file))

# ---------- IHME crosswalk (for safety if only fips are present) ----------
ihme_map <- NULL
if (file.exists(here::here("data_raw","ihme_fips.rda"))) {
  load(here::here("data_raw","ihme_fips.rda"))
  if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
    ihme_map <- ihme_fips %>%
      transmute(fips = std_fips(orig_fips), county_ihme = std_fips(ihme_fips)) %>%
      distinct()
  }
}

# ---------- load membership (dedupe to modal cluster) ----------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      mutate(
        county_ihme = std_fips(county_ihme),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    m0 <- membership_raw %>%
      mutate(
        fips    = std_fips(fips),
        period  = standardize_period(as.character(period)),
        cluster = as.character(cluster)
      )
    if (!is.null(ihme_map)) {
      m0 <- m0 %>% left_join(ihme_map, by = "fips") %>%
        mutate(county_ihme = coalesce(county_ihme, fips)) %>%
        select(county_ihme, period, cluster)
    } else {
      m0 <- m0 %>% transmute(county_ihme = fips, period, cluster)
    }
    m0
  } else stop("membership file must contain county_ihme or fips")

membership <- membership %>%
  filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  distinct(county_ihme, period, cluster)

dups <- membership %>% count(county_ihme, period, name="n") %>% filter(n > 1)
if (nrow(dups) > 0)
  message("Resolving ", nrow(dups), " county×period with multiple clusters (using modal cluster).")

membership <- membership %>%
  group_by(county_ihme, period) %>%
  summarise(cluster = mode_str(cluster), .groups="drop")

# ---------- load county-year data ----------
cy <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  mutate(year = suppressWarnings(as.integer(year)),
         period = period_of_year(year))

if ("county_ihme" %in% names(cy)) {
  cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))
} else if ("fips" %in% names(cy)) {
  cy <- cy %>% mutate(fips = std_fips(fips))
  if (!is.null(ihme_map)) {
    cy <- cy %>% left_join(ihme_map, by = "fips") %>%
      mutate(county_ihme = coalesce(county_ihme, fips))
  } else {
    cy <- cy %>% mutate(county_ihme = fips)
  }
} else stop("data file must contain county_ihme or fips")

# Ensure N_garbage & garb_k exist
nms <- names(cy)
col_n_cert <- pick_col(nms, c("n_cert","deaths","total","N","n"))
col_prop_g <- pick_col(nms, c("foreman_garbage","prop_garbage"))
if (!("N_garbage" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating N_garbage = ", col_prop_g, " * ", col_n_cert)
    cy <- cy %>% mutate(N_garbage = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("garb_k" %in% nms) {
    message("Using garb_k as N_garbage"); cy <- cy %>% mutate(N_garbage = garb_k)
  } else stop("Missing N_garbage and cannot construct it.")
}
if (!("garb_k" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating garb_k = ", col_prop_g, " * ", col_n_cert)
    cy <- cy %>% mutate(garb_k = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("N_garbage" %in% names(cy)) {
    message("Creating garb_k from N_garbage"); cy <- cy %>% mutate(garb_k = N_garbage)
  } else stop("Cannot create garb_k.")
}

# ---------- aggregate county → cluster×period (OD, garbage, RI) ----------
need_vars <- c("county_ihme","period","overd_n","overd_miss_k","garb_k","n_cert","N_garbage","RI")
miss <- setdiff(need_vars, names(cy))
if (length(miss)) stop("Missing required columns in data: ", paste(miss, collapse=", "))

cluster_core <- cy %>%
  select(all_of(need_vars)) %>%
  filter(!is.na(period)) %>%
  inner_join(membership, by = c("county_ihme","period")) %>%
  group_by(period, cluster) %>%
  summarise(
    sum_overd_miss_k = sum(overd_miss_k, na.rm = TRUE),
    sum_overd_n      = sum(overd_n,      na.rm = TRUE),
    sum_garb_k       = sum(garb_k,       na.rm = TRUE),
    sum_n_cert       = sum(n_cert,       na.rm = TRUE),
    sum_N_garbage    = sum(N_garbage,    na.rm = TRUE),
    num_RI_weighted  = sum(N_garbage * RI, na.rm = TRUE),
    prop_overd_unspec = safe_div(sum_overd_miss_k, sum_overd_n),
    prop_garbage      = safe_div(sum_garb_k,       sum_n_cert),
    RI_cluster        = safe_div(num_RI_weighted,  sum_N_garbage),
    .groups = "drop"
  )

# ---------- bring in Philips (CSTD; tolerant) ----------
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
names(ph0) <- tolower(names(ph0))
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% mutate(period = standardize_period(period))
}

if ("cluster" %in% names(ph0)) {
  ph_norm <- ph0 %>% mutate(cluster = as.character(cluster))
} else if ("county_ihme" %in% names(ph0) || "fips" %in% names(ph0)) {
  tmp <- ph0
  if ("fips" %in% names(tmp) && !("county_ihme" %in% names(tmp))) {
    if (is.null(ihme_map)) stop("Philips has fips only and ihme_fips.rda is missing.")
    tmp <- tmp %>% mutate(fips = std_fips(fips)) %>% left_join(ihme_map, by="fips")
  }
  stopifnot("county_ihme" %in% names(tmp))
  ph_norm <- tmp %>%
    mutate(county_ihme = std_fips(county_ihme)) %>%
    inner_join(membership, by = c("county_ihme","period"))
} else stop("Philips file must contain 'cluster' or county id (county_ihme/fips).")

ph_col <- pick_col(names(ph_norm),
                   c("detail_ucod_icd4_cstd","detail_mcod_icd4_cstd","cstd_ucr39","cstd",
                     "phillips_detail","philips_detail","cod_cstd","cod_cstd_ucr39"))
if (is.na(ph_col)) stop("Philips source missing CSTD column (no suitable detail/cstd column found).")
w_col  <- pick_col(names(ph_norm), c("n_cert","deaths","total","n"))

philips_clu <- ph_norm %>%
  filter(!is.na(period)) %>%
  mutate(cluster = as.character(cluster)) %>%
  group_by(period, cluster) %>%
  summarise(
    w   = if (!is.na(w_col)) sum(.data[[w_col]], na.rm=TRUE) else NA_real_,
    num = if (!is.na(w_col)) sum(.data[[w_col]] * .data[[ph_col]], na.rm=TRUE) else sum(.data[[ph_col]], na.rm=TRUE),
    den = if (!is.na(w_col)) w else sum(!is.na(.data[[ph_col]])),
    philips_cstd = safe_div(num, den),
    .groups = "drop"
  ) %>%
  filter(!is.na(philips_cstd))

# ---------- z-scores (flip signs for OD & garbage) ----------
metrics_clu <- cluster_core %>%
  inner_join(philips_clu, by = c("period","cluster")) %>%
  filter(period %in% period_levels) %>%
  arrange(period, cluster) %>%
  mutate(cluster = as.character(cluster), period = as.character(period))

score_vars  <- c("prop_overd_unspec","philips_cstd","RI_cluster","prop_garbage")
global_means <- vapply(score_vars, function(v) mean(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds   <- vapply(score_vars, function(v)  sd(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds[!is.finite(global_sds) | global_sds == 0] <- NA_real_

z_tbl <- metrics_clu %>%
  mutate(across(
    all_of(score_vars),
    \(x, nm=cur_column()) if (is.na(global_sds[[nm]])) NA_real_ else (x - global_means[[nm]]) / global_sds[[nm]],
    .names = "z_{.col}"
  )) %>%
  mutate(                      # flip signs so higher = better
    z_prop_garbage      = -z_prop_garbage,
    z_prop_overd_unspec = -z_prop_overd_unspec
  ) %>%
  mutate(direction_score = rowMeans(across(starts_with("z_")), na.rm = TRUE)) %>%
  arrange(period, cluster)

# ---------- expand to county (for all 3 panels) ----------
dir_long <- z_tbl %>%
  select(period, cluster, direction_score) %>%
  inner_join(membership %>% select(county_ihme, period, cluster),
             by = c("cluster","period")) %>%
  filter(is.finite(direction_score)) %>%
  mutate(period = factor(period, levels = period_levels))

# =================================================================
# Reporting-type LOOKUP + panel
# =================================================================
get_reporting_lookup <- function() {
  if (!is.na(reporting_file)) {
    rep_raw <- readr::read_csv(reporting_file, show_col_types = FALSE)
    get_colname <- function(df, patterns) {
      nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, \(p) grepl(p, nm, ignore.case = TRUE))))
      if (!length(hits)) return(NA_character_)
      nm[hits[1]]
    }
    fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
    type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
    stopifnot(!is.na(fips_col), !is.na(type_col))
    return(
      rep_raw %>%
        transmute(
          county_ihme = std_fips(.data[[fips_col]]),
          reporting_type = dplyr::recode(
            stringr::str_to_title(trimws(as.character(.data[[type_col]]))),
            "Me"="Medical Examiner", "Medical Examiner"="Medical Examiner",
            "Coroner"="Coroner", "Mixed"="Mixed", "Hybrid"="Mixed",
            .default = stringr::str_to_title(trimws(as.character(.data[[type_col]])))
          )
        ) %>%
        filter(nchar(county_ihme)==5, reporting_type!="") %>%
        distinct()
    )
  }
  stop("Reporting-type CSV not found under data_raw/.")
}
normalize_reporting_type <- function(x) {
  y <- stringr::str_to_lower(stringr::str_squish(as.character(x)))
  dplyr::case_when(
    y %in% c("me","medical examiner") ~ "Medical Examiner",
    y %in% c("coroner")               ~ "Coroner",
    y %in% c("mixed","hybrid")        ~ "Mixed",
    grepl("other", y)                 ~ "Other County Official",
    y %in% c("na","n/a","unknown","") ~ NA_character_,
    TRUE                              ~ stringr::str_to_title(y)
  )
}
rep_lookup <- get_reporting_lookup() %>%
  mutate(reporting_type = normalize_reporting_type(reporting_type)) %>%
  filter(!is.na(reporting_type)) %>%
  mutate(reporting_type = factor(reporting_type,
                                 levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))

ts_reporting <- dir_long %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  group_by(period, reporting_type) %>%
  summarise(mean_direction = mean(direction_score, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop")

p_rep <- ggplot(ts_reporting, aes(x = period, y = mean_direction, group = reporting_type, colour = reporting_type)) +
  geom_line(linewidth = 1.2) + geom_point(size = 2) +
  labs(title = "Z-score sum (direction_score) by reporting type",
       x = NULL, y = "Mean direction_score", colour = "Reporting type") +
  theme_bw(base_size = 12)

print(p_rep)
ggsave(here("figures","validation_zscore","direction_by_reporting.png"),
       p_rep, width = 9, height = 5.2, dpi = 320)
message("[REP] Saved reporting-type panel (rows=", nrow(ts_reporting), ").")

# =================================================================
# PH SPEND helpers + panel  — now recognizes in-memory `ph_pc`
# =================================================================
get_ph_any <- function(verbose = TRUE) {
  tell <- function(...) if (verbose) message("[PH] ", sprintf(...))

  # 0) in-memory `ph_pc` (preferred): expects county_ihme, ph_pc (and optional fin_year)
  if (exists("ph_pc", inherits = TRUE)) {
    pc <- get("ph_pc", inherits = TRUE)
    if (is.data.frame(pc)) {
      nms <- names(pc)
      id  <- pick_col(nms, c("county_ihme","fips","geoid"))
      val <- pick_col(nms, c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
      if (!is.na(id) && !is.na(val)) {
        tell("Using in-memory ph_pc object (columns: %s, %s).", id, val)
        out <- pc %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
          filter(is.finite(ph_pc))
        if (nrow(out)) return(out)
        tell("ph_pc object had no finite values after processing.")
      }
    }
  }

  # 1) in-memory `ph_pc_fin` (secondary simple frame)
  if (exists("ph_pc_fin", inherits = TRUE)) {
    ph_pc_fin <- get("ph_pc_fin", inherits = TRUE)
    if (is.data.frame(ph_pc_fin) && all(c("county_ihme","ph_pc") %in% names(ph_pc_fin))) {
      tell("Using in-memory ph_pc_fin")
      out <- ph_pc_fin %>%
        mutate(county_ihme = std_fips(county_ihme), ph_pc = suppressWarnings(as.numeric(ph_pc))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
      if (nrow(out)) return(out)
    }
  }

  # 2) file-based
  file_candidates <- c(ph_pc_file, here::here("output","finance","ph_pc.csv"), here::here("output","ph","ph_pc.csv"))
  file_candidates <- file_candidates[!is.na(file_candidates) & file.exists(file_candidates)]
  if (length(file_candidates)) {
    f <- file_candidates[1]; tell("Reading file: %s", f)
    ph_raw <- readr::read_csv(f, show_col_types = FALSE)
    id_col <- pick_col(names(ph_raw), c("county_ihme","fips","geoid"))
    val_col <- pick_col(names(ph_raw), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
    if (!is.na(id_col) && !is.na(val_col)) {
      out <- ph_raw %>%
        mutate(county_ihme = if (id_col=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id_col]]),
               ph_pc = suppressWarnings(as.numeric(.data[[val_col]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
      if (nrow(out)) return(out)
    }
  }

  # 3) fallback: column in cy
  cand <- c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap")
  ccol <- intersect(cand, names(cy))[1]
  if (!is.na(ccol)) {
    tell("Using cy$", ccol, " medians")
    out <- cy %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
      group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
      filter(is.finite(ph_pc))
    if (nrow(out)) return(out)
  }

  tell("PH per-capita not available.")
  NULL
}

get_ph_quintiles <- function() {
  # pre-made quintile in cy?
  qcol <- intersect(c("ph_quint","phspend_quint","ph_pc_quintile","ph_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[PH] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, ph_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  ph_any <- tryCatch(get_ph_any(verbose = TRUE), error = function(e) NULL)
  if (is.null(ph_any) || !nrow(ph_any)) {
    message("[PH] No PH per-capita or quintile source found — PH panel will be skipped.")
    return(NULL)
  }
  brks <- make_quintile_breaks(ph_any$ph_pc)
  ph_any %>%
    mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
}

ph_q <- get_ph_quintiles()
p_ph <- NULL
if (!is.null(ph_q) && nrow(ph_q)) {
  ts_ph <- dir_long %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))

  p_ph <- ggplot(ts_ph, aes(period, mean_direction, group = ph_quint, colour = ph_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Z-score sum (direction_score) by public-health spend quintile",
         x = NULL, y = "Mean direction_score", colour = "PH spend quintile") +
    theme_bw(base_size = 12)

  print(p_ph)
  out_path <- here("figures","validation_zscore","direction_by_spend_quintile.png")
  ggsave(out_path, p_ph, width = 9, height = 5.2, dpi = 320)
  message("[PH] Saved: ", out_path, "  (n rows=", nrow(ts_ph), ")")
} else {
  message("[PH] Panel skipped: could not derive quintiles.")
}

# =================================================================
# INCOME helpers + panel  — now recognizes in-memory `income_all`
# =================================================================
get_income_any <- function() {
  # 0) in-memory `income_all` (preferred): expects county_ihme + income column
  if (exists("income_all", inherits = TRUE)) {
    ia <- get("income_all", inherits = TRUE)
    if (is.data.frame(ia)) {
      nms <- names(ia)
      id  <- pick_col(nms, c("county_ihme","fips","geoid"))
      val <- pick_col(nms, c("avg_income","median_household_income","median_income","mhi","hh_income",
                             "income_pc","per_capita_income","pc_income","income"))
      if (!is.na(id) && !is.na(val)) {
        message("[INC] Using in-memory income_all (columns: ", id, ", ", val, ").")
        out <- ia %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 income = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
          filter(is.finite(income))
        if (nrow(out)) return(out)
      }
    }
  }

  # 1) from file
  if (!is.na(income_file) && file.exists(income_file)) {
    inc_raw <- readr::read_csv(income_file, show_col_types = FALSE)
    fips_col <- pick_col(names(inc_raw), c("county_ihme","fips","geoid"))
    val_col  <- pick_col(names(inc_raw), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                           "income_pc","per_capita_income","pc_income","income"))
    if (!is.na(fips_col) && !is.na(val_col)) {
      inc <- inc_raw %>%
        mutate(county_ihme = if (fips_col=="county_ihme") std_fips(county_ihme) else std_fips(.data[[fips_col]]),
               income = suppressWarnings(as.numeric(.data[[val_col]]))) %>%
        group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(income))
      if (nrow(inc)) return(inc)
    }
  }

  # 2) fallback: column in cy
  cand <- c("avg_income","median_household_income","median_income","mhi","hh_income",
            "income_pc","per_capita_income","pc_income","income","acs_income")
  ccol <- intersect(cand, names(cy))[1]
  if (!is.na(ccol)) {
    message("[INC] Using cy$", ccol, " medians")
    return(
      cy %>% transmute(county_ihme, income = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(income))
    )
  }
  NULL
}

get_income_quintiles <- function() {
  # pre-made quintile in cy?
  qcol <- intersect(c("inc_quint","income_quint","income_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[INC] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, inc_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  income_any <- tryCatch(get_income_any(), error = function(e) NULL)
  if (is.null(income_any) || !nrow(income_any)) {
    message("[INC] No income values or quintiles found — Income panel will be skipped.")
    return(NULL)
  }
  brks <- make_quintile_breaks(income_any$income)
  income_any %>%
    mutate(inc_quint = cut(income, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, inc_quint = factor(inc_quint, levels = labs_quint))
}

inc_q <- get_income_quintiles()
p_inc <- NULL
if (!is.null(inc_q) && nrow(inc_q)) {
  ts_inc <- dir_long %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))

  p_inc <- ggplot(ts_inc, aes(period, mean_direction, group = inc_quint, colour = inc_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Z-score sum (direction_score) by income quintile",
         x = NULL, y = "Mean direction_score", colour = "Income quintile") +
    theme_bw(base_size = 12)

  print(p_inc)
  out_path <- here("figures","validation_zscore","direction_by_income_quintile.png")
  ggsave(out_path, p_inc, width = 9, height = 5.2, dpi = 320)
  message("[INC] Saved: ", out_path, "  (n rows=", nrow(ts_inc), ")")
} else {
  message("[INC] Panel skipped: could not derive quintiles.")
}

# =================================================================
# Combined 3-panel (if at least two exist)
# =================================================================
panel_list <- list(
  "Reporting type"   = if (exists("p_rep") && inherits(p_rep, "gg")) p_rep else NULL,
  "PH spend quintile"= if (exists("p_ph")  && inherits(p_ph,  "gg")) p_ph  else NULL,
  "Income quintile"  = if (exists("p_inc") && inherits(p_inc, "gg")) p_inc else NULL
)
panel_list <- panel_list[ vapply(panel_list, inherits, logical(1), "gg") ]

if (length(panel_list) >= 2) {
  if (requireNamespace("patchwork", quietly = TRUE)) {
    p_all <- patchwork::wrap_plots(unname(panel_list), nrow = 1, guides = "collect") &
      theme(legend.position = "bottom")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel.")
  } else if (requireNamespace("cowplot", quietly = TRUE)) {
    p_all <- cowplot::plot_grid(plotlist = unname(panel_list), nrow = 1, align = "h")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel (cowplot).")
  } else {
    message("[ALL] Combined 3-panel skipped (patchwork/cowplot not available).")
  }
} else {
  message("[ALL] Not enough panels to create the combined summary; individual panels were saved.")
}

```



Correlation between the metrics
```{r}
# ──────────────────────────────────────────────────────────────
# Correlation between z-score metrics (overall, across all county-years)
# ──────────────────────────────────────────────────────────────
library(dplyr)

# Make sure these columns exist
z_cols <- c("z_DQ_prop_garbage", "z_prop_light", "z_pct_overd_miss", "z_pct_acc_miss")
stopifnot(all(z_cols %in% names(direction_year)))

# Pearson correlation
cor_pearson <- cor(direction_year %>% select(all_of(z_cols)),
                   use = "pairwise.complete.obs", method = "pearson")

# Spearman correlation
cor_spearman <- cor(direction_year %>% select(all_of(z_cols)),
                    use = "pairwise.complete.obs", method = "spearman")

cat("Pearson correlations:\n")
print(round(cor_pearson, 3))

cat("\nSpearman correlations:\n")
print(round(cor_spearman, 3))
```
Find drivers of diversity metric
```{r}
# ──────────────────────────────────────────────────────────────
# Drivers of Phillips "detail" (diversity) metric — CLUSTERS
#   • Reads UCOD/MCOD contribution files (gbdl3 or root3; top10/full)
#   • Chooses a target age bucket (prefers ALL-weighted → ALL → first found)
#   • Builds cluster polygons from county_cluster_membership.csv(.gz)
#   • Maps:
#       (A) Top driver category per cluster (limited to top-K nationwide)
#       (B) Dominant driver share (continuous)
#       (C) Small-multiples of shares for top-K categories
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(purrr)
  library(sf); library(tigris); library(ggplot2); library(glue); library(here)
  library(tidyr); library(forcats); library(tools)
})

options(tigris_use_cache = TRUE, tigris_class = "sf")
crs_proj <- 2163

# ── CONFIG ─────────────────────────────────────────────────────
# Period → shapefile year (match your clustering windows)
shapefile_years <- c(
  "1999_2006" = 2000,
  "2007_2014" = 2010,
  "2015_2022" = 2020
)

# Preferred age bucket(s) to map (first match wins)
PREFERRED_BUCKETS <- c("ALL-weighted","ALL","0-44","0-14","15-24","25-44","45-64","65-74","75-84","85+")

# How many top categories to keep for mapping; others → "Other"
TOP_K <- 8

# Color scale for share maps (in %)
lims_share <- c(0, 50)  # dominant share often in 20–50% range; adjust as needed

# Output base directory
out_dir <- here("figures","phillips_maps","drivers")

# ── Helpers: IO & parsing ─────────────────────────────────────
.read_csv_flex <- function(fname_options) {
  opts  <- as.character(fname_options)
  paths <- c(
    file.path(here("output"), opts),
    here(opts),
    file.path("/mnt/data", basename(opts))
  )
  hit <- paths[file.exists(paths)][1]
  if (is.na(hit)) stop("File not found among: ", paste(paths, collapse=" | "))
  readr::read_csv(hit, show_col_types = FALSE)
}

# Accepts .csv or .csv.gz
.try_read <- function(paths) {
  for (p in paths) {
    if (file.exists(p)) return(readr::read_csv(p, show_col_types = FALSE))
  }
  NULL
}

# Recognize an age-bucket-like string (ASCII)
.is_age_col <- function(nm) grepl("\\d{1,2}([-_ ]\\d{1,2}|\\+)|ALL", nm, ignore.case = TRUE)

# Normalizes contribution file to: cluster, period, age_bucket, cause, contrib
.normalize_contrib <- function(df) {
  nm <- names(df)

  # Harmonize id cols
  if (!"cluster" %in% nm && "clu" %in% nm) df <- dplyr::rename(df, cluster = clu)
  req <- c("cluster","period")
  if (!all(req %in% names(df))) stop("Contribution file must have: cluster, period (found: ", paste(nm, collapse=", "), ")")

  # Age bucket: if absent, assume ALL
  if (!"age_bucket" %in% nm) {
    # Some files might encode bucket inside column names; detect & gather:
    age_cols <- nm[vapply(nm, .is_age_col, logical(1))]
    if (length(age_cols) >= 2 && !"contrib" %in% nm) {
      # Wide w/ buckets as columns → long
      value_cols <- setdiff(age_cols, c("cluster","period"))
      df <- df %>%
        tidyr::pivot_longer(dplyr::all_of(value_cols), names_to = "age_bucket", values_to = "contrib")
      # guess cause col
      nm <- names(df)
    } else {
      df$age_bucket <- "ALL"
    }
  }

  # Contribution column (numeric)
  contrib_col <- intersect(names(df), c("contrib","contribution","value","detail_contrib","weight","share"))
  if (length(contrib_col) == 0) {
    # guess first numeric that's not an id
    cand <- setdiff(names(df), c("cluster","period","age_bucket"))
    numeric_candidates <- cand[vapply(df[cand], is.numeric, logical(1))]
    if (length(numeric_candidates) == 0) stop("No numeric contribution column found.")
    contrib_col <- numeric_candidates[1]
  }
  if (contrib_col[1] != "contrib") df <- dplyr::rename(df, contrib = dplyr::all_of(contrib_col[1]))

  # Cause column
  cause_candidates <- c("cause","gbd_l3","gbdl3","root3","uc3","cause_name","code","category")
  cause_col <- intersect(names(df), cause_candidates)
  if (length(cause_col) == 0) {
    # pick first non-id, non-numeric col
    cand <- setdiff(names(df), c("cluster","period","age_bucket","contrib"))
    chr_cand <- cand[vapply(df[cand], is.character, logical(1))]
    if (length(chr_cand) == 0) stop("No cause/category column found.")
    cause_col <- chr_cand[1]
  }
  if (cause_col[1] != "cause") df <- dplyr::rename(df, cause = dplyr::all_of(cause_col[1]))

  out <- df %>%
    dplyr::transmute(
      cluster = as.character(cluster),
      period  = as.character(period),
      age_bucket = as.character(age_bucket),
      cause   = as.character(cause),
      contrib = as.numeric(contrib)
    ) %>%
    dplyr::filter(!is.na(cluster), !is.na(period), !is.na(cause), !is.na(contrib))

  # Clean bucket label
  out$age_bucket <- gsub("[-_ ]", "-", out$age_bucket)
  out
}

# Choose the best available age bucket to map
.choose_bucket <- function(buckets) {
  buckets <- unique(as.character(buckets))
  hit <- intersect(PREFERRED_BUCKETS, buckets)
  if (length(hit)) return(hit[1])
  buckets[1]
}

# Filename-safe label
.sanitize <- function(x) x %>% gsub("\\+", "plus", ., perl = TRUE) %>% gsub("[^0-9A-Za-z]+", "_", ., perl = TRUE)

# ── Geospatial helpers ────────────────────────────────────────
.pick_fips <- function(df) {
  hits <- grep("^GEOID", names(df), value = TRUE)
  if (length(hits) >= 1) return(df[[hits[1]]])
  if (all(c("STATEFP","COUNTYFP") %in% names(df))) return(paste0(df$STATEFP, df$COUNTYFP))
  stop("No GEOID or STATEFP/COUNTYFP columns found in tigris::counties() output.")
}

build_cluster_sf <- function(period_name, shp_year, ccm_df) {
  counties_raw <- tigris::counties(year = shp_year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM") %>%
    sf::st_transform(crs_proj)

  counties_sf <- counties_raw %>%
    mutate(fips = stringr::str_pad(.pick_fips(counties_raw), 5, pad = "0")) %>%
    select(fips, geometry)

  m <- ccm_df %>% filter(period == period_name)
  if (nrow(m) == 0) stop("No county→cluster rows for period ", period_name)

  j <- counties_sf %>% left_join(m, by = "fips") %>% filter(!is.na(cluster))

  clusters_sf <- j %>%
    group_by(cluster) %>%
    summarise(geometry = sf::st_union(geometry), .groups = "drop")
  suppressWarnings(clusters_sf)
}

# Base map (states for outlines)
.states_sf <- function() tigris::states(cb = TRUE, class = "sf") %>% sf::st_transform(crs_proj)

# ── Plotters ──────────────────────────────────────────────────
make_category_map <- function(sf_data, var, title = NULL, palette = NULL) {
  states <- .states_sf()
  plot_title <- if (is.null(title)) var else title
  if (is.null(palette)) {
    palette <- scales::hue_pal()(length(unique(na.omit(sf_data[[var]]))))
  }
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    scale_fill_manual(values = palette, na.value = "grey90") +
    labs(title = plot_title, fill = NULL) +
    theme_void() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 9)
    )
}

make_share_map <- function(sf_data, var, title = NULL, limits = lims_share) {
  states <- .states_sf()
  plot_title <- if (is.null(title)) var else title
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[var]]), colour = NA) +
    geom_sf(data = states, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1,
                         limits = limits, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = plot_title, fill = "%") +
    theme_void() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 9)
    )
}

# ── Read inputs ───────────────────────────────────────────────
# County→cluster membership (csv or csv.gz)
ccm <- {
  paths <- c(
    here("output","county_cluster_membership.csv.gz"),
    here("output","county_cluster_membership.csv"),
    here("county_cluster_membership.csv.gz"),
    here("county_cluster_membership.csv"),
    "/mnt/data/county_cluster_membership.csv.gz"
  )
  df <- .try_read(paths)
  if (is.null(df)) stop("county_cluster_membership file not found (csv or csv.gz).")
  if (!all(c("fips","period","cluster") %in% names(df))) {
    stop("county_cluster_membership must have columns: fips, period, cluster")
  }
  df %>%
    mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0")) %>%
    select(fips, period, cluster) %>%
    mutate(period = as.character(period),
           cluster = as.character(cluster))
}

# Convenience loader for contrib files
read_contrib <- function(flavor = c("UCOD","MCOD"), domain = c("gbdl3","root3")) {
  flavor <- tolower(match.arg(flavor))
  domain <- tolower(match.arg(domain))
  base <- glue("detail_contrib_{flavor}_{domain}")
  candidates <- c(
    here("output", glue("{base}_top10.csv.gz")),
    here("output", glue("{base}_full.csv.gz")),
    here(glue("{base}_top10.csv.gz")),
    here(glue("{base}_full.csv.gz")),
    file.path("/mnt/data", glue("{base}_top10.csv.gz")),
    file.path("/mnt/data", glue("{base}_full.csv.gz")),
    here("output", glue("{base}_top10.csv")),
    here("output", glue("{base}_full.csv")),
    here(glue("{base}_top10.csv")),
    here(glue("{base}_full.csv")),
    file.path("/mnt/data", glue("{base}_top10.csv")),
    file.path("/mnt/data", glue("{base}_full.csv"))
  )
  df <- .try_read(candidates)
  if (is.null(df)) stop("No contribution file found for ", base)
  .normalize_contrib(df)
}

# ── Engine: build summaries and maps ──────────────────────────
make_driver_maps <- function(flavor = c("UCOD","MCOD"),
                             domain = c("gbdl3","root3"),
                             target_bucket = NULL,
                             top_k = TOP_K) {
  flavor <- toupper(match.arg(flavor))
  domain <- tolower(match.arg(domain))
  message("→ Loading contributions: ", flavor, " / ", toupper(domain))
  contrib <- read_contrib(flavor, domain)

  # Select target age bucket
  if (is.null(target_bucket)) {
    target_bucket <- .choose_bucket(contrib$age_bucket)
  }
  message("→ Using age bucket: ", target_bucket)

  contrib_tb <- contrib %>% filter(age_bucket == target_bucket)

  # Periods present that we have shapefiles for
  periods <- intersect(names(shapefile_years), unique(contrib_tb$period))

  # Create output dir
  base_dir <- file.path(out_dir, glue("{tolower(flavor)}-{domain}"))
  dir.create(base_dir, recursive = TRUE, showWarnings = FALSE)

  # Top-K categories nationwide (by total contrib) — separate by period to reflect shifts
  topk_by_period <- contrib_tb %>%
    group_by(period, cause) %>%
    summarise(total_contrib = sum(contrib, na.rm = TRUE), .groups = "drop_last") %>%
    arrange(period, desc(total_contrib)) %>%
    group_modify(~ head(.x, top_k)) %>%
    ungroup() %>%
    group_by(period) %>%
    summarise(top_k_causes = list(.data$cause), .groups = "drop")

  # For facet maps we’ll use a stable ordering of causes by national total
  topk_global <- contrib_tb %>%
    group_by(cause) %>%
    summarise(total_contrib = sum(contrib, na.rm = TRUE), .groups = "drop") %>%
    arrange(desc(total_contrib)) %>%
    slice_head(n = top_k) %>%
    pull(cause)

  # Build per-period maps
  walk(periods, function(win) {
    message("→ Mapping period: ", win)
    yr <- shapefile_years[[win]]
    cl_sf <- build_cluster_sf(win, yr, ccm)

    # Compute shares within cluster
    shares <- contrib_tb %>%
      filter(period == win) %>%
      group_by(cluster) %>%
      mutate(total = sum(contrib, na.rm = TRUE)) %>%
      filter(total > 0) %>%
      mutate(share = 100 * contrib / total) %>%
      ungroup()

    # Dominant cause and its share
    dom <- shares %>%
      arrange(cluster, desc(share)) %>%
      group_by(cluster) %>%
      slice_head(n = 1) %>%
      ungroup() %>%
      transmute(cluster, dom_cause = cause, dom_share = share)

    # Limit category map to period-specific top-K (others → "Other")
    period_top <- topk_by_period %>% filter(period == win) %>% pull(top_k_causes) %>% .[[1]]
    dom <- dom %>%
      mutate(dom_cause_limited = ifelse(dom_cause %in% period_top, dom_cause, "Other"),
             dom_cause_limited = forcats::fct_inorder(dom_cause_limited))

    # Join to geometry
    sf_dom <- cl_sf %>% left_join(dom, by = "cluster")

    # (A) Category map — dominant driver
    cats <- levels(sf_dom$dom_cause_limited)
    pal <- setNames(scales::hue_pal()(length(cats)), cats)
    pal["Other"] <- "grey70"

    pA <- make_category_map(
      sf_dom, "dom_cause_limited",
      title = glue("{flavor} {toupper(domain)} — Dominant driver — {win} (bucket: {target_bucket})"),
      palette = pal
    )
    foutA <- file.path(base_dir, glue("driver_domcat_{tolower(flavor)}_{domain}_{.sanitize(target_bucket)}_{win}.png"))
    ggsave(foutA, pA, width = 9, height = 6.2, dpi = 320)

    # (B) Share map — % share of dominant cause
    pB <- make_share_map(
      sf_dom, "dom_share",
      title = glue("{flavor} {toupper(domain)} — Dominant driver share (%) — {win} (bucket: {target_bucket})"),
      limits = lims_share
    )
    foutB <- file.path(base_dir, glue("driver_domshare_{tolower(flavor)}_{domain}_{.sanitize(target_bucket)}_{win}.png"))
    ggsave(foutB, pB, width = 9, height = 6.2, dpi = 320)

    # (C) Small multiples for global top-K causes — share by cluster
    shares_top <- shares %>%
      mutate(cause_f = ifelse(cause %in% topk_global, cause, NA_character_)) %>%
      filter(!is.na(cause_f)) %>%
      select(cluster, cause_f, share) %>%
      distinct()

    sf_facets <- cl_sf %>%
      left_join(shares_top, by = "cluster")

pC <- ggplot() +
  geom_sf(data = sf_facets, aes(fill = share, geometry = geometry), colour = NA) +
  geom_sf(data = .states_sf(), fill = NA, colour = "white", linewidth = 0.25) +
  scale_fill_distiller(
    palette = "RdBu", direction = 1,
    limits = c(0, max(25, ceiling(max(sf_facets$share, na.rm = TRUE) / 5) * 5))) + 
  coord_sf(
    xlim = c(-2500000, 2500000),
    ylim = c(-2200000, 730000),
    expand = FALSE
  ) +
  facet_wrap(~ cause_f, ncol = 3) +
  labs(
    title = glue("{flavor} {toupper(domain)} — Share of detail by cause — {win} (bucket: {target_bucket})"),
    fill = "%"
  ) +
  theme_void() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    legend.text = element_text(size = 9),
    strip.text = element_text(size = 10, face = "bold")
  )


    foutC <- file.path(base_dir, glue("driver_facets_{tolower(flavor)}_{domain}_{.sanitize(target_bucket)}_{win}.png"))
    ggsave(foutC, pC, width = 10, height = 9.5, dpi = 300)

    message("   Saved: ", foutA)
    message("   Saved: ", foutB)
    message("   Saved: ", foutC)
  })

  message("Done. Output in: ", base_dir)
}

# ── Run (edit as needed) ──────────────────────────────────────
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# Example runs (uncomment what you want)
make_driver_maps("UCOD", "gbdl3")  # preferred if you have GBD L3 files

# If you want ICD-10 root-3 drivers:
make_driver_maps("UCOD", "root3")
make_driver_maps("MCOD", "root3")

```
COD standardized diversity maps
```{r}
# ──────────────────────────────────────────────────────────────
# COD standardized diversity — clusters (ONE 4-panel per metric)
#   • Panels: 1999–2004, 2005–2010, 2011–2017, 2018–2022
#   • AK/HI resized & shifted
#   • No top title; facet strips show period
#   • Outputs → figures/5yr_avg_stable/<metric>_4panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(tibble)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
  library(purrr)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ paths -------------------------------
metrics_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
out_dir_base    <- here("figures", "5yr_avg_stable")  # <-- flat output here
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)

# -------------------- projection ------------------------------
crs_proj <- 2163

# --------------------- stable periods -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")

# ------------------------ helpers -----------------------------
compute_limits <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return(list(lims = c(0, 1), diverging = FALSE))
  q <- stats::quantile(x, c(0.02, 0.98), na.rm = TRUE, names = FALSE)
  if (q[1] < 0 && q[2] > 0) {
    L <- max(abs(q))
    list(lims = c(-L, L), diverging = TRUE)
  } else {
    list(lims = c(q[1], q[2]), diverging = FALSE)
  }
}

sanitize <- function(x) {
  x %>% str_replace_all("[^A-Za-z0-9]+", "_") %>% str_replace_all("^_+|_+$", "") %>% tolower()
}

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

build_cluster_sf <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df %>%
    dplyr::filter(.data$period == period_key) %>%
    dplyr::transmute(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                     cluster = as.character(cluster)) %>%
    dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)

  counties_sf %>%
    dplyr::inner_join(mm, by = "fips") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ------------------------- load data --------------------------
message("Reading metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading membership: ", membership_file)
membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster),
                period  = as.character(period),
                fips    = stringr::str_pad(as.character(fips), 5, pad = "0"))

# Prepare transformed geographies ONCE
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

# Metric columns & usable periods
metric_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
metric_cols <- setdiff(metric_cols, c("fips", "GEOID", "STATEFP", "COUNTYFP"))
periods_all <- intersect(period_levels, unique(metrics$period))

# ----------------------- faceted maps -------------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, diverging, states_sf) {
  ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(
      palette = "RdBu",
      direction = 1,
      limits = lims,
      oob = scales::squish,
      na.value = "grey90"
    ) +
    coord_sf(
      xlim = c(-2500000, 2500000),
      ylim = c(-2200000,  730000),
      expand = FALSE
    ) +
    labs(fill = NULL) +                # no legend title
    facet_wrap(~ period, ncol = 2) +   # 4 panels labeled by period
    theme_void() +
    theme(
      strip.text = element_text(size = 12, face = "bold"),
      legend.text = element_text(size = 9),
      plot.title = element_blank()     # <-- ensure no top title
    )
}

# For each metric: stack 4 periods → one 4-panel PNG
for (mcol in metric_cols) {
  message("Assembling 4-panel for metric: ", mcol)

  lims_info <- compute_limits(metrics[[mcol]])

  # Build cluster polygons per period, join metric, and stack
  stacked_sf <- map_dfr(periods_all, function(win) {
    cl_sf <- build_cluster_sf(win, membership, counties_tf)

    dat <- metrics %>%
      dplyr::filter(period == win) %>%
      dplyr::select(cluster, !!rlang::sym(mcol)) %>%
      dplyr::rename(value = !!rlang::sym(mcol))

    sf_cl <- cl_sf %>% dplyr::left_join(dat, by = "cluster")
    sf_cl$period <- win
    sf_cl
  }) %>%
    dplyr::mutate(period = factor(period, levels = period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals)) == 1) {
    message("  Skipping ", mcol, ": no finite variance across periods.")
    next
  }

  p <- make_faceted_map(
    stacked_sf = stacked_sf,
    fill_col   = "value",
    lims       = lims_info$lims,
    diverging  = lims_info$diverging,
    states_sf  = states_tf
  )

  fout <- file.path(out_dir_base, paste0(sanitize(mcol), "_4panel.png"))
  ggsave(fout, p, width = 10, height = 7.5, dpi = 320)
  message("  Saved: ", fout)
}

message("Done. 4-panel maps in: ", out_dir_base)

```
Scores by reporting type and public health spending for diversity metrics
```{r}
# ──────────────────────────────────────────────────────────────
# Phillips detail metrics vs reporting type & PH spend — FINAL+
# (period normalization, de-dup membership, robust fin-year snapping)
# + One time series per metric with 5 lines for PH-spend quintiles
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(tidyr); library(stringr)
  library(purrr); library(ggplot2); library(scales); library(here)
})

dir.create(here("figures","phillips_detail"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)

# ---- helpers --------------------------------------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

norm_period <- function(x) {
  # normalize "1999–2005", "1999-2005", "1999 — 2005", etc. → "1999_2005"
  x <- gsub("\u2013|\u2014|—|-", "_", x)  # en/em dash/hyphen → underscore
  x <- gsub("\\s+", "", x)                # drop spaces
  re <- regmatches(x, gregexpr("\\d{4}", x))
  out <- mapply(function(lbl, yrs) {
    if (length(yrs) >= 2) {
      y1 <- min(as.integer(yrs[1]), as.integer(yrs[2]))
      y2 <- max(as.integer(yrs[1]), as.integer(yrs[2]))
      paste0(y1, "_", y2)
    } else lbl
  }, x, re, USE.NAMES = FALSE)
  out
}

get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) {
    y1 <- min(yrs[1], yrs[2]); y2 <- max(yrs[1], yrs[2]); mid <- floor((y1 + y2)/2)
    tibble(period = lbl, start = y1, end = y2, mid = mid)
  } else tibble(period = lbl, start = NA_integer_, end = NA_integer_, mid = NA_integer_)
}
nearest_fin_year <- function(y, avail) if (!length(avail) || is.na(y)) NA_integer_ else avail[which.min(abs(avail - y))]

# ---- load cluster metrics + membership -----------------------
metrics_file_candidates <- c(
  here("output","cluster_metrics_ucr39_cstd.csv.gz"),
  here("output","cluster_metrics.csv.gz"),
  "output/cluster_metrics_ucr39_cstd.csv.gz",
  "output/cluster_metrics.csv.gz",
  "cluster_metrics_ucr39_cstd.csv.gz",
  "cluster_metrics.csv.gz"
)
membership_file_candidates <- c(
  here("output","county_cluster_membership.csv.gz"),
  "output/county_cluster_membership.csv.gz",
  "county_cluster_membership.csv.gz"
)
metrics_file    <- metrics_file_candidates[file.exists(metrics_file_candidates)][1]
membership_file <- membership_file_candidates[file.exists(membership_file_candidates)][1]
stopifnot(!is.na(metrics_file), !is.na(membership_file))

metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster),
         period  = norm_period(as.character(period)))

membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  mutate(cluster     = as.character(cluster),
         period      = norm_period(as.character(period)),
         county_ihme = std_fips(if ("fips" %in% names(.)) fips else if ("GEOID" %in% names(.)) GEOID else fips)) %>%
  filter(grepl("^[0-9]{5}$", county_ihme)) %>%
  distinct(cluster, period, county_ihme, .keep_all = FALSE)    # one row per key

# ---- pick 4 Phillips metrics ---------------------------------
num_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
preferred <- c(
  "detail_mcod_root3_cstd","detail_mcod_icd4_cstd","detail_ucod_root3_cstd","detail_ucod_icd4_cstd",
  "detail_d95","detail_d2000","detail_2000","detail_ref2000",
  "cod_diversity_cstd","cod_diversity_std","cod_diversity",
  "neff_cause","richness_cause","richness_cstd","neff_cstd"
)
present_pref <- intersect(preferred, num_cols)
if (length(present_pref) < 4) {
  extra <- setdiff(num_cols, present_pref)
  cand  <- extra[grepl("detail|divers|rich|neff|d95", extra, ignore.case = TRUE)]
  present_pref <- unique(c(present_pref, cand))
}
detail_cols <- unique(present_pref)[1:min(4, length(unique(present_pref)))]
stopifnot(length(detail_cols) > 0)
message("Using Phillips detail metrics: ", paste(detail_cols, collapse = " | "))

# ---- diagnostics: period coverage BEFORE expansion -----------
cat("\n# Period counts (metrics):\n")
print(metrics %>% count(period, name = "clusters_in_metrics") %>% arrange(period))
cat("\n# Period counts (membership):\n")
print(membership %>% count(period, name = "counties_in_membership") %>% arrange(period))

# ---- expand cluster→county -----------------------------------
detail_long <- metrics %>%
  select(cluster, period, all_of(detail_cols)) %>%
  pivot_longer(cols = all_of(detail_cols), names_to = "metric", values_to = "value") %>%
  inner_join(membership %>% select(cluster, period, county_ihme),
             by = c("cluster","period"),
             relationship = "many-to-many") %>%
  filter(is.finite(value))

cat("\n# After expansion: rows by period & metric\n")
print(detail_long %>% count(period, metric, name = "rows") %>% arrange(metric, period))

# ---- reporting-type lookup (or build) ------------------------
if (!exists("rep_lu")) {
  reporting_path_opts <- c(
    here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    "/mnt/data/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  reporting_path <- reporting_path_opts[file.exists(reporting_path_opts)][1]
  stopifnot(!is.na(reporting_path))
  rep_raw <- readr::read_csv(reporting_path, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df)
    hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_) else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  rep_lu <- rep_raw %>%
    mutate(county_ihme = std_fips(.data[[fips_col]]),
           reporting_type = trimws(as.character(.data[[type_col]]))) %>%
    filter(grepl("^[0-9]{5}$", county_ihme), !is.na(reporting_type), reporting_type != "") %>%
    mutate(reporting_type = dplyr::recode(tolower(reporting_type),
      "medical examiner"="Medical Examiner","me"="Medical Examiner",
      "coroner"="Coroner","mixed"="Mixed","hybrid"="Mixed",
      .default = stringr::str_to_title(reporting_type))) %>%
    select(county_ihme, reporting_type) %>% distinct()
}
cat("\n# Reporting-type coverage (distinct counties):\n")
print(rep_lu %>% count(reporting_type) %>% mutate(total = sum(n)))

# ---- finance-year snapping (+ fallback) — ROBUST --------------
# Make sure fin_year is integer for joins; be tolerant if fin_all missing
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")

# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))

# Main PH-per-period using nearest AVAILABLE finance year
ph_period_main <- period_info %>%
  dplyr::select(period, fin_year) %>%
  dplyr::inner_join(
    ph_pc %>% dplyr::select(county_ihme, fin_year, ph_pc),
    by = "fin_year", relationship = "many-to-many"
  ) %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6))) %>%
  dplyr::select(county_ihme, period, ph_pc, log_ph_pc)

# Fallback (periods without a mapped fin_year row will use county median spend)
ph_any <- ph_pc %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups = "drop") %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6)))

need_fallback <- setdiff(period_info$period, unique(ph_period_main$period))
ph_period_fb <- if (length(need_fallback)) {
  tidyr::crossing(county_ihme = unique(membership$county_ihme), period = need_fallback) %>%
    dplyr::left_join(ph_any, by = "county_ihme")
} else tibble(county_ihme = character(), period = character(), ph_pc = numeric(), log_ph_pc = numeric())

ph_period <- dplyr::bind_rows(ph_period_main, ph_period_fb)

cat("\n# Period→finance-year map (forced to available years)\n")
print(period_info %>% dplyr::mutate(fin_year = as.character(fin_year)))
cat("\n# PH spend rows by period (should be large)\n")
print(ph_period %>% dplyr::count(period, name = "rows") %>% dplyr::arrange(period))
cat("\n# ph_pc rows by fin_year\n")
print(ph_pc %>% dplyr::count(fin_year, name = "rows") %>% dplyr::arrange(fin_year))

# ---- A) Means by reporting type across periods ----------------
detail_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, reporting_type, metric) %>%
  summarise(avg_value = mean(value, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop") %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)]))

if (nrow(detail_rep) > 0) {
  g_detail_rep <- ggplot(detail_rep, aes(period_ord, avg_value, group = reporting_type, colour = reporting_type)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, scales = "free_y", ncol = 2) +
    labs(title = "Phillips detail metrics by reporting type (cluster→county, period means)",
         x = NULL, y = "Mean value", colour = "Reporting type") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_by_reporting_type_timeseries.png"),
         g_detail_rep, width = 9, height = 6.5, dpi = 300)
  print(g_detail_rep)
} else {
  message("No rows for reporting-type timeseries — skipping the plot.")
}

# ---- B) R²: metric ~ reporting_type (per period) --------------
r2_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || n_distinct(d$reporting_type) < 2) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ reporting_type, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ reporting_type (by period)\n")
print(r2_rep %>% arrange(metric, period))

# ---- C) R²: metric ~ log10(PH spend) (per period) -------------
r2_spend <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || !any(is.finite(d$log_ph_pc))) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ log_ph_pc, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ log10(PH spend per capita) (by period)\n")
print(r2_spend %>% arrange(metric, period))

# ---- D) Scatter (guarded) ------------------------------------
scatter_sample <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)])) %>%
  filter(is.finite(value), is.finite(log_ph_pc))

if (nrow(scatter_sample) > 0) {
  g_detail_spend <- ggplot(scatter_sample, aes(log_ph_pc, value)) +
    geom_point(alpha = 0.35, size = 1) +
    geom_smooth(method = "lm", se = FALSE, linewidth = 0.8) +
    facet_grid(metric ~ period_ord, scales = "free_y") +
    labs(title = "Phillips detail metrics vs log10(PH spend per capita)",
         x = "log10(PH spend per capita)", y = "Metric value") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_vs_ph_spend_scatter.png"),
         g_detail_spend, width = 12, height = 7.5, dpi = 300)
  print(g_detail_spend)
} else {
  message("No rows for spend vs metrics scatter — skipping the plot.")
}

# ---- E) NEW: Time series with multiple lines for PH-spend quintiles ----
# Quintiles computed GLOBALLY from each county's median PH spend (ph_any),
# so periods with sparse PH coverage still get full quintile lines.
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Build monotone breaks even if there are ties
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  # enforce strictly increasing breaks
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9
  qs[length(qs)] <- max(v) + 1e-9
  qs
}

quint_breaks <- make_quintile_breaks(ph_any$ph_pc)

county_quintile <- ph_any %>%
  mutate(spend_quintile = cut(ph_pc, breaks = quint_breaks, include.lowest = TRUE,
                              right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_quintile)

period_levels <- period_info$period[order(period_info$start)]

detail_with_quint <- detail_long %>%
  left_join(county_quintile, by = "county_ihme") %>%
  filter(!is.na(spend_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

# Summarize mean metric per period × quintile
ts_quint <- detail_with_quint %>%
  group_by(metric, period_ord, spend_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = dplyr::n(), .groups = "drop")

cat("\n# Rows per period × quintile (any metric):\n")
print(
  detail_with_quint %>%
    count(period_ord, spend_quintile, name = "rows") %>%
    tidyr::complete(period_ord = period_levels, spend_quintile = labs_quint, fill = list(rows = 0)) %>%
    arrange(period_ord, spend_quintile)
)

# Plot (guarded)
if (nrow(ts_quint) > 0) {
  g_quint <- ggplot(ts_quint,
                    aes(x = period_ord, y = avg_value,
                        group = spend_quintile, colour = spend_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(
      title = "Phillips detail metrics over time by public-health spend quintile",
      x = NULL, y = "Mean metric value", colour = "PH spend (per-capita) quintile"
    ) +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_spend_quintile.png"),
         g_quint, width = 10, height = 6.5, dpi = 300)
  print(g_quint)
} else {
  message("No rows for time-series-by-quintile — skipping the plot.")
}

# ---- F) Correlations with direction score (by period) ---------
assign_period <- function(y, info) {
  with(info, {
    p <- period[y >= start & y <= end]
    ifelse(length(p) >= 1, p[1], NA_character_)
  })
}
stopifnot(exists("direction_year"))
direction_period <- direction_year %>%
  mutate(period = vapply(year, assign_period, character(1), info = period_info)) %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop")

detail_wide <- detail_long %>%
  select(county_ihme, period, metric, value) %>%
  distinct() %>%
  pivot_wider(names_from = metric, values_from = value)

corr_tbl <- direction_period %>%
  inner_join(detail_wide, by = c("county_ihme","period"))

cols_metrics <- setdiff(names(detail_wide), c("county_ihme","period"))
corr_out <- map_dfr(split(corr_tbl, corr_tbl$period), function(dd) {
  tibble(
    period = unique(dd$period),
    metric = cols_metrics,
    pearson_r = map_dbl(cols_metrics, ~ suppressWarnings(
      cor(dd$direction_score, dd[[.x]], use = "pairwise.complete.obs")
    )),
    n = nrow(dd)
  )
})
readr::write_csv(corr_out, here("output","correlation_direction_vs_phillips_by_period.csv"))
cat("\nSaved correlations to: ", here("output","correlation_direction_vs_phillips_by_period.csv"), "\n")
print(corr_out %>% arrange(metric, period))
```
Check by income
```{r}
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")
# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))
# ---- G) Time series by INCOME quintiles ------------------------
safe_quintile <- function(x) {
  labs <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
  v <- x[is.finite(x)]
  if (length(v) < 5L || length(unique(v)) < 5L) {
    return(factor(rep(NA_character_, length(x)), levels = labs))
  }
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9
  cut(x, breaks = qs, include.lowest = TRUE, right = FALSE, labels = labs)
}

period_levels <- period_info$period[order(period_info$start)]

# Join detail with ACS income
detail_with_income <- detail_long %>%
  inner_join(income_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(avg_income)) %>%
  group_by(period) %>%
  mutate(income_quintile = safe_quintile(avg_income)) %>%
  ungroup() %>%
  filter(!is.na(income_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_income <- detail_with_income %>%
  group_by(metric, period_ord, income_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_income) > 0) {
  g_income <- ggplot(ts_income,
                     aes(x = period_ord, y = avg_value,
                         group = income_quintile, colour = income_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by INCOME quintile",
         x = NULL, y = "Mean metric value", colour = "Income quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_income_quintile.png"),
         g_income, width = 10, height = 6.5, dpi = 300)
  print(g_income)
} else {
  message("Income quintile time-series empty after guards — skipping.")
}


# ---- H) Time series by BA+ quintiles ---------------------------
detail_with_ba <- detail_long %>%
  inner_join(ba_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(ba_share)) %>%
  group_by(period) %>%
  mutate(ba_quintile = safe_quintile(ba_share)) %>%
  ungroup() %>%
  filter(!is.na(ba_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_ba <- detail_with_ba %>%
  group_by(metric, period_ord, ba_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_ba) > 0) {
  g_ba <- ggplot(ts_ba,
                 aes(x = period_ord, y = avg_value,
                     group = ba_quintile, colour = ba_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by BA+ share quintile",
         x = NULL, y = "Mean metric value", colour = "BA+ quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_ba_quintile.png"),
         g_ba, width = 10, height = 6.5, dpi = 300)
  print(g_ba)
} else {
  message("BA+ quintile time-series empty after guards — skipping.")
}

```
Pre-requisites
```{r}
# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("ph_pc"), exists("detail_year"))
if (!exists("prop_garbage_col") || !exists("overd_col")) {
  stop("Run the preamble that defines prop_garbage_col/overd_col and builds detail_year.")
}

# ---------- population weighting (robust & non-crashy) ----------
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) {
  as.character(pop_col)
} else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").")
        else "Population weighting OFF.")

# ---------- build base_sel (1999–2022), drop dummy FIPS ----------
base_sel <- cy %>%
  dplyr::mutate(
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    pg  = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    od  = suppressWarnings(as.numeric(.data[[overd_col]])),
    # create 'pop' ONLY if a population column is available; else NA
    pop = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  dplyr::filter(
    year >= 1999, year <= 2022,
    county_ihme != "00000", county_ihme != "0000"
  )

# ---------- temporally stable, safe weighted mean ----------
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)

# ---------- per-county temporally stable averages ----------
county_avg <- base_sel %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(
    prop_garbage = wmaybe(pg, pop),       # uses weights if present; else unweighted mean
    overd_unspec = wmaybe(od, pop),
    pop_wt       = if (pop_col_ok) mean(pop, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# ---------- detail averages from prebuilt detail_year ----------
detail_avg <- detail_year %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# PH spend quintiles (stable across finance years)
ph_any <- ph_pc %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  dplyr::filter(is.finite(ph_pc))

# Income quintiles (already pooled over time in your function)
income_quint <- income_quint %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000")


```

Validation: 4 metrics by public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# 4 line plots: Metric vs PH-spend quintile, 5 lines = Income quintiles
# Adds: Reassignability Index (RI)
# Output adds: figures/ph_spend_relationship/ri_lines.png
# Combined 4-panel: figures/ph_spend_relationship/metrics_vs_phspend_lines_4panel.png
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales); library(here); library(stringr); library(patchwork)
})

dir.create(here("figures","ph_spend_relationship"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
weighted_mean_na <- function(x, w) {
  if (missing(w) || is.null(w) || !is.numeric(w)) return(mean(x, na.rm = TRUE))
  ww <- ifelse(is.na(w), 0, w); xx <- ifelse(is.na(x), NA, x)
  if (sum(ww[is.finite(xx)], na.rm = TRUE) == 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww[is.finite(xx)], na.rm = TRUE)
}
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("ph_pc"))      # detail_year is built below if missing
cy <- cy %>% mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))

# Auto-detect metrics in cy
if (!exists("prop_garbage_col")) {
  prop_garbage_col <- find_col(
    cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
          "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
  )
}
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_

# NEW: auto-detect RI column
ri_col <- find_col(
  cy, c("^ri$","\\bri[_]?score\\b","richness.*index","\\bd95\\b","d[_]?95","rarefaction.*index")
)
have_ri <- !is.na(ri_col)

if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns: prop_garbage (auto-detected) AND pct_overd_miss (explicit).")
}

# Build detail_year if needed (period → mid-year)
period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>%
    mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)

  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
      )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("Could not find a UCOD ICD-4 detail metric inside `detail_long` (long).")
    detail_year <- dl %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(value))
      ) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000", county_ihme != "0000") %>%
    distinct()
}

# ---------- population weighting ----------
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").")
        else "Population weighting OFF.")
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)

# ---------- income quintiles (for line colors) ----------
get_income_quintiles <- function(cy_df) {
  income_candidates <- c("median_household_income","median_income","mhi","hh_income",
                         "income_pc","per_capita_income","pc_income","income")
  inc_col <- income_candidates[income_candidates %in% names(cy_df)][1]
  if (!is.na(inc_col)) {
    message("Income source: cy$", inc_col)
    inc_any <- cy_df %>%
      transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
      group_by(county_ihme) %>%
      summarise(income = median(income_val, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(income))
    qb_inc <- make_quintile_breaks(inc_any$income)
    return(inc_any %>%
      mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                            right = FALSE, labels = labs_quint)) %>%
      transmute(county_ihme, income_q))
  }
  if (requireNamespace("tidycensus", quietly = TRUE)) {
    message("Income source: ACS (B19013_001, ACS5 2022). If you see API errors, run:\n",
            "  tidycensus::census_api_key(\"YOUR_KEY\", install = TRUE)")
    inc_acs <- tryCatch(
      tidycensus::get_acs(geography = "county", variables = "B19013_001",
                          year = 2022, survey = "acs5", cache_table = TRUE, show_call = FALSE),
      error = function(e) e
    )
    if (inherits(inc_acs, "error")) stop("Failed to fetch ACS income: ", inc_acs$message)
    inc_any <- inc_acs %>%
      transmute(county_ihme = stringr::str_pad(GEOID, 5, pad = "0"),
                income = as.numeric(estimate)) %>%
      filter(is.finite(income), county_ihme != "00000", county_ihme != "0000")
    qb_inc <- make_quintile_breaks(inc_any$income)
    return(inc_any %>%
      mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                            right = FALSE, labels = labs_quint)) %>%
      transmute(county_ihme, income_q))
  }
  stop("No income available in `cy`, and {tidycensus} not installed.")
}
income_quint <- get_income_quintiles(cy) %>%
  mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  filter(county_ihme != "00000", county_ihme != "0000")

# ---------- per-county averages ----------
base_sel <- cy %>%
  mutate(
    pg  = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    od  = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri  = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    pop = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022,
         county_ihme != "00000", county_ihme != "0000")

county_avg <- base_sel %>%
  group_by(county_ihme) %>%
  summarise(
    prop_garbage   = wmaybe(pg,  pop),
    pct_overd_miss = wmaybe(od,  pop),
    ri             = wmaybe(ri,  pop),
    pop_wt         = if (pop_col_ok) mean(pop, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

detail_avg <- detail_year %>%
  mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  filter(county_ihme != "00000", county_ihme != "0000") %>%
  group_by(county_ihme) %>%
  summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# ---------- PH spend quintiles (x-axis) ----------
ph_any <- ph_pc %>%
  mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  filter(county_ihme != "00000", county_ihme != "0000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>%
  mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE, right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# ---------- combine + summarise ----------
comb <- county_avg %>%
  left_join(detail_avg,  by = "county_ihme") %>%
  inner_join(spend_quint, by = "county_ihme") %>%
  inner_join(income_quint, by = "county_ihme")

metrics_cols <- intersect(c("prop_garbage","pct_overd_miss","detail_icd4","ri"), names(comb))

by_q <- comb %>%
  pivot_longer(cols = all_of(metrics_cols), names_to = "metric", values_to = "value") %>%
  group_by(metric, spend_q, income_q) %>%
  summarise(mean_value = wmaybe(value, pop_wt), n = dplyr::n(), .groups = "drop") %>%
  mutate(
    metric = dplyr::recode(metric,
      prop_garbage   = "Proportion garbage (UCOD)",
      pct_overd_miss = "Overdose % missing",
      detail_icd4    = "Phillips detail (UCOD, ICD-4)",
      ri             = ri_label
    ),
    spend_q  = factor(spend_q,  levels = labs_quint),
    income_q = factor(income_q, levels = labs_quint)
  )

plot_lines <- function(df, mname, ylab, file_out) {
  dd <- df %>% filter(metric == mname, is.finite(mean_value))
  if (!nrow(dd)) { message("Skipping (no data): ", mname); return(NULL) }
  p <- ggplot(dd, aes(x = spend_q, y = mean_value, group = income_q, colour = income_q)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 2.2) +
    labs(
      title = ylab,
      subtitle = paste0("Y: county mean (1999–2022)",
                        if (pop_col_ok) ", population-weighted" else ", unweighted",
                        " · Lines = income quintiles"),
      x = "Public-health spend per capita (county median across finance years, quintiles)",
      y = "Mean metric", colour = "Income quintile"
    ) +
    theme_bw(base_size = 12)
  ggsave(here("figures","ph_spend_relationship", file_out), p, width = 8.8, height = 5.4, dpi = 320)
  p
}

p_garb  <- plot_lines(by_q, "Proportion garbage (UCOD)", "Proportion garbage (UCOD)", "prop_garbage_lines.png")
p_overd <- plot_lines(by_q, "Overdose % missing",        "Overdose % missing",        "pct_overd_miss_lines.png")
p_det   <- plot_lines(by_q, "Phillips detail (UCOD, ICD-4)", "Phillips detail (UCOD, ICD-4)", "detail_icd4_lines.png")
p_ri    <- plot_lines(by_q, ri_label, ri_label, "ri_lines.png")

# Combined 4-panel
plots <- list(p_garb, p_overd, p_det, p_ri) %>% purrr::compact()
combined <- wrap_plots(plots, ncol = 1) + plot_layout(heights = rep(1, length(plots)))
ggsave(here("figures","ph_spend_relationship","metrics_vs_phspend_lines_4panel.png"),
       combined, width = 9.5, height = 16, dpi = 320)

# Show in Viewer
p_garb; p_overd; p_det; p_ri

```
Validation: 4 metrics by reporting type
```{r}
# ──────────────────────────────────────────────────────────────
# Time series by REPORTING TYPE (4 plots incl. RI)
# New outputs:
#   figures/reporting_type_timeseries/ri_by_reporting_timeseries.png
#   figures/reporting_type_timeseries/metrics_by_reporting_timeseries_4panel.png
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","reporting_type_timeseries"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
weighted_mean_na <- function(x, w) {
  if (missing(w) || is.null(w) || !is.numeric(w)) return(mean(x, na.rm = TRUE))
  ww <- ifelse(is.na(w), 0, w); xx <- ifelse(is.na(x), NA, x)
  if (sum(ww[is.finite(xx)], na.rm = TRUE) == 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww[is.finite(xx)], na.rm = TRUE)
}
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# Auto-detect prop_garbage; force pct_overd_miss; detect RI
if (!exists("prop_garbage_col")) {
  prop_garbage_col <- find_col(
    cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
          "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
  )
}
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col <- find_col(cy, c("^ri$","\\bri[_]?score\\b","richness.*index","\\bd95\\b","d[_]?95","rarefaction.*index"))
have_ri <- !is.na(ri_col)

if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns in `cy`: prop_garbage (auto-detected) AND pct_overd_miss.")
}

# Pop weighting?
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").") else "Population weighting OFF.")

# Reporting type lookup (includes "Other County Official")
get_reporting_lookup <- function() {
  if (exists("rep_lu")) {
    stopifnot(all(c("county_ihme","reporting_type") %in% names(rep_lu)))
    return(rep_lu %>% transmute(county_ihme = std_fips(county_ihme),
                                reporting_type = as.character(reporting_type)))
  }
  candidates <- c(
    here::here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    here::here("data_raw","County-Death-Investigation-System-2018.csv"),
    "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  path <- candidates[file.exists(candidates)][1]
  if (is.na(path)) stop("No reporting-type lookup found. Provide `rep_lu` or put CSV under data_raw/.")
  rep_raw <- readr::read_csv(path, show_col_types = FALSE)

  get_colname <- function(df, patterns) {
    nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) NA_character_ else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  if (is.na(fips_col) || is.na(type_col)) stop("Could not detect FIPS/type columns in reporting CSV.")

  rep_raw %>%
    transmute(
      county_ihme = std_fips(.data[[fips_col]]),
      reporting_type = dplyr::recode(
        stringr::str_to_title(trimws(as.character(.data[[type_col]]))),
        "Me" = "Medical Examiner", "Medical Examiner" = "Medical Examiner",
        "Coroner" = "Coroner", "Mixed" = "Mixed", "Hybrid" = "Mixed",
        .default = stringr::str_to_title(trimws(as.character(.data[[type_col]])))
      )
    ) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000", reporting_type != "") %>%
    distinct()
}
rep_lookup <- get_reporting_lookup() %>%
  mutate(
    reporting_type = {
      y <- stringr::str_to_lower(stringr::str_squish(as.character(reporting_type)))
      dplyr::case_when(
        y %in% c("me","medical examiner") ~ "Medical Examiner",
        y %in% c("coroner")               ~ "Coroner",
        y %in% c("mixed","hybrid")        ~ "Mixed",
        grepl("other", y)                 ~ "Other County Official",
        y %in% c("na","n/a","unknown","unspecified","") ~ NA_character_,
        TRUE                              ~ stringr::str_to_title(y)
      )
    },
    reporting_type = factor(reporting_type,
                            levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
  ) %>%
  filter(!is.na(reporting_type))
rt_levels <- levels(rep_lookup$reporting_type)

# detail_year (as before)
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)

  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
      )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric found in `detail_long`.")
    detail_year <- dl %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(value))
      ) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000") %>%
    distinct()
}

# assemble series with RI
base_sel <- cy %>%
  mutate(
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    population     = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000") %>%
  select(county_ihme, year, prop_garbage, pct_overd_miss, ri, population)

series_rt <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  mutate(reporting_type = factor(reporting_type, levels = rt_levels))

ts_rt <- series_rt %>%
  group_by(year, reporting_type) %>%
  summarise(
    prop_garbage   = if (pop_col_ok) safe_wmean(prop_garbage,   population) else mean(prop_garbage,   na.rm = TRUE),
    pct_overd_miss = if (pop_col_ok) safe_wmean(pct_overd_miss, population) else mean(pct_overd_miss, na.rm = TRUE),
    detail_icd4    = if (pop_col_ok) safe_wmean(detail_icd4,    population) else mean(detail_icd4,    na.rm = TRUE),
    ri             = if (pop_col_ok) safe_wmean(ri,             population) else mean(ri,             na.rm = TRUE),
    .groups = "drop"
  )

plot_metric_rt <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = reporting_type)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("County means by reporting type (1999–2022)",
                        if (pop_col_ok) ", population-weighted" else ", unweighted"),
      x = NULL, y = "Mean value", colour = "Reporting type"
    ) +
    theme_bw(base_size = 12)
  ggsave(here("figures","reporting_type_timeseries", file_out),
         p, width = 8.8, height = 5.2, dpi = 320)
  p
}

p1 <- plot_metric_rt(ts_rt, "prop_garbage",   "Proportion garbage (UCOD)", "prop_garbage_by_reporting_timeseries.png")
p2 <- plot_metric_rt(ts_rt, "pct_overd_miss", "Overdose % missing",         "pct_overd_miss_by_reporting_timeseries.png")
p3 <- plot_metric_rt(ts_rt, "detail_icd4",    "Phillips detail (UCOD, ICD-4)", "detail_icd4_by_reporting_timeseries.png")
p4 <- plot_metric_rt(ts_rt, "ri",             ri_label, "ri_by_reporting_timeseries.png")

combined <- wrap_plots(p1, p2, p3, p4, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","reporting_type_timeseries","metrics_by_reporting_timeseries_4panel.png"),
       combined, width = 9.5, height = 16, dpi = 320)

# print to Viewer
p1; p2; p3; p4

```

Validation: 4 metrics by income
```{r}
# ──────────────────────────────────────────────────────────────
# A) x = income quintile; 5 lines = PH-spend quintiles
# B) time series by income quintile
# Adds: RI everywhere + 4-panel combined figures
# New outputs:
#   figures/income_relationship/ri_lines.png
#   figures/income_relationship/metrics_vs_income_lines_4panel.png
#   figures/income_timeseries/ri_by_income_timeseries.png
#   figures/income_timeseries/metrics_by_income_timeseries_4panel.png
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","income_relationship"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("figures","income_timeseries"),   recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
weighted_mean_na <- function(x, w) {
  if (missing(w) || is.null(w) || !is.numeric(w)) return(mean(x, na.rm = TRUE))
  ww <- ifelse(is.na(w), 0, w); xx <- ifelse(is.na(x), NA, x)
  if (sum(ww[is.finite(xx)], na.rm = TRUE) == 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww[is.finite(xx)], na.rm = TRUE)
}
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"), exists("ph_pc"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# Auto-detect + RI
if (!exists("prop_garbage_col")) {
  prop_garbage_col <- find_col(
    cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
          "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
  )
}
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col <- find_col(cy, c("^ri$","\\bri[_]?score\\b","richness.*index","\\bd95\\b","d[_]?95","rarefaction.*index"))
have_ri <- !is.na(ri_col)

if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns in `cy`: prop_garbage (auto-detected) AND pct_overd_miss.")
}

# Pop weighting?
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").") else "Population weighting OFF.")

# ---------- income quintiles (x for panel A; line colour for panel B) ----------
get_income_quintiles <- function(cy_df) {
  income_candidates <- c("median_household_income","median_income","mhi","hh_income",
                         "income_pc","per_capita_income","pc_income","income")
  inc_col <- income_candidates[income_candidates %in% names(cy_df)][1]
  if (!is.na(inc_col)) {
    message("Income source: cy$", inc_col)
    inc_any <- cy_df %>%
      transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
      group_by(county_ihme) %>%
      summarise(income = median(income_val, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(income))
    qb_inc <- make_quintile_breaks(inc_any$income)
    return(inc_any %>%
      mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                            right = FALSE, labels = labs_quint)) %>%
      transmute(county_ihme, income_q))
  }
  if (!requireNamespace("tidycensus", quietly = TRUE)) {
    stop("No income in `cy`, and {tidycensus} not installed. Add income to `cy` or install {tidycensus}.")
  }
  message("Income source: ACS (B19013_001, ACS5 2022). If you see API errors, set your Census API key.")
  inc_acs <- tryCatch(
    tidycensus::get_acs(geography = "county", variables = "B19013_001",
                        year = 2022, survey = "acs5", cache_table = TRUE, show_call = FALSE),
    error = function(e) e
  )
  if (inherits(inc_acs, "error")) stop("Failed to fetch ACS income: ", inc_acs$message)
  inc_any <- inc_acs %>%
    transmute(county_ihme = std_fips(GEOID), income = as.numeric(estimate)) %>%
    filter(is.finite(income), county_ihme != "00000")
  qb_inc <- make_quintile_breaks(inc_any$income)
  inc_any %>%
    mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                          right = FALSE, labels = labs_quint)) %>%
    transmute(county_ihme, income_q)
}
income_quint <- get_income_quintiles(cy) %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000")

# ---------- PH spend quintiles (for coloured lines in panel A) ----------
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>%
  mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE,
                       right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# ---------- detail_year ----------
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)

  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
      )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric found in `detail_long`.")
    detail_year <- dl %>%
      transmute(
        county_ihme,
        year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
        detail_icd4 = suppressWarnings(as.numeric(value))
      ) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000") %>%
    distinct()
}

# ---------- per-county averages (stable) ----------
base_sel <- cy %>%
  mutate(
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    population     = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000")

county_avg <- base_sel %>%
  group_by(county_ihme) %>%
  summarise(
    prop_garbage   = wmaybe(prop_garbage,   population),
    pct_overd_miss = wmaybe(pct_overd_miss, population),
    ri             = wmaybe(ri,             population),
    pop_wt         = if (pop_col_ok) mean(population, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

detail_avg <- detail_year %>%
  group_by(county_ihme) %>%
  summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# ============================================================
# A) Metrics vs INCOME quintile (x = income_q; 5 lines = PH-spend quintiles)
# ============================================================
comb_A <- county_avg %>%
  left_join(detail_avg,  by = "county_ihme") %>%
  inner_join(income_quint, by = "county_ihme") %>%
  inner_join(spend_quint,  by = "county_ihme")

metrics_cols_A <- intersect(c("prop_garbage","pct_overd_miss","detail_icd4","ri"), names(comb_A))

by_q_income_x <- comb_A %>%
  pivot_longer(cols = all_of(metrics_cols_A),
               names_to = "metric", values_to = "value") %>%
  group_by(metric, income_q, spend_q) %>%
  summarise(mean_value = wmaybe(value, pop_wt), n = dplyr::n(), .groups = "drop") %>%
  mutate(
    metric = dplyr::recode(metric,
      prop_garbage   = "Proportion garbage (UCOD)",
      pct_overd_miss = "Overdose % missing",
      detail_icd4    = "Phillips detail (UCOD, ICD-4)",
      ri             = ri_label
    ),
    income_q = factor(income_q, levels = labs_quint),
    spend_q  = factor(spend_q,  levels = labs_quint)
  )

plot_lines_income <- function(df, mname, title, file_out) {
  dd <- df %>% filter(metric == mname, is.finite(mean_value))
  if (!nrow(dd)) { message("Skipping (no data): ", mname); return(NULL) }
  p <- ggplot(dd, aes(x = income_q, y = mean_value, group = spend_q, colour = spend_q)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 2.2) +
    labs(
      title = title,
      subtitle = paste0("Y: county mean (1999–2022)",
                        if (pop_col_ok) ", population-weighted" else ", unweighted",
                        " · Lines = PH-spend quintiles"),
      x = "Income (median household income) quintiles",
      y = "Mean metric", colour = "PH-spend quintile"
    ) +
    theme_bw(base_size = 12)
  ggsave(here("figures","income_relationship", file_out), p, width = 8.8, height = 5.4, dpi = 320)
  p
}

pA_garb  <- plot_lines_income(by_q_income_x, "Proportion garbage (UCOD)", "Proportion garbage (UCOD)", "prop_garbage_lines.png")
pA_overd <- plot_lines_income(by_q_income_x, "Overdose % missing",       "Overdose % missing",        "pct_overd_miss_lines.png")
pA_det   <- plot_lines_income(by_q_income_x, "Phillips detail (UCOD, ICD-4)", "Phillips detail (UCOD, ICD-4)", "detail_icd4_lines.png")
pA_ri    <- plot_lines_income(by_q_income_x, ri_label, ri_label, "ri_lines.png")

combined_A <- wrap_plots(pA_garb, pA_overd, pA_det, pA_ri, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_relationship","metrics_vs_income_lines_4panel.png"),
       combined_A, width = 9.5, height = 16, dpi = 320)

# ============================================================
# B) Time series by INCOME quintile (x = year; lines = income quintiles)
# ============================================================
series_inc <- base_sel %>%
  select(county_ihme, year, prop_garbage, pct_overd_miss, ri, population) %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(income_quint, by = "county_ihme")

ts_income <- series_inc %>%
  group_by(year, income_q) %>%
  summarise(
    prop_garbage   = wmaybe(prop_garbage,   population),
    pct_overd_miss = wmaybe(pct_overd_miss, population),
    detail_icd4    = wmaybe(detail_icd4,    population),
    ri             = wmaybe(ri,             population),
    .groups = "drop"
  ) %>%
  mutate(income_q = factor(income_q, levels = labs_quint))

plot_metric_income_ts <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = income_q)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("County means by income quintile (1999–2022)",
                        if (pop_col_ok) ", population-weighted" else ", unweighted"),
      x = NULL, y = "Mean value", colour = "Income quintile"
    ) +
    theme_bw(base_size = 12)
  ggsave(here("figures","income_timeseries", file_out),
         p, width = 8.8, height = 5.2, dpi = 320)
  p
}

pB1 <- plot_metric_income_ts(ts_income, "prop_garbage",   "Proportion garbage (UCOD)", "prop_garbage_by_income_timeseries.png")
pB2 <- plot_metric_income_ts(ts_income, "pct_overd_miss", "Overdose % missing",         "pct_overd_miss_by_income_timeseries.png")
pB3 <- plot_metric_income_ts(ts_income, "detail_icd4",    "Phillips detail (UCOD, ICD-4)", "detail_icd4_by_income_timeseries.png")
pB4 <- plot_metric_income_ts(ts_income, "ri",             ri_label, "ri_by_income_timeseries.png")

combined_B <- wrap_plots(pB1, pB2, pB3, pB4, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_timeseries","metrics_by_income_timeseries_4panel.png"),
       combined_B, width = 9.5, height = 16, dpi = 320)

# Print to Viewer
pA_garb; pA_overd; pA_det; pA_ri; pB1; pB2; pB3; pB4

```







