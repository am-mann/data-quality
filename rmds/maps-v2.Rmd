---
title: "Mapping Notebook"
output: html_notebook
---

Map RI scores with light clustering
```{r}
# ──────────────────────────────────────────────────────────────
# Map RI, RI_post_only, and RI_jsd (if available) with light clusters
#   • Clustering uses n_cert as the "garbage count" proxy
#   • Robust min across 4 windows; min per-cluster threshold = 150
#   • Alaska & Hawaii included via state outlines
# ──────────────────────────────────────────────────────────────

# 0) Packages & options
required <- c("sf","tigris","readr","dplyr","stringr","purrr","ggplot2",
              "here","scales","igraph","tidyr","tibble","patchwork")
missing <- setdiff(required, rownames(installed.packages()))
if (length(missing)) install.packages(missing)
invisible(lapply(required, library, character.only = TRUE))

options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

`%||%` <- function(a, b) if (!is.null(a)) a else b

# 1) Windows & inputs
periods_vec <- c("1999_2005","2006_2012","2013_2019","2020_2022")
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

metrics_path_gz <- here::here("data","county_year_quality_metrics.csv.gz")
metrics_path    <- if (file.exists(metrics_path_gz)) metrics_path_gz else here::here("data","county_year_quality_metrics.csv")

dq <- readr::read_csv(metrics_path, show_col_types = FALSE) %>%
  dplyr::mutate(
    year        = suppressWarnings(as.integer(year)),
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    time_window = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2006 & year <= 2012 ~ "2006_2012",
      year >= 2013 & year <= 2019 ~ "2013_2019",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    ),
    time_window = stringr::str_replace_all(time_window, "[\u2013\u2014]", "_")
  )

# Required columns for this mapping step
req_cols <- c("RI","RI_post_only","n_cert")
stopifnot(all(req_cols %in% names(dq)))

has_jsd <- "RI_jsd" %in% names(dq)
if (!has_jsd) message("ℹ 'RI_jsd' not found in input; JSD maps will be skipped.")

# Use n_cert as garbage proxy
dq$gb_n <- suppressWarnings(as.numeric(dq$n_cert))
dq$gb_n[is.na(dq$gb_n)] <- 0

# 2) IHME crosswalk
load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>%
  dplyr::distinct()

# 3) Robust n_cert totals across windows (min across 4)
gb_by_window <- dq %>%
  dplyr::filter(!is.na(time_window)) %>%
  dplyr::group_by(county_ihme, time_window) %>%
  dplyr::summarise(gb = sum(gb_n, na.rm = TRUE), .groups = "drop")

gb_wide <- gb_by_window %>%
  tidyr::pivot_wider(names_from = time_window, values_from = gb, values_fill = 0)
for (w in periods_vec) if (!w %in% names(gb_wide)) gb_wide[[w]] <- 0

robust_tbl <- gb_wide %>%
  dplyr::mutate(robust_gb = pmin(`1999_2005`,`2006_2012`,`2013_2019`,`2020_2022`, na.rm = TRUE)) %>%
  dplyr::transmute(county_ihme, robust_gb = as.numeric(robust_gb))

# 4) Shapefiles
crs_proj <- 2163
albers_5070 <- 5070

normalize_geoid <- function(sfobj, year) {
  nms <- names(sfobj)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    sfobj <- dplyr::rename(sfobj, GEOID = !!rlang::sym(geoid_col))
    sfobj$GEOID <- stringr::str_pad(as.character(sfobj$GEOID), 5, pad = "0")
    return(sfobj)
  }
  state_col  <- grep("^STATE.*FP$", nms, value = TRUE)[1]
  county_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
  if (!is.na(state_col) && !is.na(county_col)) {
    sfobj$GEOID <- paste0(
      stringr::str_pad(as.character(sfobj[[state_col]]),  2, pad = "0"),
      stringr::str_pad(as.character(sfobj[[county_col]]), 3, pad = "0")
    )
    return(sfobj)
  }
  combo_col <- grep("^CNTYIDFP$", nms, value = TRUE)[1]
  if (!is.na(combo_col)) {
    sfobj <- dplyr::rename(sfobj, GEOID = !!rlang::sym(combo_col))
    sfobj$GEOID <- stringr::str_pad(as.character(sfobj$GEOID), 5, pad = "0")
    return(sfobj)
  }
  stop("No GEOID-compatible columns found in shapefile for year ", year)
}

build_ihme_groups_sf <- function(year) {
  counties_raw <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM") %>%
    sf::st_make_valid()
  counties_norm <- normalize_geoid(counties_raw, year) %>%
    sf::st_transform(crs_proj) %>%
    sf::st_make_valid()
  counties_norm %>%
    dplyr::left_join(ihme_map, by = "GEOID") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, GEOID)) %>%
    dplyr::group_by(county_ihme) %>%
    dplyr::summarise(.groups = "drop")
}

# --------------------------
# Section 5 (clustering) - Build cluster_map from merged all_county_groupings.csv
# --------------------------

# Candidate merged file locations (should already be produced earlier in script)
merged_candidates <- c(
  here::here("data_raw","all_county_groupings.csv"),
  here::here("data","all_county_groupings.csv"),
  here::here("all_county_groupings.csv")
)
merged_file <- merged_candidates[file.exists(merged_candidates)][1]
if (is.na(merged_file) || length(merged_file) == 0) {
  stop("Could not find merged all_county_groupings.csv. Expected at one of: ",
       paste(merged_candidates, collapse = ", "))
}
message("Reading merged file for cluster assignments: ", merged_file)

# Read merged CSV as character
merged_df <- readr::read_csv(merged_file, col_types = readr::cols(.default = "c"), show_col_types = FALSE)

# Ensure we have a cluster-id column: prefer "CS Area Code", else try "County Set Name"
if (!("CS Area Code" %in% names(merged_df)) && !("County Set Name" %in% names(merged_df))) {
  stop("Merged file must contain a 'CS Area Code' or 'County Set Name' column (filled down).",
       "\nPlease run the cleaning step that fills down group headers before this step.")
}
cluster_col_name <- if ("CS Area Code" %in% names(merged_df)) "CS Area Code" else "County Set Name"

# Ensure FIPS column exists
if (!("FIPS" %in% names(merged_df))) {
  stop("Merged file must contain a 'FIPS' column with county FIPS values (may be empty for header rows).")
}

# Keep only rows with non-empty FIPS (these are county member rows)
members <- merged_df %>%
  dplyr::mutate(
    FIPS_raw = stringr::str_trim(as.character(FIPS)),
    FIPS_digits = ifelse(FIPS_raw == "" | is.na(FIPS_raw), NA_character_, gsub("[^0-9]", "", FIPS_raw)),
    FIPS5 = ifelse(is.na(FIPS_digits), NA_character_, stringr::str_pad(FIPS_digits, width = 5, side = "left", pad = "0")),
    cluster_id = stringr::str_trim(as.character(.data[[cluster_col_name]]))
  ) %>%
  dplyr::filter(!is.na(FIPS5) & FIPS5 != "" & !is.na(cluster_id) & cluster_id != "") %>%
  dplyr::select(FIPS5, cluster_id) %>%
  dplyr::rename(raw_fips = FIPS5)

# Map raw_fips -> county_ihme using ihme_map if present, otherwise treat raw_fips as county_ihme
if (exists("ihme_map")) {
  # ihme_map expected to have columns GEOID and county_ihme (from earlier load)
  if (!("GEOID" %in% names(ihme_map)) || !("county_ihme" %in% names(ihme_map))) {
    # if ihme_map is the raw object format (orig_fips / ihme_fips), coerce accordingly
    if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
      xwalk <- ihme_fips %>%
        dplyr::transmute(GEOID = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
                         county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0"))
    } else {
      stop("ihme_map present but does not have expected structure. Please ensure ihme_fips / ihme_map is loaded correctly.")
    }
  } else {
    xwalk <- ihme_map %>% dplyr::transmute(GEOID = stringr::str_pad(as.character(GEOID), 5, pad = "0"),
                                          county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
  }

  members2 <- members %>%
    dplyr::left_join(xwalk, by = c("raw_fips" = "GEOID")) %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, raw_fips)) %>%
    dplyr::select(county_ihme, cluster_id)
} else {
  # No crosswalk available; use raw FIPS as county_ihme
  members2 <- members %>%
    dplyr::mutate(county_ihme = raw_fips) %>%
    dplyr::select(county_ihme, cluster_id)
}

# Build cluster_map and sanity-checks
cluster_map <- members2 %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
                cluster_id = as.character(cluster_id)) %>%
  dplyr::distinct(county_ihme, cluster_id)

if (nrow(cluster_map) == 0) stop("No valid county->cluster mappings found in merged file.")

# Check for counties mapped to >1 cluster (shouldn't happen)
dup_check <- cluster_map %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(n = dplyr::n(), clusters = paste(sort(unique(cluster_id)), collapse = ";"), .groups = "drop") %>%
  dplyr::filter(n > 1)

if (nrow(dup_check) > 0) {
  stop("Found counties assigned to multiple clusters (first 20 shown):\n", paste0(utils::capture.output(head(dup_check, 20)), collapse = "\n"),
       "\nPlease fix the merged CSV so each county FIPS appears under only one CS Area Code.")
}

# --------------------------
#  Section 6 
# --------------------------

agg_metric <- function(varname) {
  dq %>%
    dplyr::filter(!is.na(time_window)) %>%
    dplyr::inner_join(cluster_map, by = "county_ihme") %>%
    dplyr::group_by(cluster_id, time_window) %>%
    dplyr::summarise(val = mean(.data[[varname]], na.rm = TRUE),
                     n_counties = dplyr::n_distinct(county_ihme),
                     .groups = "drop") %>%
    tidyr::complete(cluster_id, time_window = periods_vec,
                    fill = list(val = NA_real_, n_counties = 0L))
}

dq_cluster_RI   <- agg_metric("RI") %>% dplyr::rename(RI = val)
dq_cluster_post <- agg_metric("RI_post_only") %>% dplyr::rename(RI_post_only = val)
dq_cluster_jsd  <- if (has_jsd) agg_metric("RI_jsd") %>% dplyr::rename(RI_jsd = val) else NULL

# 7) Shapes per period
build_clusters_sf <- function(year) {
  base <- build_ihme_groups_sf(year)
  base %>%
    dplyr::left_join(cluster_map, by = "county_ihme") %>%
    dplyr::filter(!is.na(cluster_id)) %>%
    dplyr::group_by(cluster_id) %>%
    dplyr::summarise(.groups = "drop") %>%
    sf::st_transform(crs_proj) %>%
    sf::st_make_valid()
}

join_shapes <- function(metric_df) {
  lapply(names(shapefile_years), function(window) {
    year <- unname(shapefile_years[[window]])
    shape_all <- build_clusters_sf(year)
    dplyr::left_join(shape_all, dplyr::filter(metric_df, time_window == window), by = "cluster_id")
  }) %>% setNames(names(shapefile_years))
}

joined_by_period_RI   <- join_shapes(dq_cluster_RI)
joined_by_period_post <- join_shapes(dq_cluster_post)
joined_by_period_jsd  <- if (!is.null(dq_cluster_jsd)) join_shapes(dq_cluster_jsd) else NULL

# 8) Map helpers (fixed limits)
states_outline <- tigris::states(cb = TRUE, class = "sf") |>
  sf::st_transform(crs_proj) |>
  sf::st_make_valid()

make_map_numeric <- function(sf_data, fill_col, limits, title) {
  ggplot() +
    geom_sf(data = sf_data, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_outline, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", limits = limits,
                         oob = scales::squish, direction = 1,
                         na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = title, fill = NULL) +
    theme_void() +
    theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
          legend.text = element_text(size = 9))
}

make_map_RI   <- function(sf_data, title) make_map_numeric(sf_data, "RI", c(0.018, 0.04), title)
make_map_post <- function(sf_data, title) make_map_numeric(sf_data, "RI_post_only", c(0.12, 0.19), title)
make_map_jsd  <- function(sf_data, title) make_map_numeric(sf_data, "RI_jsd", c(0.015, 0.03), title)  # tweak if needed

# 9) Save maps
output_dir <- here::here("figures", "5yr_avg_stable")
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# RI maps
p_1999_RI <- make_map_RI(joined_by_period_RI[["1999_2005"]], "1999_2005")
p_2006_RI <- make_map_RI(joined_by_period_RI[["2006_2012"]], "2006_2012")
p_2013_RI <- make_map_RI(joined_by_period_RI[["2013_2019"]], "2013_2019")
p_2020_RI <- make_map_RI(joined_by_period_RI[["2020_2022"]], "2020_2022")
combined_RI <- (p_1999_RI | p_2006_RI) / (p_2013_RI | p_2020_RI)
ggsave(file.path(output_dir, "RI_clustered_garbage150_4panel.png"),
       plot = combined_RI, width = 12, height = 9, dpi = 320)

# RI_post_only maps
p_1999_post <- make_map_post(joined_by_period_post[["1999_2005"]], "1999_2005")
p_2006_post <- make_map_post(joined_by_period_post[["2006_2012"]], "2006_2012")
p_2013_post <- make_map_post(joined_by_period_post[["2013_2019"]], "2013_2019")
p_2020_post <- make_map_post(joined_by_period_post[["2020_2022"]], "2020_2022")
combined_post <- (p_1999_post | p_2006_post) / (p_2013_post | p_2020_post)
ggsave(file.path(output_dir, "RI_post_only_clustered_garbage150_4panel.png"),
       plot = combined_post, width = 12, height = 9, dpi = 320)

# RI_jsd maps (if available)
if (!is.null(joined_by_period_jsd)) {
  p_1999_jsd <- make_map_jsd(joined_by_period_jsd[["1999_2005"]], "1999_2005")
  p_2006_jsd <- make_map_jsd(joined_by_period_jsd[["2006_2012"]], "2006_2012")
  p_2013_jsd <- make_map_jsd(joined_by_period_jsd[["2013_2019"]], "2013_2019")
  p_2020_jsd <- make_map_jsd(joined_by_period_jsd[["2020_2022"]], "2020_2022")
  combined_jsd <- (p_1999_jsd | p_2006_jsd) / (p_2013_jsd | p_2020_jsd)
  ggsave(file.path(output_dir, "RI_jsd_clustered_garbage150_4panel.png"),
         plot = combined_jsd, width = 12, height = 9, dpi = 320)
} else {
  message("⚠ Skipping JSD maps: 'RI_jsd' not present in input file.")
}

message("✓ Done. Maps saved to: ", output_dir)

```
NEW: Make a new plot with RI maps and level of detail for new paper
```{r}
#!/usr/bin/env Rscript
# 4 maps: RI (1999–2005, 2020–2022) on top + LOD (UCOD 4-digit standardized diversity) on bottom
# - RI uses standard county->cluster membership (membership_ri_file)
# - LOD uses cluster membership FROM YOUR LIST (membership_lod_file) so boundaries can differ
# - LOD polygons & styling emulate your LOD code (inner_join + st_union, Reds palette, simple period titles)
# - Output → figures/5yr_avg_stable/ri_lod_2x2.png

suppressPackageStartupMessages({
  pkgs <- c("sf","dplyr","stringr","readr","ggplot2","tigris",
            "rlang","purrr","patchwork","scales","here")
  miss <- setdiff(pkgs, rownames(installed.packages()))
  if (length(miss)) install.packages(miss, repos = "https://cloud.r-project.org")
  lapply(pkgs, library, character.only = TRUE)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ paths -------------------------------
metrics_file          <- here::here("output", "cluster_metrics_ucr39_cstd.csv.gz")   # cluster-level LOD metric
membership_ri_file   <- here::here("output", "county_cluster_membership.csv.gz")       # RI membership
membership_lod_candidates <- c(                                                        # LOD membership from your list
  here::here("data", "all_county_groupings.csv"),
  here::here("data", "all_county_groupings.csv.gz"),
  here::here("output","county_cluster_membership.csv.gz") # last-resort fallback
)
membership_lod_file <- membership_lod_candidates[file.exists(membership_lod_candidates)][1]

metrics2_file        <- here::here("data",   "county_year_quality_metrics.csv.gz")     # contains RI_post_only by fips/year/period
out_dir_base         <- here::here("figures", "5yr_avg_stable")
diag_dir             <- file.path(out_dir_base, "diagnostics")
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)
dir.create(diag_dir, recursive = TRUE, showWarnings = FALSE)

# -------------------- projection & periods --------------------
crs_proj    <- 2163
periods_two <- c("1999_2005","2020_2022")

# ------------------------ helpers -----------------------------
std_fips_vec <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
               st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
               st_scale(1)    |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid() |>
    (\(x){ sf::st_crs(x) <- crs_proj; x })() |>
    (\(x){ x$fips <- std_fips_vec(x$fips); x })()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
               st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
               st_scale(1)    |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid() |>
    (\(x){ sf::st_crs(x) <- crs_proj; x })()
}

# ----- Membership normalisers -----
norm_membership_ri <- function(df) {
  nms <- names(df); low <- tolower(nms)
  fips_col    <- nms[which(grepl("^(fips|geoid)$|^geoid|fips", low))[1]]
  cluster_col <- nms[which(grepl("^(cluster|cluster_id)$|cluster", low))[1]]
  period_col  <- nms[low == "period"]
  if (is.na(fips_col) || is.na(cluster_col) || !length(period_col))
    stop("RI membership needs fips, cluster, period.")
  df |>
    dplyr::transmute(
      fips    = std_fips_vec(.data[[fips_col]]),
      cluster = as.character(.data[[cluster_col]]),
      period  = as.character(.data[[period_col]])
    ) |>
    dplyr::distinct()
}

norm_membership_lod <- function(df, periods_two) {
  nms <- names(df); low <- tolower(nms)
  fips_col    <- nms[which(grepl("^(fips|geoid)$|^geoid|fips", low))[1]]
  cluster_col <- nms[which(grepl("^(cluster|group|cluster_id)$|cluster|group", low))[1]]
  period_col  <- nms[low == "period"]
  if (is.na(fips_col) || is.na(cluster_col))
    stop("LOD membership needs fips and cluster/group (period optional).")
  base <- df |>
    dplyr::transmute(fips = std_fips_vec(.data[[fips_col]]),
                     cluster = as.character(.data[[cluster_col]])) |>
    dplyr::distinct()
  if (length(period_col)) {
    df |>
      dplyr::transmute(
        fips    = std_fips_vec(.data[[fips_col]]),
        cluster = as.character(.data[[cluster_col]]),
        period  = as.character(.data[[period_col]])
      ) |>
      dplyr::distinct()
  } else {
    purrr::map_dfr(periods_two, ~ dplyr::mutate(base, period = .x))
  }
}

# ----- Cluster polygon builders -----
# RI: robust (ok to keep your previous approach)
build_cluster_sf_ri <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df |>
    dplyr::filter(period == period_key) |>
    dplyr::transmute(fips = std_fips_vec(fips), cluster = as.character(cluster)) |>
    dplyr::distinct()
  if (!nrow(mm)) stop("No RI membership rows for period: ", period_key)
  joined <- dplyr::inner_join(counties_sf, mm, by = c("fips" = "fips"))
  joined |>
    dplyr::group_by(cluster) |>
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") |>
    sf::st_make_valid()
}

# LOD: EXACTLY like your LOD code (inner_join counties + membership → union by cluster)
build_cluster_sf_lod <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df |>
    dplyr::filter(.data$period == period_key) |>
    dplyr::transmute(fips = std_fips_vec(as.character(fips)),
                     cluster = as.character(cluster)) |>
    dplyr::distinct()
  if (!nrow(mm)) stop("No LOD membership rows for period: ", period_key)
  counties_sf |>
    dplyr::inner_join(mm, by = "fips") |>
    dplyr::group_by(cluster) |>
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") |>
    sf::st_make_valid()
}

# ------------------------- load data --------------------------
if (!file.exists(metrics_file)) stop("Missing metrics_file: ", metrics_file)
if (!file.exists(membership_ri_file)) {
  alt <- sub("\\.csv$", ".csv.gz", membership_ri_file)
  if (file.exists(alt)) membership_ri_file <- alt else stop("Missing membership_ri_file: ", membership_ri_file)
}
if (is.na(membership_lod_file) || !file.exists(membership_lod_file))
  stop("Could not find a LOD membership list. Checked: ", paste(membership_lod_candidates, collapse = "; "))
if (!file.exists(metrics2_file)) stop("Missing metrics2_file: ", metrics2_file)

message("Reading LOD metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) |>
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading RI membership: ", membership_ri_file)
membership_ri <- readr::read_csv(membership_ri_file, show_col_types = FALSE)

message("Reading LOD list membership: ", membership_lod_file)
membership_lod_raw <- readr::read_csv(membership_lod_file, show_col_types = FALSE)

message("Reading county-year quality metrics (RI): ", metrics2_file)
metrics2_raw <- readr::read_csv(metrics2_file, show_col_types = FALSE)

# normalise memberships
membership_ri  <- norm_membership_ri(membership_ri)
membership_lod <- norm_membership_lod(membership_lod_raw, periods_two)

# geographies
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

# ---------------------- select the UCOD metric (LOD) -----------
ucod_col <- "detail_ucod_icd4_cstd"
if (!ucod_col %in% names(metrics)) stop("Column 'detail_ucod_icd4_cstd' not found in metrics.")
metrics_lod_two <- metrics |>
  dplyr::filter(period %in% periods_two) |>
  dplyr::select(cluster, period, !!rlang::sym(ucod_col)) |>
  dplyr::rename(lod_value = !!rlang::sym(ucod_col))

# ------------------ aggregate RI to cluster-period -------------
# detect id/time/ri columns robustly
possible_id_cols <- c("fips","geoid","county_ihme","county")
lower_names <- tolower(names(metrics2_raw))
id_idx <- which(lower_names %in% possible_id_cols)[1]
if (is.na(id_idx)) stop("Could not find an ID column in metrics2_file.")
id_col <- names(metrics2_raw)[id_idx]

ri_candidates <- c("RI_post_only")
ri_idx <- which(tolower(names(metrics2_raw)) %in% tolower(ri_candidates))[1]
if (is.na(ri_idx)) stop("Could not find an RI column in metrics2_file.")
ri_col <- names(metrics2_raw)[ri_idx]

time_col <- if ("period" %in% names(metrics2_raw)) {
  "period"
} else if ("year" %in% names(metrics2_raw)) {
  "year"
} else {
  stop("metrics2 must have 'period' or 'year'.")
}

metrics2 <- metrics2_raw |>
  dplyr::mutate(id_str = std_fips_vec(.data[[id_col]]))

if (time_col == "year") {
  metrics2 <- metrics2 |>
    dplyr::mutate(
      year = as.integer(.data$year),
      period = dplyr::case_when(
        year >= 1999 & year <= 2005 ~ "1999_2005",
        year >= 2006 & year <= 2012 ~ "2006_2012",
        year >= 2013 & year <= 2019 ~ "2013_2019",
        year >= 2020 & year <= 2022 ~ "2020_2022",
        TRUE ~ NA_character_
      )
    )
} else {
  metrics2 <- metrics2 |> dplyr::mutate(period = as.character(.data$period))
}

metrics2_agg <- metrics2 |>
  dplyr::transmute(fips = id_str, period = period, RI_post_only = as.numeric(.data[[ri_col]])) |>
  dplyr::filter(!is.na(fips), !is.na(period)) |>
  dplyr::group_by(fips, period) |>
  dplyr::summarise(RI_post_only = mean(RI_post_only, na.rm = TRUE), .groups = "drop")

# RI cluster means
ri_join <- membership_ri |>
  dplyr::left_join(metrics2_agg, by = c("fips","period"))
cluster_ri <- ri_join |>
  dplyr::group_by(cluster, period) |>
  dplyr::summarise(RI_post_only = mean(RI_post_only, na.rm = TRUE), .groups = "drop")

# ----------------- common limits across periods ----------------
ri_vals  <- cluster_ri      |> dplyr::filter(period %in% periods_two) |> dplyr::pull(RI_post_only) |> (\(x) x[is.finite(x)])()
lod_vals <- metrics_lod_two |> dplyr::pull(lod_value)                 |> (\(x) x[is.finite(x)])()
ri_lims  <- if (length(ri_vals)  >= 3) stats::quantile(ri_vals,  c(0.01,0.99), na.rm = TRUE) else range(ri_vals,  na.rm = TRUE)
lod_lims <- if (length(lod_vals) >= 3) stats::quantile(lod_vals, c(0.02,0.98), na.rm = TRUE) else range(lod_vals, na.rm = TRUE)

message("Building RI polygons (RI membership) ...")
cl_sf_1999_ri <- build_cluster_sf_ri ("1999_2005", membership_ri,  counties_tf)
cl_sf_2020_ri <- build_cluster_sf_ri ("2020_2022", membership_ri,  counties_tf)

message("Building LOD polygons (LIST membership; different boundaries) ...")
cl_sf_1999_lod <- build_cluster_sf_lod("1999_2005", membership_lod, counties_tf)
cl_sf_2020_lod <- build_cluster_sf_lod("2020_2022", membership_lod, counties_tf)

# ------------------------- join metrics ------------------------
map_ri_1999  <- cl_sf_1999_ri  |> dplyr::left_join(cluster_ri      |> dplyr::filter(period == "1999_2005") |> dplyr::select(cluster, RI_post_only), by = "cluster")
map_ri_2020  <- cl_sf_2020_ri  |> dplyr::left_join(cluster_ri      |> dplyr::filter(period == "2020_2022") |> dplyr::select(cluster, RI_post_only), by = "cluster")
map_lod_1999 <- cl_sf_1999_lod |> dplyr::left_join(metrics_lod_two |> dplyr::filter(period == "1999_2005") |> dplyr::select(cluster, lod_value), by = "cluster")
map_lod_2020 <- cl_sf_2020_lod |> dplyr::left_join(metrics_lod_two |> dplyr::filter(period == "2020_2022") |> dplyr::select(cluster, lod_value), by = "cluster")

# ------------------------- plotting ----------------------------
base_extent <- list(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000))
make_red_scale <- function(lims) scale_fill_distiller(palette = "Reds", direction = -1, limits = lims, oob = scales::squish, na.value = "grey90")

p_ri_a <- ggplot() +
  geom_sf(data = map_ri_1999, aes(fill = RI_post_only), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.3) +
  make_red_scale(ri_lims) +
  coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "RI — 1999–2005", fill = NULL) +
  theme_void(base_size = 11) + theme(plot.title = element_text(hjust = 0.5, face = "bold"))

p_ri_b <- ggplot() +
  geom_sf(data = map_ri_2020, aes(fill = RI_post_only), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.3) +
  make_red_scale(ri_lims) +
  coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "RI — 2020–2022", fill = NULL) +
  theme_void(base_size = 11) + theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# LOD: emulate your LOD code (Reds palette, simple titles)
p_lod_a <- ggplot() +
  geom_sf(data = map_lod_1999, aes(fill = lod_value), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.3) +
  make_red_scale(lod_lims) +
  coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "1999–2005", fill = NULL) +
  theme_void(base_size = 11) + theme(plot.title = element_text(hjust = 0.5, face = "bold"))

p_lod_b <- ggplot() +
  geom_sf(data = map_lod_2020, aes(fill = lod_value), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.3) +
  make_red_scale(lod_lims) +
  coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "2020–2022", fill = NULL) +
  theme_void(base_size = 11) + theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# ----------------------- assemble & save -----------------------
layout_plot <- (p_ri_a | p_ri_b) / (p_lod_a | p_lod_b) + patchwork::plot_annotation(tag_levels = "A")
outfile <- file.path(out_dir_base, "ri_lod_2x2.png")
ggsave(outfile, layout_plot, width = 12, height = 10, dpi = 320)
message("✓ Saved: ", outfile)

# (Optional) write polygons for inspection
dir.create(diag_dir, showWarnings = FALSE, recursive = TRUE)
sf::st_write(cl_sf_1999_ri  |> dplyr::mutate(period = "1999_2005"), file.path(diag_dir, "RI_clusters_1999_2005.geojson"),  delete_dsn = TRUE, quiet = TRUE)
sf::st_write(cl_sf_2020_ri  |> dplyr::mutate(period = "2020_2022"), file.path(diag_dir, "RI_clusters_2020_2022.geojson"),  delete_dsn = TRUE, quiet = TRUE)
sf::st_write(cl_sf_1999_lod |> dplyr::mutate(period = "1999_2005"), file.path(diag_dir, "LOD_clusters_1999_2005.geojson"), delete_dsn = TRUE, quiet = TRUE)
sf::st_write(cl_sf_2020_lod |> dplyr::mutate(period = "2020_2022"), file.path(diag_dir, "LOD_clusters_2020_2022.geojson"), delete_dsn = TRUE, quiet = TRUE)
message("Done.")

# -------------------- period summaries (print + save) --------------------
# Summarise cluster-level RI (cluster_ri) and LOD (metrics_lod_two) by the two periods.

summarise_index <- function(df, val_col, period_col = "period") {
  val_sym <- rlang::sym(val_col)
  df %>%
    dplyr::filter(.data[[period_col]] %in% periods_two) %>%
    dplyr::group_by(period = .data[[period_col]]) %>%
    dplyr::summarise(
      n_clusters = sum(!is.na(!!val_sym)),
      p25        = ifelse(n_clusters>0, as.numeric(stats::quantile(!!val_sym, 0.25, na.rm = TRUE)), NA_real_),
      median     = ifelse(n_clusters>0, as.numeric(stats::quantile(!!val_sym, 0.5, na.rm = TRUE)), NA_real_),
      p75        = ifelse(n_clusters>0, as.numeric(stats::quantile(!!val_sym, 0.75, na.rm = TRUE)), NA_real_),
      IQR        = ifelse(n_clusters>0, as.numeric(p75 - p25), NA_real_),
      mean       = ifelse(n_clusters>0, mean(!!val_sym, na.rm = TRUE), NA_real_),
      sd         = ifelse(n_clusters>0, sd(!!val_sym, na.rm = TRUE), NA_real_),
      min        = ifelse(n_clusters>0, min(!!val_sym, na.rm = TRUE), NA_real_),
      max        = ifelse(n_clusters>0, max(!!val_sym, na.rm = TRUE), NA_real_),
      .groups = "drop"
    ) %>%
    # Ensure NaN -> NA and p25/p75/IQR numeric
    dplyr::mutate(across(c(p25, median, p75, IQR, mean, sd, min, max), ~ ifelse(is.nan(.x), NA_real_, as.numeric(.x))))
}

ri_summary  <- summarise_index(cluster_ri,    "RI_post_only", period_col = "period") %>% dplyr::mutate(index = "RI_post_only")
lod_summary <- summarise_index(metrics_lod_two,"lod_value",     period_col = "period") %>% dplyr::mutate(index = "lod_value")

summary_tbl <- dplyr::bind_rows(ri_summary, lod_summary) %>%
  dplyr::select(index, period, n_clusters, p25, median, p75, IQR, mean, sd, min, max)

# print nicely to console
message("---- RI + LOD summaries by period (including IQR) ----")
print(summary_tbl)

# save CSV for reproducibility / figures folder
summary_outfile <- file.path(out_dir_base, "ri_lod_summary_by_period.csv")
readr::write_csv(summary_tbl, summary_outfile)
message("Saved summary CSV: ", summary_outfile)
```
NEW: Make a figure with 3 plots of proportion garbage over 3 time periods
```{r}
# ──────────────────────────────────────────────────────────────
# 3 maps: prop_garbage (1999–2005, 2013–2019, 2020–2022)
#   • Same workflow as RI: county-year → county-period → join membership → cluster means
#   • AK/HI resized; common 2–98% limits across all three panels
#   • Output → figures/5yr_avg_stable/prop_garbage_3maps.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  pkgs <- c("sf","dplyr","stringr","readr","ggplot2","tigris","rlang","patchwork","scales","here")
  missing <- setdiff(pkgs, rownames(installed.packages()))
  if (length(missing)) install.packages(missing, repos = "https://cloud.r-project.org")
  lapply(pkgs, library, character.only = TRUE)
})
options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

# ------------------------- paths -------------------------
membership_file <- here::here("output","county_cluster_membership.csv.gz")  
metrics2_file   <- here::here("data",  "county_year_quality_metrics.csv.gz")
out_dir_base    <- here::here("figures","5yr_avg_stable")
diag_dir        <- file.path(out_dir_base, "diagnostics")
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)
dir.create(diag_dir, recursive = TRUE, showWarnings = FALSE)

# ---------------------- helpers & geos ----------------------
crs_proj <- 2163
periods_three <- c("1999_2005","2013_2019","2020_2022")
std_fips_vec <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
st_shift <- function(sf_obj, shift = c(0,0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) { ctd <- st_centroid(st_union(sf_obj)); st_geometry(sf_obj) <- (st_geometry(sf_obj) - ctd) * scale + ctd; sf_obj }

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_zm(drop = TRUE, what = "ZM") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)
  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000,-4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |> st_scale(1.00) |> st_shift(c(5000000,-1100000)) |> sf::st_set_crs(crs_proj)
  out <- dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
  out$fips <- std_fips_vec(out$fips); sf::st_crs(out) <- crs_proj; out
}
build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)
  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000,-4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |> st_scale(1.00) |> st_shift(c(5000000,-1100000)) |> sf::st_set_crs(crs_proj)
  out <- dplyr::bind_rows(mainland, alaska, hawaii) |> sf::st_make_valid(); sf::st_crs(out) <- crs_proj; out
}

ensure_counties_have_fips <- function(counties_sf, needed_fips, year = 2020, crs_proj = 2163) {
  needed_fips <- unique(std_fips_vec(needed_fips))
  present_fips <- if ("fips" %in% names(counties_sf)) std_fips_vec(counties_sf$fips) else character(0)
  missing_fips <- setdiff(needed_fips, present_fips)
  if (!length(missing_fips)) return(counties_sf)
  fetched <- tryCatch({
    tigris::counties(year = year, cb = TRUE, class = "sf") |>
      sf::st_zm(drop = TRUE, what = "ZM") |>
      dplyr::mutate(GEOID = std_fips_vec(GEOID)) |>
      dplyr::filter(GEOID %in% missing_fips) |>
      sf::st_transform(crs_proj) |>
      sf::st_make_valid() |>
      dplyr::rename(fips = GEOID)
  }, error = function(e) NULL)
  if (is.null(fetched) || !nrow(fetched)) return(counties_sf)
  fetched$fips <- std_fips_vec(fetched$fips)
  out <- dplyr::bind_rows(counties_sf, fetched |> dplyr::anti_join(counties_sf, by = "fips"))
  out$fips <- std_fips_vec(out$fips); sf::st_crs(out) <- crs_proj; sf::st_make_valid(out)
}

build_cluster_sf_safe <- function(period_key, membership_df, counties_sf, tigris_year = 2020, crs_proj = 2163) {
  mm <- membership_df |>
    dplyr::filter(period == period_key) |>
    dplyr::transmute(fips = std_fips_vec(as.character(fips)), cluster = as.character(cluster)) |>
    dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)
  counties_sf <- ensure_counties_have_fips(counties_sf, mm$fips, year = tigris_year, crs_proj = crs_proj)
  cl_sf <- counties_sf |>
    dplyr::inner_join(mm, by = "fips") |>
    dplyr::group_by(cluster) |>
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") |>
    sf::st_make_valid()
  sf::st_crs(cl_sf) <- crs_proj; cl_sf
}

# ----------------------- load inputs -------------------------
if (!file.exists(membership_file)) {
  alt <- sub("\\.csv$", ".csv.gz", membership_file)
  if (file.exists(alt)) membership_file <- alt else stop("Missing membership_file: ", membership_file)
}
if (!file.exists(metrics2_file)) stop("Missing metrics2_file: ", metrics2_file)

membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
metrics2_raw   <- readr::read_csv(metrics2_file,   show_col_types = FALSE)

# normalize membership
nms_m <- names(membership_raw); low_m <- tolower(nms_m)
fips_col_m    <- nms_m[which(grepl("^(fips|geoid)$|^geoid|fips", low_m))[1]]
cluster_col_m <- nms_m[which(grepl("^(cluster|cluster_id)$|cluster", low_m))[1]]
period_col_m  <- nms_m[low_m == "period"][1]
if (is.na(fips_col_m) || is.na(cluster_col_m) || is.na(period_col_m)) stop("Membership needs fips, cluster, period")
membership <- membership_raw |>
  dplyr::transmute(fips = std_fips_vec(.data[[fips_col_m]]),
                   cluster = as.character(.data[[cluster_col_m]]),
                   period = as.character(.data[[period_col_m]])) |>
  dplyr::distinct()

# ---------------- aggregate county-year → county-period (prop_garbage) ----
possible_id_cols <- c("fips","geoid","county_ihme","county")
lower_names <- tolower(names(metrics2_raw))
id_idx <- which(lower_names %in% possible_id_cols)[1]
if (is.na(id_idx)) stop("Could not find an ID column in metrics2_file.")
id_col <- names(metrics2_raw)[id_idx]

pg_candidates <- c("prop_garbage","garbage_prop","pct_garbage","propgarbage")
pg_idx <- which(tolower(names(metrics2_raw)) %in% tolower(pg_candidates))[1]
if (is.na(pg_idx)) stop("Could not find a prop_garbage column (tried: ", paste(pg_candidates, collapse=", "), ").")
pg_col <- names(metrics2_raw)[pg_idx]

time_col <- if ("period" %in% names(metrics2_raw)) {
  "period"
} else if ("year" %in% names(metrics2_raw)) {
  "year"
} else {
  stop("metrics2_file must have 'period' or 'year'.")
}

metrics2 <- metrics2_raw |>
  dplyr::mutate(id_str = std_fips_vec(.data[[id_col]]))

if (time_col == "year") {
  metrics2 <- metrics2 |>
    dplyr::mutate(
      year = as.integer(.data$year),
      period = dplyr::case_when(
        year >= 1999 & year <= 2005 ~ "1999_2005",
        year >= 2006 & year <= 2012 ~ "2006_2012",
        year >= 2013 & year <= 2019 ~ "2013_2019",
        year >= 2020 & year <= 2022 ~ "2020_2022",
        TRUE ~ NA_character_
      )
    )
} else {
  metrics2 <- metrics2 |> dplyr::mutate(period = as.character(.data$period))
}

prop_garbage_by_fips_period <- metrics2 |>
  dplyr::transmute(fips = id_str,
                   period = period,
                   prop_garbage = as.numeric(.data[[pg_col]])) |>
  dplyr::filter(!is.na(fips), !is.na(period)) |>
  dplyr::group_by(fips, period) |>
  dplyr::summarise(prop_garbage = mean(prop_garbage, na.rm = TRUE), .groups = "drop")

readr::write_csv(prop_garbage_by_fips_period, file.path(diag_dir, "prop_garbage_by_fips_period.csv"))

# ---------------- cluster-level means (like RI) ----------------
cluster_pg <- membership |>
  dplyr::left_join(prop_garbage_by_fips_period, by = c("fips","period")) |>
  dplyr::group_by(cluster, period) |>
  dplyr::summarise(prop_garbage = mean(prop_garbage, na.rm = TRUE), .groups = "drop")

# ---------------- geographies & polygons ----------------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

cl_1999 <- build_cluster_sf_safe("1999_2005", membership, counties_tf, tigris_year = 2020, crs_proj = crs_proj)
cl_2013 <- build_cluster_sf_safe("2013_2019", membership, counties_tf, tigris_year = 2020, crs_proj = crs_proj)
cl_2020 <- build_cluster_sf_safe("2020_2022", membership, counties_tf, tigris_year = 2020, crs_proj = crs_proj)

map_1999 <- cl_1999 |> dplyr::left_join(cluster_pg |> dplyr::filter(period == "1999_2005") |> dplyr::select(cluster, prop_garbage), by = "cluster")
map_2013 <- cl_2013 |> dplyr::left_join(cluster_pg |> dplyr::filter(period == "2013_2019") |> dplyr::select(cluster, prop_garbage), by = "cluster")
map_2020 <- cl_2020 |> dplyr::left_join(cluster_pg |> dplyr::filter(period == "2020_2022") |> dplyr::select(cluster, prop_garbage), by = "cluster")

# ---------------- common limits across 3 periods ---------------
pg_vals <- cluster_pg |> dplyr::filter(period %in% periods_three) |> dplyr::pull(prop_garbage) |> (\(x) x[is.finite(x)])()
pg_lims <- if (length(pg_vals) >= 3) stats::quantile(pg_vals, c(0.02, 0.98), na.rm = TRUE) else range(pg_vals, na.rm = TRUE)

make_scale <- function(lims) scale_fill_distiller(palette = "Reds", direction = 1, limits = lims, oob = scales::squish, na.value = "grey90")
base_extent <- list(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000))

p1 <- ggplot() +
  geom_sf(data = map_1999, aes(fill = prop_garbage), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.25) +
  make_scale(pg_lims) + coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "Prop. garbage — 1999–2005", fill = NULL) + theme_void(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

p2 <- ggplot() +
  geom_sf(data = map_2013, aes(fill = prop_garbage), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.25) +
  make_scale(pg_lims) + coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "Prop. garbage — 2013–2019", fill = NULL) + theme_void(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

p3 <- ggplot() +
  geom_sf(data = map_2020, aes(fill = prop_garbage), colour = NA) +
  geom_sf(data = states_tf, fill = NA, colour = "white", linewidth = 0.25) +
  make_scale(pg_lims) + coord_sf(xlim = base_extent$xlim, ylim = base_extent$ylim, expand = FALSE) +
  labs(title = "Prop. garbage — 2020–2022", fill = NULL) + theme_void(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# ---------------- assemble & save ----------------------------
fig <- (p1 | p2 | p3) + patchwork::plot_annotation(tag_levels = "A")
outfile <- file.path(out_dir_base, "prop_garbage_3maps.png")
ggsave(outfile, fig, width = 15, height = 6.5, dpi = 320)
message("✓ Saved: ", outfile)
```
Average KL-divergence overtime
```{r}
metrics_path_gz <- here::here("data","county_year_quality_metrics.csv.gz")
metrics_path    <- if (file.exists(metrics_path_gz)) metrics_path_gz else here::here("data","county_year_quality_metrics.csv")
dq <- readr::read_csv(metrics_path, show_col_types = FALSE)


.wmean <- function(x, w) {
  w <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(w)) || sum(w, na.rm = TRUE) == 0) return(NA_real_)
  stats::weighted.mean(x, w, na.rm = TRUE)
}

ri_ts <- dq %>%
  dplyr::filter(!is.na(year), year >= 1999, year <= 2022, is.finite(RI)) %>%
  dplyr::group_by(year) %>%
  dplyr::summarise(
    wmean_RI  = .wmean(RI, N_garb_g1g2g4g5g6g7),  # weight by targeted garbage bins
    n_ctyyr   = dplyr::n(),
    .groups = "drop"
  )

# Save the underlying series
readr::write_csv(ri_ts, file.path(output_dir, "RI_time_series_1999_2022.csv"))

# Plot (weighted mean only)
p_ri_ts <- ggplot(ri_ts, aes(x = year, y = wmean_RI)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.7) +
  labs(
    x = NULL, y = "Normalized K-L Divergence"
  ) +
  scale_x_continuous(breaks = seq(2000, 2022, by = 2)) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  )

# Save figure
ggsave(file.path(output_dir, "RI_time_series_1999_2022.png"),
       plot = p_ri_ts, width = 8.5, height = 4.8, dpi = 320)

p_ri_ts

```
Make map of z-scores
```{r}
# ──────────────────────────────────────────────────────────────
# Cluster z-scores & maps (overdose-unspecified, prop_garbage, RI, Philips)
#   • Robust to: membership duplicates, Philips column names, odd period labels
#   • Outputs:
#       - output/cluster_scores/cluster_zscores_overdose_philips_RI_propgarbage.csv
#       - figures/5yr_avg_stable/z_<metric>_4panel.png  (+ direction_score_4panel.png)
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(purrr)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ PATHS ------------------------
data_file       <- here("data",   "county_year_quality_metrics.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
philips_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
out_dir_figs    <- here("figures","5yr_avg_stable")
out_dir_scores  <- here("output", "cluster_scores")
dir.create(out_dir_figs,   recursive = TRUE, showWarnings = FALSE)
dir.create(out_dir_scores, recursive = TRUE, showWarnings = FALSE)

# --------------------- periods & helpers -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
safe_div <- function(num, den) ifelse(is.finite(num) & is.finite(den) & den > 0, num / den, NA_real_)
compute_limits_symmetric <- function(x) {
  x <- x[is.finite(x)]; if (!length(x)) return(c(-1,1))
  L <- as.numeric(stats::quantile(abs(x), 0.98, na.rm = TRUE, names = FALSE))
  if (!is.finite(L) || L == 0) L <- 1
  c(-L, L)
}
sanitize <- function(x) { x %>% str_replace_all("[^A-Za-z0-9]+","_") %>% str_replace_all("^_+|_+$","") %>% tolower() }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }

# -------------------- projection & geometry helpers -------------------
crs_proj <- 2163
st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) { ctr <- st_centroid(st_union(sf_obj)); st_geometry(sf_obj) <- (st_geometry(sf_obj) - ctr) * scale + ctr; sf_obj }
build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)
  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> dplyr::rename(fips = GEOID, statefp = STATEFP) |> sf::st_make_valid()
}
build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)
  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> sf::st_make_valid()
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()

# ------------------------- load membership (dedupe) --------------------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        fips   = stringr::str_pad(as.character(fips), 5, pad = "0"),
        period = standardize_period(as.character(period)),
        cluster= as.character(cluster)
      ) %>%
      dplyr::left_join(ihme_map, by = "fips") %>%
      dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips)) %>%
      dplyr::select(county_ihme, period, cluster)
  } else stop("membership_file must contain 'county_ihme' or 'fips'.")

# dedupe to one row per county_ihme × period (mode if needed)
membership <- membership %>%
  dplyr::filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  dplyr::distinct(county_ihme, period, cluster)
dups <- membership %>% dplyr::count(county_ihme, period, name="n") %>% dplyr::filter(n > 1)
if (nrow(dups) > 0) message("Resolving ", nrow(dups), " county×period with multiple clusters (using modal cluster).")
membership <- membership %>%
  dplyr::group_by(county_ihme, period) %>%
  dplyr::summarise(cluster = mode_str(cluster), .groups="drop")

# --------------------- load county-year data -------------------
stopifnot(file.exists(data_file))
dy0 <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  dplyr::mutate(year = suppressWarnings(as.integer(year)),
                period = period_of_year(year))

if ("county_ihme" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
} else if ("fips" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0")) %>%
    dplyr::left_join(ihme_map, by = "fips") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))
} else stop("data_file must contain 'county_ihme' or 'fips'.")

# --- ensure N_garbage & garb_k exist before checks ---
nms <- names(dy)
col_n_cert <- pick_col(nms, c("n_cert","deaths","total","N"))
col_prop_g <- pick_col(nms, c("foreman_garbage","prop_garbage"))
if (!("N_garbage" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating N_garbage = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(N_garbage = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("garb_k" %in% nms) {
    message("Using garb_k as N_garbage"); dy <- dy %>% dplyr::mutate(N_garbage = garb_k)
  } else stop("Missing N_garbage and cannot construct it.")
}
if (!("garb_k" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating garb_k = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(garb_k = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("N_garbage" %in% names(dy)) {
    message("Creating garb_k from N_garbage"); dy <- dy %>% dplyr::mutate(garb_k = N_garbage)
  } else stop("Cannot create garb_k.")
}

# Required vars
need_vars <- c("county_ihme","period","garb_k","n_cert","N_garbage","RI_post_only")
miss <- setdiff(need_vars, names(dy))
if (length(miss)) stop("Missing required columns in data_file: ", paste(miss, collapse=", "))

# ---------------- aggregate county → cluster×period -------------
cluster_core <- dy %>%
  dplyr::select(dplyr::all_of(need_vars)) %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::inner_join(membership, by = c("county_ihme","period")) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    sum_garb_k       = sum(garb_k,       na.rm = TRUE),
    sum_n_cert       = sum(n_cert,       na.rm = TRUE),
    sum_N_garbage    = sum(N_garbage,    na.rm = TRUE),
    num_RI_weighted  = sum(n_cert * RI_post_only, na.rm = TRUE),
    prop_garbage      = safe_div(sum_garb_k,       sum_n_cert),
    RI_cluster        = safe_div(num_RI_weighted,  sum_N_garbage),
    .groups = "drop"
  )

# ---------------- bring in Philips (CSTD; tolerant) ------------
stopifnot(file.exists(philips_file))
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
# normalize column names to lowercase for matching
names(ph0) <- tolower(names(ph0))

# ensure period
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% dplyr::mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% dplyr::mutate(period = standardize_period(period))
}

# normalize IDs to cluster-level
if ("cluster" %in% names(ph0)) {
  ph_norm <- ph0 %>% dplyr::mutate(cluster = as.character(cluster))
} else if ("county_ihme" %in% names(ph0) || "fips" %in% names(ph0)) {
  tmp <- ph0
  if ("fips" %in% names(tmp) && !("county_ihme" %in% names(tmp))) {
    tmp <- tmp %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad="0")) %>%
      dplyr::left_join(ihme_map, by="fips")
  }
  if (!("county_ihme" %in% names(tmp))) stop("Philips file lacks id columns (cluster/county_ihme/fips).")
  ph_norm <- tmp %>%
    dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad="0")) %>%
    dplyr::inner_join(membership, by = c("county_ihme","period"))
} else stop("Philips file must contain 'cluster' or county id (county_ihme/fips).")

# pick cstd & weights robustly
ph_col <- pick_col(names(ph_norm), c("detail_ucod_icd4_cstd","cstd_ucr39","cstd","phillips_detail","philips_detail","cod_cstd","cod_cstd_ucr39"))
if (is.na(ph_col)) stop("Philips source missing CSTD column (tried philips_cstd/cstd_ucr39/cstd/phillips_detail/philips_detail/cod_cstd/...).")
w_col  <- pick_col(names(ph_norm), c("n_cert","deaths","total","n"))

philips_clu <- ph_norm %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::mutate(cluster = as.character(cluster)) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    w   = if (!is.na(w_col)) sum(.data[[w_col]], na.rm=TRUE) else NA_real_,
    num = if (!is.na(w_col)) sum(.data[[w_col]] * .data[[ph_col]], na.rm=TRUE) else sum(.data[[ph_col]], na.rm=TRUE),
    den = if (!is.na(w_col)) w else sum(!is.na(.data[[ph_col]])),
    philips_cstd = safe_div(num, den),
    .groups = "drop"
  ) %>%
  dplyr::filter(!is.na(philips_cstd))

# ---------------- merge & Z-scores -----------------------------
metrics_clu <- cluster_core %>%
  dplyr::inner_join(philips_clu, by = c("period","cluster")) %>%
  dplyr::filter(period %in% period_levels) %>%
  dplyr::arrange(period, cluster) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

score_vars  <- c("philips_cstd","RI_cluster","prop_garbage")
global_means <- vapply(score_vars, function(v) mean(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds   <- vapply(score_vars, function(v)  sd(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds[!is.finite(global_sds) | global_sds == 0] <- NA_real_

z_tbl <- metrics_clu %>%
  dplyr::mutate(dplyr::across(
    dplyr::all_of(score_vars),
    \(x, nm=cur_column()) if (is.na(global_sds[[nm]])) NA_real_ else (x - global_means[[nm]]) / global_sds[[nm]],
    .names = "z_{.col}"
  )) %>%
  # Flip signs: higher z = better (less garbage / fewer unspecified overdoses)
  dplyr::mutate(
    z_prop_garbage      = -z_prop_garbage,
  ) %>%
  dplyr::mutate(
    direction_score = rowMeans(dplyr::across(starts_with("z_")), na.rm = TRUE)
  ) %>%
  dplyr::arrange(period, cluster)

readr::write_csv(z_tbl, file.path(out_dir_scores, "cluster_zscores_overdose_philips_RI_propgarbage.csv"))

# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))

build_cluster_sf <- function(period_key, membership_df, counties_sf_aug) {
  mm <- membership_df %>% dplyr::filter(.data$period == period_key) %>% dplyr::transmute(county_ihme = as.character(county_ihme), cluster = as.character(cluster)) %>% dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)
  counties_sf_aug %>%
    dplyr::inner_join(mm, by = "county_ihme") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ---------------- 4-panel maps of Z-scores --------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, states_sf) {
  ggplot2::ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1, limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(fill = NULL) + facet_wrap(~ period, ncol = 2) + theme_void() +
    theme(strip.text = element_text(size = 12, face = "bold"), legend.text = element_text(size = 9), plot.title = element_blank())
}

to_map <- c("z_RI_cluster","z_prop_garbage","z_philips_cstd","direction_score")

for (mcol in to_map) {
  message("Assembling 4-panel for metric: ", mcol)
  stacked_sf <- purrr::map_dfr(period_levels, function(win){
    cl_sf <- build_cluster_sf(win, membership, counties_aug)
    dat   <- z_tbl %>% dplyr::filter(period==win) %>% dplyr::select(cluster, !!rlang::sym(mcol)) %>% dplyr::rename(value = !!rlang::sym(mcol))
    out   <- cl_sf %>% dplyr::left_join(dat, by="cluster"); out$period <- win; out
  }) %>% dplyr::mutate(period=factor(period, levels=period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals))==1) { message("  Skipping ", mcol, " (no variance)"); next }

  lims_sym <- compute_limits_symmetric(vals)  # symmetric for z-scores (centered at 0)
  p <- make_faceted_map(stacked_sf, "value", lims_sym, states_tf)

  base <- if (mcol == "direction_score") "direction_score" else sanitize(mcol)
  ggsave(file.path(out_dir_figs, paste0(base, "_4panel.png")), p, width=10, height=7.5, dpi=320)
}

message("✓ Done. Z-score CSV in: ", out_dir_scores, "  |  maps in: ", out_dir_figs)

```
Make new aggregate data quality index map with box plot (you must run previous chunk first)
```{r}
# Fixed: Two maps (1999–2005, 2020–2022) + county-by-state boxplot
suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(sf); library(ggplot2)
  library(patchwork); library(scales); library(tigris)
})

# --- user-configurable ---
metric_to_plot <- "direction_score"
out_dir_figs <- if (exists("out_dir_figs")) out_dir_figs else "figures/5yr_avg_stable"
dir.create(out_dir_figs, recursive = TRUE, showWarnings = FALSE)

metric_label <- dplyr::case_when(
  metric_to_plot == "direction_score"      ~ "Aggregate data quality index (z)",
  metric_to_plot == "z_prop_garbage"       ~ "Proportion garbage (z, higher is better)",
  metric_to_plot == "z_philips_cstd"       ~ "Philips CSTD (z, higher is better)",
  metric_to_plot == "z_RI_cluster"         ~ "RI (z, higher is better)",
  TRUE ~ metric_to_plot
)

# --- Normalize IDs (robust) ---
# membership: ensure county_ihme exists & normalised
if (!"county_ihme" %in% names(membership)) {
  if ("fips" %in% names(membership)) {
    membership <- membership %>% mutate(county_ihme = str_pad(as.character(fips), 5, pad = "0"))
  } else stop("membership lacks county_ihme and fips; please create county_ihme first.")
} else {
  membership <- membership %>%
    mutate(county_ihme = str_pad(str_replace_all(as.character(county_ihme), "[^0-9]", ""), 5, pad = "0"))
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()


# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))


# counties_lite from counties_aug (guarantee county_ihme + statefp)
counties_lite <- counties_aug %>% st_drop_geometry() %>% mutate(across(everything(), ~ if (is.factor(.)) as.character(.) else .))
if (!"county_ihme" %in% names(counties_lite)) {
  cand <- intersect(c("county_ihme","GEOID","geoid","fips","FIPS","COUNTYFP"), names(counties_lite))
  if (length(cand)) names(counties_lite)[which(names(counties_lite) == cand[1])] <- "county_ihme"
}
counties_lite <- counties_lite %>%
  mutate(county_ihme = str_pad(str_replace_all(as.character(county_ihme), "[^0-9]", ""), 5, pad = "0"))

# ensure statefp exists, derive from county_ihme if needed
if (!"statefp" %in% names(counties_lite)) {
  if ("STATEFP" %in% names(counties_lite)) {
    counties_lite <- counties_lite %>% rename(statefp = STATEFP)
  } else {
    counties_lite <- counties_lite %>% mutate(statefp = substr(county_ihme, 1, 2))
  }
}
counties_lite <- counties_lite %>% mutate(statefp = str_pad(str_replace_all(as.character(statefp), "[^0-9]", ""), 2, pad = "0"))

# states info (safe)
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") %>%
  sf::st_drop_geometry() %>%
  mutate(STATEFP = str_pad(as.character(STATEFP), 2, pad = "0")) %>%
  dplyr::select(STATEFP, STUSPS) %>%
  dplyr::rename(statefp = STATEFP, state = STUSPS)

# --- helper: make single period map (safe) ---
make_single_map <- function(period_key, mcol, lims, states_sf, membership_df, counties_sf_aug) {
  # build cluster polygons for that period using your build_cluster_sf function
  cl_sf <- build_cluster_sf(period_key, membership_df, counties_sf_aug)
  dat <- z_tbl %>%
    filter(period == period_key) %>%
    select(cluster, value = !!rlang::sym(mcol))
  map_sf <- cl_sf %>% left_join(dat, by = "cluster")
  ggplot() +
    geom_sf(data = map_sf, aes(fill = value), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1,
                         limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = gsub("_", "–", period_key), fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

# --- build map limits across the two periods ---
periods_two <- c("1999_2005","2020_2022")
map_vals <- purrr::map_dfr(periods_two, function(win) {
  cl_sf <- build_cluster_sf(win, membership, counties_aug)
  dat <- z_tbl %>% filter(period == win) %>% select(cluster, value = !!rlang::sym(metric_to_plot))
  cl_sf %>% left_join(dat, by="cluster") %>% transmute(value)
})
lims_sym <- compute_limits_symmetric(map_vals$value)

# --- create maps ---
pA <- make_single_map("1999_2005", metric_to_plot, lims_sym, states_tf, membership, counties_aug)
pB <- make_single_map("2020_2022", metric_to_plot, lims_sym, states_tf, membership, counties_aug)

# --- build county-level dataframe safely ---
build_county_values_safe <- function(per, membership_df = membership, z_tbl_df = z_tbl, counties_df = counties_lite, states_df = states_info) {
  mm <- membership_df %>% filter(period == per) %>% distinct(county_ihme, cluster, .keep_all = TRUE)
  zv <- z_tbl_df %>% filter(period == per) %>% select(cluster, value = !!rlang::sym(metric_to_plot))
  joined <- mm %>% left_join(zv, by = "cluster")
  # ensure counties_df has county_ihme and statefp
  if (!"county_ihme" %in% names(counties_df)) stop("counties_df must have county_ihme")
  if (!"statefp" %in% names(counties_df)) counties_df <- counties_df %>% mutate(statefp = substr(county_ihme,1,2))
  joined2 <- joined %>% left_join(counties_df %>% select(county_ihme, statefp), by = "county_ihme")
  joined3 <- joined2 %>% left_join(states_df, by = "statefp") %>%
    mutate(period = per)
  # keep only rows with a state label and finite value
  res <- joined3 %>% filter(!is.na(state), is.finite(value)) %>% select(state, county_ihme, period, value)
  return(res)
}

bx_df <- bind_rows(build_county_values_safe("1999_2005"),
                   build_county_values_safe("2020_2022"))

# --- prepare boxplot df: rank states by 2020-2022 median, drop territories ---
state_order <- bx_df %>%
  filter(period == "2020_2022") %>%
  group_by(state) %>%
  summarise(med = median(value, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(med)) %>% pull(state)

territories <- c("PR","GU","VI","AS","MP")
bx_df <- bx_df %>% filter(!state %in% territories)

bx_df <- bx_df %>%
  mutate(
    state = factor(state, levels = state_order),
    period = factor(period, levels = c("1999_2005","2020_2022"),
                    labels = c("1999–2005","2020–2022"))
  )

# --- boxplot (visual choices can be adjusted) ---
ylims_box <- c(-2, 2)
pC <- ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  coord_cartesian(ylim = ylims_box) +
  scale_fill_manual(values = c("#94bedf","#f2c879")) +
  labs(x = "States (ranked by declining median county-level 2020-2022 aggregate data quality index)",
       y = metric_label) +
  theme_bw(base_size = 10) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    panel.grid.minor = element_blank()
  )

# --- combine and save ---
combined <- (pA | pB) / pC + plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
base <- if (metric_to_plot == "direction_score") "direction_score" else gsub("[^A-Za-z0-9_-]", "_", metric_to_plot)
outfile <- file.path(out_dir_figs, paste0("two_maps_box_", base, ".png"))
ggsave(outfile, combined, width = 11, height = 8.5, dpi = 320)
cat("Wrote:", outfile, "\n")



# -------------------- period means + 95% CI + IQR (county-level; robust to labels) --------------------

# Helper: normalize different period label formats to canonical keys
normalize_period_key <- function(p) {
  p_chr <- as.character(p)
  # convert en/em dashes to hyphen, remove spaces
  p_chr <- gsub("\u2013|\u2014", "-", p_chr)    # en/em dash -> hyphen
  p_chr <- gsub("\\s+", "", p_chr)             # remove spaces
  sapply(p_chr, function(x) {
    if (grepl("^1999[_\\-]?2005$", x)) return("1999_2005")
    if (grepl("^2013[_\\-]?2019$", x)) return("2013_2019")
    if (grepl("^2020[_\\-]?2022$", x)) return("2020_2022")
    # if already canonical or unknown, return as-is
    return(x)
  }, USE.NAMES = FALSE)
}

# Ensure bx_df exists
if (!exists("bx_df")) stop("bx_df not found. Run the map/boxplot chunk first.")

# Add canonical period_key column (preserve original 'period' for printing)
bx_df <- bx_df %>% mutate(period_key = normalize_period_key(period))

# If 2013_2019 missing, build it and append
if (!"2013_2019" %in% unique(bx_df$period_key)) {
  message("2013_2019 not found in bx_df — building and appending county-level values for 2013_2019.")
  bx_2013_2019 <- build_county_values_safe("2013_2019")
  bx_2013_2019 <- bx_2013_2019 %>% mutate(period_key = normalize_period_key(period))
  bx_df <- bind_rows(bx_df, bx_2013_2019)
}

# Keep only canonical three periods and finite values
target_periods <- c("1999_2005", "2013_2019", "2020_2022")
bx_df2 <- bx_df %>% filter(period_key %in% target_periods & is.finite(value))

# safe IQR helper
iqr_safe <- function(x) {
  if (sum(is.finite(x)) < 2) return(c(NA_real_, NA_real_))
  stats::quantile(x, probs = c(0.25, 0.75), na.rm = TRUE, names = FALSE)
}

# Summarise: n, mean, sd, se, t CI, q1, q3, iqr
summary_ci_tbl <- bx_df2 %>%
  dplyr::group_by(period_key) %>%
  dplyr::summarise(
    n       = dplyr::n(),
    mean    = mean(value, na.rm = TRUE),
    sd      = sd(value, na.rm = TRUE),
    se      = sd / sqrt(n),
    t_975   = ifelse(n > 1, stats::qt(0.975, df = n - 1), NA_real_),
    ci_low  = ifelse(n > 1, mean - t_975 * se, NA_real_),
    ci_high = ifelse(n > 1, mean + t_975 * se, NA_real_),
    q1      = iqr_safe(value)[1],
    q3      = iqr_safe(value)[2],
    iqr     = q3 - q1,
    .groups = "drop"
  ) %>%
  dplyr::arrange(factor(period_key, levels = target_periods))

# pretty label
pretty_label <- function(key) {
  switch(as.character(key),
         "1999_2005" = "1999–2005",
         "2013_2019" = "2013–2019",
         "2020_2022" = "2020–2022",
         as.character(key))
}

# Print formatted summary to console
cat("\n---- Aggregate index (county-level) — mean ± 95% CI; SD; IQR ----\n")
cat(" Period         n     Mean     SD     95% CI [low, high]      Q1     Q3    IQR\n")
cat("-------------------------------------------------------------------------------\n")
for (i in seq_len(nrow(summary_ci_tbl))) {
  row <- summary_ci_tbl[i, ]
  lab <- pretty_label(row$period_key)
  cat(sprintf("%-13s %5d  %7.3f  %6.3f   [%7.3f, %7.3f]   %6.3f  %6.3f  %6.3f\n",
              lab, row$n, row$mean, row$sd, row$ci_low, row$ci_high, row$q1, row$q3, row$iqr))
}
cat("-------------------------------------------------------------------------------\n\n")

# Save CSV
summary_outfile2 <- file.path(out_dir_figs, paste0("two_maps_box_", base, "_mean_CI_IQR_by_period.csv"))
readr::write_csv(summary_ci_tbl, summary_outfile2)
cat("Saved summary CSV: ", summary_outfile2, "\n")
```
NEW: Correlation time series figure
```{r}
# ──────────────────────────────────────────────────────────────
# Re-create inputs for correlation time series (unchanged from your snippet)
# ... (keep the top part of your original script that reads cy, income_all, ph_pc, rep_lu)
# For brevity here I assume you've already run the input-loading section from your original message
# and we resume at the Correlation time series section.
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(tidyr)
  library(ggplot2); library(patchwork); library(scales); library(here); library(purrr)
})

dir.create(here("figures"), recursive = TRUE, showWarnings = FALSE)

# ---------- guards: insist on separate inputs ----------
stopifnot(exists("cy"), is.data.frame(cy))
stopifnot(exists("income_all"), is.data.frame(income_all))
stopifnot(exists("ph_pc"), is.data.frame(ph_pc))
stopifnot(exists("rep_lu"), is.data.frame(rep_lu))

# ---------- helper utils ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !all(is.na(a))) a else b
find_col <- function(df, patterns) {
  for (pat in patterns) {
    hit <- names(df)[grepl(pat, names(df), ignore.case = TRUE)]
    if (length(hit)) return(hit[1])
  }
  NA_character_
}
safe_cor <- function(x, y) {
  ok <- is.finite(x) & is.finite(y)
  if (sum(ok) < 3) return(NA_real_)
  cor(x[ok], y[ok], method = "pearson")
}
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_midyrs <- c(2002L, 2009L, 2016L, 2021L)
period_map <- tibble(period = period_levels, year = period_midyrs)

# ---------- normalize core inputs ----------
cy <- cy %>%
  mutate(county_ihme = std_fips(county_ihme),
         year = suppressWarnings(as.integer(year))) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000")

# prop_garbage + RI columns in cy
prop_garbage_col <- find_col(
  cy, c("prop_garbage")
)
ri_col <- c("RI_post_only")
ri_col <- ri_col[ri_col %in% names(cy)][1] %||% NA_character_
stopifnot(!is.na(prop_garbage_col), !is.na(ri_col))

cy_metrics <- cy %>%
  transmute(county_ihme, year,
            prop_garbage = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
            ri           = suppressWarnings(as.numeric(.data[[ri_col]])))

# ---------- build per-county STABLE predictors from separate inputs ----------
income_pred <- income_all %>%
  transmute(county_ihme = std_fips(county_ihme),
            avg_income = suppressWarnings(as.numeric(
              .data[[find_col(., c("^avg[_ ]?income$","median[_ ]?household[_ ]?income","median[_ ]?income","b19013_001"))]]
            ))) %>%
  filter(is.finite(avg_income)) %>%
  group_by(county_ihme) %>%
  summarise(income_med = median(avg_income, na.rm = TRUE), .groups = "drop")

ph_val_col <- find_col(ph_pc, c("^ph[_ ]?pc$","ph[_ ]?per[_ ]?capita","per[_ ]?capita"))
ph_pred <- ph_pc %>%
  transmute(county_ihme = std_fips(county_ihme),
            ph_pc_val  = suppressWarnings(as.numeric(.data[[ph_val_col]]))) %>%
  filter(is.finite(ph_pc_val)) %>%
  group_by(county_ihme) %>%
  summarise(ph_pc_med = median(ph_pc_val, na.rm = TRUE), .groups = "drop")

# ---------- MODIFY: reporting type -> binary 1/0 for ME vs Coroner, exclude Mixed/Other ----------
# 1 = Medical Examiner, 0 = Coroner, Mixed/Other -> NA (excluded)
rep_pred <- rep_lu %>%
  transmute(county_ihme = std_fips(county_ihme),
            reporting_raw = tolower(trimws(as.character(reporting_type)))) %>%
  mutate(
    reporting_num = case_when(
      grepl("medical|\\bme\\b|examiner", reporting_raw) ~ 1L,
      grepl("coroner", reporting_raw)                 ~ 0L,
      TRUE                                            ~ NA_integer_
    )
  ) %>%
  select(county_ihme, reporting_num)

# ---------- DETAIL (ICD-4) at 4 periods → assign to counties via membership ----------
detail_path <- here("output","cluster_metrics_ucr39_cstd.csv.gz")
membership_path <- here("output","county_cluster_membership.csv.gz")
stopifnot(file.exists(detail_path), file.exists(membership_path))

detail_cluster <- readr::read_csv(detail_path, show_col_types = FALSE)
mem <- readr::read_csv(membership_path, show_col_types = FALSE) %>%
  transmute(county_ihme = std_fips(fips %||% county_ihme %||% GEOID %||% FIPS),
            period = as.character(period),
            cluster = as.character(cluster)) %>%
  distinct()

detail_col <- "detail_ucod_icd4_cstd"
stopifnot(!is.na(detail_col))

detail_cnty_midyears <- detail_cluster %>%
  transmute(period = as.character(period),
            cluster = as.character(cluster),
            detail_icd4 = suppressWarnings(as.numeric(.data[[detail_col]]))) %>%
  inner_join(mem, by = c("cluster","period")) %>%
  inner_join(period_map, by = "period") %>%
  transmute(county_ihme, year, detail_icd4)

# ---------- AGGREGATE INDEX at those 4 midyears ----------
z <- function(v){ m <- mean(v, na.rm = TRUE); s <- sd(v, na.rm = TRUE); if (!is.finite(s) || s==0) return(rep(0,length(v))); (v-m)/s }
agg_df <- cy_metrics %>%
  semi_join(period_map, by = "year") %>%
  left_join(detail_cnty_midyears, by = c("county_ihme","year")) %>%
  group_by(year) %>%
  mutate(agg_index = z(-prop_garbage) + z(detail_icd4) + z(ri)) %>%
  ungroup() %>%
  select(county_ihme, year, agg_index)

# ---------- attach predictors to each metric frame ----------
with_preds <- function(df) {
  df %>%
    left_join(income_pred, by = "county_ihme") %>%
    left_join(ph_pred,     by = "county_ihme") %>%
    left_join(rep_pred,    by = "county_ihme")
}

cy_pg  <- with_preds(cy_metrics %>% select(county_ihme, year, value = prop_garbage))
cy_ri  <- with_preds(cy_metrics %>% select(county_ihme, year, value = ri))
cy_det <- with_preds(detail_cnty_midyears %>% select(county_ihme, year, value = detail_icd4))
cy_agg <- with_preds(agg_df %>% select(county_ihme, year, value = agg_index))

# ---------- compute yearly correlations across counties ----------
compute_yearly_corrs <- function(df, label) {
  df %>%
    group_by(year) %>%
    summarise(
      `Income`                        = safe_cor(value, income_med),
      `PH spend (pc)`                 = safe_cor(value, ph_pc_med),
      # use binary reporting_num: 1 = ME, 0 = Coroner; Mixed/Other are NA and excluded
      `Reporting (ME=1, Coroner=0)`   = safe_cor(value, reporting_num),
      .groups = "drop"
    ) %>%
    pivot_longer(cols = -year, names_to = "predictor", values_to = "corr") %>%
    mutate(metric = label)
}

ts_pg  <- compute_yearly_corrs(cy_pg,  "Proportion garbage")
ts_ri  <- compute_yearly_corrs(cy_ri,  "RI")
ts_det <- compute_yearly_corrs(cy_det, "Level of detail") %>% semi_join(period_map, by = "year")
ts_agg <- compute_yearly_corrs(cy_agg, "Aggregate index") %>% semi_join(period_map, by = "year")

# ---------- plotting ----------
y_lim_pg  <- c(-0.35, 0.35)  # Panel 1: prop_garbage vs predictors
y_lim_ri  <- c(-0.35, 0.35)  # Panel 2: RI vs predictors
y_lim_det <- c(-0.35, 0.35)  # Panel 3: Detail vs predictors (4 points)
y_lim_agg <- c(-0.35, 0.35)  # Panel 4: Aggregate index vs predictors (4 points)

plot_ts <- function(df, title, show_points = TRUE, y_lim = c(-0.35, 0.35)) {
  df <- df %>% dplyr::filter(!is.na(corr))
  ggplot(df, aes(x = year, y = corr, colour = predictor)) +
    geom_hline(yintercept = 0, linewidth = 0.4, linetype = "dashed") +
    geom_line(linewidth = 1) +
    { if (show_points) geom_point(size = 1.8) else NULL } +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    coord_cartesian(ylim = y_lim) +
    labs(title = title, x = NULL, y = "Pearson correlation", colour = NULL) +
    theme_bw(base_size = 11) +
    theme(legend.position = "bottom",
          plot.title = element_text(face = "bold"))
}

g1 <- plot_ts(ts_pg,  "Proportion garbage", TRUE, y_lim_pg)
g2 <- plot_ts(ts_ri,  "RI ",            TRUE, y_lim_ri)
g3 <- plot_ts(ts_det, "Level of detail", TRUE, y_lim_det)
g4 <- plot_ts(ts_agg, "Aggregate data quality index vs income / PH spend / reporting (ME=1, Coroner=0)", TRUE, y_lim_agg)

fig <- (g1 | g2) / (g3 | g4) + patchwork::plot_layout(guides = "collect") &
  theme(legend.position = "bottom")

# ---------- NEW: summary of average correlations (across years) ----------
summary_df <- bind_rows(ts_pg, ts_ri, ts_det, ts_agg) %>%
  group_by(metric, predictor) %>%
  summarise(
    mean_corr = mean(corr, na.rm = TRUE),
    n_years   = sum(!is.na(corr)),
    .groups = "drop"
  ) %>%
  arrange(metric, predictor) %>%
  mutate(mean_corr = round(mean_corr, 3))

# print nicely in console
message("\n# Average Pearson correlations (mean across years) — metric × predictor\n")
print(summary_df)

# also pivot to wide for easy viewing/saving
summary_wide <- summary_df %>%
  select(metric, predictor, mean_corr) %>%
  pivot_wider(names_from = predictor, values_from = mean_corr)

# write CSV for record
summary_outfile <- here::here("figures","correlations_summary.csv")
readr::write_csv(summary_wide, summary_outfile)
message("Wrote summary CSV: ", summary_outfile, "\n")

# ---------- save figure ----------
outfile <- here::here("figures","correlations_four_panel.png")
ggsave(outfile, fig, width = 13, height = 8.5, dpi = 320)
message("Wrote: ", outfile)

```
Make new level of detail maps with box plots
```{r}
# ──────────────────────────────────────────────────────────────
# Two maps (1999–2005, 2020–2022) + box plot
# COD standardized diversity — UCOD 4-digit (detail_ucod_icd4_cstd)
#   • Clustering EXACTLY like your COD script: membership (fips, cluster, period)
#   • AK/HI resized & shifted (same helpers as your script)
#   • Viridis "D"; common limits across the two periods from 2–98% quantiles
#   • NO imputation/backup fills — if a cluster-period is missing, it will be NA
#   • Saves → figures/5yr_avg_stable/two_maps_box_detail_ucod_icd4_cstd.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(tibble)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
  library(purrr);   library(patchwork)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ paths -------------------------------
metrics_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
out_dir_base    <- here("figures", "5yr_avg_stable")
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)

# -------------------- projection ------------------------------
crs_proj <- 2163

# --------------------- stable periods -------------------------
# Use the same labels as your working scripts
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
periods_two   <- c("1999_2005","2020_2022")
territories   <- c("PR","GU","VI","AS","MP")

# ------------------------ helpers -----------------------------
sanitize <- function(x) {
  x %>% str_replace_all("[^A-Za-z0-9]+", "_") %>%
    str_replace_all("^_+|_+$", "") %>% tolower()
}

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

# Build cluster polygons exactly like your COD script: per-period membership → union by cluster
build_cluster_sf <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df %>%
    dplyr::filter(.data$period == period_key) %>%
    dplyr::transmute(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                     cluster = as.character(cluster)) %>%
    dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)

  counties_sf %>%
    dplyr::inner_join(mm, by = "fips") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ------------------------- load data --------------------------
message("Reading metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading membership: ", membership_file)
membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  dplyr::mutate(cluster = as.character(cluster),
                period  = as.character(period),
                fips    = stringr::str_pad(as.character(fips), 5, pad = "0"))

# Prepare transformed geographies ONCE (AK/HI resized exactly like your script)
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()

# ---------------------- select the UCOD metric ----------------
# Column name provided by you
ucod_col <- "detail_ucod_icd4_cstd"
if (!ucod_col %in% names(metrics)) {
  stop("Column 'detail_ucod_icd4_cstd' not found in metrics. Available: ", paste(names(metrics), collapse = ", "))
}

# Keep only periods we need, preserve labels
metrics_two <- metrics %>%
  dplyr::filter(period %in% periods_two) %>%
  dplyr::select(cluster, period, !!rlang::sym(ucod_col)) %>%
  dplyr::rename(value = !!rlang::sym(ucod_col))

# ----------------- common limits across the two periods -----------------
lims_info <- {
  vals <- metrics_two$value[is.finite(metrics_two$value)]
  if (length(vals) >= 3) {
    stats::quantile(vals, c(0.02, 0.98), na.rm = TRUE, names = FALSE)
  } else {
    range(vals, na.rm = TRUE)
  }
}

# ------------------------- make the two maps ----------------------------
make_single_map <- function(period_key, lims, states_sf, membership_df, counties_sf, metrics_df) {
  cl_sf <- build_cluster_sf(period_key, membership_df, counties_sf)

  dat <- metrics_df %>%
    dplyr::filter(period == period_key) %>%
    dplyr::select(cluster, value)

  map_sf <- cl_sf %>% dplyr::left_join(dat, by = "cluster")

ggplot2::ggplot() +
  geom_sf(data = map_sf, aes(fill = value), colour = NA) +
  geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
  scale_fill_distiller(palette = "Reds", direction = -1,
                       limits = lims, oob = scales::squish, na.value = "grey90") +
  coord_sf(xlim = c(-2500000, 2500000),
           ylim = c(-2200000,  730000),
           expand = FALSE) +
  labs(title = gsub("_", "–", period_key), fill = NULL) +
  theme_void(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

pA <- make_single_map("1999_2005", lims_info, states_tf, membership, counties_tf, metrics_two)
pB <- make_single_map("2020_2022", lims_info, states_tf, membership, counties_tf, metrics_two)

# ----------------------- box plot (by state) ----------------------------
# For each period:
#   membership (fips -> cluster) ⟶ join cluster value ⟶ attach state via counties_tf ⟶ box by STUSPS
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
  sf::st_drop_geometry() |>
  dplyr::select(STATEFP, STUSPS) |>
  dplyr::rename(statefp = STATEFP, state = STUSPS) |>
  dplyr::mutate(statefp = stringr::str_pad(as.character(statefp), 2, pad = "0"))

counties_lite <- counties_tf %>%
  sf::st_drop_geometry() %>%
  dplyr::select(fips, statefp) %>%
  dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0"),
                statefp = stringr::str_pad(as.character(statefp), 2, pad = "0"))

build_county_values <- function(per) {
  mm <- membership %>%
    dplyr::filter(period == per) %>%
    dplyr::select(fips, cluster)

  zv <- metrics_two %>%
    dplyr::filter(period == per) %>%
    dplyr::select(cluster, value)

  mm %>%
    dplyr::left_join(zv, by = "cluster") %>%
    dplyr::left_join(counties_lite, by = c("fips" = "fips")) %>%
    dplyr::left_join(states_info,  by = "statefp") %>%
    dplyr::transmute(state, fips, period = per, value) %>%
    dplyr::filter(!is.na(state), is.finite(value))
}

bx_df <- dplyr::bind_rows(
  build_county_values("1999_2005"),
  build_county_values("2020_2022")
) %>% dplyr::filter(!state %in% territories)

# Order states by declining median of 2020–2022
state_order <- bx_df %>%
  dplyr::filter(period == "2020_2022") %>%
  dplyr::group_by(state) %>%
  dplyr::summarise(med = median(value, na.rm = TRUE), .groups = "drop") %>%
  dplyr::arrange(dplyr::desc(med)) %>% dplyr::pull(state)

bx_df <- bx_df %>%
  dplyr::mutate(
    state  = factor(state, levels = state_order),
    period = factor(period, levels = c("1999_2005","2020_2022"),
                    labels = c("1999–2005","2020–2022"))
  )

pC <- ggplot2::ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
    scale_y_continuous(limits = c(48, 60)) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  # UCOD diversity is not necessarily 0–1; let ggplot choose sensible y scaling
  labs(x = "States (ranked by declining median county-level 2020–2022 UCOD 4-digit standardized diversity)",
       y = "UCOD 4-digit standardized diversity") +
  theme_bw(base_size = 10) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    panel.grid.minor = element_blank()
  )

# ----------------------- assemble & save ----------------------
combined <- (pA | pB) / pC + plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
outfile <- file.path(out_dir_base, "two_maps_box_detail_ucod_icd4_cstd.png")
ggsave(outfile, combined, width = 11, height = 8.5, dpi = 320)
message("✓ Saved: ", outfile)

```
Make new RI and prop_garabge maps with box plot
```{r}
# ──────────────────────────────────────────────────────────────
# Three-period maps + box plot for RI and prop_garbage
#   • Periods: 1999–2005, 2013–2019, 2020–2022
#   • Uses temporally-stable clusters in `cluster_map`
#   • AK/HI identical to aggregate maps (uses counties_aug & states_tf; falls back if needed)
#   • Viridis "D" (inverted for prop_garbage)
#   • Custom box plot y-limits
#   • Box-plot legend centered above the panel
#   • Outputs → figures/5yr_avg_stable/two_maps_box_<metric>.png
# Prereqs expected in memory (if present): dq (with time_window & metrics), cluster_map, counties_aug, states_tf
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(sf); library(scales)
  library(patchwork); library(here); library(stringr); library(readr)
  library(tidyr); library(tigris)
})

options(tigris_use_cache = TRUE, tigris_class = "sf")

# ---- Periods & constants ----
periods_three <- c("1999_2005","2013_2019","2020_2022")
territories   <- c("PR","GU","VI","AS","MP")

# ──────────────────────────────────────────────────────────────
# Fallback builders (only run if needed)
# ──────────────────────────────────────────────────────────────

# 0) Build AK/HI-shifted county/state layers if not supplied (same recipe as your aggregate maps)
crs_proj <- 2163

st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) {
  centroid <- st_centroid(st_union(sf_obj))
  st_geometry(sf_obj) <- (st_geometry(sf_obj) - centroid) * scale + centroid
  sf_obj
}

build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID, statefp = STATEFP) |>
    sf::st_make_valid()
}

build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |>
                st_scale(0.33) |>
                st_shift(c(1100000, -4700000)) |>
                sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |>
                st_scale(1)  |>
                st_shift(c(5000000, -1100000)) |>
                sf::st_set_crs(crs_proj)

  dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()
}

# 1) Ensure we have states_tf
if (!exists("states_tf")) {
  states_tf <- build_states_2163_resized()
}

# 2) Ensure counties_aug_fixed with county_ihme & statefp (IHME crosswalk) + clusters_aug_sf
if (!exists("clusters_aug_sf") || !exists("counties_lite")) {
  if (!exists("counties_aug")) stop("Please provide `counties_aug` or precomputed `clusters_aug_sf`.")

  # IHME crosswalk
  load(here::here("data_raw","ihme_fips.rda"))  # -> ihme_fips
  ihme_map <- ihme_fips %>%
    transmute(
      GEOID       = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
      county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
    ) %>% distinct()

  counties_aug_fixed <- counties_aug
  if ("fips" %in% names(counties_aug_fixed)) {
    counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(fips), 5, pad = "0"))
  } else if ("GEOID" %in% names(counties_aug_fixed)) {
    counties_aug_fixed <- counties_aug_fixed %>% mutate(fips = str_pad(as.character(GEOID), 5, pad = "0"))
  } else stop("`counties_aug` must have either 'fips' or 'GEOID'.")

  if (!"statefp" %in% names(counties_aug_fixed)) {
    if ("STATEFP" %in% names(counties_aug_fixed)) {
      counties_aug_fixed <- counties_aug_fixed %>% mutate(statefp = as.character(STATEFP))
    } else stop("`counties_aug` must have 'statefp' or 'STATEFP'.")
  }
  counties_aug_fixed <- counties_aug_fixed %>% mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

counties_aug_fixed <- counties_aug_fixed %>%
  left_join(ihme_map, by = "fips", suffix = c(".orig", ".map")) %>%
  mutate(
    county_ihme = coalesce(county_ihme.orig, county_ihme.map, fips)
  ) %>%
  select(-county_ihme.orig, -county_ihme.map)

  if (!exists("cluster_map")) stop("`cluster_map` (county_ihme -> cluster_id) is required.")

  clusters_aug_sf <- counties_aug_fixed %>%
    select(county_ihme, geometry) %>%
    inner_join(cluster_map, by = "county_ihme.x") %>%
    group_by(cluster_id) %>%
    summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()

  counties_lite <- counties_aug_fixed %>%
    sf::st_drop_geometry() %>%
    select(county_ihme, statefp)


counties_lite <- counties_lite %>%
  rename(county_ihme = fips) %>%
  mutate(county_ihme = str_pad(as.character(county_ihme), 5, pad = "0"))

# 2) Quick sanity checks (optional but useful)
cat("counties_lite names: ", paste(names(counties_lite), collapse = ", "), "\n")
cat("example counties_lite rows:\n"); print(head(counties_lite))
cat("Sample county_ihme in cluster_map but not in counties_lite (should be empty or small):\n")
print(setdiff(cluster_map$county_ihme, counties_lite$county_ihme)[1:10])

}

# 3) State labels (for box plot)
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") %>%
  sf::st_drop_geometry() %>%
  select(STATEFP, STUSPS) %>%
  rename(statefp = STATEFP, state = STUSPS) %>%
  mutate(statefp = str_pad(as.character(statefp), 2, pad = "0"))

# ──────────────────────────────────────────────────────────────
# Plot helpers
# ──────────────────────────────────────────────────────────────

make_map <- function(map_sf, fill_col, title, lims, states_sf, reverse = FALSE) {
  ggplot() +
    geom_sf(data = map_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(
      palette = "Reds",
      limits = lims,
      oob = scales::squish,
      direction = 1,
      na.value = "grey90"
    ) +
    coord_sf(
      xlim = c(-2500000, 2500000),
      ylim = c(-2200000,  730000),
      expand = FALSE
    ) +
    labs(title = title, fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

# Box plot helper — legend centered **above** the panel
make_boxplot <- function(bx_df, y_lab, percent_scale = FALSE, fixed_ylim = NULL) {
  p <- ggplot(bx_df, aes(x = state, y = value, fill = period)) +
    geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
    geom_boxplot(width = 0.7, outlier.alpha = 0.4,
                 position = position_dodge2(width = 0.75, preserve = "single")) +
    labs(x = "States (ranked by declining median county-level 2020–2022)",
         y = y_lab) +
    # Center the legend over the panel area
    coord_cartesian(ylim = fixed_ylim, clip = "off") +
    theme_bw(base_size = 10) +
    theme(
      legend.position      = c(0.5, 1.05),   # center horizontally, slightly above panel
      legend.justification = c(0.5, 0),      # anchor from center-bottom
      legend.direction     = "horizontal",
      legend.box           = "horizontal",
      legend.title         = element_blank(),
      plot.margin          = margin(t = 18, r = 5, b = 5, l = 5),
      axis.text.x          = element_text(angle = 90, vjust = 0.5, hjust = 1),
      panel.grid.minor     = element_blank()
    ) +
    guides(fill = guide_legend(nrow = 1, byrow = TRUE))
  if (percent_scale) p <- p + scale_y_continuous(labels = percent_format(accuracy = 1))
  p
}

# Wrapper to make the figure for one metric
make_three_period_map_box <- function(metric_col,
                                      file_tag,
                                      pretty_y_label,
                                      percent_scale  = FALSE,
                                      fixed_ylim     = NULL,
                                      reverse_fill   = FALSE) {
  if (!exists("dq")) stop("`dq` not found. It must include `county_ihme`, `time_window`, and the metric column.")

  all_clusters <- sort(unique(cluster_map$cluster_id))

  cl_df <- dq %>%
    filter(!is.na(time_window), time_window %in% periods_three) %>%
    select(county_ihme, time_window, !!sym(metric_col)) %>%
    rename(value = !!sym(metric_col)) %>%
    inner_join(cluster_map, by = "county_ihme") %>%
    group_by(cluster_id, time_window) %>%
    summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
    tidyr::complete(cluster_id = all_clusters,
                    time_window = periods_three,
                    fill = list(value = NA_real_))   # do NOT force zeros; keep NA if a cluster truly missing

  # colourbar limits across the three periods (2–98% to avoid extreme outliers)
  vals <- cl_df$value[is.finite(cl_df$value)]
  lims <- if (length(vals) >= 10) stats::quantile(vals, c(0.02, 0.98), na.rm = TRUE) else range(vals, na.rm = TRUE)

  # build maps (no NA->0 for maps; leave grey if truly missing)
  mp_1999 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "1999_2005"), by = "cluster_id")
  mp_2013 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "2013_2019"), by = "cluster_id")
  mp_2020 <- clusters_aug_sf %>% left_join(filter(cl_df, time_window == "2020_2022"), by = "cluster_id")

  pA <- make_map(mp_1999, "value", "1999–2005", lims, states_tf, reverse_fill)
  pB <- make_map(mp_2013, "value", "2013–2019", lims, states_tf, reverse_fill)
  pC_map <- make_map(mp_2020, "value", "2020–2022", lims, states_tf, reverse_fill)

  # box plot data
  build_bx_df <- function(per) {
    zv <- cl_df %>% filter(time_window == per) %>% select(cluster_id, value)
    cluster_map %>%
      left_join(zv, by = "cluster_id") %>%
      left_join(counties_lite, by = "county_ihme") %>%
      left_join(states_info,  by = "statefp") %>%
      transmute(state, county_ihme, period = per, value) %>%
      filter(!is.na(state), is.finite(value))
  }
  bx_df <- bind_rows(
    build_bx_df("1999_2005"),
    build_bx_df("2020_2022")
  ) %>% filter(!state %in% territories)

  # order states by 2020–2022 median
  state_order <- bx_df %>%
    filter(period == "2020_2022") %>%
    group_by(state) %>%
    summarise(med = median(value, na.rm=TRUE), .groups = "drop") %>%
    arrange(desc(med)) %>% pull(state)

  bx_df <- bx_df %>%
    mutate(state  = factor(state, levels = state_order),
           period = factor(period, levels = periods_three,
                           labels = c("1999–2005","2013–2019","2020–2022")))

  p_box <- make_boxplot(bx_df, pretty_y_label, percent_scale, fixed_ylim)

  combined <- (pA | pB | pC_map) / p_box +
    plot_layout(heights = c(2, 1), guides = "keep") +
    plot_annotation(tag_levels = "A")

  dir.create(here::here("figures","5yr_avg_stable"), recursive = TRUE, showWarnings = FALSE)
  outfile <- here::here("figures","5yr_avg_stable", paste0("two_maps_box_", file_tag, ".png"))
  ggsave(outfile, combined, width = 13, height = 9, dpi = 320)
  message("✓ Saved: ", outfile)
}

# ──────────────────────────────────────────────────────────────
# RUN: RI (box plot limits 0.025–0.05; maps not inverted)
make_three_period_map_box(
  metric_col      = "RI_post_only",     # ensure this column exists in `dq`
  file_tag        = "RI_post_only",
  pretty_y_label  = "Reassignment Index (RI)",
  percent_scale   = FALSE,
  fixed_ylim      = c(0.07, 0.13),
  reverse_fill    = FALSE
)

# RUN: prop_garbage (box plot limits 15%–50%; maps inverted)
make_three_period_map_box(
  metric_col      = "prop_garbage",   # ensure this column exists in `dq`
  file_tag        = "prop_garbage",
  pretty_y_label  = "Percentage of deaths that are garbage coded (%)",
  percent_scale   = TRUE,
  fixed_ylim      = c(0.15, 0.50),
  reverse_fill    = TRUE
)

```
Build public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# Build `fin_all` from fixed-width FinEstDAT (2017/2022) + PID crosswalk
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr); library(here)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# ---- 1) Parser for FinEst Individual Unit fixed-width file ----
# Layout (robustly inferred):
# [govt_id (14 chars)] [item_code (3 chars)] [amount (digits, right-justified)] [year (4)] [flag (1)]
# We parse from the RIGHT to avoid depending on space counts.
parse_finest_fixed <- function(path) {
  stopifnot(file.exists(path))
  lines <- read_lines(path, progress = FALSE)
  # drop blanks
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(tibble())

  # RIGHT-anchored extraction
  year  <- as.integer(str_sub(lines, -5, -2))
  flag  <- str_sub(lines, -1, -1)
  left1 <- str_sub(lines,  1, -6)                       # everything before year+flag
  # amount is trailing digits on left1
  m <- regexpr("(\\d+)\\s*$", left1, perl = TRUE)
  amt_str <- ifelse(m > 0, regmatches(left1, m), NA_character_)
  amount  <- suppressWarnings(as.numeric(amt_str))
  left2   <- ifelse(m > 0, substr(left1, 1, m - 1L), left1)
  left2   <- rtrim <- sub("\\s+$", "", left2)           # trim right spaces

  # last 3 chars of left2 are the raw item code (alpha+2digits OR 2digits+alpha)
  raw_item <- str_sub(left2, -3, -1)
  govt_id  <- str_sub(left2,  1, -4)

  # Normalize item code to LETTER+2DIGITS (e.g., "E32", "T01")
  item_code <- ifelse(grepl("^[A-Z][0-9]{2}$", raw_item, ignore.case = TRUE),
                      toupper(raw_item),
               ifelse(grepl("^[0-9]{2}[A-Z]$", raw_item, ignore.case = TRUE),
                      paste0(toupper(str_sub(raw_item, -1, -1)), str_sub(raw_item, 1, 2)),
                      toupper(raw_item)))

  tibble(
    govt_id  = govt_id,
    item_code = item_code,
    amount   = amount,
    year     = year,
    flag     = flag
  ) %>%
    filter(!is.na(amount), !is.na(year), nchar(govt_id) >= 10)
}

# ---- 2) PID crosswalk (maps govt_id → county FIPS if available) ----
# PID files vary; try TSV/CSV; look for columns like GOVTID/GOVT_ID and FIPS/GEOID/COUNTYFIPS.
# ──────────────────────────────────────────────────────────────
# Robust PID crosswalk for fixed‑width PID (e.g., Fin_PID_2022.txt)
# Extracts: govt_id (leading digits), county_ihme (stateFIPS + county)
# Lines look like:
# 011003160514BALDWIN COUNTY … 99003   22928722             093022
# ──────────────────────────────────────────────────────────────
read_pid_xwalk <- function(path) {
  if (!file.exists(path)) return(NULL)
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(NULL)

  # helper: leading digits = GOVTID
  lead_digits <- function(x) sub("^([0-9]+).*$", "\\1", x)

  # find the right-most 5-digit token that starts with "99" (e.g., 99015)
  find_99_code <- function(x) {
    m <- gregexpr("\\b99\\d{3}\\b", x, perl = TRUE)
    if (m[[1]][1] == -1) return(NA_character_)
    # take the last match on the line
    ix <- tail(m[[1]], 1)
    substr(x, ix, ix + attr(m[[1]], "match.length")[length(m[[1]])] - 1)
  }

  tib <- tibble::tibble(raw = lines) %>%
    dplyr::mutate(
      govt_id_raw = lead_digits(raw),
      state_fips  = substr(govt_id_raw, 1, 2),
      code_99     = vapply(raw, find_99_code, character(1)),
      county_ihme = dplyr::if_else(
        !is.na(code_99),
        paste0(state_fips, substr(code_99, 3, 5)),
        NA_character_
      )
    ) %>%
    dplyr::filter(!is.na(county_ihme), nchar(county_ihme) == 5) %>%
    dplyr::transmute(
      govt_id = govt_id_raw,
      county_ihme = stringr::str_pad(county_ihme, 5, pad = "0")
    ) %>%
    dplyr::distinct()

  if (!nrow(tib)) return(NULL)
  tib
}
# ---- 3) Locate files and build fin_all ----
find_first <- function(fname) {
  c(here("data_raw/finance", fname), fname) |> {\(p) p[file.exists(p)][1]}()
}

fin2017_path <- find_first("2017FinEstDAT_09202024modp_pu.txt")
fin2022_path <- find_first("2022FinEstDAT_09202024modp_pu.txt")
pid2017_path <- find_first("Fin_PID_2017.txt")
pid2022_path <- find_first("Fin_PID_2022.txt")

fin_tbls <- list()
if (!is.na(fin2017_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2017_path)))
if (!is.na(fin2022_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2022_path)))
stopifnot(length(fin_tbls) > 0)

fin_raw <- bind_rows(fin_tbls)

# PID crosswalks (optional but recommended for county mapping)
pid_xw <- bind_rows(
  list(read_pid_xwalk(pid2017_path), read_pid_xwalk(pid2022_path)) |> compact()
) %>% distinct()

# ---- 4) Filter to Public Health Expenditures (E32) and summarize by county ----
# item_code "E32" = expenditures, function 32 (Public Health)
fin_e32 <- fin_raw %>% filter(item_code == "E32")

if (nrow(fin_e32) == 0) {
  stop("Parsed finance files but found ZERO rows with item_code == 'E32'. ",
       "Double-check files and item code list; if needed, print a sample of item_code counts.")
}

# Map to counties
if (!nrow(pid_xw)) {
  stop("PID crosswalk not found or had no usable (govt_id, FIPS) columns. ",
       "Please provide Fin_PID_2017.txt / Fin_PID_2022.txt (or their actual paths).")
}

fin_all <- fin_e32 %>%
  left_join(pid_xw, by = "govt_id") %>%
  filter(!is.na(county_ihme)) %>%
  transmute(
    county_ihme = county_ihme,
    fin_year    = as.integer(year),
    ph_exp_total = as.numeric(amount)
  ) %>%
  group_by(county_ihme, fin_year) %>%
  summarise(ph_exp_total = sum(ph_exp_total, na.rm = TRUE), .groups = "drop")

# Sanity check
cat("# fin_all rows:", nrow(fin_all), "\n")
print(fin_all %>% count(fin_year, sort = TRUE))
```
Build pop and other needed things for next chunk
```{r}
# ──────────────────────────────────────────────────────────────
# REPAIR BLOCK — ensure components + build pop_join
# Run this ONCE before the PH-spend plotting code
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(purrr)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
as_county_ihme <- function(df) {
  nm <- names(df)
  id_col <- dplyr::case_when(
    "county_ihme" %in% nm ~ "county_ihme",
    "GEOID"       %in% nm ~ "GEOID",
    "fips"        %in% nm ~ "fips",
    "FIPS"        %in% nm ~ "FIPS",
    "countyrs"    %in% nm ~ "countyrs",
    TRUE ~ NA_character_
  )
  if (is.na(id_col)) stop("No county ID column found. Expect one of county_ihme/GEOID/fips/FIPS/countyrs.")
  df %>% mutate(county_ihme = std_fips(.data[[id_col]]))
}


# 2) Build pop_join (ACS preferred; pid_all fallback)
build_pop_join <- function(fin_years) {
  # Reuse if already valid
  if (exists("pop_join", inherits = TRUE)) {
    pj <- get("pop_join", inherits = TRUE)
    if (all(c("county_ihme","fin_year","pop") %in% names(pj))) return(pj)
  }

  # Try ACS via tidycensus
  if (requireNamespace("tidycensus", quietly = TRUE)) {
    message("Building pop_join from ACS (B01001_001, ACS5) …")
    out <- purrr::map_dfr(sort(unique(stats::na.omit(as.integer(fin_years)))), function(y) {
      yy <- max(2009L, min(2023L, as.integer(y)))  # ACS5 window
      tidycensus::get_acs(
        geography = "county", variables = "B01001_001",
        year = yy, survey = "acs5", cache_table = TRUE, show_call = FALSE
      ) %>%
        transmute(county_ihme = GEOID, fin_year = y, pop = estimate)
    })
    if (nrow(out)) return(out)
  }

  # Fallback: pid_all (must exist and have year/pop)
  if (exists("pid_all", inherits = TRUE)) {
    message("Falling back to pid_all for population …")
    pid <- get("pid_all", inherits = TRUE)
    stopifnot(all(c("county_ihme","year","pop") %in% names(pid)))
    return(pid %>% transmute(county_ihme, fin_year = as.integer(year), pop))
  }

  stop("Could not build pop_join: neither ACS nor pid_all available.")
}

# Need fin_years from fin_all
if (!exists("fin_all", inherits = TRUE)) stop("fin_all not found — run the finance builder first.")
fin_all <- as_county_ihme(fin_all)
stopifnot(all(c("county_ihme","fin_year","ph_exp_total") %in% names(fin_all)))

avail_fin_years <- sort(unique(stats::na.omit(as.integer(fin_all$fin_year))))
if (!length(avail_fin_years)) stop("No valid fin_year values in fin_all.")

pop_join <- build_pop_join(avail_fin_years)

# Finally: build ph_pc for downstream chunk
ph_pc <- fin_all %>%
  filter(!is.na(fin_year)) %>%
  left_join(pop_join, by = c("county_ihme","fin_year")) %>%
  mutate(ph_pc = ph_exp_total / pop) %>%
  filter(is.finite(ph_pc))
```
Build income (need for next chunk)
```{r}
# ──────────────────────────────────────────────────────────────
# Build income_all from the US Census API (ACS 5-year, B19013_001)
# • Output columns: county_ihme, acs_year, avg_income
# • Uses fin_years_actual if present; otherwise defaults to c(2017, 2022)
# • Requires: tidycensus (preferred). Falls back to censusapi if needed.
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(tidyr)
})

# Helper: install/load a package quietly
ensure_pkg <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  invisible(TRUE)
}

# Decide which ACS years to fetch.
# County-level ACS 5-year is available 2009+; you likely want finance years like 2017 & 2022.
acs_years <- if (exists("fin_years_actual") && length(fin_years_actual)) {
  unique(suppressWarnings(as.integer(fin_years_actual)))
} else {
  c(2017L, 2022L)
}
acs_years <- acs_years[is.finite(acs_years) & acs_years >= 2009L]
acs_years <- sort(unique(acs_years))

if (!length(acs_years)) stop("No valid ACS years to fetch (need >=2009).")

# Preferred path: tidycensus
have_tidycensus <- FALSE
if (ensure_pkg("tidycensus")) {
  # Only set a key if user already has one in env/options; otherwise tidycensus still works for many calls.
  # You can pre-set with: tidycensus::census_api_key("YOUR_KEY", install = FALSE, overwrite = FALSE)
  suppressWarnings({
    have_tidycensus <- requireNamespace("tidycensus", quietly = TRUE)
  })
}

pull_income_tidycensus <- function(years) {
  purrr::map_dfr(years, function(y) {
    df <- tidycensus::get_acs(
      geography = "county",
      variables = "B19013_001",  # Median household income (dollars)
      year = y,
      survey = "acs5",
      cache_table = TRUE,
      geometry = FALSE
    )
    tibble::tibble(
      county_ihme = df$GEOID,                   # 5-digit FIPS
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$estimate))
    )
  })
}

# Fallback path: censusapi (raw var names differ slightly but include "B19013_001E")
pull_income_censusapi <- function(years) {
  ensure_pkg("censusapi")
  purrr::map_dfr(years, function(y) {
    df <- censusapi::getCensus(
      name   = "acs/acs5",
      vintage= y,
      vars   = c("NAME", "B19013_001E"),
      region = "county:*",
      regionin = "state:*"
    )
    tibble::tibble(
      county_ihme = stringr::str_pad(paste0(df$state, df$county), 5, pad = "0"),
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$B19013_001E))
    )
  })
}

income_all <- tryCatch(
  if (have_tidycensus) pull_income_tidycensus(acs_years) else pull_income_censusapi(acs_years),
  error = function(e) {
    message("[income_all] tidycensus pull failed or unavailable; trying censusapi…\n", conditionMessage(e))
    pull_income_censusapi(acs_years)
  }
) %>%
  mutate(
    county_ihme = as.character(county_ihme),
    acs_year    = as.integer(acs_year),
    avg_income  = suppressWarnings(as.numeric(avg_income))
  ) %>%
  filter(!is.na(avg_income), is.finite(avg_income)) %>%
  arrange(acs_year, county_ihme)

# Optional: restrict to CONUS (drop PR/AK/HI) if your workflow expects that
# income_all <- income_all %>% filter(!stringr::str_sub(county_ihme, 1, 2) %in% c("02","15","72"))

# Sanity checks
message("[income_all] Years fetched: ", paste(unique(income_all$acs_year), collapse = ", "))
message("[income_all] Rows: ", nrow(income_all), " | Counties per year (median): ",
        stats::median(table(income_all$acs_year)))

# (Optional) If you want real (inflation-adjusted) dollars, bring your CPI deflator here and do:
# income_all <- income_all %>% left_join(cpi_tbl, by = c("acs_year" = "year")) %>%
#   mutate(avg_income_real_2022 = avg_income * deflator_to_2022)
# Then, in your plotting chunk, switch avg_income → avg_income_real_2022.
``` 
Validation: z-scores by reporting type, per capita healthcare expenditure, and income
```{r}
# ──────────────────────────────────────────────────────────────
# Validation (NEW): Aggregate index built from county–year z-scores
#   Index = mean( -Z(prop_garbage), -Z(pct_overd_miss), Z(RI_post_only), Z(Phillips detail) )
#   • Phillips detail pulled from cluster CSV, expanded to county–year
#   • Time series by Reporting Type, PH-spend quintile, Income quintile
# Saves:
#   figures/validation_zscore/direction_by_reporting.png
#   figures/validation_zscore/direction_by_spend_quintile.png
#   figures/validation_zscore/direction_by_income_quintile.png
#   figures/validation_zscore/direction_timeseries_3panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr);  library(tidyr);  library(ggplot2); library(scales)
  library(readr);  library(stringr); library(here);   library(purrr)
})

dir.create(here("figures","validation_zscore"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
pick_first <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# ---------- file paths (robust candidates) ----------
data_candidates <- c(here("data","county_year_quality_metrics.csv"),
                     here("data","county_year_quality_metrics.csv.gz"))
membership_candidates <- c(here("output","county_cluster_membership.csv.gz"),
                           here("output","county_cluster_membership.csv"),
                           "output/county_cluster_membership.csv.gz")
philips_candidates <- c(here("output","cluster_metrics_ucr39_cstd.csv.gz"),
                        here("output","cluster_metrics.csv.gz"),
                        "output/cluster_metrics_ucr39_cstd.csv.gz")
reporting_candidates <- c(
  here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
  here("data_raw","County-Death-Investigation-System-2018.csv"),
  "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv",
  "data_raw/County-Death-Investigation-System-2018.csv"
)
ph_pc_candidates <- c(                       # PH per-capita (county, finance years or tidy)
  here("output","ph_pc.csv"),
  here("output","ph_per_capita.csv"),
  here("data","ph_pc.csv"),
  "output/ph_pc.csv"
)
income_candidates <- c(                      # income (county, ACS)
  here("output","income_all.csv"),
  here("data","income_all.csv"),
  "output/income_all.csv",
  "data/income_all.csv"
)

data_file       <- pick_first(data_candidates)
membership_file <- pick_first(membership_candidates)
philips_file    <- pick_first(philips_candidates)
reporting_file  <- pick_first(reporting_candidates)
ph_pc_file      <- pick_first(ph_pc_candidates)
income_file     <- pick_first(income_candidates)

stopifnot(!is.na(data_file), !is.na(membership_file), !is.na(philips_file))

# ---------- optional IHME crosswalk if available ----------
ihme_map <- NULL
if (file.exists(here::here("data_raw","ihme_fips.rda"))) {
  load(here::here("data_raw","ihme_fips.rda"))
  if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
    ihme_map <- ihme_fips %>%
      transmute(fips = std_fips(orig_fips), county_ihme = std_fips(ihme_fips)) %>%
      distinct()
  }
}

# ---------- load membership (one modal cluster per county×period) ----------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      mutate(
        county_ihme = std_fips(county_ihme),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    m0 <- membership_raw %>%
      mutate(
        fips    = std_fips(fips),
        period  = standardize_period(as.character(period)),
        cluster = as.character(cluster)
      )
    if (!is.null(ihme_map)) {
      m0 <- m0 %>% left_join(ihme_map, by = "fips") %>%
        mutate(county_ihme = coalesce(county_ihme, fips)) %>%
        select(county_ihme, period, cluster)
    } else {
      m0 <- m0 %>% transmute(county_ihme = fips, period, cluster)
    }
    m0
  } else stop("membership file must contain county_ihme or fips")

# modal cluster if duplicates
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }
membership <- membership %>%
  filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  group_by(county_ihme, period) %>%
  summarise(cluster = mode_str(cluster), .groups="drop")

# ---------- load county-year data ----------
cy <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  mutate(year = suppressWarnings(as.integer(year)),
         period = period_of_year(year))

# normalize ids
if ("county_ihme" %in% names(cy)) {
  cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))
} else if ("fips" %in% names(cy)) {
  cy <- cy %>% mutate(fips = std_fips(fips))
  cy <- if (!is.null(ihme_map)) {
    cy %>% left_join(ihme_map, by = "fips") %>% mutate(county_ihme = coalesce(county_ihme, fips))
  } else {
    cy %>% mutate(county_ihme = fips)
  }
} else stop("data file must contain county_ihme or fips")

# ---------- ensure the FOUR components exist (county–year) ----------
# 1) prop_garbage
nms <- names(cy)
col_prop_g <- pick_col(nms, c("prop_garbage","foreman_garbage"))
if (is.na(col_prop_g)) stop("Need prop_garbage (or foreman_garbage) in county-year file.")

# 2) pct_overd_miss  (if missing, derive from counts if available)
if (!("pct_overd_miss" %in% nms)) {
  k <- pick_col(nms, c("overd_miss_k","overdose_unspecified_k","overdose_unspec_k","od_unspec_k"))
  N <- pick_col(nms, c("overd_n","overdose_total_n","od_total_n"))
  if (!is.na(k) && !is.na(N)) {
    cy <- cy %>% mutate(pct_overd_miss = ifelse(.data[[N]] > 0, .data[[k]] / .data[[N]], NA_real_))
  } else {
    stop("pct_overd_miss not found and cannot derive from counts.")
  }
}

# 3) RI_post_only
if (!("RI_post_only" %in% nms)) {
  alt <- pick_col(nms, c("RI","ri_post_only","ri"))
  if (!is.na(alt)) {
    cy <- cy %>% rename(RI_post_only = all_of(alt))
  } else stop("RI_post_only not found.")
}

# 4) Phillips detail from cluster CSV → expand to county–year
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
names(ph0) <- tolower(names(ph0))
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% mutate(period = standardize_period(period))
}
# choose a detail/CSTD column (fallbacks in order)
philips_col <- pick_col(names(ph0),
                        c("detail_ucod_icd4_cstd","detail_mcod_icd4_cstd",
                          "cod_diversity_cstd","cod_diversity_std","neff_cstd","richness_cstd"))
stopifnot(!is.na(philips_col))
# ensure cluster present (or map from county)
if (!("cluster" %in% names(ph0))) {
  # if provided at county level, map to cluster using membership
  idcol <- pick_col(names(ph0), c("county_ihme","fips","geoid"))
  stopifnot(!is.na(idcol))
  ph0 <- ph0 %>%
    mutate(county_ihme = if (idcol=="county_ihme") std_fips(county_ihme) else std_fips(.data[[idcol]])) %>%
    inner_join(membership, by = c("county_ihme","period"))
}
ph0 <- ph0 %>% mutate(cluster = as.character(cluster))

# build period endpoints & expand to years
get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) tibble(period = lbl, start = min(yrs[1], yrs[2]), end = max(yrs[1], yrs[2]))
  else tibble(period = lbl, start = NA_integer_, end = NA_integer_)
}
period_tbl <- unique(ph0$period) %>% sort() %>% map_dfr(parse_period) %>% filter(!is.na(start), !is.na(end))

ph_cy <- ph0 %>%
  select(cluster, period, value = all_of(philips_col)) %>%
  inner_join(membership, by = c("cluster","period")) %>%        # → county
  left_join(period_tbl, by = "period") %>%
  mutate(year = map2(start, end, seq)) %>%
  select(county_ihme, year, philips_detail = value) %>%
  unnest(year)

# ---------- join Phillips with county–year + compute z's ----------
# restrict to years we care about
cy <- cy %>% filter(!is.na(year), year >= 1999, year <= 2022)
cy4 <- cy %>%
  select(county_ihme, year, period,
         prop_garbage = all_of(col_prop_g),
         pct_overd_miss, RI_post_only)

cy4 <- cy4 %>%
  left_join(ph_cy, by = c("county_ihme","year"))

# global z's (across ALL county–years)
zcol <- function(x){ m <- mean(x, na.rm = TRUE); s <- sd(x, na.rm = TRUE); if (!is.finite(s) || s==0) return((x-x)*NA_real_); (x-m)/s }

cy4 <- cy4 %>%
  mutate(
    z_prop_garbage    = zcol(prop_garbage),
    z_pct_overd_miss  = zcol(pct_overd_miss),
    z_RI_post_only    = zcol(RI_post_only),
    z_phillips_detail = zcol(philips_detail)
  ) %>%
  # flip so that larger is always better
  mutate(
    z_prop_garbage    = -z_prop_garbage,
    z_pct_overd_miss  = -z_pct_overd_miss
  )

# aggregate index (county–year)
cy4 <- cy4 %>%
  mutate(
    direction_score = rowMeans(select(., z_prop_garbage, z_pct_overd_miss, z_RI_post_only, z_phillips_detail),
                               na.rm = TRUE)
  ) %>%
  mutate(direction_score = ifelse(is.nan(direction_score), NA_real_, direction_score))

# collapse to county–PERIOD means for plotting
dir_cp <- cy4 %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
  mutate(period = factor(period, levels = period_levels))

# =================================================================
# Reporting-type LOOKUP + panel
# =================================================================
normalize_reporting_type <- function(x) {
  y <- stringr::str_to_lower(stringr::str_squish(as.character(x)))
  dplyr::case_when(
    y %in% c("me","medical examiner") ~ "Medical Examiner",
    y %in% c("coroner")               ~ "Coroner",
    y %in% c("mixed","hybrid")        ~ "Mixed",
    grepl("other", y)                 ~ "Other County Official",
    y %in% c("na","n/a","unknown","") ~ NA_character_,
    TRUE                              ~ stringr::str_to_title(y)
  )
}
get_reporting_lookup <- function() {
  stopifnot(!is.na(reporting_file))
  rep_raw <- readr::read_csv(reporting_file, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, \(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_)
    nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5","county_ihme"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  out <- rep_raw %>%
    mutate(
      county_ihme = if (tolower(fips_col)=="county_ihme") std_fips(.data[[fips_col]]) else std_fips(.data[[fips_col]]),
      reporting_type = normalize_reporting_type(.data[[type_col]])
    ) %>%
    filter(nchar(county_ihme)==5, !is.na(reporting_type)) %>%
    distinct(county_ihme, reporting_type)
  out
}
rep_lookup <- get_reporting_lookup()

ts_reporting <- dir_cp %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  group_by(period, reporting_type) %>%
  summarise(mean_direction = mean(direction_score, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop")

p_rep <- ggplot(ts_reporting, aes(x = period, y = mean_direction, group = reporting_type, colour = reporting_type)) +
  geom_line(linewidth = 1.2) + geom_point(size = 2) +
  labs(title = "Aggregate data quality by reporting type",
       x = NULL, y = "Aggregate data quality (z)", colour = "Reporting type") +
  theme_bw(base_size = 12)

print(p_rep)
ggsave(here("figures","validation_zscore","direction_by_reporting.png"),
       p_rep, width = 9, height = 5.2, dpi = 320)
message("[REP] Saved reporting-type panel (rows=", nrow(ts_reporting), ").")

# =================================================================
# PH SPEND helpers + panel
# =================================================================
get_ph_any <- function() {
  # prefer in-memory ph_pc object
  if (exists("ph_pc", inherits = TRUE)) {
    pc <- get("ph_pc", inherits = TRUE)
    if (is.data.frame(pc)) {
      id  <- pick_col(names(pc), c("county_ihme","fips","geoid"))
      val <- pick_col(names(pc), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
      if (!is.na(id) && !is.na(val)) {
        return(
          pc %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
            filter(is.finite(ph_pc))
        )
      }
    }
  }
  # files
  f <- ph_pc_file
  if (!is.na(f) && file.exists(f)) {
    ph_raw <- readr::read_csv(f, show_col_types = FALSE)
    id  <- pick_col(names(ph_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(ph_raw), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
    if (!is.na(id) && !is.na(val)) {
      return(
        ph_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
          filter(is.finite(ph_pc))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
    )
  }
  NULL
}
get_ph_quintiles <- function() {
  qcol <- intersect(c("ph_quint","phspend_quint","ph_pc_quintile","ph_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[PH] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, ph_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  ph_any <- get_ph_any()
  if (is.null(ph_any) || !nrow(ph_any)) return(NULL)
  brks <- make_quintile_breaks(ph_any$ph_pc)
  ph_any %>%
    mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
}

ph_q <- get_ph_quintiles()
p_ph <- NULL
if (!is.null(ph_q) && nrow(ph_q)) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))

  p_ph <- ggplot(ts_ph, aes(period, mean_direction, group = ph_quint, colour = ph_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by public-health spending",
         x = NULL, y = "Aggregate data quality (z)", colour = "PH spend quintile") +
    theme_bw(base_size = 12)

  print(p_ph)
  out_path <- here("figures","validation_zscore","direction_by_spend_quintile.png")
  ggsave(out_path, p_ph, width = 9, height = 5.2, dpi = 320)
  message("[PH] Saved: ", out_path, "  (n rows=", nrow(ts_ph), ")")
} else {
  message("[PH] Panel skipped: could not derive PH quintiles.")
}

# =================================================================
# INCOME helpers + panel
# =================================================================
get_income_any <- function() {
  # prefer in-memory income_all
  if (exists("income_all", inherits = TRUE)) {
    ia <- get("income_all", inherits = TRUE)
    if (is.data.frame(ia)) {
      id  <- pick_col(names(ia), c("county_ihme","fips","geoid"))
      val <- pick_col(names(ia), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                   "income_pc","per_capita_income","pc_income","income"))
      if (!is.na(id) && !is.na(val)) {
        return(
          ia %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   income = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
            filter(is.finite(income))
        )
      }
    }
  }
  # from file
  if (!is.na(income_file) && file.exists(income_file)) {
    inc_raw <- readr::read_csv(income_file, show_col_types = FALSE)
    id  <- pick_col(names(inc_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(inc_raw), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                      "income_pc","per_capita_income","pc_income","income"))
    if (!is.na(id) && !is.na(val)) {
      return(
        inc_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 income = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
          filter(is.finite(income))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("avg_income","median_household_income","median_income","mhi","hh_income",
                      "income_pc","per_capita_income","pc_income","income","acs_income"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, income = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(income))
    )
  }
  NULL
}
get_income_quintiles <- function() {
  qcol <- intersect(c("inc_quint","income_quint","income_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[INC] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, inc_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  income_any <- get_income_any()
  if (is.null(income_any) || !nrow(income_any)) return(NULL)
  brks <- make_quintile_breaks(income_any$income)
  income_any %>%
    mutate(inc_quint = cut(income, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, inc_quint = factor(inc_quint, levels = labs_quint))
}

inc_q <- get_income_quintiles()
p_inc <- NULL
if (!is.null(inc_q) && nrow(inc_q)) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))

  p_inc <- ggplot(ts_inc, aes(period, mean_direction, group = inc_quint, colour = inc_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by income quintile",
         x = NULL, y = "Aggregate data quality (z)", colour = "Income quintile") +
    theme_bw(base_size = 12)

  print(p_inc)
  out_path <- here("figures","validation_zscore","direction_by_income_quintile.png")
  ggsave(out_path, p_inc, width = 9, height = 5.2, dpi = 320)
  message("[INC] Saved: ", out_path, "  (n rows=", nrow(ts_inc), ")")
} else {
  message("[INC] Panel skipped: could not derive income quintiles.")
}

# =================================================================
# Combined 3-panel (if at least two exist)
# =================================================================
panel_list <- list(
  "Reporting type"   = if (exists("p_rep") && inherits(p_rep, "gg")) p_rep else NULL,
  "PH spend quintile"= if (exists("p_ph")  && inherits(p_ph,  "gg")) p_ph  else NULL,
  "Income quintile"  = if (exists("p_inc") && inherits(p_inc, "gg")) p_inc else NULL
)
panel_list <- panel_list[ vapply(panel_list, inherits, logical(1), "gg") ]

if (length(panel_list) >= 2) {
  if (requireNamespace("patchwork", quietly = TRUE)) {
    p_all <- patchwork::wrap_plots(unname(panel_list), nrow = 1, guides = "collect") &
      theme(legend.position = "bottom")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel.")
  } else if (requireNamespace("cowplot", quietly = TRUE)) {
    p_all <- cowplot::plot_grid(plotlist = unname(panel_list), nrow = 1, align = "h")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel (cowplot).")
  } else {
    message("[ALL] Combined 3-panel skipped (patchwork/cowplot not available).")
  }
} else {
  message("[ALL] Not enough panels to create the combined summary; individual panels were saved.")
}

# ──────────────────────────────────────────────────────────────
# Compact 2-row table for the paper:
# Columns: Per capita public health spending | Reporting type | Income quintile
# Rows:    1999–2005, 2020–2022
# Saves → output/validation_zscore/aggregate_index_table_2periods.csv
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr); library(readr); library(here) })

out_dir_csv <- here::here("output","validation_zscore")
dir.create(out_dir_csv, recursive = TRUE, showWarnings = FALSE)

# ensure helpers from earlier exist
`%||%` <- function(a,b) if (!is.null(a)) a else b
labs_quint <- exists("labs_quint") %||% FALSE
if (identical(labs_quint, FALSE)) labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Recompute dir_cp (county × period aggregate index) if missing
if (!exists("dir_cp")) {
  stopifnot(exists("cy4"))
  period_levels2 <- c("1999_2005","2006_2012","2013_2019","2020_2022")
  dir_cp <- cy4 %>%
    filter(!is.na(period), period %in% period_levels2) %>%
    group_by(county_ihme, period) %>%
    summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
    mutate(period = factor(period, levels = period_levels2))
}

# (Re)build PH spend quintiles if needed
if (!exists("ph_q")) {
  make_quintile_breaks <- function(v) {
    v <- v[is.finite(v)]
    stopifnot(length(v) > 0)
    qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
    for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
    qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
  }
  # derive from cy4 if needed
  if (!exists("ph_q")) {
    cand <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                      names(cy4))
    if (length(cand)) {
      ph_any <- cy4 %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[cand[1]]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
      if (nrow(ph_any)) {
        brks <- make_quintile_breaks(ph_any$ph_pc)
        ph_q <- ph_any %>%
          mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
          transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
      }
    }
  }
}

# Recompute PH / Reporting / Income summaries if missing
if (!exists("ts_ph") && exists("ph_q")) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))
}
if (!exists("ts_reporting") && exists("rep_lookup")) {
  ts_reporting <- dir_cp %>%
    inner_join(rep_lookup, by = "county_ihme") %>%
    group_by(period, reporting_type) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop")
}
if (!exists("ts_inc") && exists("inc_q")) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))
}

# ------- formatting helpers (period-scoped “label: value” strings) -------
fmt_pairs <- function(df, period_key, group_col, value_col = "mean_direction", levels = NULL, digits = 2, label_map = NULL) {
  if (is.null(df) || !nrow(df)) return(NA_character_)
  d <- df %>% filter(as.character(period) == period_key)
  if (!is.null(levels)) {
    d[[group_col]] <- factor(d[[group_col]], levels = levels)
    d <- d %>% arrange(.data[[group_col]])
  }
  if (!is.null(label_map)) {
    labs <- label_map(as.character(d[[group_col]]))
  } else {
    labs <- as.character(d[[group_col]])
  }
  vals <- round(d[[value_col]], digits = digits)
  # keep N if present
  if ("n" %in% names(d)) {
    paste0(labs, ": ", vals, " (n=", d$n, ")") %>% paste(collapse = "; ")
  } else {
    paste0(labs, ": ", vals) %>% paste(collapse = "; ")
  }
}

# Labels/order for reporting types
rt_levels <- c("Coroner","Other County Official","Mixed","Medical Examiner")
rt_label_map <- function(x) x  # already pretty

# Build the 2-row table
period_keep <- c("1999_2005","2020_2022")
period_label <- function(p) dplyr::recode(p, `1999_2005`="1999–2005", `2020_2022`="2020–2022", .default = p)

tbl_rows <- lapply(period_keep, function(pk) {
  tibble::tibble(
    Period = period_label(pk),
    `Per capita public health spending` =
      fmt_pairs(ts_ph %||% tibble(), pk, "ph_quint", levels = labs_quint),
    `Reporting type` =
      fmt_pairs(ts_reporting %||% tibble(), pk, "reporting_type", levels = rt_levels, label_map = rt_label_map),
    `Income quintile` =
      fmt_pairs(ts_inc %||% tibble(), pk, "inc_quint", levels = labs_quint)
  )
})
table_2rows <- dplyr::bind_rows(tbl_rows)

# Save CSV
out_csv <- file.path(out_dir_csv, "aggregate_index_table_2periods.csv")
readr::write_csv(table_2rows, out_csv)
message("[CSV] Saved compact 2-row table to: ", out_csv)

# (Optional) print to console
print(table_2rows)

```
R^2
```{r}
# ===================== Variance explained (weighted R²) =====================
# What this does
# • Builds a cluster×period metrics table (adds direction_score).
# • REPORTING TYPE: expands cluster metrics to counties, joins reporting type per county,
#   fits weighted models y ~ reporting_type with weights = county n_cert (within period).
# • INCOME & PH SPEND: computes cluster×period weighted averages from county values
#   (weights = county n_cert within period), then fits y ~ cluster_avg predictor
#   with cluster weight = sum_n_cert.
# • Prints one compact table per predictor: R² by metric (no files written).

suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr); library(rlang) })

# ---- Safety: small utils ----
wt_mean <- function(x, w) { w <- ifelse(is.finite(w), w, 0); if (sum(w) > 0) sum(w * x, na.rm=TRUE) / sum(w) else NA_real_ }
r2_weighted_from_lm <- function(fit){
  w <- if (!is.null(fit$weights)) fit$weights else rep(1, nrow(fit$model))
  y <- model.response(model.frame(fit))
  rss <- sum(w * stats::residuals(fit)^2, na.rm = TRUE)
  yb  <- stats::weighted.mean(y, w)
  tss <- sum(w * (y - yb)^2, na.rm = TRUE)
  if (tss > 0) 1 - rss/tss else NA_real_
}
safe_print_matrix <- function(title, mat){
  cat("\n[R2] ", title, " (weighted)\n", sep = "")
  base::print.data.frame(as.data.frame(mat), row.names = FALSE)
}

# ---- 1) Metrics at cluster×period, incl. z-score sum ----
stopifnot(exists("metrics_clu"), exists("z_tbl"))  # created in your script above

metrics_all <- metrics_clu %>%
  inner_join(z_tbl %>% select(period, cluster, direction_score),
             by = c("period","cluster")) %>%
  # Keep a cluster weight (sum certificates) for continuous models
  mutate(w_cluster = replace_na(sum_n_cert, 0)) %>%
  filter(is.finite(w_cluster))

metric_cols <- c("prop_overd_unspec", "philips_cstd", "RI_cluster", "prop_garbage", "direction_score")

# ---- 2) County×period weights (for expansion) ----
stopifnot(exists("cy"))
cw <- cy %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(w_cnty = sum(n_cert, na.rm = TRUE), .groups = "drop") %>%
  mutate(w_cnty = ifelse(is.finite(w_cnty) & w_cnty > 0, w_cnty, NA_real_))

# ---- 3) REPORTING TYPE R² (categorical) ----
# Ensure reporting lookup available
if (!exists("rep_lookup")) {
  rep_lookup <- tryCatch(
    get_reporting_lookup() %>%
      mutate(reporting_type = normalize_reporting_type(reporting_type)) %>%
      filter(!is.na(reporting_type)),
    error = function(e) NULL
  )
}
r2_by_reporting <- NULL
if (!is.null(rep_lookup) && nrow(rep_lookup)) {
  # Expand cluster metrics down to counties (carry metric values), attach reporting type & weights
  met_cnty <- metrics_all %>%
    inner_join(membership %>% select(county_ihme, period, cluster), by = c("period","cluster")) %>%
    inner_join(rep_lookup, by = "county_ihme") %>%
    inner_join(cw, by = c("county_ihme","period")) %>%
    filter(is.finite(w_cnty)) %>%
    mutate(reporting_type = factor(reporting_type))

  r2_vals <- lapply(metric_cols, function(m) {
    df <- met_cnty %>% select(y = all_of(m), reporting_type, w_cnty) %>%
      filter(is.finite(y), !is.na(reporting_type), is.finite(w_cnty))
    if (!nrow(df)) return(NA_real_)
    fit <- stats::lm(y ~ reporting_type, data = df, weights = w_cnty)
    r2_weighted_from_lm(fit)
  })
  r2_by_reporting <- tibble::tibble(metric = metric_cols, R2_reporting_type = unlist(r2_vals))
  safe_print_matrix("Variance explained by REPORTING TYPE",
                    transform(r2_by_reporting, R2_reporting_type = round(R2_reporting_type, 3)))
} else {
  cat("\n[R2] Reporting-type lookup not available; skipping REPORTING TYPE R².\n")
}

# ---- 4) Cluster-average INCOME & PH SPEND predictors (continuous) ----
# Build county-level income & PH datasets
income_any <- tryCatch(get_income_any(), error = function(e) NULL)
ph_any     <- tryCatch(get_ph_any(),     error = function(e) NULL)

# Compute cluster×period weighted averages from county values (weights = county n_cert within period)
cl_preds <- membership %>%
  inner_join(cw, by = c("county_ihme","period")) %>%
  { df <- .;
    # Income
    inc_cl <- NULL
    if (!is.null(income_any) && nrow(income_any)) {
      inc_cl <- df %>% inner_join(income_any, by = "county_ihme") %>%
        group_by(period, cluster) %>%
        summarise(cluster_avg_income = wt_mean(income, w_cnty), .groups = "drop")
    }
    # PH per-capita
    ph_cl <- NULL
    if (!is.null(ph_any) && nrow(ph_any)) {
      ph_cl <- df %>% inner_join(ph_any, by = "county_ihme") %>%
        group_by(period, cluster) %>%
        summarise(cluster_ph_pc = wt_mean(ph_pc, w_cnty), .groups = "drop")
    }
    full_join(inc_cl, ph_cl, by = c("period","cluster"))
  }

metrics_with_preds <- metrics_all %>% left_join(cl_preds, by = c("period","cluster"))

# Helper to fit y ~ x with cluster weights
fit_r2_cont <- function(y_col, x_col) {
  df <- metrics_with_preds %>%
    select(y = all_of(y_col), x = all_of(x_col), w = w_cluster) %>%
    filter(is.finite(y), is.finite(x), is.finite(w), w > 0)
  if (!nrow(df)) return(NA_real_)
  fit <- stats::lm(y ~ x, data = df, weights = w)
  r2_weighted_from_lm(fit)
}

# ---- 4a) R² by cluster-average INCOME ----
r2_by_income <- NULL
if ("cluster_avg_income" %in% names(metrics_with_preds)) {
  r2_vals_inc <- vapply(metric_cols, function(m) fit_r2_cont(m, "cluster_avg_income"), numeric(1))
  r2_by_income <- tibble::tibble(metric = metric_cols, R2_cluster_avg_income = r2_vals_inc)
  safe_print_matrix("Variance explained by CLUSTER AVERAGE INCOME",
                    transform(r2_by_income, R2_cluster_avg_income = round(R2_cluster_avg_income, 3)))
} else {
  cat("\n[R2] Income data not available; skipping INCOME R².\n")
}

# ---- 4b) R² by per-capita PUBLIC-HEALTH SPENDING ----
r2_by_ph <- NULL
if ("cluster_ph_pc" %in% names(metrics_with_preds)) {
  r2_vals_ph <- vapply(metric_cols, function(m) fit_r2_cont(m, "cluster_ph_pc"), numeric(1))
  r2_by_ph <- tibble::tibble(metric = metric_cols, R2_ph_per_capita = r2_vals_ph)
  safe_print_matrix("Variance explained by PH PER-CAPITA SPENDING",
                    transform(r2_by_ph, R2_ph_per_capita = round(R2_ph_per_capita, 3)))
} else {
  cat("\n[R2] PH per-capita not available; skipping PH-SPEND R².\n")
}

# ---- 5) Optional: compact summary table (print if multiple available) ----
if (!is.null(r2_by_reporting) || !is.null(r2_by_income) || !is.null(r2_by_ph)) {
  summary_tbl <- tibble::tibble(metric = metric_cols)
  if (!is.null(r2_by_reporting)) summary_tbl <- summary_tbl %>% left_join(r2_by_reporting, by = "metric")
  if (!is.null(r2_by_income))    summary_tbl <- summary_tbl %>% left_join(r2_by_income,    by = "metric")
  if (!is.null(r2_by_ph))        summary_tbl <- summary_tbl %>% left_join(r2_by_ph,        by = "metric")
  summary_tbl <- summary_tbl %>% mutate(across(where(is.numeric), ~round(.x, 3)))
  safe_print_matrix("SUMMARY — R² by predictor and metric", summary_tbl)
}
# ===========================================================================

```
Correlation between the 4 metrics
```{r}
# ──────────────────────────────────────────────────────────────
# PRINT-ONLY CORRELATIONS (no CSVs)
#   Metrics: z_prop_overd_unspec, z_philips_cstd, z_RI_cluster, z_prop_garbage
#   Levels: overall; by reporting type (if rep_lookup);
#           by PH-spend quintile (if ph_q); by income quintile (if inc_q)
#   Notes:
#     • Weighted = death-weighted (sum_n_cert) at cluster×period
#     • Also prints unweighted
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(tibble)
})

options(pillar.max_cols = Inf)  # show all columns

# ---- Inputs expected from earlier chunks ----
stopifnot(exists("z_tbl"), exists("cluster_core"), exists("membership"), exists("cy"))

# ---- Select z-variables & weights at cluster×period ----
zvars <- c("z_prop_overd_unspec","z_philips_cstd","z_RI_cluster","z_prop_garbage")
present_z <- intersect(zvars, names(z_tbl))
if (length(present_z) != length(zvars)) {
  stop("Missing z-variables in z_tbl: ", paste(setdiff(zvars, present_z), collapse = ", "))
}

z_cluster <- z_tbl %>%
  select(period, cluster, all_of(zvars)) %>%
  inner_join(cluster_core %>% select(period, cluster, sum_n_cert),
             by = c("period","cluster")) %>%
  filter(if_all(all_of(zvars), ~ is.finite(.x)),
         is.finite(sum_n_cert) & sum_n_cert > 0)

# ---- Correlation helpers ----
weighted_cor_mat <- function(df, vars, wcol = NULL, method = c("pearson","spearman")) {
  method <- match.arg(method)
  X <- df %>% dplyr::select(dplyr::all_of(vars))
  w <- if (!is.null(wcol) && wcol %in% names(df)) df[[wcol]] else NULL

  # listwise complete rows; handle weights safely
  if (is.null(w)) keep <- stats::complete.cases(X) else keep <- stats::complete.cases(X) & is.finite(w) & w > 0
  if (!length(keep)) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = 0))
  }

  X <- as.matrix(X[keep, , drop = FALSE])
  w <- if (is.null(w)) NULL else as.numeric(w[keep])
  n_used <- nrow(X)
  if (n_used < 3) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = n_used))
  }

  if (method == "spearman") X <- apply(X, 2, rank, ties.method = "average")

  if (is.null(w)) {
    C <- stats::cov(X)
  } else {
    w <- w / sum(w)
    C <- stats::cov.wt(X, wt = w, method = "ML")$cov
  }

  s <- sqrt(diag(C)); s[!is.finite(s) | s == 0] <- NA_real_
  R <- C / (s %o% s)
  dimnames(R) <- list(colnames(X), colnames(X))
  list(cor = R, n = n_used)
}

mat_to_tidy <- function(corlst, method, group_type, group_value, weighted, include_group = TRUE) {
  R <- corlst$cor; n_used <- corlst$n; vars <- colnames(R)
  if (is.null(vars)) vars <- zvars
  comb <- t(combn(vars, 2))
  out <- tibble(
    group_type = group_type,
    method     = method,
    weighted   = weighted,
    n_used     = n_used,
    var1       = comb[,1],
    var2       = comb[,2],
    correlation= mapply(function(a,b) R[a,b], comb[,1], comb[,2])
  )
  if (isTRUE(include_group)) {
    gv <- if (length(group_value)) as.character(group_value)[1] else NA_character_
    out <- out |> dplyr::mutate(group = gv, .before = method)
  }
  out
}

compute_all_methods <- function(df, label_type, label_val, wcol = NULL, include_group = TRUE) {
  dplyr::bind_rows(
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "pearson"),
                "pearson",  label_type, label_val, !is.null(wcol), include_group),
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "spearman"),
                "spearman", label_type, label_val, !is.null(wcol), include_group)
  )
}

# Pretty printer (forces full width, shows key cols first)
pp <- function(x, title) {
  cat("\n", strrep("=", nchar(title)+4), "\n", "= ", title, " =\n",
      strrep("=", nchar(title)+4), "\n", sep = "")

  grpcol <- intersect(names(x),
                      c("reporting_type","ph_spend_quintile","income_quintile","group"))[1]
  x2 <- x %>%
    mutate(correlation = round(correlation, 3)) %>%
    arrange(desc(weighted), method, var1, var2)

  if (length(grpcol)) {
    x2 <- x2 %>% select(group_type, all_of(grpcol), method, weighted, n_used, var1, var2, correlation)
  } else {
    x2 <- x2 %>% select(group_type, method, weighted, n_used, var1, var2, correlation)
  }

  print(x2, n = Inf, width = Inf)
  invisible(NULL)
}

# ---- 1) OVERALL correlations (weighted & unweighted) ----
corr_overall <- bind_rows(
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = "sum_n_cert"),
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = NULL)
)
pp(corr_overall, "Overall correlations (Pearson & Spearman; weighted & unweighted)")

# ---- 2) Build county weights for modal grouping at cluster×period ----
county_w <- cy %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(w = sum(n_cert, na.rm = TRUE), .groups = "drop") %>%
  mutate(w = ifelse(is.finite(w) & w > 0, w, 1))

modal_group <- function(lookup_df, value_col) {
  req_cols <- c("county_ihme", value_col)
  if (is.null(lookup_df) || !all(req_cols %in% names(lookup_df))) return(NULL)

  membership %>%
    left_join(lookup_df %>% select(county_ihme, !!rlang::sym(value_col)), by = "county_ihme") %>%
    left_join(county_w, by = c("county_ihme","period")) %>%
    filter(!is.na(.data[[value_col]])) %>%
    mutate(w = ifelse(is.finite(w) & w > 0, w, 1)) %>%
    group_by(period, cluster, .data[[value_col]]) %>%
    summarise(w = sum(w, na.rm = TRUE), .groups = "drop") %>%
    group_by(period, cluster) %>%
    slice_max(order_by = w, n = 1, with_ties = FALSE) %>%
    ungroup() %>%
    rename(group = !!rlang::sym(value_col))
}

# ---- 3a) By REPORTING TYPE (if available) ----
if (exists("rep_lookup") && is.data.frame(rep_lookup)) {
  cl_rep <- modal_group(rep_lookup %>% mutate(reporting_type = as.character(reporting_type)),
                        "reporting_type")
  if (!is.null(cl_rep) && nrow(cl_rep)) {
    corr_by_reporting <- bind_rows(
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_reporting %>% rename(reporting_type = group),
       "By reporting type (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Reporting-type lookup present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Reporting-type lookup not found; skipping by-reporting correlations.\n")
}

# ---- 3b) By PH SPEND quintile (if available) ----
if (exists("ph_q") && is.data.frame(ph_q) && nrow(ph_q)) {
  cl_ph <- modal_group(ph_q %>% mutate(ph_quint = as.character(ph_quint)), "ph_quint")
  if (!is.null(cl_ph) && nrow(cl_ph)) {
    corr_by_ph <- bind_rows(
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_ph %>% rename(ph_spend_quintile = group),
       "By PH-spend quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] PH spend quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] PH spend quintiles not available; skipping.\n")
}

# ---- 3c) By INCOME quintile (if available) ----
if (exists("inc_q") && is.data.frame(inc_q) && nrow(inc_q)) {
  cl_inc <- modal_group(inc_q %>% mutate(inc_quint = as.character(inc_quint)), "inc_quint")
  if (!is.null(cl_inc) && nrow(cl_inc)) {
    corr_by_inc <- bind_rows(
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_inc %>% rename(income_quintile = group),
       "By income quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Income quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Income quintiles not available; skipping.\n")
}

```
COD standardized diversity maps
```{r}
# Full corrected script: COD standardized diversity maps (temporally-stable, IHME-aware)
# ---------------------------------------------------------------------------------
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(tibble)
  library(ggplot2); library(sf); library(tigris); library(scales); library(here)
  library(purrr)
})
options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)
crs_proj <- 2163

# helper: safe %||% (used for deterministic duplicate resolution)
`%||%` <- function(a, b) {
  if (is.null(a) || length(a) == 0 || (length(a) == 1 && is.na(a))) b else a
}

# ------------------------ paths & inputs -------------------------------
metrics_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
merged_candidates <- c(
  here("data_raw","all_county_groupings.csv"),
  here("data","all_county_groupings.csv"),
  here("all_county_groupings.csv")
)
merged_file <- merged_candidates[file.exists(merged_candidates)][1]
if (is.na(merged_file) || length(merged_file) == 0) stop("Cannot find merged all_county_groupings.csv; please provide it.")
ihme_rda <- here("data_raw", "ihme_fips.rda")  # optional crosswalk (may not exist)
out_dir_base <- here("figures", "5yr_avg_stable")
dir.create(out_dir_base, recursive = TRUE, showWarnings = FALSE)

period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
shapefile_years <- c("1999_2005"=2000, "2006_2012"=2010, "2013_2019"=2019, "2020_2022"=2020)

# ------------------------ helpers & normalizers -------------------------
sanitize <- function(x) {
  x %>% str_replace_all("[^A-Za-z0-9]+", "_") %>% str_replace_all("^_+|_+$", "") %>% tolower()
}
normalize_id <- function(x) {
  x %>% as.character() %>% stringr::str_trim() %>%
    stringr::str_replace_all("[^A-Za-z0-9]+", "_") %>%
    stringr::str_replace_all("^_+|_+$", "") %>% tolower()
}
compute_limits <- function(x) {
  x <- x[is.finite(x)]
  if (!length(x)) return(list(lims = c(0, 1), diverging = FALSE))
  q <- stats::quantile(x, c(0.02, 0.98), na.rm = TRUE, names = FALSE)
  if (q[1] < 0 && q[2] > 0) {
    L <- max(abs(q))
    list(lims = c(-L, L), diverging = TRUE)
  } else {
    list(lims = c(q[1], q[2]), diverging = FALSE)
  }
}

# ----------------- IHME crosswalk (optional) ---------------------------
ihme_map <- NULL
if (file.exists(ihme_rda)) {
  load(ihme_rda) # may create ihme_fips or ihme_map
  if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
    ihme_map <- ihme_fips %>% transmute(GEOID = stringr::str_pad(as.character(orig_fips), width = 5, pad = "0"),
                                        county_ihme = stringr::str_pad(as.character(ihme_fips), width = 5, pad = "0")) %>% distinct()
  } else if (exists("ihme_map") && all(c("GEOID","county_ihme") %in% names(ihme_map))) {
    ihme_map <- ihme_map %>% transmute(GEOID = stringr::str_pad(as.character(GEOID), width = 5, pad = "0"),
                                       county_ihme = stringr::str_pad(as.character(county_ihme), width = 5, pad = "0"))
  } else {
    message("Loaded ihme_rda but could not coerce expected structure; proceeding without ihme_map.")
    ihme_map <- NULL
  }
}

# ----------------- functions to build canonical counties & clusters -----
build_counties_2163_resized_with_ihme <- function(year = 2020, ihme_map = NULL) {
  us_counties <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM") %>%
    sf::st_make_valid() %>%
    sf::st_transform(crs_proj)

  # ensure a GEOID column
  nms <- names(us_counties)
  geoid_col <- grep("^GEOID", nms, value = TRUE)[1]
  if (!is.na(geoid_col)) {
    us_counties$GEOID <- as.character(us_counties[[geoid_col]])
  } else {
    st_col <- grep("^STATE.*FP$", nms, value = TRUE)[1]
    co_col <- grep("^COUNTY.*FP$", nms, value = TRUE)[1]
    if (!is.na(st_col) && !is.na(co_col)) {
      us_counties$GEOID <- paste0(
        stringr::str_pad(as.character(us_counties[[st_col]]), width = 2, pad = "0"),
        stringr::str_pad(as.character(us_counties[[co_col]]), width = 3, pad = "0")
      )
    } else if ("CNTYIDFP" %in% nms) {
      us_counties$GEOID <- as.character(us_counties$CNTYIDFP)
    } else {
      stop("Could not find GEOID fields in counties shapefile")
    }
  }
  us_counties <- us_counties %>% mutate(GEOID = stringr::str_pad(as.character(GEOID), width = 5, pad = "0"))

  # attach IHME mapping (if available)
  if (!is.null(ihme_map)) {
    ihme_df <- ihme_map %>% transmute(GEOID = stringr::str_pad(as.character(GEOID), width = 5, pad = "0"),
                                      county_ihme = stringr::str_pad(as.character(county_ihme), width = 5, pad = "0"))
    us_counties <- us_counties %>% left_join(ihme_df, by = "GEOID") %>% mutate(county_ihme = coalesce(county_ihme, GEOID))
  } else {
    us_counties <- us_counties %>% mutate(county_ihme = GEOID)
  }

  # NOTE: previous code repositioned AK/HI; to avoid depending on custom helpers
  # (st_scale/st_shift) we keep the raw projection here. If you want repositioning,
  # reintroduce st_scale/st_shift implementations or add manual transforms.

  # collapse any GEOIDs that map to same county_ihme
  us_counties %>%
    group_by(county_ihme) %>%
    summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid() %>%
    sf::st_transform(crs_proj)
}

# build cluster polygons from membership (joins by county_ihme)
# NOTE: ensure returned polygon sf has column 'cluster' (not 'membership_cluster') to match downstream joins
build_cluster_sf_from_membership <- function(period_key, membership_df, counties_sf) {
  mm <- membership_df %>%
    filter(period == period_key) %>%
    transmute(county_ihme = stringr::str_pad(as.character(fips), width = 5, pad = "0"),
              membership_cluster = normalize_id(cluster)) %>%
    distinct()

  if (!nrow(mm)) stop("No membership rows for period: ", period_key)

  counties_sf %>%
    left_join(mm, by = "county_ihme") %>%
    filter(!is.na(membership_cluster)) %>%
    group_by(membership_cluster) %>%
    summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    rename(cluster = membership_cluster) %>%   # IMPORTANT: name as 'cluster' for downstream joins
    sf::st_make_valid()
}

# state outlines builder
build_states_2163_resized <- function(year = 2020) {
  us_states <- tigris::states(year = year, cb = TRUE, class = "sf") %>%
    sf::st_transform(crs_proj) %>%
    sf::st_make_valid()
  # no repositioning here; return as-is
  us_states
}

# ------------------------ read inputs ------------------------------
message("Reading COD metrics: ", metrics_file)
metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster), period = as.character(period))

message("Reading membership file: ", membership_file)
membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster), period = as.character(period),
         fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"))

message("Reading merged cluster mapping: ", merged_file)
merged_df <- readr::read_csv(merged_file, col_types = readr::cols(.default = "c"), show_col_types = FALSE)

cluster_col_name <- if ("CS Area Code" %in% names(merged_df)) "CS Area Code" else if ("County Set Name" %in% names(merged_df)) "County Set Name" else stop("Merged file missing required header column ('CS Area Code' or 'County Set Name').")
if (!("FIPS" %in% names(merged_df))) stop("Merged file must contain a 'FIPS' column.")

# Build initial cluster_map from merged file (map raw_fips -> county_ihme if ihme_map present)
members <- merged_df %>%
  mutate(FIPS_raw = stringr::str_trim(as.character(FIPS)),
         FIPS_digits = ifelse(FIPS_raw==""|is.na(FIPS_raw), NA_character_, gsub("[^0-9]", "", FIPS_raw)),
         FIPS5 = ifelse(is.na(FIPS_digits), NA_character_, stringr::str_pad(FIPS_digits, width = 5, pad = "0")),
         cluster_id = stringr::str_trim(as.character(.data[[cluster_col_name]]))) %>%
  filter(!is.na(FIPS5) & FIPS5 != "" & !is.na(cluster_id) & cluster_id != "") %>%
  select(FIPS5, cluster_id) %>%
  rename(raw_fips = FIPS5)

if (!is.null(ihme_map)) {
  cluster_map_raw <- members %>%
    left_join(ihme_map, by = c("raw_fips" = "GEOID")) %>%
    mutate(county_ihme = coalesce(county_ihme, raw_fips)) %>%
    select(county_ihme, cluster_id)
} else {
  cluster_map_raw <- members %>% mutate(county_ihme = raw_fips) %>% select(county_ihme, cluster_id)
}

cluster_map <- cluster_map_raw %>%
  mutate(county_ihme = stringr::str_pad(as.character(county_ihme), width = 5, pad = "0"),
         cluster_id = normalize_id(cluster_id)) %>%
  distinct(county_ihme, cluster_id)

if (nrow(cluster_map) == 0) stop("No valid county->cluster mappings found in merged file.")

# ---------------- detect & resolve duplicates deterministically ------------
dup_summary <- cluster_map %>%
  group_by(county_ihme) %>%
  summarise(n = n(), clusters = paste(sort(unique(cluster_id)), collapse = ";"), .groups = "drop") %>%
  filter(n > 1)

if (nrow(dup_summary) > 0) {
  message("Found ", nrow(dup_summary), " counties assigned to multiple candidate clusters. Preparing deterministic resolution...")

  membership_ids <- membership %>% mutate(cluster = normalize_id(as.character(cluster))) %>% pull(cluster) %>% unique()
  metrics_ids    <- if ("cluster" %in% names(metrics)) metrics %>% mutate(cluster = normalize_id(as.character(cluster))) %>% pull(cluster) %>% unique() else character(0)

  dup_audit_path <- file.path(out_dir_base, "dup_county_cluster_candidates_full.csv")
  readr::write_csv(cluster_map %>% semi_join(dup_summary, by = "county_ihme"), dup_audit_path)

  resolutions <- cluster_map %>%
    semi_join(dup_summary, by = "county_ihme") %>%
    group_by(county_ihme) %>%
    summarise(candidate_clusters = list(sort(unique(cluster_id))), .groups = "drop") %>%
    rowwise() %>%
    mutate(
      candidate_vec = candidate_clusters[[1]],
      pick_membership = (sort(intersect(candidate_vec, membership_ids))[1]) %||% NA_character_,
      pick_metrics = (sort(intersect(candidate_vec, metrics_ids))[1]) %||% NA_character_,
      pick_majority = {
        tmp <- cluster_map %>% filter(county_ihme == county_ihme) %>% group_by(cluster_id) %>% summarise(cnt = n(), .groups = "drop") %>% arrange(desc(cnt), cluster_id)
        if (nrow(tmp) > 0) tmp$cluster_id[1] else NA_character_
      },
      resolved_cluster = coalesce(pick_membership, pick_metrics, pick_majority, candidate_vec[1])
    ) %>%
    ungroup() %>%
    select(county_ihme, resolved_cluster, pick_membership, pick_metrics, pick_majority, candidate_clusters)

  res_path <- file.path(out_dir_base, "dup_county_cluster_resolutions.csv")
  resolutions_csv <- resolutions %>% mutate(candidates = vapply(candidate_clusters, function(x) paste(x, collapse=";"), FUN.VALUE = ""))
  readr::write_csv(resolutions_csv %>% select(county_ihme, candidates, resolved_cluster, pick_membership, pick_metrics, pick_majority), res_path)

  resolved_map <- resolutions %>% transmute(county_ihme = county_ihme, cluster_id = resolved_cluster)
  nondup_map <- cluster_map %>% filter(!county_ihme %in% resolutions$county_ihme)
  cluster_map <- bind_rows(nondup_map, resolved_map) %>% distinct(county_ihme, cluster_id)

  if (any(duplicated(cluster_map$county_ihme))) stop("Duplicates remain in cluster_map after resolution — aborting.")
  message("Resolved duplicates; cluster_map now has ", nrow(cluster_map), " rows and ", length(unique(cluster_map$cluster_id)), " unique stable clusters.")
} else {
  message("No duplicate county -> cluster candidates found; proceeding.")
}

# ------------------- Build metrics_clustered (county-level) -----------------------
membership <- membership %>% mutate(fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"))
metrics <- metrics %>% mutate(cluster = if ("cluster" %in% names(.)) normalize_id(cluster) else cluster)

attach_stable_cluster <- function(df, fips_col = "fips") {
  df %>%
    mutate(!!fips_col := stringr::str_pad(as.character(.data[[fips_col]]), width = 5, pad = "0")) %>%
    left_join(cluster_map, by = setNames("county_ihme", fips_col))
}

if ("fips" %in% names(metrics) || "GEOID" %in% names(metrics) || "county_ihme" %in% names(metrics)) {
  if (!("fips" %in% names(metrics))) {
    if ("GEOID" %in% names(metrics)) metrics <- metrics %>% mutate(fips = stringr::str_pad(as.character(GEOID), width = 5, pad = "0"))
    else if ("county_ihme" %in% names(metrics)) metrics <- metrics %>% mutate(fips = stringr::str_pad(as.character(county_ihme), width = 5, pad = "0"))
  } else {
    metrics <- metrics %>% mutate(fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"))
  }

  metrics_clustered <- metrics %>%
    attach_stable_cluster("fips") %>%
    filter(!is.na(cluster_id)) %>%
    mutate(cluster_id = normalize_id(cluster_id))

  message("metrics contained county fips; joined to temporally-stable cluster_map. Rows kept: ", nrow(metrics_clustered))

} else {
  message("metrics does not contain county fips; expanding cluster-level metrics via membership (period + cluster -> fips).")

  if (!("cluster" %in% names(metrics)) && ("cluster_id" %in% names(metrics))) metrics <- metrics %>% rename(cluster = cluster_id)
  if (!("cluster" %in% names(metrics))) stop("metrics does not contain 'cluster' (or 'cluster_id'). Cannot expand to counties.")
  if (!("period" %in% names(metrics))) stop("metrics must contain 'period' to join to membership.")

  metrics <- metrics %>% mutate(cluster = normalize_id(cluster))
  metric_cols_cluster <- setdiff(names(metrics), c("cluster","period"))

  metrics_expanded <- membership %>%
    select(period, cluster, fips) %>%
    mutate(cluster = normalize_id(cluster)) %>%
    left_join(metrics, by = c("period", "cluster"))

  metrics_clustered <- metrics_expanded %>%
    attach_stable_cluster("fips") %>%
    filter(!is.na(cluster_id)) %>%
    mutate(cluster_id = normalize_id(cluster_id))

  message("Expanded cluster-level metrics to ", nrow(metrics_expanded), " county rows; ", nrow(metrics_clustered),
          " matched temporally-stable cluster_map (", round(100 * nrow(metrics_clustered) / max(1, nrow(metrics_expanded)), 1), "%).")

  unmapped_rows <- metrics_expanded %>% filter(!fips %in% cluster_map$county_ihme)
  if (nrow(unmapped_rows) > 0) {
    message("Warning: ", nrow(unmapped_rows), " expanded membership rows did not map to temporally-stable cluster_map. Writing CSV to inspect.")
    readr::write_csv(unmapped_rows, file.path(out_dir_base, "unmapped_expanded_membership_rows.csv"))
  }
}

if (nrow(metrics_clustered) == 0) stop("No metrics rows joined to cluster_map. Check fips / county_ihme / membership alignment.")

# -------------------- prepare geographies (IHME-aware counties) ------------
counties_tf <- build_counties_2163_resized_with_ihme(year = 2020, ihme_map = ihme_map)
states_tf   <- build_states_2163_resized(year = 2020)

# Diagnostic: which referenced county ids are missing from counties_tf?
counties_geo_ids <- {
  if ("county_ihme" %in% names(counties_tf)) ids <- counties_tf$county_ihme
  else if ("GEOID" %in% names(counties_tf)) ids <- counties_tf$GEOID
  else ids <- counties_tf[[1]]
  unique(stringr::str_pad(as.character(ids), width = 5, pad = "0"))
}

membership_fips <- membership %>% pull(fips) %>% unique() %>% stringr::str_pad(width = 5, pad = "0")
clustermap_fips <- cluster_map %>% pull(county_ihme) %>% unique() %>% stringr::str_pad(width = 5, pad = "0")
metrics_fips    <- character(0)
if ("fips" %in% names(metrics)) metrics_fips <- metrics %>% pull(fips) %>% unique() %>% stringr::str_pad(width = 5, pad = "0")
if ("county_ihme" %in% names(metrics)) metrics_fips <- union(metrics_fips, metrics %>% pull(county_ihme) %>% unique() %>% stringr::str_pad(width = 5, pad = "0"))
all_referenced <- unique(c(clustermap_fips, membership_fips, metrics_fips))
missing_in_geo <- setdiff(all_referenced, counties_geo_ids)

if (length(missing_in_geo) > 0) {
  message("Counties referenced but missing from counties_tf (n = ", length(missing_in_geo), "). Writing CSV.")
  readr::write_csv(tibble(missing_fips = missing_in_geo), file.path(out_dir_base, "missing_counties_in_geo.csv"))
} else {
  message("No referenced counties missing from counties_tf.")
}

# ----------------- hotfix: try remapping deleted/renamed FIPS -----------------
# Known deletions / replacements (extend this list as you discover others)
remap_deleted_fips <- list(
  # Valdez-Cordova (deleted 2019-01-02) -> Chugach (02063) + Copper River (02066)
  "02261" = c("02063", "02066")
  # add more mappings here if needed
)

# Helper: get county geometry for a FIPS code (year = 2020 used here to match counties_tf)
get_county_geom <- function(fip5, year = 2020) {
  tmp <- tigris::counties(year = year, cb = TRUE, class = "sf") %>%
    sf::st_zm(drop = TRUE, what = "ZM") %>%
    mutate(GEOID = stringr::str_pad(as.character(GEOID), width = 5, pad = "0")) %>%
    filter(GEOID == fip5)
  if (nrow(tmp) == 0) return(NULL)
  tmp %>% sf::st_transform(crs_proj) %>% sf::st_make_valid()
}

# Hotfix: append any missing GEOIDs from tigris (safe - only appends)
if (length(missing_in_geo) > 0) {
  for (mf in missing_in_geo) {
    mf <- stringr::str_pad(as.character(mf), width = 5, pad = "0")
    if (!(mf %in% counties_tf$county_ihme)) {
      message("Attempting to hotfix missing county ", mf, " from tigris / remap table.")
      tmp <- get_county_geom(mf, year = 2020)

      if (is.null(tmp) || nrow(tmp) == 0) {
        # Try remap to replacement FIPS if available
        if (!is.null(remap_deleted_fips[[mf]])) {
          replacements <- remap_deleted_fips[[mf]]
          message("  No geometry for ", mf, ". Will try to build from replacements: ", paste(replacements, collapse = ", "))
          parts <- lapply(replacements, function(rf) get_county_geom(rf, year = 2020))
          parts <- parts[!vapply(parts, is.null, logical(1))]

          if (length(parts) == 0) {
            warning("  Could not fetch replacement geometries for ", mf, ".")
          } else {
            # union replacement geometries to create an approximation of old county
            unioned <- do.call(rbind, parts) %>% group_by(1) %>% summarise(geometry = sf::st_union(geometry), .groups = "drop")
            unioned <- sf::st_as_sf(unioned)
            unioned$county_ihme <- mf
            unioned <- unioned %>% select(county_ihme, geometry)
            counties_tf <- counties_tf %>% filter(!(county_ihme %in% mf)) %>% bind_rows(unioned) %>% sf::st_make_valid()
            message("  Constructed geometry for ", mf, " by unioning replacements; appended to counties_tf.")
          }
        } else {
          warning("  No replacement mapping known for ", mf, " and tigris returned no geometry.")
        }
      } else {
        # append direct geometry
        tmp2 <- tmp %>% transmute(county_ihme = GEOID, geometry = geometry) %>% sf::st_as_sf()
        counties_tf <- counties_tf %>% filter(!(county_ihme %in% mf)) %>% bind_rows(tmp2) %>% sf::st_make_valid()
        message("  Appended ", mf, " to counties_tf from tigris.")
      }
    }
  }

  # recompute counties_geo_ids after append attempts
  counties_geo_ids <- {
    if ("county_ihme" %in% names(counties_tf)) ids <- counties_tf$county_ihme
    else if ("GEOID" %in% names(counties_tf)) ids <- counties_tf$GEOID
    else ids <- counties_tf[[1]]
    unique(stringr::str_pad(as.character(ids), width = 5, pad = "0"))
  }
  missing_in_geo <- setdiff(all_referenced, counties_geo_ids)
  if (length(missing_in_geo) > 0) {
    message("Still missing counties after hotfix: ", paste(missing_in_geo, collapse = ", "))
    readr::write_csv(tibble(still_missing = missing_in_geo), file.path(out_dir_base, "still_missing_counties_after_hotfix.csv"))
  }
}

# ensure county_ihme column exists
if (!("county_ihme" %in% names(counties_tf))) {
  if ("GEOID" %in% names(counties_tf)) counties_tf <- counties_tf %>% mutate(county_ihme = GEOID)
  else counties_tf <- counties_tf %>% mutate(county_ihme = stringr::str_pad(as.character(row_number()), width = 5, pad = "0"))
}

# ----------------------- faceted map function --------------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, diverging, states_sf) {
  ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(
      palette = "RdBu",
      direction = 1,
      limits = lims,
      oob = scales::squish,
      na.value = "grey90"
    ) +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000,  730000), expand = FALSE) +
    labs(fill = NULL) +
    facet_wrap(~ period, ncol = 2) +
    theme_void() +
    theme(strip.text = element_text(size = 12, face = "bold"),
          legend.text = element_text(size = 9),
          plot.title = element_blank())
}

# metric columns (numeric)
metric_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
metric_cols <- setdiff(metric_cols, c("fips", "GEOID", "STATEFP", "COUNTYFP"))
periods_all <- intersect(period_levels, unique(metrics_clustered$period))

# ----------------- Main: produce 4-panel maps for each metric -----------------
message("Starting assembly of 4-panel COD diversity maps using temporally-stable groupings...")

# Precompute stable mapping for convenience: fips -> cluster_id
stable_fips_to_cluster <- cluster_map %>% rename(fips = county_ihme) %>% mutate(fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"))

for (mcol in metric_cols) {
  message("Assembling 4-panel for metric: ", mcol)

  stacked_sf <- map_dfr(periods_all, function(win) {
    cl_sf <- build_cluster_sf_from_membership(win, membership, counties_tf)

    dat <- metrics_clustered %>%
      filter(period == win) %>%
      group_by(cluster_id) %>%
      summarise(value = mean(.data[[mcol]], na.rm = TRUE), .groups = "drop")

    member_map <- membership %>%
      filter(period == win) %>%
      transmute(fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"),
                membership_cluster = normalize_id(cluster)) %>%
      left_join(stable_fips_to_cluster, by = "fips")  # yields cluster_id

    map_cluster_to_stable <- member_map %>%
      filter(!is.na(cluster_id)) %>%
      group_by(membership_cluster, cluster_id) %>%
      summarise(n = n(), .groups = "drop") %>%
      group_by(membership_cluster) %>%
      arrange(membership_cluster, desc(n), cluster_id) %>%
      slice_head(n = 1) %>%
      ungroup() %>%
      transmute(cluster = membership_cluster, cluster_id = normalize_id(cluster_id))

    missing_map_members <- setdiff(unique(member_map$membership_cluster), map_cluster_to_stable$cluster)
    if (length(missing_map_members) > 0) {
      message("  Note: ", length(missing_map_members), " membership clusters in period ", win, " have no temporally-stable mapping (examples up to 10):")
      print(utils::head(missing_map_members, 10))
      readr::write_csv(member_map %>% filter(membership_cluster %in% missing_map_members),
                       file.path(out_dir_base, paste0("unmapped_membership_clusters_", win, ".csv")))
    }

    # left_join expects cl_sf to have 'cluster' column (we ensure that in build_cluster_sf_from_membership)
    sf_cl <- cl_sf %>% left_join(map_cluster_to_stable, by = "cluster") %>% left_join(dat, by = "cluster_id")
    sf_cl$period <- win
    sf_cl
  }) %>%
    mutate(period = factor(period, levels = period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals)) == 1) {
    message("  Skipping ", mcol, ": no finite variance across periods.")
    next
  }

  lims_info <- compute_limits(stacked_sf$value)

  p <- make_faceted_map(
    stacked_sf = stacked_sf,
    fill_col   = "value",
    lims       = lims_info$lims,
    diverging  = lims_info$diverging,
    states_sf  = states_tf
  )

  fout <- file.path(out_dir_base, paste0(sanitize(mcol), "_4panel.png"))
  ggsave(fout, p, width = 10, height = 7.5, dpi = 320)
  message("  Saved: ", fout)
}

# Coverage summary
coverage_df <- membership %>%
  mutate(fips = stringr::str_pad(as.character(fips), width = 5, pad = "0"),
         membership_cluster = normalize_id(cluster)) %>%
  left_join(cluster_map, by = c("fips" = "county_ihme")) %>%
  group_by(period, membership_cluster) %>%
  summarise(n_counties = n(), n_mapped = sum(!is.na(cluster_id)), pct_mapped = 100 * n_mapped / n_counties, .groups = "drop")

readr::write_csv(coverage_df, file.path(out_dir_base, "membership_to_stable_coverage_summary.csv"))
message("Wrote coverage summary: ", file.path(out_dir_base, "membership_to_stable_coverage_summary.csv"))
message("Done. 4-panel maps in: ", out_dir_base)

```
Scores by reporting type and public health spending for diversity metrics
```{r}
# ──────────────────────────────────────────────────────────────
# Phillips detail metrics vs reporting type & PH spend — FINAL+
# (period normalization, de-dup membership, robust fin-year snapping)
# + One time series per metric with 5 lines for PH-spend quintiles
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(tidyr); library(stringr)
  library(purrr); library(ggplot2); library(scales); library(here)
})

dir.create(here("figures","phillips_detail"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)

# ---- helpers --------------------------------------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

norm_period <- function(x) {
  # normalize "1999–2005", "1999-2005", "1999 — 2005", etc. → "1999_2005"
  x <- gsub("\u2013|\u2014|—|-", "_", x)  # en/em dash/hyphen → underscore
  x <- gsub("\\s+", "", x)                # drop spaces
  re <- regmatches(x, gregexpr("\\d{4}", x))
  out <- mapply(function(lbl, yrs) {
    if (length(yrs) >= 2) {
      y1 <- min(as.integer(yrs[1]), as.integer(yrs[2]))
      y2 <- max(as.integer(yrs[1]), as.integer(yrs[2]))
      paste0(y1, "_", y2)
    } else lbl
  }, x, re, USE.NAMES = FALSE)
  out
}

get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) {
    y1 <- min(yrs[1], yrs[2]); y2 <- max(yrs[1], yrs[2]); mid <- floor((y1 + y2)/2)
    tibble(period = lbl, start = y1, end = y2, mid = mid)
  } else tibble(period = lbl, start = NA_integer_, end = NA_integer_, mid = NA_integer_)
}
nearest_fin_year <- function(y, avail) if (!length(avail) || is.na(y)) NA_integer_ else avail[which.min(abs(avail - y))]

# ---- load cluster metrics + membership -----------------------
metrics_file_candidates <- c(
  here("output","cluster_metrics_ucr39_cstd.csv.gz"),
  here("output","cluster_metrics.csv.gz"),
  "output/cluster_metrics_ucr39_cstd.csv.gz",
  "output/cluster_metrics.csv.gz",
  "cluster_metrics_ucr39_cstd.csv.gz",
  "cluster_metrics.csv.gz"
)
membership_file_candidates <- c(
  here("output","county_cluster_membership.csv.gz"),
  "output/county_cluster_membership.csv.gz",
  "county_cluster_membership.csv.gz"
)
metrics_file    <- metrics_file_candidates[file.exists(metrics_file_candidates)][1]
membership_file <- membership_file_candidates[file.exists(membership_file_candidates)][1]
stopifnot(!is.na(metrics_file), !is.na(membership_file))

metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster),
         period  = norm_period(as.character(period)))

membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  mutate(cluster     = as.character(cluster),
         period      = norm_period(as.character(period)),
         county_ihme = std_fips(if ("fips" %in% names(.)) fips else if ("GEOID" %in% names(.)) GEOID else fips)) %>%
  filter(grepl("^[0-9]{5}$", county_ihme)) %>%
  distinct(cluster, period, county_ihme, .keep_all = FALSE)    # one row per key

# ---- pick 4 Phillips metrics ---------------------------------
num_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
preferred <- c(
  "detail_mcod_root3_cstd","detail_mcod_icd4_cstd","detail_ucod_root3_cstd","detail_ucod_icd4_cstd",
  "detail_d95","detail_d2000","detail_2000","detail_ref2000",
  "cod_diversity_cstd","cod_diversity_std","cod_diversity",
  "neff_cause","richness_cause","richness_cstd","neff_cstd"
)
present_pref <- intersect(preferred, num_cols)
if (length(present_pref) < 4) {
  extra <- setdiff(num_cols, present_pref)
  cand  <- extra[grepl("detail|divers|rich|neff|d95", extra, ignore.case = TRUE)]
  present_pref <- unique(c(present_pref, cand))
}
detail_cols <- unique(present_pref)[1:min(4, length(unique(present_pref)))]
stopifnot(length(detail_cols) > 0)
message("Using Phillips detail metrics: ", paste(detail_cols, collapse = " | "))

# ---- diagnostics: period coverage BEFORE expansion -----------
cat("\n# Period counts (metrics):\n")
print(metrics %>% count(period, name = "clusters_in_metrics") %>% arrange(period))
cat("\n# Period counts (membership):\n")
print(membership %>% count(period, name = "counties_in_membership") %>% arrange(period))

# ---- expand cluster→county -----------------------------------
detail_long <- metrics %>%
  select(cluster, period, all_of(detail_cols)) %>%
  pivot_longer(cols = all_of(detail_cols), names_to = "metric", values_to = "value") %>%
  inner_join(membership %>% select(cluster, period, county_ihme),
             by = c("cluster","period"),
             relationship = "many-to-many") %>%
  filter(is.finite(value))

cat("\n# After expansion: rows by period & metric\n")
print(detail_long %>% count(period, metric, name = "rows") %>% arrange(metric, period))

# ---- reporting-type lookup (or build) ------------------------
if (!exists("rep_lu")) {
  reporting_path_opts <- c(
    here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    "/mnt/data/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  reporting_path <- reporting_path_opts[file.exists(reporting_path_opts)][1]
  stopifnot(!is.na(reporting_path))
  rep_raw <- readr::read_csv(reporting_path, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df)
    hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_) else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  rep_lu <- rep_raw %>%
    mutate(county_ihme = std_fips(.data[[fips_col]]),
           reporting_type = trimws(as.character(.data[[type_col]]))) %>%
    filter(grepl("^[0-9]{5}$", county_ihme), !is.na(reporting_type), reporting_type != "") %>%
    mutate(reporting_type = dplyr::recode(tolower(reporting_type),
      "medical examiner"="Medical Examiner","me"="Medical Examiner",
      "coroner"="Coroner","mixed"="Mixed","hybrid"="Mixed",
      .default = stringr::str_to_title(reporting_type))) %>%
    select(county_ihme, reporting_type) %>% distinct()
}
cat("\n# Reporting-type coverage (distinct counties):\n")
print(rep_lu %>% count(reporting_type) %>% mutate(total = sum(n)))

# ---- finance-year snapping (+ fallback) — ROBUST --------------
# Make sure fin_year is integer for joins; be tolerant if fin_all missing
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")

# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))

# Main PH-per-period using nearest AVAILABLE finance year
ph_period_main <- period_info %>%
  dplyr::select(period, fin_year) %>%
  dplyr::inner_join(
    ph_pc %>% dplyr::select(county_ihme, fin_year, ph_pc),
    by = "fin_year", relationship = "many-to-many"
  ) %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6))) %>%
  dplyr::select(county_ihme, period, ph_pc, log_ph_pc)

# Fallback (periods without a mapped fin_year row will use county median spend)
ph_any <- ph_pc %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups = "drop") %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6)))

need_fallback <- setdiff(period_info$period, unique(ph_period_main$period))
ph_period_fb <- if (length(need_fallback)) {
  tidyr::crossing(county_ihme = unique(membership$county_ihme), period = need_fallback) %>%
    dplyr::left_join(ph_any, by = "county_ihme")
} else tibble(county_ihme = character(), period = character(), ph_pc = numeric(), log_ph_pc = numeric())

ph_period <- dplyr::bind_rows(ph_period_main, ph_period_fb)

cat("\n# Period→finance-year map (forced to available years)\n")
print(period_info %>% dplyr::mutate(fin_year = as.character(fin_year)))
cat("\n# PH spend rows by period (should be large)\n")
print(ph_period %>% dplyr::count(period, name = "rows") %>% dplyr::arrange(period))
cat("\n# ph_pc rows by fin_year\n")
print(ph_pc %>% dplyr::count(fin_year, name = "rows") %>% dplyr::arrange(fin_year))

# ---- A) Means by reporting type across periods ----------------
detail_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, reporting_type, metric) %>%
  summarise(avg_value = mean(value, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop") %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)]))

if (nrow(detail_rep) > 0) {
  g_detail_rep <- ggplot(detail_rep, aes(period_ord, avg_value, group = reporting_type, colour = reporting_type)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, scales = "free_y", ncol = 2) +
    labs(title = "Phillips detail metrics by reporting type (cluster→county, period means)",
         x = NULL, y = "Mean value", colour = "Reporting type") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_by_reporting_type_timeseries.png"),
         g_detail_rep, width = 9, height = 6.5, dpi = 300)
  print(g_detail_rep)
} else {
  message("No rows for reporting-type timeseries — skipping the plot.")
}

# ---- B) R²: metric ~ reporting_type (per period) --------------
r2_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || n_distinct(d$reporting_type) < 2) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ reporting_type, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ reporting_type (by period)\n")
print(r2_rep %>% arrange(metric, period))

# ---- C) R²: metric ~ log10(PH spend) (per period) -------------
r2_spend <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || !any(is.finite(d$log_ph_pc))) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ log_ph_pc, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ log10(PH spend per capita) (by period)\n")
print(r2_spend %>% arrange(metric, period))

# ---- D) Scatter (guarded) ------------------------------------
scatter_sample <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)])) %>%
  filter(is.finite(value), is.finite(log_ph_pc))

if (nrow(scatter_sample) > 0) {
  g_detail_spend <- ggplot(scatter_sample, aes(log_ph_pc, value)) +
    geom_point(alpha = 0.35, size = 1) +
    geom_smooth(method = "lm", se = FALSE, linewidth = 0.8) +
    facet_grid(metric ~ period_ord, scales = "free_y") +
    labs(title = "Phillips detail metrics vs log10(PH spend per capita)",
         x = "log10(PH spend per capita)", y = "Metric value") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_vs_ph_spend_scatter.png"),
         g_detail_spend, width = 12, height = 7.5, dpi = 300)
  print(g_detail_spend)
} else {
  message("No rows for spend vs metrics scatter — skipping the plot.")
}

# ---- E) NEW: Time series with multiple lines for PH-spend quintiles ----
# Quintiles computed GLOBALLY from each county's median PH spend (ph_any),
# so periods with sparse PH coverage still get full quintile lines.
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Build monotone breaks even if there are ties
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  # enforce strictly increasing breaks
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9
  qs[length(qs)] <- max(v) + 1e-9
  qs
}

quint_breaks <- make_quintile_breaks(ph_any$ph_pc)

county_quintile <- ph_any %>%
  mutate(spend_quintile = cut(ph_pc, breaks = quint_breaks, include.lowest = TRUE,
                              right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_quintile)

period_levels <- period_info$period[order(period_info$start)]

detail_with_quint <- detail_long %>%
  left_join(county_quintile, by = "county_ihme") %>%
  filter(!is.na(spend_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

# Summarize mean metric per period × quintile
ts_quint <- detail_with_quint %>%
  group_by(metric, period_ord, spend_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = dplyr::n(), .groups = "drop")

cat("\n# Rows per period × quintile (any metric):\n")
print(
  detail_with_quint %>%
    count(period_ord, spend_quintile, name = "rows") %>%
    tidyr::complete(period_ord = period_levels, spend_quintile = labs_quint, fill = list(rows = 0)) %>%
    arrange(period_ord, spend_quintile)
)

# Plot (guarded)
if (nrow(ts_quint) > 0) {
  g_quint <- ggplot(ts_quint,
                    aes(x = period_ord, y = avg_value,
                        group = spend_quintile, colour = spend_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(
      title = "Phillips detail metrics over time by public-health spend quintile",
      x = NULL, y = "Mean metric value", colour = "PH spend (per-capita) quintile"
    ) +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_spend_quintile.png"),
         g_quint, width = 10, height = 6.5, dpi = 300)
  print(g_quint)
} else {
  message("No rows for time-series-by-quintile — skipping the plot.")
}

# ---- F) Correlations with direction score (by period) ---------
assign_period <- function(y, info) {
  with(info, {
    p <- period[y >= start & y <= end]
    ifelse(length(p) >= 1, p[1], NA_character_)
  })
}
stopifnot(exists("direction_year"))
direction_period <- direction_year %>%
  mutate(period = vapply(year, assign_period, character(1), info = period_info)) %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop")

detail_wide <- detail_long %>%
  select(county_ihme, period, metric, value) %>%
  distinct() %>%
  pivot_wider(names_from = metric, values_from = value)

corr_tbl <- direction_period %>%
  inner_join(detail_wide, by = c("county_ihme","period"))

cols_metrics <- setdiff(names(detail_wide), c("county_ihme","period"))
corr_out <- map_dfr(split(corr_tbl, corr_tbl$period), function(dd) {
  tibble(
    period = unique(dd$period),
    metric = cols_metrics,
    pearson_r = map_dbl(cols_metrics, ~ suppressWarnings(
      cor(dd$direction_score, dd[[.x]], use = "pairwise.complete.obs")
    )),
    n = nrow(dd)
  )
})
readr::write_csv(corr_out, here("output","correlation_direction_vs_phillips_by_period.csv"))
cat("\nSaved correlations to: ", here("output","correlation_direction_vs_phillips_by_period.csv"), "\n")
print(corr_out %>% arrange(metric, period))
```
Check by income
```{r}
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")
# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))
# ---- G) Time series by INCOME quintiles ------------------------
safe_quintile <- function(x) {
  labs <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
  v <- x[is.finite(x)]
  if (length(v) < 5L || length(unique(v)) < 5L) {
    return(factor(rep(NA_character_, length(x)), levels = labs))
  }
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9
  cut(x, breaks = qs, include.lowest = TRUE, right = FALSE, labels = labs)
}

period_levels <- period_info$period[order(period_info$start)]

# Join detail with ACS income
detail_with_income <- detail_long %>%
  inner_join(income_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(avg_income)) %>%
  group_by(period) %>%
  mutate(income_quintile = safe_quintile(avg_income)) %>%
  ungroup() %>%
  filter(!is.na(income_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_income <- detail_with_income %>%
  group_by(metric, period_ord, income_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_income) > 0) {
  g_income <- ggplot(ts_income,
                     aes(x = period_ord, y = avg_value,
                         group = income_quintile, colour = income_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by INCOME quintile",
         x = NULL, y = "Mean metric value", colour = "Income quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_income_quintile.png"),
         g_income, width = 10, height = 6.5, dpi = 300)
  print(g_income)
} else {
  message("Income quintile time-series empty after guards — skipping.")
}


# ---- H) Time series by BA+ quintiles ---------------------------
detail_with_ba <- detail_long %>%
  inner_join(ba_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(ba_share)) %>%
  group_by(period) %>%
  mutate(ba_quintile = safe_quintile(ba_share)) %>%
  ungroup() %>%
  filter(!is.na(ba_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_ba <- detail_with_ba %>%
  group_by(metric, period_ord, ba_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_ba) > 0) {
  g_ba <- ggplot(ts_ba,
                 aes(x = period_ord, y = avg_value,
                     group = ba_quintile, colour = ba_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by BA+ share quintile",
         x = NULL, y = "Mean metric value", colour = "BA+ quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_ba_quintile.png"),
         g_ba, width = 10, height = 6.5, dpi = 300)
  print(g_ba)
} else {
  message("BA+ quintile time-series empty after guards — skipping.")
}

```
Pre-requisites
```{r}
# ---------- prerequisites ----------
if (!exists("prop_garbage_col") || !exists("overd_col")) {
  stop("Run the preamble that defines prop_garbage_col/overd_col and builds detail_year.")
}

# ---------- population weighting (robust & non-crashy) ----------
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) {
  as.character(pop_col)
} else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").")
        else "Population weighting OFF.")

# ---------- build base_sel (1999–2022), drop dummy FIPS ----------
base_sel <- cy %>%
  dplyr::mutate(
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    pg  = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    od  = suppressWarnings(as.numeric(.data[[overd_col]])),
    # create 'pop' ONLY if a population column is available; else NA
    pop = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  dplyr::filter(
    year >= 1999, year <= 2022,
    county_ihme != "00000", county_ihme != "0000"
  )

# ---------- temporally stable, safe weighted mean ----------
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)

# ---------- per-county temporally stable averages ----------
county_avg <- base_sel %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(
    prop_garbage = wmaybe(pg, pop),       # uses weights if present; else unweighted mean
    overd_unspec = wmaybe(od, pop),
    pop_wt       = if (pop_col_ok) mean(pop, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# ---------- detail averages from prebuilt detail_year ----------
detail_avg <- detail_year %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# PH spend quintiles (stable across finance years)
ph_any <- ph_pc %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  dplyr::filter(is.finite(ph_pc))

# Income quintiles (already pooled over time in your function)
income_quint <- income_quint %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000")


```
Validation: 4 metrics by public health spending
```{r}
# Validation: 4 metrics by public health spending (table output, unspecified overdoses removed/adjusted)
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(scales)
  library(here);  library(readr); library(stringr)
})

dir.create(here("figures","ph_spend_relationship"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers (as before) ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b

find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}

period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}

safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("ph_pc"))     # needs cy (county-year), ph_pc (finance)
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# Detect metric columns
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns in `cy`: prop_garbage (auto-detected) AND pct_overd_miss.")
}
ri_label <- "Reassignability Index (RI)"
have_ri  <- !is.na(ri_col)

# Population weights (prefer explicit pop_col; else fall back to n_cert if present)
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(pop_col_name)) pop_col_name <- if ("population" %in% names(cy)) "population" else NA_character_
weight_fallback <- NA_character_
if (is.na(pop_col_name)) {
  if ("n_cert" %in% names(cy)) { pop_col_name <- "n_cert"; weight_fallback <- "n_cert" }
}
pop_col_ok <- !is.na(pop_col_name)
message(
  if (pop_col_ok && is.na(weight_fallback)) paste0("Population weighting ON (", pop_col_name, ").")
  else if (pop_col_ok && weight_fallback == "n_cert") "Weighting by n_cert (fallback)."
  else "Population weighting OFF (no weights found)."
)

# ---------- PH spend quintiles (stable per county) ----------
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000", county_ihme != "0000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>%
  mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE, right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# ---------- detail_year (bring ICD-4 detail to year) ----------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit   <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric found in `detail_long`.")
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000", county_ihme != "0000") %>%
    distinct()
}

# ---------- Attempt to find unspecified-overdose column ----------
unspec_patterns <- c("unspec","unspecified","unclass","not[_ ]specified","notspecified")
unspec_overd_col <- NA_character_
for (pat in unspec_patterns) {
  # find any column name containing both the pat and overdose/overd/poison
  cand <- names(cy)[grepl(pat, tolower(names(cy))) & grepl("overd|overdose|poison|opiate|opioid", tolower(names(cy)))]
  if (length(cand)) { unspec_overd_col <- cand[1]; break }
}
# Also check for more general unspecified overdose-like names if above fails
if (is.na(unspec_overd_col)) {
  cand2 <- names(cy)[grepl("unspec|unspecified|unclass|not[_ ]specified", tolower(names(cy)))]
  # see if any of these also mention 'overd' elsewhere in another column to match by context (fallback)
  if (length(cand2)) unspec_overd_col <- cand2[1]
}

if (!is.na(unspec_overd_col)) {
  message("Detected unspecified-overdose column: ", unspec_overd_col)
} else {
  message("No unspecified-overdose column detected. pct_overd_miss will be used as-is.")
}

# ---------- assemble county-year series (with weights) ----------
base_sel <- cy %>%
  mutate(
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    weight         = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022,
         county_ihme != "00000", county_ihme != "0000") %>%
  select(county_ihme, year, prop_garbage, pct_overd_miss, ri, weight, everything()) %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(spend_quint,  by = "county_ihme")

# ---------- create adjusted overdose metric with unspecified removed (if detected) ----------
if (!is.na(unspec_overd_col)) {
  # Extract unspecified column from base_sel if present
  # We allow the detected column to be either percent or counts; try to disambiguate.
  base_sel <- base_sel %>%
    mutate(unspecified_raw = suppressWarnings(as.numeric(.data[[unspec_overd_col]])))
  
  # If unspecified values look like counts (>1.5), try to convert to percent by dividing by n_cert (if available)
  if ("n_cert" %in% names(base_sel)) {
    # create unspecified_pct: if raw looks like counts (max>1.5), compute percent = 100 * raw / n_cert
    suspect_counts <- max(base_sel$unspecified_raw, na.rm = TRUE) > 1.5
    if (isTRUE(suspect_counts)) {
      message("Unspecified-overdose column appears to be counts; converting to percent using n_cert.")
      base_sel <- base_sel %>%
        mutate(unspecified_pct = ifelse(is.finite(unspecified_raw) & is.finite(n_cert) & n_cert > 0,
                                        100 * unspecified_raw / n_cert, NA_real_))
    } else {
      # treat as percent already
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    }
  } else {
    # no n_cert: if raw values appear to be percent (<= 100) assume percent; otherwise keep raw but warn
    suspect_counts <- max(base_sel$unspecified_raw, na.rm = TRUE) > 100
    if (isTRUE(suspect_counts)) {
      warning("Unspecified-overdose column looks like large counts but n_cert is unavailable; using raw values. Consider providing n_cert for correct conversion.")
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    } else {
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    }
  }
  # Now compute adjusted pct_overd_miss (remove unspecified_pct)
  base_sel <- base_sel %>%
    mutate(
      pct_overd_miss_orig = pct_overd_miss,
      pct_overd_miss_adj  = case_when(
        !is.finite(pct_overd_miss) ~ NA_real_,
        !is.finite(unspecified_pct) ~ pct_overd_miss,          # no unspecified info for that row
        TRUE ~ pmax(0, pct_overd_miss - unspecified_pct)       # subtract and clamp at 0
      )
    )
} else {
  # no unspecified column found: keep original and duplicate column
  base_sel <- base_sel %>%
    mutate(
      pct_overd_miss_orig = pct_overd_miss,
      pct_overd_miss_adj  = pct_overd_miss
    )
}

# ---------- aggregate to year × PH-spend quintile (WEIGHTED) ----------
ts_spend <- base_sel %>%
  group_by(year, spend_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss_orig = safe_wmean(pct_overd_miss_orig, weight),
    pct_overd_miss_adj  = safe_wmean(pct_overd_miss_adj,  weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(spend_q = factor(spend_q, levels = labs_quint)) %>%
  arrange(year, spend_q)

# ---------- output table (CSV + print top rows) ----------
out_file <- here("figures","ph_spend_relationship","metrics_by_phspend_timeseries_table.csv")
readr::write_csv(ts_spend, out_file)
message("Wrote table to: ", out_file)

# Print a compact preview to console
print(utils::head(ts_spend, 20))

# Also return ts_spend invisibly if running interactively
invisible(ts_spend)

```
Validation: 4 metrics by reporting type
```{r}
# ─────────────────────────────────────────────────────────────
# Plot: reporting type vs. level of detail (UCOD, ICD-4)
# ─────────────────────────────────────────────────────────────
suppressPackageStartupMessages({ library(ggplot2); library(dplyr); library(scales); library(here) })

out_dir <- get0("out_dir", ifnotfound = here("figures","reporting_type_timeseries"))
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

if (!exists("agg_by_rt") || !("mean_detail_icd4" %in% names(agg_by_rt))) {
  stop("`agg_by_rt` with `mean_detail_icd4` not found. Run the aggregation block first.")
}

w_lab <- ifelse(exists("w_col") && !is.na(w_col), w_col, "UNWEIGHTED")

plot_df <- agg_by_rt %>%
  select(year, reporting_type, mean_detail_icd4) %>%
  filter(!is.na(mean_detail_icd4))

# Colors to match the example; includes 'Mixed' as a neutral tone if present
pal <- c(
  "Coroner"               = "#ef5350",
  "Other County Official" = "#43a047",
  "Medical Examiner"      = "#42a5f5",
  "Mixed"                 = "#8d6e63"
)
# keep only colors for types present
pal <- pal[names(pal) %in% unique(as.character(plot_df$reporting_type))]

p_detail_by_rt <- ggplot(plot_df,
                         aes(x = year, y = mean_detail_icd4,
                             color = reporting_type, group = reporting_type)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = pal, name = "Reporting type") +
  scale_x_continuous(breaks = pretty_breaks(6)) +
  labs(
    title = "Phillips detail (UCOD, ICD-4)",
    subtitle = paste0("Weighted by ", w_lab, " · County means by reporting type (1999–2022)"),
    x = NULL, y = "Mean value"
  ) +
  theme_minimal(base_size = 13) +
  theme(panel.grid.minor = element_blank(),
        legend.position = "right")

ggsave(file.path(out_dir, "detail_icd4_by_reporting_timeseries.png"),
       p_detail_by_rt, width = 10, height = 6, dpi = 150)

p_detail_by_rt

```

Check correlations
```{r}
# -------------------------------------------------------------------------
# Full corrected reporting-type analysis (table outputs + correlations)
# - No plots. Writes CSVs to figures/reporting_type_timeseries/
# - Excludes overdose from final metrics and from aggregate index.
# -------------------------------------------------------------------------
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(readr); library(stringr); library(here)
})

dir.create(here("figures","reporting_type_timeseries"), recursive = TRUE, showWarnings = FALSE)

# -------------------- helpers --------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b

find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) {
    m <- nms[grepl(pat, tolower(nms))]
    if (length(m)) { hit <- m[1]; break }
  }
  hit %||% NA_character_
}

period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}

safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

safe_z <- function(x) {
  if (all(is.na(x))) return(rep(NA_real_, length(x)))
  mu <- mean(x, na.rm = TRUE); sdv <- sd(x, na.rm = TRUE)
  if (!is.finite(sdv) || sdv == 0) return(rep(0, length(x)))
  (x - mu) / sdv
}

make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  if (length(v) == 0) stop("Empty vector in make_quintile_breaks()")
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}

eta_squared_from_aov <- function(y, group) {
  ok <- is.finite(y) & !is.na(group)
  if (sum(ok) < 3) return(NA_real_)
  a <- tryCatch(aov(y[ok] ~ as.factor(group[ok])), error = function(e) NULL)
  if (is.null(a)) return(NA_real_)
  ss <- summary(a)[[1]][["Sum Sq"]]
  if (length(ss) < 2) return(NA_real_)
  ss_between <- ss[1]; ss_total <- sum(ss)
  ss_between / ss_total
}

# -------------------- prerequisites & detection --------------------
stopifnot(exists("cy"))  # requires cy in environment
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# detect prop_garbage
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage","dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
if (is.na(prop_garbage_col)) stop("prop_garbage column not found in `cy` (auto-detect failed).")

# detect overdose column (we will not write overdose to final tables, but can adjust internally)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_

# detect RI column - try common names
ri_col_candidates <- c(get0("ri_col"), "RI_post_only", "RI", "RI_jsd", "ri")
ri_col_candidates <- ri_col_candidates[!is.na(ri_col_candidates)]
ri_col <- ri_col_candidates[ri_col_candidates %in% names(cy)][1] %||% NA_character_
if (!is.na(ri_col)) message("Using RI column: ", ri_col) else message("No RI column found; RI will be NA in outputs.")

# detect weight column
w_col <- tryCatch({
  if (exists("pop_col") && !is.null(pop_col) && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col)
  else if ("population" %in% names(cy)) "population"
  else if ("n_cert" %in% names(cy)) "n_cert"
  else NA_character_
}, error = function(e) NA_character_)
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# detect income column (optional)
income_col <- get0("income_col") %||% find_col(cy, c("median[_ ]?income","medianhousehold","med[_ ]?income","income","household[_ ]?income"))
if (is.na(income_col)) message("No income-like column detected in `cy`; income correlations / quintiles will be skipped.")

# attach ph_pc if present (ph_pc data frame expected in environment)
ph_median_county <- if (exists("ph_pc")) {
  ph_pc %>% mutate(county_ihme = std_fips(county_ihme)) %>%
    filter(!is.na(ph_pc)) %>%
    group_by(county_ihme) %>%
    summarise(ph_pc_med = median(as.numeric(ph_pc), na.rm = TRUE), .groups = "drop") %>%
    filter(is.finite(ph_pc_med))
} else {
  warning("ph_pc not found in environment; PH-spend correlations / quintiles will be skipped.")
  tibble(county_ihme = character(0), ph_pc_med = numeric(0))
}

# -------------------- detail_year (prepare) --------------------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4))
}

# -------------------- reporting-type lookup (prefer Medicolegal col) --------------------
get_reporting_lookup <- function() {
  if (exists("rep_lu")) {
    stopifnot(all(c("county_ihme","reporting_type") %in% names(rep_lu)))
    return(rep_lu %>% transmute(county_ihme = std_fips(county_ihme), reporting_type = as.character(reporting_type)))
  }

  candidates <- c(
    here::here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    here::here("data_raw","County-Death-Investigation-System-2018.csv"),
    here::here("data_raw","County-Death-Investigation-System.csv")
  )
  path <- candidates[file.exists(candidates)][1]
  if (is.na(path)) stop("No reporting-type lookup found in expected paths.")
  rep_raw <- readr::read_csv(path, show_col_types = FALSE)

  # prefer exact column "Medicolegal Death Investigation Type"
  exact_col <- names(rep_raw)[tolower(names(rep_raw)) == tolower("Medicolegal Death Investigation Type")]
  type_col <- if (length(exact_col) == 1) exact_col else find_col(rep_raw, c("medicolegal","reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  fips_col  <- find_col(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  if (is.na(fips_col) || is.na(type_col)) stop("Could not detect FIPS/type columns in reporting-type lookup.")

  rep_raw %>%
    transmute(county_ihme = std_fips(.data[[fips_col]]),
              reporting_type_raw = trimws(as.character(.data[[type_col]]))) %>%
    mutate(
      rt_lower = tolower(replace_na(reporting_type_raw,"")),
      reporting_type = dplyr::case_when(
        grepl("medical", rt_lower) | grepl("\\bme\\b", rt_lower) | grepl("examiner", rt_lower) ~ "Medical Examiner",
        grepl("coroner", rt_lower)                                                       ~ "Coroner",
        grepl("other", rt_lower)                                                         ~ "Other County Official",
        TRUE                                                                             ~ "Other County Official"
      )
    ) %>%
    select(county_ihme, reporting_type) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000", !is.na(reporting_type)) %>%
    distinct() %>%
    mutate(reporting_type = factor(reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))
}

rep_lookup <- get_reporting_lookup()
# ensure 'Mixed' level exists
if (!("Mixed" %in% levels(rep_lookup$reporting_type))) {
  rep_lookup$reporting_type <- factor(as.character(rep_lookup$reporting_type), levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
}
rt_levels <- levels(rep_lookup$reporting_type)

# -------------------- assemble base_sel (county-year rows) --------------------
# determine safe weight col name presence
weight_col_present <- if (!is.na(w_col) && w_col %in% names(cy)) TRUE else FALSE

base_sel <- cy %>%
  transmute(
    county_ihme,
    year,
    prop_garbage = as.numeric(.data[[prop_garbage_col]]),
    n_cert = if ("n_cert" %in% names(.)) as.numeric(.data[["n_cert"]]) else NA_real_,
    weight = if (weight_col_present) as.numeric(.data[[w_col]]) else NA_real_,
    ph_pc_raw = if ("ph_pc" %in% names(cy)) as.numeric(.data[["ph_pc"]]) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000") %>%
  # bring detail_icd4 from detail_year (defensive)
  left_join(detail_year, by = c("county_ihme","year")) %>%
  mutate(detail_icd4 = as.numeric(coalesce(detail_icd4, NA_real_))) %>%
  # attach RI from cy (use ri_col if available), by matching on county/year
  left_join(
    cy %>% transmute(county_ihme, year,
                     ri_in_cy = if (!is.na(ri_col) && ri_col %in% names(cy)) as.numeric(.data[[ri_col]]) else NA_real_),
    by = c("county_ihme","year")
  ) %>%
  mutate(ri = as.numeric(coalesce(ri_in_cy, NA_real_))) %>%
  select(-ri_in_cy) %>%
  # attach reporting type & PH median
  left_join(rep_lookup, by = "county_ihme") %>%
  left_join(ph_median_county, by = "county_ihme") %>%
  mutate(
    reporting_type = as.character(reporting_type),
    reporting_type = ifelse(is.na(reporting_type), "Other County Official", reporting_type),
    reporting_type = factor(reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
  )

# attach income if present (per county-year)
if (!is.na(income_col) && income_col %in% names(cy)) {
  base_sel <- base_sel %>%
    left_join(cy %>% transmute(county_ihme, year, income_raw = suppressWarnings(as.numeric(.data[[income_col]]))),
              by = c("county_ihme","year"))
} else base_sel <- base_sel %>% mutate(income_raw = NA_real_)

# ensure ph_pc_med exists (fall back to ph_pc_raw)
if (!"ph_pc_med" %in% names(base_sel)) base_sel <- base_sel %>% mutate(ph_pc_med = NA_real_)
base_sel <- base_sel %>% mutate(ph_pc_med = ifelse(is.na(ph_pc_med) & is.finite(ph_pc_raw), ph_pc_raw, ph_pc_med))

# -------------------- unspecified-overdose: safe attach/compute (internal only) --------------------
unspec_col <- names(cy)[grepl("unspec|unclass|not[_ ]specified|unspecified", tolower(names(cy))) &
                        grepl("overd|overdose|poison|opiate|opioid", tolower(names(cy)))]
unspec_col <- unspec_col[1] %||% NA_character_

if (!is.na(unspec_col) && unspec_col %in% names(cy)) {
  uvals <- cy %>% transmute(county_ihme = as.character(county_ihme),
                            year = as.integer(year),
                            unspecified_raw = suppressWarnings(as.numeric(.data[[unspec_col]]))) %>%
    group_by(county_ihme, year) %>%
    summarise(unspecified_raw = if (all(is.na(unspecified_raw))) NA_real_ else unspecified_raw[which(!is.na(unspecified_raw))[1]], .groups = "drop")
  # replace any ambiguous columns then join cleanly
  base_sel <- base_sel %>% select(-any_of(c("unspecified_raw","unspecified_pct","pct_overd_miss_adj"))) %>%
    left_join(uvals, by = c("county_ihme","year")) %>%
    mutate(
      unspecified_raw = suppressWarnings(as.numeric(unspecified_raw)),
      unspecified_pct = ifelse(!is.na(unspecified_raw) & !is.na(n_cert) & unspecified_raw > 1.5 & n_cert > 0,
                               100 * unspecified_raw / n_cert, unspecified_raw),
      pct_overd_miss_adj = NA_real_  # keep adj but set NA to exclude from outputs
    )
} else {
  base_sel <- base_sel %>% select(-any_of(c("unspecified_raw","unspecified_pct","pct_overd_miss_adj"))) %>%
    mutate(unspecified_raw = NA_real_, unspecified_pct = NA_real_, pct_overd_miss_adj = NA_real_)
}

# -------------------- build aggregate index (EXCLUDING overdose) --------------------
# Components: inverted prop_garbage (lower better), detail_icd4 (higher better), ri (higher better)
base_sel <- base_sel %>%
  mutate(
    prop_garbage = as.numeric(prop_garbage),
    detail_icd4  = as.numeric(detail_icd4),
    ri           = as.numeric(ri),
    gz = safe_z(-prop_garbage),
    dz = safe_z(detail_icd4),
    rz = safe_z(ri),
    agg_index = gz + dz + rz
  ) %>%
  select(-gz, -dz, -rz)

# -------------------- aggregate: time-series by reporting type (no overdose columns) --------------------
ts_rt <- base_sel %>%
  group_by(year, reporting_type) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    agg_index_mean = safe_wmean(agg_index,      weight),
    total_n_cert   = sum(n_cert, na.rm = TRUE),
    n_counties     = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(year, reporting_type)

# -------------------- CORRELATIONS --------------------
# 1) By reporting type: correlations of ph_pc_med & income vs metrics + aggregate (per-county rows)
corr_by_reporting <- base_sel %>%
  filter(!is.na(reporting_type)) %>%
  group_by(reporting_type) %>%
  summarise(
    cor_ph_garbage = if (sum(is.finite(ph_pc_med) & is.finite(prop_garbage)) >= 3) cor(ph_pc_med, prop_garbage, use = "complete.obs") else NA_real_,
    cor_ph_detail  = if (sum(is.finite(ph_pc_med) & is.finite(detail_icd4)) >= 3) cor(ph_pc_med, detail_icd4, use = "complete.obs") else NA_real_,
    cor_ph_ri      = if (sum(is.finite(ph_pc_med) & is.finite(ri)) >= 3) cor(ph_pc_med, ri, use = "complete.obs") else NA_real_,
    cor_ph_agg     = if (sum(is.finite(ph_pc_med) & is.finite(agg_index)) >= 3) cor(ph_pc_med, agg_index, use = "complete.obs") else NA_real_,
    cor_income_garbage = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(prop_garbage)) >= 3) cor(income_raw, prop_garbage, use = "complete.obs") else NA_real_,
    cor_income_detail  = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(detail_icd4)) >= 3) cor(income_raw, detail_icd4, use = "complete.obs") else NA_real_,
    cor_income_ri      = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(ri)) >= 3) cor(income_raw, ri, use = "complete.obs") else NA_real_,
    cor_income_agg     = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(agg_index)) >= 3) cor(income_raw, agg_index, use = "complete.obs") else NA_real_,
    mean_ph_pc = mean(ph_pc_med, na.rm = TRUE),
    mean_income = mean(income_raw, na.rm = TRUE),
    n_counties = n_distinct(county_ihme),
    .groups = "drop"
  )

# 2) Overall correlations (ph_pc_med, income_raw, reporting_type numeric) across all counties (one table)
tmp_all <- base_sel
reporting_num <- as.numeric(factor(tmp_all$reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))

overall_corrs <- tibble(
  predictor = c("ph_pc_med", "income_raw", "reporting_type_numeric"),
  cor_garbage = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$prop_garbage)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$prop_garbage, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$prop_garbage)) >= 3) cor(tmp_all$income_raw, tmp_all$prop_garbage, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$prop_garbage)) >= 3) cor(reporting_num, tmp_all$prop_garbage, use = "complete.obs") else NA_real_
  ),
  cor_detail = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$detail_icd4)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$detail_icd4, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$detail_icd4)) >= 3) cor(tmp_all$income_raw, tmp_all$detail_icd4, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$detail_icd4)) >= 3) cor(reporting_num, tmp_all$detail_icd4, use = "complete.obs") else NA_real_
  ),
  cor_ri = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$ri)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$ri, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$ri)) >= 3) cor(tmp_all$income_raw, tmp_all$ri, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$ri)) >= 3) cor(reporting_num, tmp_all$ri, use = "complete.obs") else NA_real_
  ),
  cor_agg = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$agg_index)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$agg_index, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$agg_index)) >= 3) cor(tmp_all$income_raw, tmp_all$agg_index, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$agg_index)) >= 3) cor(reporting_num, tmp_all$agg_index, use = "complete.obs") else NA_real_
  )
)

# 3) Reporting-type effect sizes (eta^2) for each metric (one-row summary per metric)
reporting_eta_single <- tibble(
  metric = c("prop_garbage","detail_icd4","ri","agg_index"),
  eta_squared = c(
    eta_squared_from_aov(base_sel$prop_garbage, base_sel$reporting_type),
    eta_squared_from_aov(base_sel$detail_icd4,  base_sel$reporting_type),
    eta_squared_from_aov(base_sel$ri,          base_sel$reporting_type),
    eta_squared_from_aov(base_sel$agg_index,   base_sel$reporting_type)
  )
)

# -------------------- GROUP TABLES: raw means by Income quintile, PH-spend quintile, Reporting type --------------------
# Income quintiles: per-county median income across years (if income exists)
if (!is.na(income_col) && income_col %in% names(cy)) {
  income_median_county <- cy %>%
    mutate(county_ihme = std_fips(county_ihme)) %>%
    filter(!is.na(.data[[income_col]])) %>%
    group_by(county_ihme) %>%
    summarise(income_med = median(suppressWarnings(as.numeric(.data[[income_col]])), na.rm = TRUE), .groups = "drop") %>%
    filter(is.finite(income_med))
  iq_breaks <- make_quintile_breaks(income_median_county$income_med)
  income_q <- income_median_county %>%
    mutate(income_q = cut(income_med, breaks = iq_breaks, include.lowest = TRUE, right = FALSE,
                          labels = c("Q1 lowest","Q2","Q3","Q4","Q5 highest")))
  base_sel <- base_sel %>% left_join(income_q %>% select(county_ihme, income_q), by = "county_ihme")
} else base_sel <- base_sel %>% mutate(income_q = NA_character_)

# PH-spend quintiles
if (nrow(ph_median_county) > 0) {
  qb_spend <- make_quintile_breaks(ph_median_county$ph_pc_med)
  spend_q <- ph_median_county %>%
    mutate(spend_q = cut(ph_pc_med, breaks = qb_spend, include.lowest = TRUE, right = FALSE,
                         labels = c("Q1 lowest","Q2","Q3","Q4","Q5 highest")))
  base_sel <- base_sel %>% left_join(spend_q %>% select(county_ihme, spend_q), by = "county_ihme")
} else base_sel <- base_sel %>% mutate(spend_q = NA_character_)

# group summaries (unweighted raw means)
group_by_income_q <- base_sel %>%
  filter(!is.na(income_q)) %>%
  group_by(income_q) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(income_q)

group_by_spend_q <- base_sel %>%
  filter(!is.na(spend_q)) %>%
  group_by(spend_q) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(spend_q)

group_by_reporting <- base_sel %>%
  group_by(reporting_type) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(reporting_type)

# -------------------- WRITE CSV OUTPUTS --------------------
out_base_ts     <- here("figures","reporting_type_timeseries","metrics_by_reporting_timeseries_table_no_overdose.csv")
out_corr_by_rt   <- here("figures","reporting_type_timeseries","corr_by_reporting_ph_income.csv")
out_overall_corrs <- here("figures","reporting_type_timeseries","overall_correlations_ph_income_reportingnum.csv")
out_report_eta    <- here("figures","reporting_type_timeseries","reporting_eta_squared_by_metric.csv")
out_group_income  <- here("figures","reporting_type_timeseries","group_by_income_quintile_means.csv")
out_group_spend   <- here("figures","reporting_type_timeseries","group_by_phspend_quintile_means.csv")
out_group_report  <- here("figures","reporting_type_timeseries","group_by_reporting_type_means.csv")

readr::write_csv(ts_rt, out_base_ts)
readr::write_csv(corr_by_reporting, out_corr_by_rt)
readr::write_csv(overall_corrs, out_overall_corrs)
readr::write_csv(reporting_eta_single, out_report_eta)
readr::write_csv(group_by_income_q, out_group_income)
readr::write_csv(group_by_spend_q, out_group_spend)
readr::write_csv(group_by_reporting, out_group_report)

message("Wrote CSVs:")
message(" - metrics by reporting type (no overdose): ", out_base_ts)
message(" - correlations by reporting: ", out_corr_by_rt)
message(" - overall correlations: ", out_overall_corrs)
message(" - reporting-type eta^2 per metric: ", out_report_eta)
message(" - group means by income quintile: ", out_group_income)
message(" - group means by PH-spend quintile: ", out_group_spend)
message(" - group means by reporting type: ", out_group_report)

# -------------------- Preview (console) --------------------
cat("\nPreview: time-series by reporting type (first 12 rows)\n")
print(utils::head(ts_rt, 12))
cat("\nPreview: correlations by reporting type\n")
print(utils::head(corr_by_reporting, 12))
cat("\nPreview: overall correlations (predictor rows)\n")
print(overall_corrs)
cat("\nPreview: reporting-type eta^2 (metrics)\n")
print(reporting_eta_single)
cat("\nPreview: group_by_reporting\n")
print(group_by_reporting)

# Return invisibly for programmatic use
invisible(list(
  ts_by_reporting = ts_rt,
  corr_by_reporting = corr_by_reporting,
  overall_corrs = overall_corrs,
  reporting_eta = reporting_eta_single,
  group_by_income_q = group_by_income_q,
  group_by_spend_q = group_by_spend_q,
  group_by_reporting = group_by_reporting
))

```
other correlations check
```{r}
# -------------------------------------------------------------------------
# Full corrected reporting-type analysis (table outputs + correlations)
# - No plots. Writes CSVs to figures/reporting_type_timeseries/
# - Excludes overdose from final metrics and from aggregate index.
# - Adds explicit support for RI_post_only in addition to RI.
# -------------------------------------------------------------------------
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(readr); library(stringr); library(here)
})

dir.create(here("figures","reporting_type_timeseries"), recursive = TRUE, showWarnings = FALSE)

# -------------------- helpers --------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b

find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) {
    m <- nms[grepl(pat, tolower(nms))]
    if (length(m)) { hit <- m[1]; break }
  }
  hit %||% NA_character_
}

period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}

safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

safe_z <- function(x) {
  if (all(is.na(x))) return(rep(NA_real_, length(x)))
  mu <- mean(x, na.rm = TRUE); sdv <- sd(x, na.rm = TRUE)
  if (!is.finite(sdv) || sdv == 0) return(rep(0, length(x)))
  (x - mu) / sdv
}

make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  if (length(v) == 0) stop("Empty vector in make_quintile_breaks()")
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}

eta_squared_from_aov <- function(y, group) {
  ok <- is.finite(y) & !is.na(group)
  if (sum(ok) < 3) return(NA_real_)
  a <- tryCatch(aov(y[ok] ~ as.factor(group[ok])), error = function(e) NULL)
  if (is.null(a)) return(NA_real_)
  ss <- summary(a)[[1]][["Sum Sq"]]
  if (length(ss) < 2) return(NA_real_)
  ss_between <- ss[1]; ss_total <- sum(ss)
  ss_between / ss_total
}

# -------------------- prerequisites & detection --------------------
stopifnot(exists("cy"))  # requires cy in environment
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# detect prop_garbage
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage","dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
if (is.na(prop_garbage_col)) stop("prop_garbage column not found in `cy` (auto-detect failed).")

# detect overdose column (we will not write overdose to final tables, but can adjust internally)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_

# detect RI column - try common names
ri_col_candidates <- c(get0("ri_col"), "RI", "RI_jsd", "ri")
ri_col_candidates <- ri_col_candidates[!is.na(ri_col_candidates)]
ri_col <- ri_col_candidates[ri_col_candidates %in% names(cy)][1] %||% NA_character_
if (!is.na(ri_col)) message("Using RI column: ", ri_col) else message("No RI column found; RI will be NA in outputs.")

# detect RI_post_only explicitly (so we can compare both)
ri_post_col_candidates <- c("RI_post_only", "ri_post_only", "ri_post", "RI_post")
ri_post_col <- ri_post_col_candidates[ri_post_col_candidates %in% names(cy)][1] %||% NA_character_
if (!is.na(ri_post_col)) message("Using RI_post_only column: ", ri_post_col) else message("No RI_post_only column found; ri_post_only will be NA in outputs.")

# detect weight column
w_col <- tryCatch({
  if (exists("pop_col") && !is.null(pop_col) && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col)
  else if ("population" %in% names(cy)) "population"
  else if ("n_cert" %in% names(cy)) "n_cert"
  else NA_character_
}, error = function(e) NA_character_)
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# detect income column (optional)
income_col <- get0("income_col") %||% find_col(cy, c("median[_ ]?income","medianhousehold","med[_ ]?income","income","household[_ ]?income"))
if (is.na(income_col)) message("No income-like column detected in `cy`; income correlations / quintiles will be skipped.")

# attach ph_pc if present (ph_pc data frame expected in environment)
ph_median_county <- if (exists("ph_pc")) {
  ph_pc %>% mutate(county_ihme = std_fips(county_ihme)) %>%
    filter(!is.na(ph_pc)) %>%
    group_by(county_ihme) %>%
    summarise(ph_pc_med = median(as.numeric(ph_pc), na.rm = TRUE), .groups = "drop") %>%
    filter(is.finite(ph_pc_med))
} else {
  warning("ph_pc not found in environment; PH-spend correlations / quintiles will be skipped.")
  tibble(county_ihme = character(0), ph_pc_med = numeric(0))
}

# -------------------- detail_year (prepare) --------------------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4))
}

# -------------------- reporting-type lookup (prefer Medicolegal col) --------------------
get_reporting_lookup <- function() {
  if (exists("rep_lu")) {
    stopifnot(all(c("county_ihme","reporting_type") %in% names(rep_lu)))
    return(rep_lu %>% transmute(county_ihme = std_fips(county_ihme), reporting_type = as.character(reporting_type)))
  }

  candidates <- c(
    here::here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    here::here("data_raw","County-Death-Investigation-System-2018.csv"),
    here::here("data_raw","County-Death-Investigation-System.csv")
  )
  path <- candidates[file.exists(candidates)][1]
  if (is.na(path)) stop("No reporting-type lookup found in expected paths.")
  rep_raw <- readr::read_csv(path, show_col_types = FALSE)

  # prefer exact column "Medicolegal Death Investigation Type"
  exact_col <- names(rep_raw)[tolower(names(rep_raw)) == tolower("Medicolegal Death Investigation Type")]
  type_col <- if (length(exact_col) == 1) exact_col else find_col(rep_raw, c("medicolegal","reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  fips_col  <- find_col(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  if (is.na(fips_col) || is.na(type_col)) stop("Could not detect FIPS/type columns in reporting-type lookup.")

  rep_raw %>%
    transmute(county_ihme = std_fips(.data[[fips_col]]),
              reporting_type_raw = trimws(as.character(.data[[type_col]]))) %>%
    mutate(
      rt_lower = tolower(replace_na(reporting_type_raw,"")),
      reporting_type = dplyr::case_when(
        grepl("medical", rt_lower) | grepl("\\bme\\b", rt_lower) | grepl("examiner", rt_lower) ~ "Medical Examiner",
        grepl("coroner", rt_lower)                                                       ~ "Coroner",
        grepl("other", rt_lower)                                                         ~ "Other County Official",
        TRUE                                                                             ~ "Other County Official"
      )
    ) %>%
    select(county_ihme, reporting_type) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000", !is.na(reporting_type)) %>%
    distinct() %>%
    mutate(reporting_type = factor(reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))
}

rep_lookup <- get_reporting_lookup()
# ensure 'Mixed' level exists
if (!("Mixed" %in% levels(rep_lookup$reporting_type))) {
  rep_lookup$reporting_type <- factor(as.character(rep_lookup$reporting_type), levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
}
rt_levels <- levels(rep_lookup$reporting_type)

# -------------------- assemble base_sel (county-year rows) --------------------
# determine safe weight col name presence
weight_col_present <- if (!is.na(w_col) && w_col %in% names(cy)) TRUE else FALSE

base_sel <- cy %>%
  transmute(
    county_ihme,
    year,
    prop_garbage = as.numeric(.data[[prop_garbage_col]]),
    n_cert = if ("n_cert" %in% names(.)) as.numeric(.data[["n_cert"]]) else NA_real_,
    weight = if (weight_col_present) as.numeric(.data[[w_col]]) else NA_real_,
    ph_pc_raw = if ("ph_pc" %in% names(cy)) as.numeric(.data[["ph_pc"]]) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022, county_ihme != "00000") %>%
  # bring detail_icd4 from detail_year (defensive)
  left_join(detail_year, by = c("county_ihme","year")) %>%
  mutate(detail_icd4 = as.numeric(coalesce(detail_icd4, NA_real_))) %>%
  # attach RI from cy (use ri_col if available), by matching on county/year
  left_join(
    cy %>% transmute(county_ihme, year,
                     ri_in_cy = if (!is.na(ri_col) && ri_col %in% names(cy)) as.numeric(.data[[ri_col]]) else NA_real_),
    by = c("county_ihme","year")
  ) %>%
  mutate(ri = as.numeric(coalesce(ri_in_cy, NA_real_))) %>%
  select(-ri_in_cy) %>%
  # attach RI_post_only if present
  left_join(
    cy %>% transmute(county_ihme, year,
                     ri_post_only = if (!is.na(ri_post_col) && ri_post_col %in% names(cy)) as.numeric(.data[[ri_post_col]]) else NA_real_),
    by = c("county_ihme","year")
  ) %>%
  # attach reporting type & PH median
  left_join(rep_lookup, by = "county_ihme") %>%
  left_join(ph_median_county, by = "county_ihme") %>%
  mutate(
    reporting_type = as.character(reporting_type),
    reporting_type = ifelse(is.na(reporting_type), "Other County Official", reporting_type),
    reporting_type = factor(reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner"))
  )

# attach income if present (per county-year)
if (!is.na(income_col) && income_col %in% names(cy)) {
  base_sel <- base_sel %>%
    left_join(cy %>% transmute(county_ihme, year, income_raw = suppressWarnings(as.numeric(.data[[income_col]]))),
              by = c("county_ihme","year"))
} else base_sel <- base_sel %>% mutate(income_raw = NA_real_)

# ensure ph_pc_med exists (fall back to ph_pc_raw)
if (!"ph_pc_med" %in% names(base_sel)) base_sel <- base_sel %>% mutate(ph_pc_med = NA_real_)
base_sel <- base_sel %>% mutate(ph_pc_med = ifelse(is.na(ph_pc_med) & is.finite(ph_pc_raw), ph_pc_raw, ph_pc_med))

# -------------------- unspecified-overdose: safe attach/compute (internal only) --------------------
unspec_col <- names(cy)[grepl("unspec|unclass|not[_ ]specified|unspecified", tolower(names(cy))) &
                        grepl("overd|overdose|poison|opiate|opioid", tolower(names(cy)))]
unspec_col <- unspec_col[1] %||% NA_character_

if (!is.na(unspec_col) && unspec_col %in% names(cy)) {
  uvals <- cy %>% transmute(county_ihme = as.character(county_ihme),
                            year = as.integer(year),
                            unspecified_raw = suppressWarnings(as.numeric(.data[[unspec_col]]))) %>%
    group_by(county_ihme, year) %>%
    summarise(unspecified_raw = if (all(is.na(unspecified_raw))) NA_real_ else unspecified_raw[which(!is.na(unspecified_raw))[1]], .groups = "drop")
  # replace any ambiguous columns then join cleanly
  base_sel <- base_sel %>% select(-any_of(c("unspecified_raw","unspecified_pct","pct_overd_miss_adj"))) %>%
    left_join(uvals, by = c("county_ihme","year")) %>%
    mutate(
      unspecified_raw = suppressWarnings(as.numeric(unspecified_raw)),
      unspecified_pct = ifelse(!is.na(unspecified_raw) & !is.na(n_cert) & unspecified_raw > 1.5 & n_cert > 0,
                               100 * unspecified_raw / n_cert, unspecified_raw),
      pct_overd_miss_adj = NA_real_  # keep adj but set NA to exclude from outputs
    )
} else {
  base_sel <- base_sel %>% select(-any_of(c("unspecified_raw","unspecified_pct","pct_overd_miss_adj"))) %>%
    mutate(unspecified_raw = NA_real_, unspecified_pct = NA_real_, pct_overd_miss_adj = NA_real_)
}

# -------------------- build aggregate index (EXCLUDING overdose) --------------------
# Components: inverted prop_garbage (lower better), detail_icd4 (higher better), ri (higher better)
base_sel <- base_sel %>%
  mutate(
    prop_garbage = as.numeric(prop_garbage),
    detail_icd4  = as.numeric(detail_icd4),
    ri           = as.numeric(ri),
    ri_post_only = as.numeric(ifelse(exists("ri_post_only") && "ri_post_only" %in% names(.) && !is.null(ri_post_only), ri_post_only, .data[["ri_post_only"]])),
    gz = safe_z(-prop_garbage),
    dz = safe_z(detail_icd4),
    rz = safe_z(ri),
    rz_post = safe_z(ri_post_only),
    agg_index = gz + dz + rz
  ) %>%
  select(-gz, -dz, -rz)  # keep rz_post in case helpful for debugging

# -------------------- aggregate: time-series by reporting type (no overdose columns) --------------------
ts_rt <- base_sel %>%
  group_by(year, reporting_type) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    ri_post_only   = safe_wmean(ri_post_only,   weight),
    agg_index_mean = safe_wmean(agg_index,      weight),
    total_n_cert   = sum(n_cert, na.rm = TRUE),
    n_counties     = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(year, reporting_type)

# -------------------- CORRELATIONS --------------------
# 1) By reporting type: correlations of ph_pc_med & income vs metrics + aggregate (per-county rows)
corr_by_reporting <- base_sel %>%
  filter(!is.na(reporting_type)) %>%
  group_by(reporting_type) %>%
  summarise(
    cor_ph_garbage = if (sum(is.finite(ph_pc_med) & is.finite(prop_garbage)) >= 3) cor(ph_pc_med, prop_garbage, use = "complete.obs") else NA_real_,
    cor_ph_detail  = if (sum(is.finite(ph_pc_med) & is.finite(detail_icd4)) >= 3) cor(ph_pc_med, detail_icd4, use = "complete.obs") else NA_real_,
    cor_ph_ri      = if (sum(is.finite(ph_pc_med) & is.finite(ri)) >= 3) cor(ph_pc_med, ri, use = "complete.obs") else NA_real_,
    cor_ph_ri_post = if (sum(is.finite(ph_pc_med) & is.finite(ri_post_only)) >= 3) cor(ph_pc_med, ri_post_only, use = "complete.obs") else NA_real_,
    cor_ph_agg     = if (sum(is.finite(ph_pc_med) & is.finite(agg_index)) >= 3) cor(ph_pc_med, agg_index, use = "complete.obs") else NA_real_,
    cor_income_garbage = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(prop_garbage)) >= 3) cor(income_raw, prop_garbage, use = "complete.obs") else NA_real_,
    cor_income_detail  = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(detail_icd4)) >= 3) cor(income_raw, detail_icd4, use = "complete.obs") else NA_real_,
    cor_income_ri      = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(ri)) >= 3) cor(income_raw, ri, use = "complete.obs") else NA_real_,
    cor_income_ri_post = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(ri_post_only)) >= 3) cor(income_raw, ri_post_only, use = "complete.obs") else NA_real_,
    cor_income_agg     = if (!is.na(income_col) && sum(is.finite(income_raw) & is.finite(agg_index)) >= 3) cor(income_raw, agg_index, use = "complete.obs") else NA_real_,
    mean_ph_pc = mean(ph_pc_med, na.rm = TRUE),
    mean_income = mean(income_raw, na.rm = TRUE),
    mean_ri = mean(ri, na.rm = TRUE),
    mean_ri_post_only = mean(ri_post_only, na.rm = TRUE),
    n_counties = n_distinct(county_ihme),
    .groups = "drop"
  )

# 2) Overall correlations (ph_pc_med, income_raw, reporting_type numeric) across all counties (one table)
tmp_all <- base_sel
reporting_num <- as.numeric(factor(tmp_all$reporting_type, levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))

overall_corrs <- tibble(
  predictor = c("ph_pc_med", "income_raw", "reporting_type_numeric"),
  cor_garbage = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$prop_garbage)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$prop_garbage, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$prop_garbage)) >= 3) cor(tmp_all$income_raw, tmp_all$prop_garbage, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$prop_garbage)) >= 3) cor(reporting_num, tmp_all$prop_garbage, use = "complete.obs") else NA_real_
  ),
  cor_detail = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$detail_icd4)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$detail_icd4, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$detail_icd4)) >= 3) cor(tmp_all$income_raw, tmp_all$detail_icd4, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$detail_icd4)) >= 3) cor(reporting_num, tmp_all$detail_icd4, use = "complete.obs") else NA_real_
  ),
  cor_ri = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$ri)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$ri, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$ri)) >= 3) cor(tmp_all$income_raw, tmp_all$ri, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$ri)) >= 3) cor(reporting_num, tmp_all$ri, use = "complete.obs") else NA_real_
  ),
  cor_ri_post = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$ri_post_only)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$ri_post_only, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$ri_post_only)) >= 3) cor(tmp_all$income_raw, tmp_all$ri_post_only, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$ri_post_only)) >= 3) cor(reporting_num, tmp_all$ri_post_only, use = "complete.obs") else NA_real_
  ),
  cor_agg = c(
    if (sum(is.finite(tmp_all$ph_pc_med) & is.finite(tmp_all$agg_index)) >= 3) cor(tmp_all$ph_pc_med, tmp_all$agg_index, use = "complete.obs") else NA_real_,
    if (!is.na(income_col) && sum(is.finite(tmp_all$income_raw) & is.finite(tmp_all$agg_index)) >= 3) cor(tmp_all$income_raw, tmp_all$agg_index, use = "complete.obs") else NA_real_,
    if (sum(is.finite(reporting_num) & is.finite(tmp_all$agg_index)) >= 3) cor(reporting_num, tmp_all$agg_index, use = "complete.obs") else NA_real_
  )
)

# 3) Reporting-type effect sizes (eta^2) for each metric (one-row summary per metric)
reporting_eta_single <- tibble(
  metric = c("prop_garbage","detail_icd4","ri","ri_post_only","agg_index"),
  eta_squared = c(
    eta_squared_from_aov(base_sel$prop_garbage, base_sel$reporting_type),
    eta_squared_from_aov(base_sel$detail_icd4,  base_sel$reporting_type),
    eta_squared_from_aov(base_sel$ri,          base_sel$reporting_type),
    eta_squared_from_aov(base_sel$ri_post_only, base_sel$reporting_type),
    eta_squared_from_aov(base_sel$agg_index,   base_sel$reporting_type)
  )
)

# -------------------- GROUP TABLES: raw means by Income quintile, PH-spend quintile, Reporting type --------------------
# Income quintiles: per-county median income across years (if income exists)
if (!is.na(income_col) && income_col %in% names(cy)) {
  income_median_county <- cy %>%
    mutate(county_ihme = std_fips(county_ihme)) %>%
    filter(!is.na(.data[[income_col]])) %>%
    group_by(county_ihme) %>%
    summarise(income_med = median(suppressWarnings(as.numeric(.data[[income_col]])), na.rm = TRUE), .groups = "drop") %>%
    filter(is.finite(income_med))
  iq_breaks <- make_quintile_breaks(income_median_county$income_med)
  income_q <- income_median_county %>%
    mutate(income_q = cut(income_med, breaks = iq_breaks, include.lowest = TRUE, right = FALSE,
                          labels = c("Q1 lowest","Q2","Q3","Q4","Q5 highest")))
  base_sel <- base_sel %>% left_join(income_q %>% select(county_ihme, income_q), by = "county_ihme")
} else base_sel <- base_sel %>% mutate(income_q = NA_character_)

# PH-spend quintiles
if (nrow(ph_median_county) > 0) {
  qb_spend <- make_quintile_breaks(ph_median_county$ph_pc_med)
  spend_q <- ph_median_county %>%
    mutate(spend_q = cut(ph_pc_med, breaks = qb_spend, include.lowest = TRUE, right = FALSE,
                         labels = c("Q1 lowest","Q2","Q3","Q4","Q5 highest")))
  base_sel <- base_sel %>% left_join(spend_q %>% select(county_ihme, spend_q), by = "county_ihme")
} else base_sel <- base_sel %>% mutate(spend_q = NA_character_)

# group summaries (unweighted raw means)
group_by_income_q <- base_sel %>%
  filter(!is.na(income_q)) %>%
  group_by(income_q) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_ri_post_only = mean(ri_post_only, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(income_q)

group_by_spend_q <- base_sel %>%
  filter(!is.na(spend_q)) %>%
  group_by(spend_q) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_ri_post_only = mean(ri_post_only, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(spend_q)

group_by_reporting <- base_sel %>%
  group_by(reporting_type) %>%
  summarise(
    mean_prop_garbage = mean(prop_garbage, na.rm = TRUE),
    mean_detail_icd4  = mean(detail_icd4, na.rm = TRUE),
    mean_ri           = mean(ri, na.rm = TRUE),
    mean_ri_post_only = mean(ri_post_only, na.rm = TRUE),
    mean_agg_index    = mean(agg_index, na.rm = TRUE),
    n_counties        = n_distinct(county_ihme),
    .groups = "drop"
  ) %>% arrange(reporting_type)

# -------------------- WRITE CSV OUTPUTS --------------------
out_base_ts     <- here("figures","reporting_type_timeseries","metrics_by_reporting_timeseries_table_no_overdose.csv")
out_corr_by_rt   <- here("figures","reporting_type_timeseries","corr_by_reporting_ph_income.csv")
out_overall_corrs <- here("figures","reporting_type_timeseries","overall_correlations_ph_income_reportingnum.csv")
out_report_eta    <- here("figures","reporting_type_timeseries","reporting_eta_squared_by_metric.csv")
out_group_income  <- here("figures","reporting_type_timeseries","group_by_income_quintile_means.csv")
out_group_spend   <- here("figures","reporting_type_timeseries","group_by_phspend_quintile_means.csv")
out_group_report  <- here("figures","reporting_type_timeseries","group_by_reporting_type_means.csv")

readr::write_csv(ts_rt, out_base_ts)
readr::write_csv(corr_by_reporting, out_corr_by_rt)
readr::write_csv(overall_corrs, out_overall_corrs)
readr::write_csv(reporting_eta_single, out_report_eta)
readr::write_csv(group_by_income_q, out_group_income)
readr::write_csv(group_by_spend_q, out_group_spend)
readr::write_csv(group_by_reporting, out_group_report)

message("Wrote CSVs:")
message(" - metrics by reporting type (no overdose): ", out_base_ts)
message(" - correlations by reporting: ", out_corr_by_rt)
message(" - overall correlations: ", out_overall_corrs)
message(" - reporting-type eta^2 per metric: ", out_report_eta)
message(" - group means by income quintile: ", out_group_income)
message(" - group means by PH-spend quintile: ", out_group_spend)
message(" - group means by reporting type: ", out_group_report)

# -------------------- Preview (console) --------------------
cat("\nPreview: time-series by reporting type (first 12 rows)\n")
print(utils::head(ts_rt, 12))
cat("\nPreview: correlations by reporting type\n")
print(utils::head(corr_by_reporting, 12))
cat("\nPreview: overall correlations (predictor rows)\n")
print(overall_corrs)
cat("\nPreview: reporting-type eta^2 (metrics)\n")
print(reporting_eta_single)
cat("\nPreview: group_by_reporting\n")
print(group_by_reporting)

# Return invisibly for programmatic use
invisible(list(
  ts_by_reporting = ts_rt,
  corr_by_reporting = corr_by_reporting,
  overall_corrs = overall_corrs,
  reporting_eta = reporting_eta_single,
  group_by_income_q = group_by_income_q,
  group_by_spend_q = group_by_spend_q,
  group_by_reporting = group_by_reporting
))
```

Validation: 4 metrics by income
```{r}
# ──────────────────────────────────────────────────────────────
# Metrics by INCOME — weighted everywhere (incl. RI)
#   A) x = income quintile; lines = PH-spend quintiles
#      • County-level metric averaged across years USING WEIGHTS
#      • Group means weighted by county SUM of weights across years
#   B) Time series: x = year; lines = income quintiles
#      • Weighted by year-specific weights
# Weights: pop_col > population > n_cert (fallback)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","income_relationship"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("figures","income_timeseries"),   recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"), exists("ph_pc"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# metrics
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) stop("Need prop_garbage + pct_overd_miss in `cy`.")
have_ri <- !is.na(ri_col)

# weights (pop_col > population > n_cert)
w_col <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(w_col) && "population" %in% names(cy)) w_col <- "population"
if (is.na(w_col) && "n_cert"     %in% names(cy)) w_col <- "n_cert"
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# income quintiles (county-level, stable)
get_income_quintiles <- function(cy_df) {
  income_candidates <- c("median_household_income","median_income","mhi","hh_income",
                         "income_pc","per_capita_income","pc_income","income")
  inc_col <- income_candidates[income_candidates %in% names(cy_df)][1]
  if (!is.na(inc_col)) {
    inc_any <- cy_df %>%
      transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
      group_by(county_ihme) %>% summarise(income = median(income_val, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(income))
  } else {
    if (!requireNamespace("tidycensus", quietly = TRUE)) stop("No income in `cy` and {tidycensus} not installed.")
    inc_acs <- tidycensus::get_acs(geography = "county", variables = "B19013_001",
                                   year = 2022, survey = "acs5", cache_table = TRUE, show_call = FALSE)
    inc_any <- inc_acs %>% transmute(county_ihme = std_fips(GEOID), income = as.numeric(estimate)) %>%
      filter(is.finite(income), county_ihme != "00000")
  }
  qb_inc <- make_quintile_breaks(inc_any$income)
  inc_any %>% mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                                    right = FALSE, labels = labs_quint)) %>%
    transmute(county_ihme, income_q)
}
income_quint <- get_income_quintiles(cy)

# PH-spend quintiles (for panel A line colour)
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>% mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE,
                                               right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# detail_year (to year)
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
    )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% dplyr::filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric in `detail_long`.")
    detail_year <- dl %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(value))
    ) %>% group_by(county_ihme, year) %>% summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>% filter(county_ihme != "00000") %>% distinct()
}

# ---------- weights per county-year ----------
w_df <- cy %>%
  transmute(county_ihme, year,
            weight = if (!is.na(w_col)) suppressWarnings(as.numeric(.data[[w_col]])) else NA_real_) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-year series (with weights) ----------
base_sel <- cy %>%
  transmute(
    county_ihme = std_fips(county_ihme), year,
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_
  ) %>%
  left_join(w_df, by = c("county_ihme","year")) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-level STABLE averages (weighted across years) ----------
county_avg <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  group_by(county_ihme) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    wt_sum         = sum(weight, na.rm = TRUE),
    .groups = "drop"
  )

# ============================================================
# A) Metrics vs INCOME quintile (x = income_q; lines = PH-spend quintiles)
#     Group means weighted by county wt_sum
# ============================================================
comb_A <- county_avg %>%
  inner_join(income_quint, by = "county_ihme") %>%
  inner_join(spend_quint,  by = "county_ihme")

metrics_cols_A <- intersect(c("prop_garbage","detail_icd4","ri"), names(comb_A))

by_q_income_x <- comb_A %>%
  pivot_longer(cols = all_of(metrics_cols_A), names_to = "metric", values_to = "value") %>%
  group_by(metric, income_q, spend_q) %>%
  summarise(mean_value = safe_wmean(value, wt_sum), n = dplyr::n(), .groups = "drop") %>%
  mutate(
    metric   = dplyr::recode(metric,
                  prop_garbage="Proportion garbage (UCOD)",
                  pct_overd_miss="Overdose % missing",
                  detail_icd4="Phillips detail (UCOD, ICD-4)",
                  ri=ri_label),
    income_q = factor(income_q, levels = labs_quint),
    spend_q  = factor(spend_q,  levels = labs_quint)
  )

plot_lines_income <- function(df, mname, title, file_out) {
  dd <- df %>% filter(metric == mname, is.finite(mean_value))
  if (!nrow(dd)) { message("Skipping (no data): ", mname); return(NULL) }
  p <- ggplot(dd, aes(x = income_q, y = mean_value, group = spend_q, colour = spend_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2.2) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means (1999–2022) · Lines = PH-spend quintiles"),
      x = "Income quintile (median HH income)", y = "Mean metric", colour = "PH-spend quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_relationship", file_out), p, width = 8.8, height = 5.4, dpi = 320)
  p
}

pA_garb  <- plot_lines_income(by_q_income_x, "Proportion garbage (UCOD)", "Proportion garbage (UCOD)",       "prop_garbage_lines.png")
pA_overd <- plot_lines_income(by_q_income_x, "Overdose % missing",        "Overdose % missing",              "pct_overd_miss_lines.png")
pA_det   <- plot_lines_income(by_q_income_x, "Phillips detail (UCOD, ICD-4)", "Phillips detail (UCOD, ICD-4)", "detail_icd4_lines.png")
pA_ri    <- plot_lines_income(by_q_income_x, ri_label, ri_label, "ri_lines.png")

combined_A <- wrap_plots(pA_garb, pA_overd, pA_det, pA_ri, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_relationship","metrics_vs_income_lines_4panel.png"),
       combined_A, width = 9.5, height = 16, dpi = 320)

# ============================================================
# B) Time series by INCOME quintile (x = year; lines = income quintiles)
#     Weighted by year-specific weights
# ============================================================
series_inc <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(income_quint, by = "county_ihme")

ts_income <- series_inc %>%
  group_by(year, income_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(income_q = factor(income_q, levels = labs_quint))

plot_metric_income_ts <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = income_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means by income quintile (1999–2022)"),
      x = NULL, y = "Mean value", colour = "Income quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_timeseries", file_out), p, width = 8.8, height = 5.2, dpi = 320)
  p
}

pB1 <- plot_metric_income_ts(ts_income, "prop_garbage",   "Proportion garbage (UCOD)",      "prop_garbage_by_income_timeseries.png")
pB3 <- plot_metric_income_ts(ts_income, "detail_icd4",    "Phillips detail (UCOD, ICD-4)",  "detail_icd4_by_income_timeseries.png")
pB4 <- plot_metric_income_ts(ts_income, "ri",             ri_label,                          "ri_by_income_timeseries.png")

combined_B <- wrap_plots(pB1, pB3, pB4, ncol = 1) + plot_layout(heights = rep(1,3))
ggsave(here("figures","income_timeseries","metrics_by_income_timeseries_4panel.png"),
       combined_B, width = 9.5, height = 16, dpi = 320)

pA_garb; pA_det; pA_ri; pB1; pB2; pB3; pB4

```

Validation: 4 metrics by excess COVID-19 deaths
```{r}
# Validation: 4 metrics by excess COVID-19 deaths (with LOD-by-cluster)
# ──────────────────────────────────────────────────────────────
# Builds in memory: est, pop_by_county, counts_by_county,
#                   metrics_by_county(garbage, ri, detail_icd4),
#                   county_avg, check_df (+ agg_index)
# Writes:           output/excess_percap_by_county.csv
# Correlations:     metrics vs relExcDeathsMean  (PRIMARY)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(tidyr); library(here)
  options(dplyr.summarise.inform = FALSE)
})

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
safe_num <- function(x) suppressWarnings(as.numeric(x))
first_existing <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
first_col_val <- function(df, candidates) { nm <- intersect(candidates, names(df)); if (length(nm)) df[[nm[1]]] else NA }
z_std <- function(v) { m <- mean(v, na.rm=TRUE); s <- sd(v, na.rm=TRUE); if (!is.finite(s) || s==0) rep(NA_real_, length(v)) else (v-m)/s }
make_fips5 <- function(fips_code, state_fips=NULL){
  fc <- str_replace_all(as.character(fips_code), "[^0-9]", "")
  if (!is.null(state_fips) && !all(is.na(state_fips))) {
    sf <- str_pad(as.character(state_fips), 2, pad="0")
    ifelse(nchar(fc) >= 5, str_pad(substr(fc,1,5),5,pad="0"),
           paste0(sf, str_pad(substr(fc, pmax(1, nchar(fc)-2), nchar(fc)), 3, pad="0")))
  } else str_pad(substr(fc,1,5), 5, pad="0")
}
w_pearson <- function(x,y,w=NULL){
  ok <- is.finite(x) & is.finite(y); if (!is.null(w)) ok <- ok & is.finite(w) & w>0
  x<-x[ok]; y<-y[ok]; w <- if (is.null(w)) rep(1,length(x)) else w[ok]
  if (length(x) < 3) return(c(r=NA_real_, p=NA_real_, lo=NA_real_, hi=NA_real_))
  wx <- sum(w*x)/sum(w); wy <- sum(w*y)/sum(w); xc <- x-wx; yc <- y-wy
  r <- (sum(w*xc*yc)/sum(w)) / sqrt((sum(w*xc^2)/sum(w))*(sum(w*yc^2)/sum(w)))
  n_eff <- (sum(w)^2)/sum(w^2); df <- max(1, n_eff-2)
  if (!is.finite(r) || abs(r)>=1 || !is.finite(df) || df<=0) return(c(r=r,p=NA,lo=NA,hi=NA))
  t <- r*sqrt(df/(1-r^2)); p <- 2*pt(-abs(t), df); z <- atanh(r); se <- 1/sqrt(max(4, n_eff-3))
  c(r=r, p=p, lo=tanh(z-1.96*se), hi=tanh(z+1.96*se))
}

# ---------- optional county-year (for metrics & weights) ----------
cy <- if (exists("cy") && is.data.frame(cy)) cy else {
  fp <- first_existing(c(here("data","county_year_quality_metrics.csv"),
                         here("data","county_year_quality_metrics.csv.gz")))
  if (!is.na(fp)) { message("Reading cy: ", fp); suppressMessages(readr::read_csv(fp, show_col_types = FALSE)) } else NULL
}
if (!is.null(cy)) {
  if ("county_ihme" %in% names(cy)) cy$county_ihme <- std_fips(cy$county_ihme)
  if (!"county_ihme" %in% names(cy) && "fips" %in% names(cy)) cy$county_ihme <- std_fips(cy$fips)
}

# ---------- load estimatesMonthly & build county_ihme ----------
read_estimates_monthly <- function(path){
  df <- suppressMessages(readr::read_csv(path, show_col_types = FALSE, progress = FALSE))
  if (ncol(df) == 1) df <- suppressMessages(readr::read_tsv(path, show_col_types = FALSE, progress = FALSE))
  df
}
est_path <- first_existing(c(here("data_raw","estimatesMonthly.csv"), "data_raw/estimatesMonthly.csv"))
stopifnot(!is.na(est_path))
raw_est <- read_estimates_monthly(est_path)

# Require relExcDeathsMean explicitly (as requested)
need <- c("year","month","FIPSCode","COVIDDeathsUCD","excDeathsMed","relExcDeathsMean")
miss <- setdiff(need, names(raw_est))
if (length(miss)) stop("Missing in estimatesMonthly.csv: ", paste(miss, collapse=", "))

raw_est <- raw_est %>% mutate(
  county_ihme = make_fips5(first_col_val(., c("FIPSCode","FIPS","fips","GEOID","geoid")),
                           if ("stateFIPS" %in% names(.)) .$stateFIPS else NULL)
)

est <- raw_est %>%
  transmute(
    county_ihme = county_ihme,
    year        = as.integer(year),
    month       = as.integer(month),
    excDeaths   = safe_num(excDeathsMed),
    COVIDDeaths = safe_num(COVIDDeathsUCD),
    relExc      = safe_num(relExcDeathsMean)  # <-- primary outcome (relative excess)
  )

# ---------- population (prefer cy → else ACS fallback) ----------
pop_by_county <- NULL
if (!is.null(cy)) {
  pop_col_cy <- names(cy)[tolower(names(cy)) %in% c("population","pop","pop_total","pop_estimate")][1]
  if (!is.na(pop_col_cy)) {
    pop_by_county <- cy %>%
      filter(!is.na(county_ihme)) %>%
      transmute(county_ihme = std_fips(county_ihme), pop = safe_num(.data[[pop_col_cy]])) %>%
      group_by(county_ihme) %>% summarise(pop = mean(pop, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(pop))
  }
}
if (is.null(pop_by_county) || nrow(pop_by_county) == 0) {
  if (!requireNamespace("tidycensus", quietly = TRUE)) {
    stop("No population in `cy` and {tidycensus} not installed. Install tidycensus (set API key) or add a pop column to cy.")
  }
  message("Building pop_join from ACS (B01001_001, ACS5) …")
  suppressPackageStartupMessages(library(tidycensus))
  pop_by_county <- tidycensus::get_acs(
    geography = "county", variables = "B01001_001", year = 2017,
    survey = "acs5", geometry = FALSE, cache_table = TRUE
  ) %>% transmute(county_ihme = std_fips(GEOID), pop = as.numeric(estimate))
}
stopifnot(nrow(pop_by_county) > 0)

# ---------- excess window + county averages ----------
est_sub <- est %>% mutate(ym = year*100L + month) %>% filter(ym >= 202003L, ym <= 202208L)
counts_by_county <- est_sub %>%
  group_by(county_ihme) %>%
  summarise(
    exc_avg      = mean(excDeaths, na.rm = TRUE),
    covid_avg    = mean(COVIDDeaths, na.rm = TRUE),
    rel_exc_mean = mean(relExc,    na.rm = TRUE),   # <-- primary outcome
    .groups = "drop"
  )

# =================================================================
# LEVEL OF DETAIL (LOD) BY CLUSTER → map to counties
# =================================================================
pick_lod_period <- function(avail) {
  pref <- c("2013_2019","2006_2012","1999_2005","2020_2022")
  hit <- pref[pref %in% avail]; if (length(hit)) hit[1] else avail[1]
}
load_lod_cluster_metrics <- function() {
  metrics_path <- first_existing(c(
    here("output","cluster_metrics_ucr39_cstd.csv.gz"),
    here("output","cluster_metrics_ucr39_cstd.csv")
  ))
  if (is.na(metrics_path)) stop("Missing LOD metrics file (cluster_metrics_ucr39_cstd.*).")
  message("Reading LOD cluster metrics: ", metrics_path)
  met <- suppressMessages(readr::read_csv(metrics_path, show_col_types = FALSE))
  val_col <- intersect(c("detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4"), names(met))[1]
  if (is.na(val_col)) stop("No detail_* column found in LOD metrics file.")
  if (!all(c("cluster","period") %in% names(met))) stop("LOD metrics must have 'cluster' and 'period' columns.")
  met %>% transmute(cluster = as.character(cluster),
                    period  = as.character(period),
                    detail_icd4 = safe_num(.data[[val_col]]))
}
normalize_membership_lod <- function(df, target_period) {
  nms <- names(df); low <- tolower(nms)
  fips_col    <- nms[which(grepl("^(fips|geoid)$|^geoid|fips", low))[1]]
  cluster_col <- nms[which(grepl("^(cluster|group|cluster_id)$|cluster|group", low))[1]]
  period_col  <- nms[low == "period"]
  if (is.na(fips_col) || is.na(cluster_col)) stop("LOD membership needs FIPS & cluster/group column.")
  base <- df %>% transmute(county_ihme = std_fips(.data[[fips_col]]),
                           cluster     = as.character(.data[[cluster_col]])) %>% distinct()
  if (length(period_col)) {
    df %>% transmute(county_ihme = std_fips(.data[[fips_col]]),
                     cluster     = as.character(.data[[cluster_col]]),
                     period      = as.character(.data[[period_col]])) %>% distinct()
  } else {
    base %>% mutate(period = target_period)
  }
}
attach_lod_to_counties <- function(target_period = "2013_2019") {
  met <- load_lod_cluster_metrics()
  avail <- sort(unique(met$period))
  use_period <- pick_lod_period(avail)
  if (!identical(use_period, target_period))
    message("LOD target period ", target_period, " not found; using ", use_period, ".")
  met_use <- met %>% filter(period == use_period) %>% select(cluster, detail_icd4)

  membership_path <- first_existing(c(
    here("data","all_county_groupings.csv"),
    here("data","all_county_groupings.csv.gz"),
    here("output","county_cluster_membership.csv.gz"),
    here("output","county_cluster_membership.csv")
  ))
  if (is.na(membership_path)) stop("No county→cluster membership file found (looked for all_county_groupings.* or county_cluster_membership.*).")
  message("Reading LOD membership: ", membership_path)
  mem_raw  <- suppressMessages(readr::read_csv(membership_path, show_col_types = FALSE))
  mem_norm <- normalize_membership_lod(mem_raw, use_period) %>% filter(period == use_period)

  mem_norm %>% select(county_ihme, cluster) %>%
    distinct() %>%
    left_join(met_use, by = "cluster")
}

detail_by_county <- attach_lod_to_counties("2013_2019")
message("LOD rows mapped: ", nrow(detail_by_county), " (",
        sum(is.finite(detail_by_county$detail_icd4)), " with non-missing values).")

# ---------- metrics from cy (prop_garbage, ri averaged 2013–2019) ----------
metrics_by_county <- NULL
if (!is.null(cy)) {
  year_col <- names(cy)[tolower(names(cy)) %in% c("year","yr")][1]
  ri_col <- intersect(names(cy), c("RI_post_only"))[1]
  have_metrics <- c("prop_garbage", ri_col); have_metrics <- have_metrics[!is.na(have_metrics)]
  if (!is.na(year_col) && length(have_metrics) > 0) {
    metrics_by_county <- cy %>%
      mutate(year = as.integer(.data[[year_col]])) %>%
      filter(year %in% 2013:2019) %>%
      group_by(county_ihme) %>%
      summarise(across(all_of(have_metrics), ~ mean(safe_num(.), na.rm = TRUE)), .groups = "drop") %>%
      rename(ri = !!ri_col)
  }
}
if (is.null(metrics_by_county)) metrics_by_county <- tibble(county_ihme = character())

# add detail_icd4 (by cluster→county) to metrics_by_county
metrics_by_county <- metrics_by_county %>%
  full_join(detail_by_county %>% select(county_ihme, detail_icd4), by = "county_ihme")

# ---------- weights (certificates over 2013–2019; else population) ----------
county_avg <- {
  wt_tbl <- NULL
  if (!is.null(cy)) {
    ncert_col <- names(cy)[tolower(names(cy)) %in% c("n_cert","deaths","total","cert_count")][1]
    year_col  <- names(cy)[tolower(names(cy)) %in% c("year","yr")][1]
    if (!is.na(ncert_col) && !is.na(year_col)) {
      wt_tbl <- cy %>%
        transmute(county_ihme = std_fips(county_ihme),
                  year = as.integer(.data[[year_col]]),
                  n_cert = safe_num(.data[[ncert_col]])) %>%
        filter(is.finite(n_cert)) %>%
        mutate(use = ifelse(year %in% 2013:2019, 1L, 0L)) %>%
        group_by(county_ihme) %>%
        summarise(wt_sum = if (sum(use)>0) sum(n_cert[use==1], na.rm=TRUE) else sum(n_cert, na.rm=TRUE),
                  .groups = "drop")
    }
  }
  if (is.null(wt_tbl) || nrow(wt_tbl) == 0) wt_tbl <- pop_by_county %>% transmute(county_ihme, wt_sum = pop)
  wt_tbl %>% left_join(metrics_by_county, by = "county_ihme")
}

# ---------- per-capita outcomes & aggregate z-score ----------
check_df <- county_avg %>%
  full_join(counts_by_county, by = "county_ihme") %>%
  left_join(pop_by_county,     by = "county_ihme") %>%
  mutate(
    pop = ifelse(is.finite(pop) & pop > 0, pop, NA_real_),
    exc_per100k       = (exc_avg   / pop) * 1e5,
    covid_per100k     = (covid_avg / pop) * 1e5,
    nc_excess_per100k = ((exc_avg - covid_avg) / pop) * 1e5
  ) %>%
  mutate(
    z_garbage = z_std(-prop_garbage),  # lower is better
    z_detail  = z_std(detail_icd4),    # higher is better
    z_ri      = z_std(ri),             # higher is better
    n_comp    = rowSums(cbind(!is.na(z_garbage), !is.na(z_detail), !is.na(z_ri))),
    agg_index = ifelse(n_comp >= 2, rowMeans(cbind(z_garbage, z_detail, z_ri), na.rm = TRUE), NA_real_)
  ) %>%
  select(-n_comp)

# ---------- sanity print + export ----------
message("Rows with missing population will be omitted from per-capita checks.")
print(
  check_df %>%
    arrange(desc(wt_sum)) %>%
    select(county_ihme, wt_sum, pop, exc_avg, covid_avg, rel_exc_mean,
           exc_per100k, covid_per100k, nc_excess_per100k,
           prop_garbage, detail_icd4, ri, agg_index) %>%
    head(20),
  n = 20
)

dir.create(here("output"), showWarnings = FALSE, recursive = TRUE)
out_csv <- here("output","excess_percap_by_county.csv")
readr::write_csv(check_df, out_csv)
message("✓ Wrote: ", out_csv)

# ---------- correlations: metrics (incl aggregate) vs relExcDeathsMean (PRIMARY) ----------
metrics <- intersect(c("prop_garbage","detail_icd4","ri","agg_index"), names(check_df))
if (length(metrics) > 0) {
  out_list <- lapply(metrics, function(m) {
    dfm <- check_df %>% filter(is.finite(.data[[m]]), is.finite(rel_exc_mean))
    if (nrow(dfm) < 4) return(NULL)
    w_ok <- any(is.finite(dfm$wt_sum) & dfm$wt_sum > 0)

    # PRIMARY: correlation with relExcDeathsMean (averaged)
    corr_rel <- if (w_ok) w_pearson(dfm[[m]], dfm$rel_exc_mean, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$rel_exc_mean, NULL)

    # Optionally keep the others for reference
    corr_nc  <- if (w_ok) w_pearson(dfm[[m]], dfm$nc_excess_per100k, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$nc_excess_per100k, NULL)
    corr_exc <- if (w_ok) w_pearson(dfm[[m]], dfm$exc_per100k,     dfm$wt_sum) else w_pearson(dfm[[m]], dfm$exc_per100k,     NULL)
    corr_cvd <- if (w_ok) w_pearson(dfm[[m]], dfm$covid_per100k,   dfm$wt_sum) else w_pearson(dfm[[m]], dfm$covid_per100k,   NULL)

    data.frame(
      metric = m,
      n_counties = nrow(dfm),
      # primary (relExcDeathsMean)
      cor_rel_r  = unname(corr_rel["r"]),  cor_rel_p  = unname(corr_rel["p"]),
      cor_rel_lo = unname(corr_rel["lo"]), cor_rel_hi = unname(corr_rel["hi"]),
      # optional extras
      cor_nc_r   = unname(corr_nc["r"]),
      cor_exc_r  = unname(corr_exc["r"]),
      cor_cvd_r  = unname(corr_cvd["r"])
    )
  }) %>% bind_rows()
  print(out_list)
} else {
  message("No metrics found to correlate.")
}

# --- read/augment estimatesMonthly with ratioMedUCD + excDeathsMean (per-capita) ---

# helper to read if not already present (reuses helpers from above: first_existing, read_estimates_monthly, make_fips5, safe_num)
if (!exists("raw_est")) {
  est_path <- first_existing(c(here("data_raw","estimatesMonthly.csv"), "data_raw/estimatesMonthly.csv"))
  stopifnot(!is.na(est_path))
  raw_est <- read_estimates_monthly(est_path)
  raw_est <- raw_est %>% mutate(
    county_ihme = make_fips5(
      first_existing(list(names(.)[match(TRUE, names(.) %in% c("FIPSCode","FIPS","fips","GEOID","geoid"))])),
      if ("stateFIPS" %in% names(.)) .$stateFIPS else NULL
    )
  )
}

need_core <- c("year","month","COVIDDeathsUCD","relExcDeathsMean")
miss_core <- setdiff(need_core, names(raw_est))
if (length(miss_core)) stop("Missing in estimatesMonthly.csv: ", paste(miss_core, collapse=", "))

has_excMed  <- "excDeathsMed"  %in% names(raw_est)
has_excMean <- "excDeathsMean" %in% names(raw_est)
has_ratio   <- "ratioMedUCD"   %in% names(raw_est)

est <- raw_est %>%
  transmute(
    county_ihme = county_ihme,
    year        = as.integer(year),
    month       = as.integer(month),
    COVIDDeaths = safe_num(COVIDDeathsUCD),
    relExc      = safe_num(relExcDeathsMean),
    excMed      = if (has_excMed)  safe_num(excDeathsMed)  else NA_real_,
    excMean     = if (has_excMean) safe_num(excDeathsMean) else NA_real_,
    ratioMedUCD = if (has_ratio)   safe_num(ratioMedUCD)   else NA_real_
  )

# Window: Mar 2020–Aug 2022
est_sub <- est %>%
  mutate(ym = year*100L + month) %>%
  filter(ym >= 202003L, ym <= 202208L)

# county-level averages in window
counts_by_county <- est_sub %>%
  group_by(county_ihme) %>%
  summarise(
    exc_avg              = if (has_excMed)  mean(excMed,  na.rm = TRUE) else NA_real_,
    covid_avg            = mean(COVIDDeaths, na.rm = TRUE),
    rel_exc_mean         = mean(relExc,      na.rm = TRUE),
    exc_mean_avg         = if (has_excMean) mean(excMean, na.rm = TRUE) else NA_real_,
    ratio_med_ucd_mean   = if (has_ratio)   mean(ratioMedUCD, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# join population + quality metrics and compute per-capita outcomes
check_df <- county_avg %>%
  full_join(counts_by_county, by = "county_ihme") %>%
  left_join(pop_by_county,     by = "county_ihme") %>%
  mutate(
    pop = ifelse(is.finite(pop) & pop > 0, pop, NA_real_),
    # per-capita (per 100k) outcomes
    exc_per100k        = if (has_excMed)  (exc_avg      / pop) * 1e5 else NA_real_,
    covid_per100k      =                     (covid_avg    / pop) * 1e5,
    nc_excess_per100k  = if (has_excMed)  ((exc_avg - covid_avg) / pop) * 1e5 else NA_real_,
    exc_mean_per100k   = if (has_excMean) (exc_mean_avg / pop) * 1e5 else NA_real_
  ) %>%
  # z-scores/aggregate index stay the same
  mutate(
    z_garbage = z_std(-prop_garbage),
    z_detail  = z_std(detail_icd4),
    z_ri      = z_std(ri),
    n_comp    = rowSums(cbind(!is.na(z_garbage), !is.na(z_detail), !is.na(z_ri))),
    agg_index = ifelse(n_comp >= 2, rowMeans(cbind(z_garbage, z_detail, z_ri), na.rm = TRUE), NA_real_)
  ) %>% select(-n_comp)

# (optional) quick peek
print(
  check_df %>% arrange(desc(wt_sum)) %>%
    select(county_ihme, wt_sum, pop,
           exc_avg, exc_mean_avg, covid_avg, rel_exc_mean,
           exc_per100k, exc_mean_per100k, covid_per100k, nc_excess_per100k,
           ratio_med_ucd_mean, prop_garbage, detail_icd4, ri, agg_index) %>% head(12),
  n = 12
)

# ---------------- correlations: add exc_mean_per100k and ratio_med_ucd_mean ----------------
metrics <- intersect(c("prop_garbage","detail_icd4","ri","agg_index"), names(check_df))

if (length(metrics) > 0) {
  out_list <- lapply(metrics, function(m) {
    dfm <- check_df %>% filter(is.finite(.data[[m]]), is.finite(rel_exc_mean))
    if (nrow(dfm) < 4) return(NULL)
    w_ok <- any(is.finite(dfm$wt_sum) & dfm$wt_sum > 0)

    w <- if (w_ok) dfm$wt_sum else NULL
    c_rel   <- w_pearson(dfm[[m]], dfm$rel_exc_mean,    w)   # primary
    c_nc    <- w_pearson(dfm[[m]], dfm$nc_excess_per100k, w)
    c_exc   <- w_pearson(dfm[[m]], dfm$exc_per100k,      w)  # using excDeathsMed per-capita (if present)
    c_cvd   <- w_pearson(dfm[[m]], dfm$covid_per100k,    w)
    c_excMn <- w_pearson(dfm[[m]], dfm$exc_mean_per100k, w)  # NEW: excDeathsMean per-capita
    c_ratio <- w_pearson(dfm[[m]], dfm$ratio_med_ucd_mean, w) # NEW: ratioMedUCD (dimensionless)

    data.frame(
      metric = m,
      n_counties = nrow(dfm),
      # primary
      cor_rel_r  = unname(c_rel["r"]),  cor_rel_p  = unname(c_rel["p"]),
      cor_rel_lo = unname(c_rel["lo"]), cor_rel_hi = unname(c_rel["hi"]),
      # extras
      cor_nc_r      = unname(c_nc["r"]),
      cor_exc_r     = unname(c_exc["r"]),
      cor_cvd_r     = unname(c_cvd["r"]),
      cor_excMean_r = unname(c_excMn["r"]),     # NEW
      cor_ratio_r   = unname(c_ratio["r"])      # NEW
    )
  }) %>% dplyr::bind_rows()
  print(out_list)
} else {
  message("No metrics found to correlate.")
}


```




