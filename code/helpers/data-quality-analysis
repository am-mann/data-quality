# mortality_timeseries.py
# --------------------------------------------------
import polars as pl
from pathlib import Path

DATA_DIR   = Path("/Users/amymann/Documents/Data Quality Project/data/parquet")
YEAR_RANGE = pl.int_range(1999, 2024, eager=True)      # 1999-2023 inclusive

# 0.  Scan the Parquet folder lazily ----------------
ds = (
    pl.scan_parquet(DATA_DIR)                       # NO data loaded yet
      .select(                                      # read only the columns we need
          "year", "ucod", "sex",
          "racer3", "educr", "marstat", "placdth"
      )
      .filter(pl.col("year").is_in(YEAR_RANGE))     # restrict upfront for perf
)

# 1.  Helper ---------------------------------------------------------------
def make_ts(base_lazyframe: pl.LazyFrame,
            group_cols: list[str] | str,
            where   : pl.Expr | None = None) -> pl.DataFrame:
    """
    Create a time-series table with counts (n) and within-year proportions (prop).

    Parameters
    ----------
    base_lazyframe : a Polars LazyFrame that already contains `year`
    group_cols     : one or more columns to group on
    where          : optional Polars expression to pre-filter rows
    """
    lf = base_lazyframe
    if where is not None:
        lf = lf.filter(where)                       # e.g. marstat == "M"

    # guarantee group_cols is list-like
    if isinstance(group_cols, str):
        group_cols = [group_cols]

    # counts by year & group -----------------------
    grouped = (
        lf.groupby(["year", *group_cols], maintain_order=False)
          .len()
          .rename({"len": "n"})
    )

    # proportions within each year ----------------
    # (Polars' join preserves Lazy execution)
    totals = grouped.group_by("year").agg(pl.sum("n").alias("year_total"))
    ts     = (
        grouped.join(totals, on="year")
               .with_columns(prop = pl.col("n") / pl.col("year_total"))
               .drop("year_total")
               .sort(["year", *group_cols])
    )
    return ts.collect()                             # materialise only now

# 2.  Build the five tables -----------------------------------------------
ts_married = make_ts(ds,  "marstat", where = pl.col("marstat") == "M")
ts_sex     = make_ts(ds,  "sex")
ts_race    = make_ts(ds,  "racer3")
ts_edu     = make_ts(ds,  "educr")
ts_place   = make_ts(ds,  "placdth")

# 3.  (Optional) bundle them for easy export -------------------------------
timeseries = {
    "married": ts_married,
    "sex"    : ts_sex,
    "race"   : ts_race,
    "educr"  : ts_edu,
    "placdth": ts_place,
}

# 4.  Save to disk if you like ---------------------------------------------
OUT_DIR = Path("./ts_outputs")
OUT_DIR.mkdir(exist_ok=True)

for name, df in timeseries.items():
    df.write_parquet(OUT_DIR / f"{name}_1999_2023.parquet")
    # or: df.write_csv(...) if colleagues prefer CSV
