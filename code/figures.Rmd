---
title: "Final Figure Notebook (Dec 23)"
output: html_notebook
---

Plot of  RI maps, garbage codes, and level of detail (Figure 2)
```{r}
# ──────────────────────────────────────────────────────────────
# ONE FIGURE: 3 rows × 2 columns
# Columns: 1999–2005 | 2020–2022
# Rows:
#   (1) Re-assignment Index (RI)
#   (2) Level of detail (UCOD ICD-4 standardized diversity)
#   (3) Proportion garbage-coded deaths  (higher = darker)
# Output → figures/5yr_avg_stable/quality_3x2_maps.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  pkgs <- c("sf","dplyr","stringr","readr","ggplot2","tigris",
            "rlang","patchwork","scales","here")
  miss <- setdiff(pkgs, rownames(installed.packages()))
  if (length(miss)) install.packages(miss, repos = "https://cloud.r-project.org")
  lapply(pkgs, library, character.only = TRUE)
})

options(tigris_use_cache = TRUE, tigris_class = "sf")
sf::sf_use_s2(FALSE)

# ----------------------------- paths ----------------------------
metrics_lod_file <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
metrics_cty_file <- here("data",   "county_year_quality_metrics.csv.gz")
membership_file  <- here("output", "county_cluster_membership.csv.gz")

out_dir <- here("figures", "5yr_avg_stable")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# -------------------------- constants ---------------------------
crs_proj  <- 2163
periods_2 <- c("1999_2005","2020_2022")

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# -------------------- AK / HI helpers ---------------------------
st_shift <- function(sf_obj, shift) {
  sf::st_geometry(sf_obj) <- sf::st_geometry(sf_obj) + shift
  sf_obj
}
st_scale <- function(sf_obj, k) {
  ctr <- sf::st_centroid(sf::st_union(sf_obj))
  sf::st_geometry(sf_obj) <- (sf::st_geometry(sf_obj) - ctr) * k + ctr
  sf_obj
}

build_counties <- function() {
  cty <- tigris::counties(cb = TRUE, year = 2020, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)

  mainland <- cty |> dplyr::filter(!STATEFP %in% c("02","15"))

  alaska <- cty |>
    dplyr::filter(STATEFP == "02") |>
    st_scale(0.33) |>
    st_shift(c(1100000, -4700000)) |>
    sf::st_set_crs(crs_proj)

  hawaii <- cty |>
    dplyr::filter(STATEFP == "15") |>
    st_shift(c(5000000, -1100000)) |>
    sf::st_set_crs(crs_proj)

  out <- dplyr::bind_rows(mainland, alaska, hawaii) |>
    dplyr::rename(fips = GEOID) |>
    dplyr::mutate(fips = std_fips(fips)) |>
    sf::st_make_valid()

  sf::st_crs(out) <- crs_proj
  out
}

build_states <- function() {
  st <- tigris::states(cb = TRUE, year = 2020, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)

  mainland <- st |> dplyr::filter(!STATEFP %in% c("02","15"))

  alaska <- st |>
    dplyr::filter(STATEFP == "02") |>
    st_scale(0.33) |>
    st_shift(c(1100000, -4700000)) |>
    sf::st_set_crs(crs_proj)

  hawaii <- st |>
    dplyr::filter(STATEFP == "15") |>
    st_shift(c(5000000, -1100000)) |>
    sf::st_set_crs(crs_proj)

  out <- dplyr::bind_rows(mainland, alaska, hawaii) |>
    sf::st_make_valid()

  sf::st_crs(out) <- crs_proj
  out
}

# ----------------------- load inputs ---------------------------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)

# robust membership normalisation (in case column names vary)
nms_m <- names(membership_raw); low_m <- tolower(nms_m)
fips_col_m    <- nms_m[which(grepl("^(fips|geoid)$|^geoid|fips", low_m))[1]]
cluster_col_m <- nms_m[which(grepl("^(cluster|cluster_id)$|cluster", low_m))[1]]
period_col_m  <- nms_m[low_m == "period"][1]
if (is.na(fips_col_m) || is.na(cluster_col_m) || is.na(period_col_m)) {
  stop("Membership file must contain fips/geoid, cluster, and period columns.")
}

membership <- membership_raw |>
  dplyr::transmute(
    fips    = std_fips(.data[[fips_col_m]]),
    cluster = as.character(.data[[cluster_col_m]]),
    period  = as.character(.data[[period_col_m]])
  ) |>
  dplyr::distinct()

counties <- build_counties()
states   <- build_states()

# ---------------- cluster polygon builder ----------------------
build_cluster_sf <- function(period_key) {
  counties |>
    dplyr::inner_join(membership |> dplyr::filter(period == period_key), by = "fips") |>
    dplyr::group_by(cluster) |>
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") |>
    sf::st_make_valid() |>
    (\(x){ sf::st_crs(x) <- crs_proj; x })()
}

# ===================== county-year metrics (robust id) ==========
metrics_raw <- readr::read_csv(metrics_cty_file, show_col_types = FALSE)

possible_id_cols <- c("fips", "geoid", "county_ihme", "county")
lower_names <- tolower(names(metrics_raw))
id_idx <- which(lower_names %in% possible_id_cols)[1]
if (is.na(id_idx)) stop("Could not find county identifier column in county_year_quality_metrics.csv.gz")
id_col <- names(metrics_raw)[id_idx]

metrics_cty <- metrics_raw |>
  dplyr::mutate(
    fips = std_fips(.data[[id_col]]),
    year = as.integer(year),
    period = dplyr::case_when(
      year >= 1999 & year <= 2005 ~ "1999_2005",
      year >= 2020 & year <= 2022 ~ "2020_2022",
      TRUE ~ NA_character_
    )
  ) |>
  dplyr::filter(period %in% periods_2)

# ===================== (1) RI =================================
cluster_ri <- membership |>
  dplyr::left_join(metrics_cty, by = c("fips","period")) |>
  dplyr::group_by(cluster, period) |>
  dplyr::summarise(RI = mean(RI_post_only, na.rm = TRUE), .groups = "drop")

ri_lims <- stats::quantile(cluster_ri$RI, c(0.01, 0.99), na.rm = TRUE)

ri_1999 <- build_cluster_sf("1999_2005") |>
  dplyr::left_join(cluster_ri |> dplyr::filter(period == "1999_2005"), by = "cluster")

ri_2020 <- build_cluster_sf("2020_2022") |>
  dplyr::left_join(cluster_ri |> dplyr::filter(period == "2020_2022"), by = "cluster")

# ===================== (2) LOD ================================
lod <- readr::read_csv(metrics_lod_file, show_col_types = FALSE) |>
  dplyr::filter(period %in% periods_2) |>
  dplyr::transmute(
    cluster = as.character(cluster),
    period  = as.character(period),
    lod     = as.numeric(detail_ucod_icd4_cstd)
  )

lod_lims <- stats::quantile(lod$lod, c(0.02, 0.98), na.rm = TRUE)

lod_1999 <- build_cluster_sf("1999_2005") |>
  dplyr::left_join(lod |> dplyr::filter(period == "1999_2005"), by = "cluster")

lod_2020 <- build_cluster_sf("2020_2022") |>
  dplyr::left_join(lod |> dplyr::filter(period == "2020_2022"), by = "cluster")

# ===================== (3) Proportion garbage ==================
pg_by_fips_period <- metrics_cty |>
  dplyr::group_by(fips, period) |>
  dplyr::summarise(prop_garbage = mean(prop_garbage, na.rm = TRUE), .groups = "drop")

cluster_pg <- membership |>
  dplyr::left_join(pg_by_fips_period, by = c("fips","period")) |>
  dplyr::group_by(cluster, period) |>
  dplyr::summarise(prop_garbage = mean(prop_garbage, na.rm = TRUE), .groups = "drop")

pg_lims <- stats::quantile(cluster_pg$prop_garbage, c(0.02, 0.98), na.rm = TRUE)

pg_1999 <- build_cluster_sf("1999_2005") |>
  dplyr::left_join(cluster_pg |> dplyr::filter(period == "1999_2005"), by = "cluster")

pg_2020 <- build_cluster_sf("2020_2022") |>
  dplyr::left_join(cluster_pg |> dplyr::filter(period == "2020_2022"), by = "cluster")

# ----------------------- plotting helper -----------------------
base_extent <- list(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000))

red_scale_high_good <- function(lims) {
  ggplot2::scale_fill_distiller(
    palette = "Reds",
    direction = -1,   # ← flip
    limits  = lims,
    oob     = scales::squish,
    na.value = "grey90"
  )
}

# Higher = darker (BAD metric: proportion garbage)
red_scale_high_bad <- function(lims) {
  ggplot2::scale_fill_distiller(
    palette = "Reds",
    direction = 1,    # unchanged
    limits  = lims,
    oob     = scales::squish,
    na.value = "grey90"
  )
}

make_map <- function(sf_obj, fill_var, title, lims) {
  ggplot2::ggplot() +
    ggplot2::geom_sf(
      data = sf_obj,
      ggplot2::aes(fill = {{ fill_var }}),
      colour = NA
    ) +
    ggplot2::geom_sf(
      data = states,
      fill = NA,
      colour = "white",
      linewidth = 0.25
    ) +
    red_scale_high_good(lims) +
    ggplot2::coord_sf(
      xlim = base_extent$xlim,
      ylim = base_extent$ylim,
      expand = FALSE
    ) +
    ggplot2::labs(title = title, fill = NULL) +
    ggplot2::theme_void(base_size = 11) +
    ggplot2::theme(
      plot.title = ggplot2::element_text(hjust = 0.5, face = "bold")
    )
}

# Proportion garbage maps (use same scale; higher = darker)
make_pg_map <- function(sf_obj, title, lims) {
  ggplot2::ggplot() +
    ggplot2::geom_sf(
      data = sf_obj,
      ggplot2::aes(fill = prop_garbage),
      colour = NA
    ) +
    ggplot2::geom_sf(
      data = states,
      fill = NA,
      colour = "white",
      linewidth = 0.25
    ) +
    red_scale_high_bad(lims) +
    ggplot2::coord_sf(
      xlim = base_extent$xlim,
      ylim = base_extent$ylim,
      expand = FALSE
    ) +
    ggplot2::labs(title = title, fill = NULL) +
    ggplot2::theme_void(base_size = 11) +
    ggplot2::theme(
      plot.title = ggplot2::element_text(hjust = 0.5, face = "bold")
    )
}

# ----------------------- assemble ------------------------------
fig <-
  ( make_map(ri_1999,  RI,    "RI, 1999–2005",              ri_lims) |
      make_map(ri_2020, RI,   "RI, 2020–2022",              ri_lims) ) /
  ( make_map(lod_1999, lod,   "Level of detail, 1999–2005", lod_lims) |
      make_map(lod_2020, lod, "Level of detail, 2020–2022", lod_lims) ) /
  ( make_pg_map(pg_1999, "Proportion garbage, 1999–2005",   pg_lims) |
      make_pg_map(pg_2020, "Proportion garbage, 2020–2022", pg_lims) ) +
  patchwork::plot_annotation(tag_levels = "A")

outfile <- file.path(out_dir, "quality_3x2_maps.png")
ggplot2::ggsave(outfile, fig, width = 12, height = 14, dpi = 320)
message("✓ Saved: ", outfile)

```
SUPPLEMENTARY FIGURE: Average KL-divergence overtime
```{r}
metrics_path_gz <- here::here("data","county_year_quality_metrics.csv.gz")
metrics_path    <- if (file.exists(metrics_path_gz)) metrics_path_gz else here::here("data","county_year_quality_metrics.csv")
dq <- readr::read_csv(metrics_path, show_col_types = FALSE)


.wmean <- function(x, w) {
  w <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(w)) || sum(w, na.rm = TRUE) == 0) return(NA_real_)
  stats::weighted.mean(x, w, na.rm = TRUE)
}

ri_ts <- dq %>%
  dplyr::filter(!is.na(year), year >= 1999, year <= 2022, is.finite(RI)) %>%
  dplyr::group_by(year) %>%
  dplyr::summarise(
    wmean_RI  = .wmean(RI, N_garb_g1g2g4g5g6g7),  # weight by targeted garbage bins
    n_ctyyr   = dplyr::n(),
    .groups = "drop"
  )

# Save the underlying series
readr::write_csv(ri_ts, file.path(output_dir, "RI_time_series_1999_2022.csv"))

# Plot (weighted mean only)
p_ri_ts <- ggplot(ri_ts, aes(x = year, y = wmean_RI)) +
  geom_line(linewidth = 1) +
  geom_point(size = 1.7) +
  labs(
    x = NULL, y = "Normalized K-L Divergence"
  ) +
  scale_x_continuous(breaks = seq(2000, 2022, by = 2)) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  )

# Save figure
ggsave(file.path(output_dir, "RI_time_series_1999_2022.png"),
       plot = p_ri_ts, width = 8.5, height = 4.8, dpi = 320)

p_ri_ts

```
Map of z-scores 
```{r}
# ──────────────────────────────────────────────────────────────
# Cluster z-scores & maps (overdose-unspecified, prop_garbage, RI, Philips)
#   • Robust to: membership duplicates, Philips column names, odd period labels
#   • Outputs:
#       - output/cluster_scores/cluster_zscores_overdose_philips_RI_propgarbage.csv
#       - figures/5yr_avg_stable/z_<metric>_4panel.png  (+ direction_score_4panel.png)
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr);  library(dplyr);  library(stringr); library(tidyr);  library(purrr)
  library(ggplot2); library(sf);     library(tigris);  library(scales); library(here)
})

options(tigris_use_cache = TRUE, tigris_class = "sf", sf_use_s2 = TRUE)

# ------------------------ PATHS ------------------------
data_file       <- here("data",   "county_year_quality_metrics.csv.gz")
membership_file <- here("output", "county_cluster_membership.csv.gz")
philips_file    <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
out_dir_figs    <- here("figures","5yr_avg_stable")
out_dir_scores  <- here("output", "cluster_scores")
dir.create(out_dir_figs,   recursive = TRUE, showWarnings = FALSE)
dir.create(out_dir_scores, recursive = TRUE, showWarnings = FALSE)

# --------------------- periods & helpers -------------------------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
safe_div <- function(num, den) ifelse(is.finite(num) & is.finite(den) & den > 0, num / den, NA_real_)
compute_limits_symmetric <- function(x) {
  x <- x[is.finite(x)]; if (!length(x)) return(c(-1,1))
  L <- as.numeric(stats::quantile(abs(x), 0.98, na.rm = TRUE, names = FALSE))
  if (!is.finite(L) || L == 0) L <- 1
  c(-L, L)
}
sanitize <- function(x) { x %>% str_replace_all("[^A-Za-z0-9]+","_") %>% str_replace_all("^_+|_+$","") %>% tolower() }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }

# -------------------- projection & geometry helpers -------------------
crs_proj <- 2163
st_shift <- function(sf_obj, shift = c(0, 0)) { st_geometry(sf_obj) <- st_geometry(sf_obj) + shift; sf_obj }
st_scale <- function(sf_obj, scale = 1) { ctr <- st_centroid(st_union(sf_obj)); st_geometry(sf_obj) <- (st_geometry(sf_obj) - ctr) * scale + ctr; sf_obj }
build_counties_2163_resized <- function() {
  us_counties <- tigris::counties(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(GEOID, STATEFP, geometry)
  mainland <- us_counties |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_counties |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_counties |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> dplyr::rename(fips = GEOID, statefp = STATEFP) |> sf::st_make_valid()
}
build_states_2163_resized <- function() {
  us_states <- tigris::states(year = 2020, cb = TRUE, class = "sf") |>
    sf::st_transform(crs_proj) |>
    dplyr::select(STATEFP, geometry)
  mainland <- us_states |> dplyr::filter(!STATEFP %in% c("02","15"))
  alaska   <- us_states |> dplyr::filter(STATEFP == "02") |> st_scale(0.33) |> st_shift(c(1100000, -4700000)) |> sf::st_set_crs(crs_proj)
  hawaii   <- us_states |> dplyr::filter(STATEFP == "15") |> st_scale(1.00)  |> st_shift(c(5000000, -1100000)) |> sf::st_set_crs(crs_proj)
  dplyr::bind_rows(mainland, alaska, hawaii) |> sf::st_make_valid()
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()

# ------------------------- load membership (dedupe) --------------------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    membership_raw %>%
      dplyr::mutate(
        fips   = stringr::str_pad(as.character(fips), 5, pad = "0"),
        period = standardize_period(as.character(period)),
        cluster= as.character(cluster)
      ) %>%
      dplyr::left_join(ihme_map, by = "fips") %>%
      dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips)) %>%
      dplyr::select(county_ihme, period, cluster)
  } else stop("membership_file must contain 'county_ihme' or 'fips'.")

# dedupe to one row per county_ihme × period (mode if needed)
membership <- membership %>%
  dplyr::filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  dplyr::distinct(county_ihme, period, cluster)
dups <- membership %>% dplyr::count(county_ihme, period, name="n") %>% dplyr::filter(n > 1)
if (nrow(dups) > 0) message("Resolving ", nrow(dups), " county×period with multiple clusters (using modal cluster).")
membership <- membership %>%
  dplyr::group_by(county_ihme, period) %>%
  dplyr::summarise(cluster = mode_str(cluster), .groups="drop")

# --------------------- load county-year data -------------------
stopifnot(file.exists(data_file))
dy0 <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  dplyr::mutate(year = suppressWarnings(as.integer(year)),
                period = period_of_year(year))

if ("county_ihme" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"))
} else if ("fips" %in% names(dy0)) {
  dy <- dy0 %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad = "0")) %>%
    dplyr::left_join(ihme_map, by = "fips") %>%
    dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))
} else stop("data_file must contain 'county_ihme' or 'fips'.")

# --- ensure N_garbage & garb_k exist before checks ---
nms <- names(dy)
col_n_cert <- pick_col(nms, c("n_cert","deaths","total","N"))
col_prop_g <- pick_col(nms, c("foreman_garbage","prop_garbage"))
if (!("N_garbage" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating N_garbage = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(N_garbage = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("garb_k" %in% nms) {
    message("Using garb_k as N_garbage"); dy <- dy %>% dplyr::mutate(N_garbage = garb_k)
  } else stop("Missing N_garbage and cannot construct it.")
}
if (!("garb_k" %in% nms)) {
  if (!is.na(col_prop_g) && !is.na(col_n_cert)) {
    message("Creating garb_k = ", col_prop_g, " * ", col_n_cert)
    dy <- dy %>% dplyr::mutate(garb_k = .data[[col_prop_g]] * .data[[col_n_cert]])
  } else if ("N_garbage" %in% names(dy)) {
    message("Creating garb_k from N_garbage"); dy <- dy %>% dplyr::mutate(garb_k = N_garbage)
  } else stop("Cannot create garb_k.")
}

# Required vars
need_vars <- c("county_ihme","period","garb_k","n_cert","N_garbage","RI_post_only")
miss <- setdiff(need_vars, names(dy))
if (length(miss)) stop("Missing required columns in data_file: ", paste(miss, collapse=", "))

# ---------------- aggregate county → cluster×period -------------
cluster_core <- dy %>%
  dplyr::select(dplyr::all_of(need_vars)) %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::inner_join(membership, by = c("county_ihme","period")) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    sum_garb_k       = sum(garb_k,       na.rm = TRUE),
    sum_n_cert       = sum(n_cert,       na.rm = TRUE),
    sum_N_garbage    = sum(N_garbage,    na.rm = TRUE),
    num_RI_weighted  = sum(n_cert * RI_post_only, na.rm = TRUE),
    prop_garbage      = safe_div(sum_garb_k,       sum_n_cert),
    RI_cluster        = safe_div(num_RI_weighted,  sum_N_garbage),
    .groups = "drop"
  )

# ---------------- bring in Philips (CSTD; tolerant) ------------
stopifnot(file.exists(philips_file))
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
# normalize column names to lowercase for matching
names(ph0) <- tolower(names(ph0))

# ensure period
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% dplyr::mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% dplyr::mutate(period = standardize_period(period))
}

# normalize IDs to cluster-level
if ("cluster" %in% names(ph0)) {
  ph_norm <- ph0 %>% dplyr::mutate(cluster = as.character(cluster))
} else if ("county_ihme" %in% names(ph0) || "fips" %in% names(ph0)) {
  tmp <- ph0
  if ("fips" %in% names(tmp) && !("county_ihme" %in% names(tmp))) {
    tmp <- tmp %>% dplyr::mutate(fips = stringr::str_pad(as.character(fips), 5, pad="0")) %>%
      dplyr::left_join(ihme_map, by="fips")
  }
  if (!("county_ihme" %in% names(tmp))) stop("Philips file lacks id columns (cluster/county_ihme/fips).")
  ph_norm <- tmp %>%
    dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad="0")) %>%
    dplyr::inner_join(membership, by = c("county_ihme","period"))
} else stop("Philips file must contain 'cluster' or county id (county_ihme/fips).")

# pick cstd & weights robustly
ph_col <- pick_col(names(ph_norm), c("detail_ucod_icd4_cstd","cstd_ucr39","cstd","phillips_detail","philips_detail","cod_cstd","cod_cstd_ucr39"))
if (is.na(ph_col)) stop("Philips source missing CSTD column (tried philips_cstd/cstd_ucr39/cstd/phillips_detail/philips_detail/cod_cstd/...).")
w_col  <- pick_col(names(ph_norm), c("n_cert","deaths","total","n"))

philips_clu <- ph_norm %>%
  dplyr::filter(!is.na(period)) %>%
  dplyr::mutate(cluster = as.character(cluster)) %>%
  dplyr::group_by(period, cluster) %>%
  dplyr::summarise(
    w   = if (!is.na(w_col)) sum(.data[[w_col]], na.rm=TRUE) else NA_real_,
    num = if (!is.na(w_col)) sum(.data[[w_col]] * .data[[ph_col]], na.rm=TRUE) else sum(.data[[ph_col]], na.rm=TRUE),
    den = if (!is.na(w_col)) w else sum(!is.na(.data[[ph_col]])),
    philips_cstd = safe_div(num, den),
    .groups = "drop"
  ) %>%
  dplyr::filter(!is.na(philips_cstd))

# ---------------- merge & Z-scores -----------------------------
metrics_clu <- cluster_core %>%
  dplyr::inner_join(philips_clu, by = c("period","cluster")) %>%
  dplyr::filter(period %in% period_levels) %>%
  dplyr::arrange(period, cluster) %>%
  dplyr::mutate(cluster = as.character(cluster), period = as.character(period))

score_vars  <- c("philips_cstd","RI_cluster","prop_garbage")
global_means <- vapply(score_vars, function(v) mean(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds   <- vapply(score_vars, function(v)  sd(metrics_clu[[v]], na.rm = TRUE), numeric(1))
global_sds[!is.finite(global_sds) | global_sds == 0] <- NA_real_

z_tbl <- metrics_clu %>%
  dplyr::mutate(dplyr::across(
    dplyr::all_of(score_vars),
    \(x, nm=cur_column()) if (is.na(global_sds[[nm]])) NA_real_ else (x - global_means[[nm]]) / global_sds[[nm]],
    .names = "z_{.col}"
  )) %>%
  # Flip signs: higher z = better (less garbage / fewer unspecified overdoses)
  dplyr::mutate(
    z_prop_garbage      = -z_prop_garbage,
  ) %>%
  dplyr::mutate(
    direction_score = rowMeans(dplyr::across(starts_with("z_")), na.rm = TRUE)
  ) %>%
  dplyr::arrange(period, cluster)

readr::write_csv(z_tbl, file.path(out_dir_scores, "cluster_zscores_overdose_philips_RI_propgarbage.csv"))

# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))

build_cluster_sf <- function(period_key, membership_df, counties_sf_aug) {
  mm <- membership_df %>% dplyr::filter(.data$period == period_key) %>% dplyr::transmute(county_ihme = as.character(county_ihme), cluster = as.character(cluster)) %>% dplyr::distinct()
  if (!nrow(mm)) stop("No membership rows for period: ", period_key)
  counties_sf_aug %>%
    dplyr::inner_join(mm, by = "county_ihme") %>%
    dplyr::group_by(cluster) %>%
    dplyr::summarise(geometry = sf::st_union(geometry), .groups = "drop") %>%
    sf::st_make_valid()
}

# ---------------- 4-panel maps of Z-scores --------------------
make_faceted_map <- function(stacked_sf, fill_col, lims, states_sf) {
  ggplot2::ggplot() +
    geom_sf(data = stacked_sf, aes(fill = .data[[fill_col]]), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1, limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(fill = NULL) + facet_wrap(~ period, ncol = 2) + theme_void() +
    theme(strip.text = element_text(size = 12, face = "bold"), legend.text = element_text(size = 9), plot.title = element_blank())
}

to_map <- c("z_RI_cluster","z_prop_garbage","z_philips_cstd","direction_score")

for (mcol in to_map) {
  message("Assembling 4-panel for metric: ", mcol)
  stacked_sf <- purrr::map_dfr(period_levels, function(win){
    cl_sf <- build_cluster_sf(win, membership, counties_aug)
    dat   <- z_tbl %>% dplyr::filter(period==win) %>% dplyr::select(cluster, !!rlang::sym(mcol)) %>% dplyr::rename(value = !!rlang::sym(mcol))
    out   <- cl_sf %>% dplyr::left_join(dat, by="cluster"); out$period <- win; out
  }) %>% dplyr::mutate(period=factor(period, levels=period_levels))

  vals <- stacked_sf$value[is.finite(stacked_sf$value)]
  if (!length(vals) || length(unique(vals))==1) { message("  Skipping ", mcol, " (no variance)"); next }

  lims_sym <- compute_limits_symmetric(vals)  # symmetric for z-scores (centered at 0)
  p <- make_faceted_map(stacked_sf, "value", lims_sym, states_tf)

  base <- if (mcol == "direction_score") "direction_score" else sanitize(mcol)
  ggsave(file.path(out_dir_figs, paste0(base, "_4panel.png")), p, width=10, height=7.5, dpi=320)
}

message("✓ Done. Z-score CSV in: ", out_dir_scores, "  |  maps in: ", out_dir_figs)

```
Make new aggregate data quality index map with box plot (you must run previous chunk first) (Figure 3)
```{r}
# Fixed: Two maps (1999–2005, 2020–2022) + county-by-state boxplot
suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(sf); library(ggplot2)
  library(patchwork); library(scales); library(tigris)
})

# --- user-configurable ---
metric_to_plot <- "direction_score"
out_dir_figs <- if (exists("out_dir_figs")) out_dir_figs else "figures/5yr_avg_stable"
dir.create(out_dir_figs, recursive = TRUE, showWarnings = FALSE)

metric_label <- dplyr::case_when(
  metric_to_plot == "direction_score"      ~ "Aggregate data quality index (z)",
  metric_to_plot == "z_prop_garbage"       ~ "Proportion garbage (z, higher is better)",
  metric_to_plot == "z_philips_cstd"       ~ "Philips CSTD (z, higher is better)",
  metric_to_plot == "z_RI_cluster"         ~ "RI (z, higher is better)",
  TRUE ~ metric_to_plot
)

# --- Normalize IDs (robust) ---
# membership: ensure county_ihme exists & normalised
if (!"county_ihme" %in% names(membership)) {
  if ("fips" %in% names(membership)) {
    membership <- membership %>% mutate(county_ihme = str_pad(as.character(fips), 5, pad = "0"))
  } else stop("membership lacks county_ihme and fips; please create county_ihme first.")
} else {
  membership <- membership %>%
    mutate(county_ihme = str_pad(str_replace_all(as.character(county_ihme), "[^0-9]", ""), 5, pad = "0"))
}

# -------------------- IHME crosswalk (.rda) -------------------
load(here::here("data_raw","ihme_fips.rda"))  # provides ihme_fips
stopifnot(exists("ihme_fips"))
stopifnot(all(c("orig_fips","ihme_fips") %in% names(ihme_fips)))
ihme_map <- ihme_fips %>%
  dplyr::transmute(
    fips        = stringr::str_pad(as.character(orig_fips), 5, pad = "0"),
    county_ihme = stringr::str_pad(as.character(ihme_fips), 5, pad = "0")
  ) %>% dplyr::distinct()


# ---------------- geometry & cluster polygons -----------------
counties_tf <- build_counties_2163_resized()
states_tf   <- build_states_2163_resized()
counties_aug <- counties_tf %>% dplyr::left_join(ihme_map, by = "fips") %>% dplyr::mutate(county_ihme = dplyr::coalesce(county_ihme, fips))


# counties_lite from counties_aug (guarantee county_ihme + statefp)
counties_lite <- counties_aug %>% st_drop_geometry() %>% mutate(across(everything(), ~ if (is.factor(.)) as.character(.) else .))
if (!"county_ihme" %in% names(counties_lite)) {
  cand <- intersect(c("county_ihme","GEOID","geoid","fips","FIPS","COUNTYFP"), names(counties_lite))
  if (length(cand)) names(counties_lite)[which(names(counties_lite) == cand[1])] <- "county_ihme"
}
counties_lite <- counties_lite %>%
  mutate(county_ihme = str_pad(str_replace_all(as.character(county_ihme), "[^0-9]", ""), 5, pad = "0"))

# ensure statefp exists, derive from county_ihme if needed
if (!"statefp" %in% names(counties_lite)) {
  if ("STATEFP" %in% names(counties_lite)) {
    counties_lite <- counties_lite %>% rename(statefp = STATEFP)
  } else {
    counties_lite <- counties_lite %>% mutate(statefp = substr(county_ihme, 1, 2))
  }
}
counties_lite <- counties_lite %>% mutate(statefp = str_pad(str_replace_all(as.character(statefp), "[^0-9]", ""), 2, pad = "0"))

# states info (safe)
states_info <- tigris::states(year = 2020, cb = TRUE, class = "sf") %>%
  sf::st_drop_geometry() %>%
  mutate(STATEFP = str_pad(as.character(STATEFP), 2, pad = "0")) %>%
  dplyr::select(STATEFP, STUSPS) %>%
  dplyr::rename(statefp = STATEFP, state = STUSPS)

# --- helper: make single period map (safe) ---
make_single_map <- function(period_key, mcol, lims, states_sf, membership_df, counties_sf_aug) {
  # build cluster polygons for that period using your build_cluster_sf function
  cl_sf <- build_cluster_sf(period_key, membership_df, counties_sf_aug)
  dat <- z_tbl %>%
    filter(period == period_key) %>%
    select(cluster, value = !!rlang::sym(mcol))
  map_sf <- cl_sf %>% left_join(dat, by = "cluster")
  ggplot() +
    geom_sf(data = map_sf, aes(fill = value), colour = NA) +
    geom_sf(data = states_sf, fill = NA, colour = "white", linewidth = 0.3) +
    scale_fill_distiller(palette = "RdBu", direction = 1,
                         limits = lims, oob = scales::squish, na.value = "grey90") +
    coord_sf(xlim = c(-2500000, 2500000), ylim = c(-2200000, 730000), expand = FALSE) +
    labs(title = gsub("_", "–", period_key), fill = NULL) +
    theme_void(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
}

# --- build map limits across the two periods ---
periods_two <- c("1999_2005","2020_2022")
map_vals <- purrr::map_dfr(periods_two, function(win) {
  cl_sf <- build_cluster_sf(win, membership, counties_aug)
  dat <- z_tbl %>% filter(period == win) %>% select(cluster, value = !!rlang::sym(metric_to_plot))
  cl_sf %>% left_join(dat, by="cluster") %>% transmute(value)
})
lims_sym <- compute_limits_symmetric(map_vals$value)

# --- create maps ---
pA <- make_single_map("1999_2005", metric_to_plot, lims_sym, states_tf, membership, counties_aug)
pB <- make_single_map("2020_2022", metric_to_plot, lims_sym, states_tf, membership, counties_aug)

# --- build county-level dataframe safely ---
build_county_values_safe <- function(per, membership_df = membership, z_tbl_df = z_tbl, counties_df = counties_lite, states_df = states_info) {
  mm <- membership_df %>% filter(period == per) %>% distinct(county_ihme, cluster, .keep_all = TRUE)
  zv <- z_tbl_df %>% filter(period == per) %>% select(cluster, value = !!rlang::sym(metric_to_plot))
  joined <- mm %>% left_join(zv, by = "cluster")
  # ensure counties_df has county_ihme and statefp
  if (!"county_ihme" %in% names(counties_df)) stop("counties_df must have county_ihme")
  if (!"statefp" %in% names(counties_df)) counties_df <- counties_df %>% mutate(statefp = substr(county_ihme,1,2))
  joined2 <- joined %>% left_join(counties_df %>% select(county_ihme, statefp), by = "county_ihme")
  joined3 <- joined2 %>% left_join(states_df, by = "statefp") %>%
    mutate(period = per)
  # keep only rows with a state label and finite value
  res <- joined3 %>% filter(!is.na(state), is.finite(value)) %>% select(state, county_ihme, period, value)
  return(res)
}

bx_df <- bind_rows(build_county_values_safe("1999_2005"),
                   build_county_values_safe("2020_2022"))

# --- prepare boxplot df: rank states by 2020-2022 median, drop territories ---
state_order <- bx_df %>%
  filter(period == "2020_2022") %>%
  group_by(state) %>%
  summarise(med = median(value, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(med)) %>% pull(state)

territories <- c("PR","GU","VI","AS","MP")
bx_df <- bx_df %>% filter(!state %in% territories)

bx_df <- bx_df %>%
  mutate(
    state = factor(state, levels = state_order),
    period = factor(period, levels = c("1999_2005","2020_2022"),
                    labels = c("1999–2005","2020–2022"))
  )

# --- boxplot (visual choices can be adjusted) ---
ylims_box <- c(-2, 2)
pC <- ggplot(bx_df, aes(x = state, y = value, fill = period)) +
  geom_hline(yintercept = 0, linetype = 3, linewidth = 0.3) +
  geom_boxplot(width = 0.7, outlier.alpha = 0.4,
               position = position_dodge2(width = 0.75, preserve = "single")) +
  coord_cartesian(ylim = ylims_box) +
  scale_fill_manual(
  values = c(
    "1999–2005" = "#9e9e9e",  # neutral grey
    "2020–2022" = "#e69f00"   # orange (Okabe–Ito)
  )
) +
  labs(x = "States (ranked by declining median county-level 2020-2022 aggregate data quality index)",
       y = metric_label) +
  theme_bw(base_size = 10) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    panel.grid.minor = element_blank()
  )

# --- combine and save ---
combined <- (pA | pB) / pC + plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
base <- if (metric_to_plot == "direction_score") "direction_score" else gsub("[^A-Za-z0-9_-]", "_", metric_to_plot)
outfile <- file.path(out_dir_figs, paste0("two_maps_box_", base, ".png"))
ggsave(outfile, combined, width = 11, height = 8.5, dpi = 320)
cat("Wrote:", outfile, "\n")



# -------------------- period means + 95% CI + IQR (county-level; robust to labels) --------------------

# Helper: normalize different period label formats to canonical keys
normalize_period_key <- function(p) {
  p_chr <- as.character(p)
  # convert en/em dashes to hyphen, remove spaces
  p_chr <- gsub("\u2013|\u2014", "-", p_chr)    # en/em dash -> hyphen
  p_chr <- gsub("\\s+", "", p_chr)             # remove spaces
  sapply(p_chr, function(x) {
    if (grepl("^1999[_\\-]?2005$", x)) return("1999_2005")
    if (grepl("^2013[_\\-]?2019$", x)) return("2013_2019")
    if (grepl("^2020[_\\-]?2022$", x)) return("2020_2022")
    # if already canonical or unknown, return as-is
    return(x)
  }, USE.NAMES = FALSE)
}

# Ensure bx_df exists
if (!exists("bx_df")) stop("bx_df not found. Run the map/boxplot chunk first.")

# Add canonical period_key column (preserve original 'period' for printing)
bx_df <- bx_df %>% mutate(period_key = normalize_period_key(period))

# If 2013_2019 missing, build it and append
if (!"2013_2019" %in% unique(bx_df$period_key)) {
  message("2013_2019 not found in bx_df — building and appending county-level values for 2013_2019.")
  bx_2013_2019 <- build_county_values_safe("2013_2019")
  bx_2013_2019 <- bx_2013_2019 %>% mutate(period_key = normalize_period_key(period))
  bx_df <- bind_rows(bx_df, bx_2013_2019)
}

# Keep only canonical three periods and finite values
target_periods <- c("1999_2005", "2013_2019", "2020_2022")
bx_df2 <- bx_df %>% filter(period_key %in% target_periods & is.finite(value))

# safe IQR helper
iqr_safe <- function(x) {
  if (sum(is.finite(x)) < 2) return(c(NA_real_, NA_real_))
  stats::quantile(x, probs = c(0.25, 0.75), na.rm = TRUE, names = FALSE)
}

# Summarise: n, mean, sd, se, t CI, q1, q3, iqr
summary_ci_tbl <- bx_df2 %>%
  dplyr::group_by(period_key) %>%
  dplyr::summarise(
    n       = dplyr::n(),
    mean    = mean(value, na.rm = TRUE),
    sd      = sd(value, na.rm = TRUE),
    se      = sd / sqrt(n),
    t_975   = ifelse(n > 1, stats::qt(0.975, df = n - 1), NA_real_),
    ci_low  = ifelse(n > 1, mean - t_975 * se, NA_real_),
    ci_high = ifelse(n > 1, mean + t_975 * se, NA_real_),
    q1      = iqr_safe(value)[1],
    q3      = iqr_safe(value)[2],
    iqr     = q3 - q1,
    .groups = "drop"
  ) %>%
  dplyr::arrange(factor(period_key, levels = target_periods))

# pretty label
pretty_label <- function(key) {
  switch(as.character(key),
         "1999_2005" = "1999–2005",
         "2013_2019" = "2013–2019",
         "2020_2022" = "2020–2022",
         as.character(key))
}

# Print formatted summary to console
cat("\n---- Aggregate index (county-level) — mean ± 95% CI; SD; IQR ----\n")
cat(" Period         n     Mean     SD     95% CI [low, high]      Q1     Q3    IQR\n")
cat("-------------------------------------------------------------------------------\n")
for (i in seq_len(nrow(summary_ci_tbl))) {
  row <- summary_ci_tbl[i, ]
  lab <- pretty_label(row$period_key)
  cat(sprintf("%-13s %5d  %7.3f  %6.3f   [%7.3f, %7.3f]   %6.3f  %6.3f  %6.3f\n",
              lab, row$n, row$mean, row$sd, row$ci_low, row$ci_high, row$q1, row$q3, row$iqr))
}
cat("-------------------------------------------------------------------------------\n\n")

# Save CSV
summary_outfile2 <- file.path(out_dir_figs, paste0("two_maps_box_", base, "_mean_CI_IQR_by_period.csv"))
readr::write_csv(summary_ci_tbl, summary_outfile2)
cat("Saved summary CSV: ", summary_outfile2, "\n")
```
Build public health spending
```{r}
# ──────────────────────────────────────────────────────────────
# Build `fin_all` from fixed-width FinEstDAT (2017/2022) + PID crosswalk
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr); library(here)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# ---- 1) Parser for FinEst Individual Unit fixed-width file ----
# Layout (robustly inferred):
# [govt_id (14 chars)] [item_code (3 chars)] [amount (digits, right-justified)] [year (4)] [flag (1)]
# We parse from the RIGHT to avoid depending on space counts.
parse_finest_fixed <- function(path) {
  stopifnot(file.exists(path))
  lines <- read_lines(path, progress = FALSE)
  # drop blanks
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(tibble())

  # RIGHT-anchored extraction
  year  <- as.integer(str_sub(lines, -5, -2))
  flag  <- str_sub(lines, -1, -1)
  left1 <- str_sub(lines,  1, -6)                       # everything before year+flag
  # amount is trailing digits on left1
  m <- regexpr("(\\d+)\\s*$", left1, perl = TRUE)
  amt_str <- ifelse(m > 0, regmatches(left1, m), NA_character_)
  amount  <- suppressWarnings(as.numeric(amt_str))
  left2   <- ifelse(m > 0, substr(left1, 1, m - 1L), left1)
  left2   <- rtrim <- sub("\\s+$", "", left2)           # trim right spaces

  # last 3 chars of left2 are the raw item code (alpha+2digits OR 2digits+alpha)
  raw_item <- str_sub(left2, -3, -1)
  govt_id  <- str_sub(left2,  1, -4)

  # Normalize item code to LETTER+2DIGITS (e.g., "E32", "T01")
  item_code <- ifelse(grepl("^[A-Z][0-9]{2}$", raw_item, ignore.case = TRUE),
                      toupper(raw_item),
               ifelse(grepl("^[0-9]{2}[A-Z]$", raw_item, ignore.case = TRUE),
                      paste0(toupper(str_sub(raw_item, -1, -1)), str_sub(raw_item, 1, 2)),
                      toupper(raw_item)))

  tibble(
    govt_id  = govt_id,
    item_code = item_code,
    amount   = amount,
    year     = year,
    flag     = flag
  ) %>%
    filter(!is.na(amount), !is.na(year), nchar(govt_id) >= 10)
}

# ---- 2) PID crosswalk (maps govt_id → county FIPS if available) ----
# PID files vary; try TSV/CSV; look for columns like GOVTID/GOVT_ID and FIPS/GEOID/COUNTYFIPS.
# ──────────────────────────────────────────────────────────────
# Robust PID crosswalk for fixed‑width PID (e.g., Fin_PID_2022.txt)
# Extracts: govt_id (leading digits), county_ihme (stateFIPS + county)
# Lines look like:
# 011003160514BALDWIN COUNTY … 99003   22928722             093022
# ──────────────────────────────────────────────────────────────
read_pid_xwalk <- function(path) {
  if (!file.exists(path)) return(NULL)
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(NULL)

  # helper: leading digits = GOVTID
  lead_digits <- function(x) sub("^([0-9]+).*$", "\\1", x)

  # find the right-most 5-digit token that starts with "99" (e.g., 99015)
  find_99_code <- function(x) {
    m <- gregexpr("\\b99\\d{3}\\b", x, perl = TRUE)
    if (m[[1]][1] == -1) return(NA_character_)
    # take the last match on the line
    ix <- tail(m[[1]], 1)
    substr(x, ix, ix + attr(m[[1]], "match.length")[length(m[[1]])] - 1)
  }

  tib <- tibble::tibble(raw = lines) %>%
    dplyr::mutate(
      govt_id_raw = lead_digits(raw),
      state_fips  = substr(govt_id_raw, 1, 2),
      code_99     = vapply(raw, find_99_code, character(1)),
      county_ihme = dplyr::if_else(
        !is.na(code_99),
        paste0(state_fips, substr(code_99, 3, 5)),
        NA_character_
      )
    ) %>%
    dplyr::filter(!is.na(county_ihme), nchar(county_ihme) == 5) %>%
    dplyr::transmute(
      govt_id = govt_id_raw,
      county_ihme = stringr::str_pad(county_ihme, 5, pad = "0")
    ) %>%
    dplyr::distinct()

  if (!nrow(tib)) return(NULL)
  tib
}
# ---- 3) Locate files and build fin_all ----
find_first <- function(fname) {
  c(here("data_raw/finance", fname), fname) |> {\(p) p[file.exists(p)][1]}()
}

fin2017_path <- find_first("2017FinEstDAT_09202024modp_pu.txt")
fin2022_path <- find_first("2022FinEstDAT_09202024modp_pu.txt")
pid2017_path <- find_first("Fin_PID_2017.txt")
pid2022_path <- find_first("Fin_PID_2022.txt")

fin_tbls <- list()
if (!is.na(fin2017_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2017_path)))
if (!is.na(fin2022_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2022_path)))
stopifnot(length(fin_tbls) > 0)

fin_raw <- bind_rows(fin_tbls)

# PID crosswalks (optional but recommended for county mapping)
pid_xw <- bind_rows(
  list(read_pid_xwalk(pid2017_path), read_pid_xwalk(pid2022_path)) |> compact()
) %>% distinct()

# ---- 4) Filter to Public Health Expenditures (E32) and summarize by county ----
# item_code "E32" = expenditures, function 32 (Public Health)
fin_e32 <- fin_raw %>% filter(item_code == "E32")

if (nrow(fin_e32) == 0) {
  stop("Parsed finance files but found ZERO rows with item_code == 'E32'. ",
       "Double-check files and item code list; if needed, print a sample of item_code counts.")
}

# Map to counties
if (!nrow(pid_xw)) {
  stop("PID crosswalk not found or had no usable (govt_id, FIPS) columns. ",
       "Please provide Fin_PID_2017.txt / Fin_PID_2022.txt (or their actual paths).")
}

fin_all <- fin_e32 %>%
  left_join(pid_xw, by = "govt_id") %>%
  filter(!is.na(county_ihme)) %>%
  transmute(
    county_ihme = county_ihme,
    fin_year    = as.integer(year),
    ph_exp_total = as.numeric(amount)
  ) %>%
  group_by(county_ihme, fin_year) %>%
  summarise(ph_exp_total = sum(ph_exp_total, na.rm = TRUE), .groups = "drop")

# Sanity check
cat("# fin_all rows:", nrow(fin_all), "\n")
print(fin_all %>% count(fin_year, sort = TRUE))
```
Build pop and other needed things for next chunk
```{r}
# ──────────────────────────────────────────────────────────────
# REPAIR BLOCK — ensure components + build pop_join
# Run this ONCE before the PH-spend plotting code
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(purrr)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
as_county_ihme <- function(df) {
  nm <- names(df)
  id_col <- dplyr::case_when(
    "county_ihme" %in% nm ~ "county_ihme",
    "GEOID"       %in% nm ~ "GEOID",
    "fips"        %in% nm ~ "fips",
    "FIPS"        %in% nm ~ "FIPS",
    "countyrs"    %in% nm ~ "countyrs",
    TRUE ~ NA_character_
  )
  if (is.na(id_col)) stop("No county ID column found. Expect one of county_ihme/GEOID/fips/FIPS/countyrs.")
  df %>% mutate(county_ihme = std_fips(.data[[id_col]]))
}


# 2) Build pop_join (ACS preferred; pid_all fallback)
build_pop_join <- function(fin_years) {
  # Reuse if already valid
  if (exists("pop_join", inherits = TRUE)) {
    pj <- get("pop_join", inherits = TRUE)
    if (all(c("county_ihme","fin_year","pop") %in% names(pj))) return(pj)
  }

  # Try ACS via tidycensus
  if (requireNamespace("tidycensus", quietly = TRUE)) {
    message("Building pop_join from ACS (B01001_001, ACS5) …")
    out <- purrr::map_dfr(sort(unique(stats::na.omit(as.integer(fin_years)))), function(y) {
      yy <- max(2009L, min(2023L, as.integer(y)))  # ACS5 window
      tidycensus::get_acs(
        geography = "county", variables = "B01001_001",
        year = yy, survey = "acs5", cache_table = TRUE, show_call = FALSE
      ) %>%
        transmute(county_ihme = GEOID, fin_year = y, pop = estimate)
    })
    if (nrow(out)) return(out)
  }

  # Fallback: pid_all (must exist and have year/pop)
  if (exists("pid_all", inherits = TRUE)) {
    message("Falling back to pid_all for population …")
    pid <- get("pid_all", inherits = TRUE)
    stopifnot(all(c("county_ihme","year","pop") %in% names(pid)))
    return(pid %>% transmute(county_ihme, fin_year = as.integer(year), pop))
  }

  stop("Could not build pop_join: neither ACS nor pid_all available.")
}

# Need fin_years from fin_all
if (!exists("fin_all", inherits = TRUE)) stop("fin_all not found — run the finance builder first.")
fin_all <- as_county_ihme(fin_all)
stopifnot(all(c("county_ihme","fin_year","ph_exp_total") %in% names(fin_all)))

avail_fin_years <- sort(unique(stats::na.omit(as.integer(fin_all$fin_year))))
if (!length(avail_fin_years)) stop("No valid fin_year values in fin_all.")

pop_join <- build_pop_join(avail_fin_years)

# Finally: build ph_pc for downstream chunk
ph_pc <- fin_all %>%
  filter(!is.na(fin_year)) %>%
  left_join(pop_join, by = c("county_ihme","fin_year")) %>%
  mutate(ph_pc = ph_exp_total / pop) %>%
  filter(is.finite(ph_pc))
```
Build income (need for next chunk)
```{r}
# ──────────────────────────────────────────────────────────────
# Build income_all from the US Census API (ACS 5-year, B19013_001)
# • Output columns: county_ihme, acs_year, avg_income
# • Uses fin_years_actual if present; otherwise defaults to c(2017, 2022)
# • Requires: tidycensus (preferred). Falls back to censusapi if needed.
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr); library(stringr); library(tidyr)
})

# Helper: install/load a package quietly
ensure_pkg <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  invisible(TRUE)
}

# Decide which ACS years to fetch.
# County-level ACS 5-year is available 2009+; you likely want finance years like 2017 & 2022.
acs_years <- if (exists("fin_years_actual") && length(fin_years_actual)) {
  unique(suppressWarnings(as.integer(fin_years_actual)))
} else {
  c(2017L, 2022L)
}
acs_years <- acs_years[is.finite(acs_years) & acs_years >= 2009L]
acs_years <- sort(unique(acs_years))

if (!length(acs_years)) stop("No valid ACS years to fetch (need >=2009).")

# Preferred path: tidycensus
have_tidycensus <- FALSE
if (ensure_pkg("tidycensus")) {
  # Only set a key if user already has one in env/options; otherwise tidycensus still works for many calls.
  # You can pre-set with: tidycensus::census_api_key("YOUR_KEY", install = FALSE, overwrite = FALSE)
  suppressWarnings({
    have_tidycensus <- requireNamespace("tidycensus", quietly = TRUE)
  })
}

pull_income_tidycensus <- function(years) {
  purrr::map_dfr(years, function(y) {
    df <- tidycensus::get_acs(
      geography = "county",
      variables = "B19013_001",  # Median household income (dollars)
      year = y,
      survey = "acs5",
      cache_table = TRUE,
      geometry = FALSE
    )
    tibble::tibble(
      county_ihme = df$GEOID,                   # 5-digit FIPS
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$estimate))
    )
  })
}

# Fallback path: censusapi (raw var names differ slightly but include "B19013_001E")
pull_income_censusapi <- function(years) {
  ensure_pkg("censusapi")
  purrr::map_dfr(years, function(y) {
    df <- censusapi::getCensus(
      name   = "acs/acs5",
      vintage= y,
      vars   = c("NAME", "B19013_001E"),
      region = "county:*",
      regionin = "state:*"
    )
    tibble::tibble(
      county_ihme = stringr::str_pad(paste0(df$state, df$county), 5, pad = "0"),
      acs_year    = y,
      avg_income  = suppressWarnings(as.numeric(df$B19013_001E))
    )
  })
}

income_all <- tryCatch(
  if (have_tidycensus) pull_income_tidycensus(acs_years) else pull_income_censusapi(acs_years),
  error = function(e) {
    message("[income_all] tidycensus pull failed or unavailable; trying censusapi…\n", conditionMessage(e))
    pull_income_censusapi(acs_years)
  }
) %>%
  mutate(
    county_ihme = as.character(county_ihme),
    acs_year    = as.integer(acs_year),
    avg_income  = suppressWarnings(as.numeric(avg_income))
  ) %>%
  filter(!is.na(avg_income), is.finite(avg_income)) %>%
  arrange(acs_year, county_ihme)

# Optional: restrict to CONUS (drop PR/AK/HI) if your workflow expects that
# income_all <- income_all %>% filter(!stringr::str_sub(county_ihme, 1, 2) %in% c("02","15","72"))

# Sanity checks
message("[income_all] Years fetched: ", paste(unique(income_all$acs_year), collapse = ", "))
message("[income_all] Rows: ", nrow(income_all), " | Counties per year (median): ",
        stats::median(table(income_all$acs_year)))

# (Optional) If you want real (inflation-adjusted) dollars, bring your CPI deflator here and do:
# income_all <- income_all %>% left_join(cpi_tbl, by = c("acs_year" = "year")) %>%
#   mutate(avg_income_real_2022 = avg_income * deflator_to_2022)
# Then, in your plotting chunk, switch avg_income → avg_income_real_2022.
``` 
Validation: z-scores by reporting type, per capita healthcare expenditure, and income
```{r}
# ──────────────────────────────────────────────────────────────
# Validation (NEW): Aggregate index built from county–year z-scores
#   Index = mean( -Z(prop_garbage), -Z(pct_overd_miss), Z(RI_post_only), Z(Phillips detail) )
#   • Phillips detail pulled from cluster CSV, expanded to county–year
#   • Time series by Reporting Type, PH-spend quintile, Income quintile
# Saves:
#   figures/validation_zscore/direction_by_reporting.png
#   figures/validation_zscore/direction_by_spend_quintile.png
#   figures/validation_zscore/direction_by_income_quintile.png
#   figures/validation_zscore/direction_timeseries_3panel.png
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(dplyr);  library(tidyr);  library(ggplot2); library(scales)
  library(readr);  library(stringr); library(here);   library(purrr)
})

dir.create(here("figures","validation_zscore"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
period_levels <- c("1999_2005","2006_2012","2013_2019","2020_2022")
period_of_year <- function(y){
  dplyr::case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
standardize_period <- function(p){
  p <- as.character(p)
  out <- ifelse(p %in% period_levels, p, NA_character_)
  bad <- is.na(out) & grepl("^\\d{4}_\\d{4}$", p)
  if (any(bad)) {
    start <- suppressWarnings(as.integer(sub("_(\\d{4})$", "", p[bad])))
    out[bad] <- period_of_year(start)
  }
  out
}
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
pick_first <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
pick_col <- function(nms, candidates) { hit <- intersect(candidates, nms); if (length(hit)) hit[1] else NA_character_ }
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# ---------- file paths (robust candidates) ----------
data_candidates <- c(here("data","county_year_quality_metrics.csv"),
                     here("data","county_year_quality_metrics.csv.gz"))
membership_candidates <- c(here("output","county_cluster_membership.csv.gz"),
                           here("output","county_cluster_membership.csv"),
                           "output/county_cluster_membership.csv.gz")
philips_candidates <- c(here("output","cluster_metrics_ucr39_cstd.csv.gz"),
                        here("output","cluster_metrics.csv.gz"),
                        "output/cluster_metrics_ucr39_cstd.csv.gz")
reporting_candidates <- c(
  here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
  here("data_raw","County-Death-Investigation-System-2018.csv"),
  "data_raw/County-Death-Investigation-System-2018-1-9-2024.csv",
  "data_raw/County-Death-Investigation-System-2018.csv"
)
ph_pc_candidates <- c(                       # PH per-capita (county, finance years or tidy)
  here("output","ph_pc.csv"),
  here("output","ph_per_capita.csv"),
  here("data","ph_pc.csv"),
  "output/ph_pc.csv"
)
income_candidates <- c(                      # income (county, ACS)
  here("output","income_all.csv"),
  here("data","income_all.csv"),
  "output/income_all.csv",
  "data/income_all.csv"
)

data_file       <- pick_first(data_candidates)
membership_file <- pick_first(membership_candidates)
philips_file    <- pick_first(philips_candidates)
reporting_file  <- pick_first(reporting_candidates)
ph_pc_file      <- pick_first(ph_pc_candidates)
income_file     <- pick_first(income_candidates)

stopifnot(!is.na(data_file), !is.na(membership_file), !is.na(philips_file))

# ---------- optional IHME crosswalk if available ----------
ihme_map <- NULL
if (file.exists(here::here("data_raw","ihme_fips.rda"))) {
  load(here::here("data_raw","ihme_fips.rda"))
  if (exists("ihme_fips") && all(c("orig_fips","ihme_fips") %in% names(ihme_fips))) {
    ihme_map <- ihme_fips %>%
      transmute(fips = std_fips(orig_fips), county_ihme = std_fips(ihme_fips)) %>%
      distinct()
  }
}

# ---------- load membership (one modal cluster per county×period) ----------
membership_raw <- readr::read_csv(membership_file, show_col_types = FALSE)
membership <-
  if ("county_ihme" %in% names(membership_raw)) {
    membership_raw %>%
      mutate(
        county_ihme = std_fips(county_ihme),
        period      = standardize_period(as.character(period)),
        cluster     = as.character(cluster)
      )
  } else if ("fips" %in% names(membership_raw)) {
    m0 <- membership_raw %>%
      mutate(
        fips    = std_fips(fips),
        period  = standardize_period(as.character(period)),
        cluster = as.character(cluster)
      )
    if (!is.null(ihme_map)) {
      m0 <- m0 %>% left_join(ihme_map, by = "fips") %>%
        mutate(county_ihme = coalesce(county_ihme, fips)) %>%
        select(county_ihme, period, cluster)
    } else {
      m0 <- m0 %>% transmute(county_ihme = fips, period, cluster)
    }
    m0
  } else stop("membership file must contain county_ihme or fips")

# modal cluster if duplicates
mode_str <- function(x){ ux <- unique(x); ux[which.max(tabulate(match(x, ux)))] }
membership <- membership %>%
  filter(!is.na(period), !is.na(county_ihme), !is.na(cluster)) %>%
  group_by(county_ihme, period) %>%
  summarise(cluster = mode_str(cluster), .groups="drop")

# ---------- load county-year data ----------
cy <- readr::read_csv(data_file, show_col_types = FALSE) %>%
  mutate(year = suppressWarnings(as.integer(year)),
         period = period_of_year(year))

# normalize ids
if ("county_ihme" %in% names(cy)) {
  cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))
} else if ("fips" %in% names(cy)) {
  cy <- cy %>% mutate(fips = std_fips(fips))
  cy <- if (!is.null(ihme_map)) {
    cy %>% left_join(ihme_map, by = "fips") %>% mutate(county_ihme = coalesce(county_ihme, fips))
  } else {
    cy %>% mutate(county_ihme = fips)
  }
} else stop("data file must contain county_ihme or fips")

# ---------- ensure the FOUR components exist (county–year) ----------
# 1) prop_garbage
nms <- names(cy)
col_prop_g <- pick_col(nms, c("prop_garbage","foreman_garbage"))
if (is.na(col_prop_g)) stop("Need prop_garbage (or foreman_garbage) in county-year file.")

# 2) pct_overd_miss  (if missing, derive from counts if available)
if (!("pct_overd_miss" %in% nms)) {
  k <- pick_col(nms, c("overd_miss_k","overdose_unspecified_k","overdose_unspec_k","od_unspec_k"))
  N <- pick_col(nms, c("overd_n","overdose_total_n","od_total_n"))
  if (!is.na(k) && !is.na(N)) {
    cy <- cy %>% mutate(pct_overd_miss = ifelse(.data[[N]] > 0, .data[[k]] / .data[[N]], NA_real_))
  } else {
    stop("pct_overd_miss not found and cannot derive from counts.")
  }
}

# 3) RI_post_only
if (!("RI_post_only" %in% nms)) {
  alt <- pick_col(nms, c("RI","ri_post_only","ri"))
  if (!is.na(alt)) {
    cy <- cy %>% rename(RI_post_only = all_of(alt))
  } else stop("RI_post_only not found.")
}

# 4) Phillips detail from cluster CSV → expand to county–year
ph0 <- readr::read_csv(philips_file, show_col_types = FALSE)
names(ph0) <- tolower(names(ph0))
if (!("period" %in% names(ph0))) {
  if ("year" %in% names(ph0)) ph0 <- ph0 %>% mutate(period = period_of_year(as.integer(year)))
  else stop("Philips file needs 'period' or 'year'.")
} else {
  ph0 <- ph0 %>% mutate(period = standardize_period(period))
}
# choose a detail/CSTD column (fallbacks in order)
philips_col <- pick_col(names(ph0),
                        c("detail_ucod_icd4_cstd","detail_mcod_icd4_cstd",
                          "cod_diversity_cstd","cod_diversity_std","neff_cstd","richness_cstd"))
stopifnot(!is.na(philips_col))
# ensure cluster present (or map from county)
if (!("cluster" %in% names(ph0))) {
  # if provided at county level, map to cluster using membership
  idcol <- pick_col(names(ph0), c("county_ihme","fips","geoid"))
  stopifnot(!is.na(idcol))
  ph0 <- ph0 %>%
    mutate(county_ihme = if (idcol=="county_ihme") std_fips(county_ihme) else std_fips(.data[[idcol]])) %>%
    inner_join(membership, by = c("county_ihme","period"))
}
ph0 <- ph0 %>% mutate(cluster = as.character(cluster))

# build period endpoints & expand to years
get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) tibble(period = lbl, start = min(yrs[1], yrs[2]), end = max(yrs[1], yrs[2]))
  else tibble(period = lbl, start = NA_integer_, end = NA_integer_)
}
period_tbl <- unique(ph0$period) %>% sort() %>% map_dfr(parse_period) %>% filter(!is.na(start), !is.na(end))

ph_cy <- ph0 %>%
  select(cluster, period, value = all_of(philips_col)) %>%
  inner_join(membership, by = c("cluster","period")) %>%        # → county
  left_join(period_tbl, by = "period") %>%
  mutate(year = map2(start, end, seq)) %>%
  select(county_ihme, year, philips_detail = value) %>%
  unnest(year)

# ---------- join Phillips with county–year + compute z's ----------
# restrict to years we care about
cy <- cy %>% filter(!is.na(year), year >= 1999, year <= 2022)
cy4 <- cy %>%
  select(county_ihme, year, period,
         prop_garbage = all_of(col_prop_g),
         pct_overd_miss, RI_post_only)

cy4 <- cy4 %>%
  left_join(ph_cy, by = c("county_ihme","year"))

# global z's (across ALL county–years)
zcol <- function(x){ m <- mean(x, na.rm = TRUE); s <- sd(x, na.rm = TRUE); if (!is.finite(s) || s==0) return((x-x)*NA_real_); (x-m)/s }

cy4 <- cy4 %>%
  mutate(
    z_prop_garbage    = zcol(prop_garbage),
    z_pct_overd_miss  = zcol(pct_overd_miss),
    z_RI_post_only    = zcol(RI_post_only),
    z_phillips_detail = zcol(philips_detail)
  ) %>%
  # flip so that larger is always better
  mutate(
    z_prop_garbage    = -z_prop_garbage,
    z_pct_overd_miss  = -z_pct_overd_miss
  )

# aggregate index (county–year)
cy4 <- cy4 %>%
  mutate(
    direction_score = rowMeans(select(., z_prop_garbage, z_pct_overd_miss, z_RI_post_only, z_phillips_detail),
                               na.rm = TRUE)
  ) %>%
  mutate(direction_score = ifelse(is.nan(direction_score), NA_real_, direction_score))

# collapse to county–PERIOD means for plotting
dir_cp <- cy4 %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
  mutate(period = factor(period, levels = period_levels))

# =================================================================
# Reporting-type LOOKUP + panel
# =================================================================
normalize_reporting_type <- function(x) {
  y <- stringr::str_to_lower(stringr::str_squish(as.character(x)))
  dplyr::case_when(
    y %in% c("me","medical examiner") ~ "Medical Examiner",
    y %in% c("coroner")               ~ "Coroner",
    y %in% c("mixed","hybrid")        ~ "Mixed",
    grepl("other", y)                 ~ "Other County Official",
    y %in% c("na","n/a","unknown","") ~ NA_character_,
    TRUE                              ~ stringr::str_to_title(y)
  )
}
get_reporting_lookup <- function() {
  stopifnot(!is.na(reporting_file))
  rep_raw <- readr::read_csv(reporting_file, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df); hits <- which(Reduce(`|`, lapply(patterns, \(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_)
    nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5","county_ihme"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  out <- rep_raw %>%
    mutate(
      county_ihme = if (tolower(fips_col)=="county_ihme") std_fips(.data[[fips_col]]) else std_fips(.data[[fips_col]]),
      reporting_type = normalize_reporting_type(.data[[type_col]])
    ) %>%
    filter(nchar(county_ihme)==5, !is.na(reporting_type)) %>%
    distinct(county_ihme, reporting_type)
  out
}
rep_lookup <- get_reporting_lookup()

ts_reporting <- dir_cp %>%
  inner_join(rep_lookup, by = "county_ihme") %>%
  group_by(period, reporting_type) %>%
  summarise(mean_direction = mean(direction_score, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop")

p_rep <- ggplot(ts_reporting, aes(x = period, y = mean_direction, group = reporting_type, colour = reporting_type)) +
  geom_line(linewidth = 1.2) + geom_point(size = 2) +
  labs(title = "Aggregate data quality by reporting type",
       x = NULL, y = "Aggregate data quality (z)", colour = "Reporting type") +
  theme_bw(base_size = 12)

print(p_rep)
ggsave(here("figures","validation_zscore","direction_by_reporting.png"),
       p_rep, width = 9, height = 5.2, dpi = 320)
message("[REP] Saved reporting-type panel (rows=", nrow(ts_reporting), ").")

# =================================================================
# PH SPEND helpers + panel
# =================================================================
get_ph_any <- function() {
  # prefer in-memory ph_pc object
  if (exists("ph_pc", inherits = TRUE)) {
    pc <- get("ph_pc", inherits = TRUE)
    if (is.data.frame(pc)) {
      id  <- pick_col(names(pc), c("county_ihme","fips","geoid"))
      val <- pick_col(names(pc), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
      if (!is.na(id) && !is.na(val)) {
        return(
          pc %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
            filter(is.finite(ph_pc))
        )
      }
    }
  }
  # files
  f <- ph_pc_file
  if (!is.na(f) && file.exists(f)) {
    ph_raw <- readr::read_csv(f, show_col_types = FALSE)
    id  <- pick_col(names(ph_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(ph_raw), c("ph_pc","ph_per_capita","percap","ph_pc_usd"))
    if (!is.na(id) && !is.na(val)) {
      return(
        ph_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 ph_pc = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups="drop") %>%
          filter(is.finite(ph_pc))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
    )
  }
  NULL
}
get_ph_quintiles <- function() {
  qcol <- intersect(c("ph_quint","phspend_quint","ph_pc_quintile","ph_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[PH] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, ph_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  ph_any <- get_ph_any()
  if (is.null(ph_any) || !nrow(ph_any)) return(NULL)
  brks <- make_quintile_breaks(ph_any$ph_pc)
  ph_any %>%
    mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
}

ph_q <- get_ph_quintiles()
p_ph <- NULL
if (!is.null(ph_q) && nrow(ph_q)) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))

  p_ph <- ggplot(ts_ph, aes(period, mean_direction, group = ph_quint, colour = ph_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by public-health spending",
         x = NULL, y = "Aggregate data quality (z)", colour = "PH spend quintile") +
    theme_bw(base_size = 12)

  print(p_ph)
  out_path <- here("figures","validation_zscore","direction_by_spend_quintile.png")
  ggsave(out_path, p_ph, width = 9, height = 5.2, dpi = 320)
  message("[PH] Saved: ", out_path, "  (n rows=", nrow(ts_ph), ")")
} else {
  message("[PH] Panel skipped: could not derive PH quintiles.")
}

# =================================================================
# INCOME helpers + panel
# =================================================================
get_income_any <- function() {
  # prefer in-memory income_all
  if (exists("income_all", inherits = TRUE)) {
    ia <- get("income_all", inherits = TRUE)
    if (is.data.frame(ia)) {
      id  <- pick_col(names(ia), c("county_ihme","fips","geoid"))
      val <- pick_col(names(ia), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                   "income_pc","per_capita_income","pc_income","income"))
      if (!is.na(id) && !is.na(val)) {
        return(
          ia %>%
            mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                   income = suppressWarnings(as.numeric(.data[[val]]))) %>%
            group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
            filter(is.finite(income))
        )
      }
    }
  }
  # from file
  if (!is.na(income_file) && file.exists(income_file)) {
    inc_raw <- readr::read_csv(income_file, show_col_types = FALSE)
    id  <- pick_col(names(inc_raw), c("county_ihme","fips","geoid"))
    val <- pick_col(names(inc_raw), c("avg_income","median_household_income","median_income","mhi","hh_income",
                                      "income_pc","per_capita_income","pc_income","income"))
    if (!is.na(id) && !is.na(val)) {
      return(
        inc_raw %>%
          mutate(county_ihme = if (id=="county_ihme") std_fips(county_ihme) else std_fips(.data[[id]]),
                 income = suppressWarnings(as.numeric(.data[[val]]))) %>%
          group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
          filter(is.finite(income))
      )
    }
  }
  # fallback: from cy if present
  ccol <- intersect(c("avg_income","median_household_income","median_income","mhi","hh_income",
                      "income_pc","per_capita_income","pc_income","income","acs_income"),
                    names(cy))[1]
  if (!is.na(ccol)) {
    return(
      cy %>% transmute(county_ihme, income = suppressWarnings(as.numeric(.data[[ccol]]))) %>%
        group_by(county_ihme) %>% summarise(income = median(income, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(income))
    )
  }
  NULL
}
get_income_quintiles <- function() {
  qcol <- intersect(c("inc_quint","income_quint","income_quintile"), names(cy))[1]
  if (!is.na(qcol)) {
    message("[INC] Using existing quintile from cy$", qcol)
    return(cy %>% distinct(county_ihme, .keep_all = TRUE) %>%
             transmute(county_ihme, inc_quint = factor(.data[[qcol]], levels = labs_quint)))
  }
  income_any <- get_income_any()
  if (is.null(income_any) || !nrow(income_any)) return(NULL)
  brks <- make_quintile_breaks(income_any$income)
  income_any %>%
    mutate(inc_quint = cut(income, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
    transmute(county_ihme, inc_quint = factor(inc_quint, levels = labs_quint))
}

inc_q <- get_income_quintiles()
p_inc <- NULL
if (!is.null(inc_q) && nrow(inc_q)) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n=dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))

  p_inc <- ggplot(ts_inc, aes(period, mean_direction, group = inc_quint, colour = inc_quint)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2) +
    labs(title = "Aggregate data quality by income quintile",
         x = NULL, y = "Aggregate data quality (z)", colour = "Income quintile") +
    theme_bw(base_size = 12)

  print(p_inc)
  out_path <- here("figures","validation_zscore","direction_by_income_quintile.png")
  ggsave(out_path, p_inc, width = 9, height = 5.2, dpi = 320)
  message("[INC] Saved: ", out_path, "  (n rows=", nrow(ts_inc), ")")
} else {
  message("[INC] Panel skipped: could not derive income quintiles.")
}

# =================================================================
# Combined 3-panel (if at least two exist)
# =================================================================
panel_list <- list(
  "Reporting type"   = if (exists("p_rep") && inherits(p_rep, "gg")) p_rep else NULL,
  "PH spend quintile"= if (exists("p_ph")  && inherits(p_ph,  "gg")) p_ph  else NULL,
  "Income quintile"  = if (exists("p_inc") && inherits(p_inc, "gg")) p_inc else NULL
)
panel_list <- panel_list[ vapply(panel_list, inherits, logical(1), "gg") ]

if (length(panel_list) >= 2) {
  if (requireNamespace("patchwork", quietly = TRUE)) {
    p_all <- patchwork::wrap_plots(unname(panel_list), nrow = 1, guides = "collect") &
      theme(legend.position = "bottom")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel.")
  } else if (requireNamespace("cowplot", quietly = TRUE)) {
    p_all <- cowplot::plot_grid(plotlist = unname(panel_list), nrow = 1, align = "h")
    print(p_all)
    ggsave(here("figures","validation_zscore","direction_timeseries_3panel.png"),
           p_all, width = 16, height = 5.6, dpi = 320)
    message("[ALL] Saved combined 3-panel (cowplot).")
  } else {
    message("[ALL] Combined 3-panel skipped (patchwork/cowplot not available).")
  }
} else {
  message("[ALL] Not enough panels to create the combined summary; individual panels were saved.")
}

# ──────────────────────────────────────────────────────────────
# Compact 2-row table for the paper:
# Columns: Per capita public health spending | Reporting type | Income quintile
# Rows:    1999–2005, 2020–2022
# Saves → output/validation_zscore/aggregate_index_table_2periods.csv
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(stringr); library(readr); library(here) })

out_dir_csv <- here::here("output","validation_zscore")
dir.create(out_dir_csv, recursive = TRUE, showWarnings = FALSE)

# ensure helpers from earlier exist
`%||%` <- function(a,b) if (!is.null(a)) a else b
labs_quint <- exists("labs_quint") %||% FALSE
if (identical(labs_quint, FALSE)) labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Recompute dir_cp (county × period aggregate index) if missing
if (!exists("dir_cp")) {
  stopifnot(exists("cy4"))
  period_levels2 <- c("1999_2005","2006_2012","2013_2019","2020_2022")
  dir_cp <- cy4 %>%
    filter(!is.na(period), period %in% period_levels2) %>%
    group_by(county_ihme, period) %>%
    summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop") %>%
    mutate(period = factor(period, levels = period_levels2))
}

# (Re)build PH spend quintiles if needed
if (!exists("ph_q")) {
  make_quintile_breaks <- function(v) {
    v <- v[is.finite(v)]
    stopifnot(length(v) > 0)
    qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
    for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
    qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
  }
  # derive from cy4 if needed
  if (!exists("ph_q")) {
    cand <- intersect(c("ph_pc","ph_per_capita","phspend_pc","ph_spend_pc","public_health_spend_pc","ph_pc_usd","ph_percap"),
                      names(cy4))
    if (length(cand)) {
      ph_any <- cy4 %>% transmute(county_ihme, ph_pc = suppressWarnings(as.numeric(.data[[cand[1]]]))) %>%
        group_by(county_ihme) %>% summarise(ph_pc = median(ph_pc, na.rm=TRUE), .groups="drop") %>%
        filter(is.finite(ph_pc))
      if (nrow(ph_any)) {
        brks <- make_quintile_breaks(ph_any$ph_pc)
        ph_q <- ph_any %>%
          mutate(ph_quint = cut(ph_pc, breaks = brks, labels = labs_quint, include.lowest = TRUE)) %>%
          transmute(county_ihme, ph_quint = factor(ph_quint, levels = labs_quint))
      }
    }
  }
}

# Recompute PH / Reporting / Income summaries if missing
if (!exists("ts_ph") && exists("ph_q")) {
  ts_ph <- dir_cp %>%
    inner_join(ph_q, by = "county_ihme") %>%
    group_by(period, ph_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(ph_quint = factor(ph_quint, levels = labs_quint))
}
if (!exists("ts_reporting") && exists("rep_lookup")) {
  ts_reporting <- dir_cp %>%
    inner_join(rep_lookup, by = "county_ihme") %>%
    group_by(period, reporting_type) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop")
}
if (!exists("ts_inc") && exists("inc_q")) {
  ts_inc <- dir_cp %>%
    inner_join(inc_q, by = "county_ihme") %>%
    group_by(period, inc_quint) %>%
    summarise(mean_direction = mean(direction_score, na.rm=TRUE), n = dplyr::n(), .groups="drop") %>%
    mutate(inc_quint = factor(inc_quint, levels = labs_quint))
}

# ------- formatting helpers (period-scoped “label: value” strings) -------
fmt_pairs <- function(df, period_key, group_col, value_col = "mean_direction", levels = NULL, digits = 2, label_map = NULL) {
  if (is.null(df) || !nrow(df)) return(NA_character_)
  d <- df %>% filter(as.character(period) == period_key)
  if (!is.null(levels)) {
    d[[group_col]] <- factor(d[[group_col]], levels = levels)
    d <- d %>% arrange(.data[[group_col]])
  }
  if (!is.null(label_map)) {
    labs <- label_map(as.character(d[[group_col]]))
  } else {
    labs <- as.character(d[[group_col]])
  }
  vals <- round(d[[value_col]], digits = digits)
  # keep N if present
  if ("n" %in% names(d)) {
    paste0(labs, ": ", vals, " (n=", d$n, ")") %>% paste(collapse = "; ")
  } else {
    paste0(labs, ": ", vals) %>% paste(collapse = "; ")
  }
}

# Labels/order for reporting types
rt_levels <- c("Coroner","Other County Official","Mixed","Medical Examiner")
rt_label_map <- function(x) x  # already pretty

# Build the 2-row table
period_keep <- c("1999_2005","2020_2022")
period_label <- function(p) dplyr::recode(p, `1999_2005`="1999–2005", `2020_2022`="2020–2022", .default = p)

tbl_rows <- lapply(period_keep, function(pk) {
  tibble::tibble(
    Period = period_label(pk),
    `Per capita public health spending` =
      fmt_pairs(ts_ph %||% tibble(), pk, "ph_quint", levels = labs_quint),
    `Reporting type` =
      fmt_pairs(ts_reporting %||% tibble(), pk, "reporting_type", levels = rt_levels, label_map = rt_label_map),
    `Income quintile` =
      fmt_pairs(ts_inc %||% tibble(), pk, "inc_quint", levels = labs_quint)
  )
})
table_2rows <- dplyr::bind_rows(tbl_rows)

# Save CSV
out_csv <- file.path(out_dir_csv, "aggregate_index_table_2periods.csv")
readr::write_csv(table_2rows, out_csv)
message("[CSV] Saved compact 2-row table to: ", out_csv)

# (Optional) print to console
print(table_2rows)

```
Correlation between the 4 metrics
```{r}
# ──────────────────────────────────────────────────────────────
# PRINT-ONLY CORRELATIONS (no CSVs)
#   Metrics: z_prop_overd_unspec, z_philips_cstd, z_RI_cluster, z_prop_garbage
#   Levels: overall; by reporting type (if rep_lookup);
#           by PH-spend quintile (if ph_q); by income quintile (if inc_q)
#   Notes:
#     • Weighted = death-weighted (sum_n_cert) at cluster×period
#     • Also prints unweighted
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(tibble)
})

options(pillar.max_cols = Inf)  # show all columns

# ---- Inputs expected from earlier chunks ----
stopifnot(exists("z_tbl"), exists("cluster_core"), exists("membership"), exists("cy"))

# ---- Select z-variables & weights at cluster×period ----
zvars <- c("z_prop_overd_unspec","z_philips_cstd","z_RI_cluster","z_prop_garbage")
present_z <- intersect(zvars, names(z_tbl))
if (length(present_z) != length(zvars)) {
  stop("Missing z-variables in z_tbl: ", paste(setdiff(zvars, present_z), collapse = ", "))
}

z_cluster <- z_tbl %>%
  select(period, cluster, all_of(zvars)) %>%
  inner_join(cluster_core %>% select(period, cluster, sum_n_cert),
             by = c("period","cluster")) %>%
  filter(if_all(all_of(zvars), ~ is.finite(.x)),
         is.finite(sum_n_cert) & sum_n_cert > 0)

# ---- Correlation helpers ----
weighted_cor_mat <- function(df, vars, wcol = NULL, method = c("pearson","spearman")) {
  method <- match.arg(method)
  X <- df %>% dplyr::select(dplyr::all_of(vars))
  w <- if (!is.null(wcol) && wcol %in% names(df)) df[[wcol]] else NULL

  # listwise complete rows; handle weights safely
  if (is.null(w)) keep <- stats::complete.cases(X) else keep <- stats::complete.cases(X) & is.finite(w) & w > 0
  if (!length(keep)) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = 0))
  }

  X <- as.matrix(X[keep, , drop = FALSE])
  w <- if (is.null(w)) NULL else as.numeric(w[keep])
  n_used <- nrow(X)
  if (n_used < 3) {
    R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars), dimnames = list(vars, vars))
    return(list(cor = R, n = n_used))
  }

  if (method == "spearman") X <- apply(X, 2, rank, ties.method = "average")

  if (is.null(w)) {
    C <- stats::cov(X)
  } else {
    w <- w / sum(w)
    C <- stats::cov.wt(X, wt = w, method = "ML")$cov
  }

  s <- sqrt(diag(C)); s[!is.finite(s) | s == 0] <- NA_real_
  R <- C / (s %o% s)
  dimnames(R) <- list(colnames(X), colnames(X))
  list(cor = R, n = n_used)
}

mat_to_tidy <- function(corlst, method, group_type, group_value, weighted, include_group = TRUE) {
  R <- corlst$cor; n_used <- corlst$n; vars <- colnames(R)
  if (is.null(vars)) vars <- zvars
  comb <- t(combn(vars, 2))
  out <- tibble(
    group_type = group_type,
    method     = method,
    weighted   = weighted,
    n_used     = n_used,
    var1       = comb[,1],
    var2       = comb[,2],
    correlation= mapply(function(a,b) R[a,b], comb[,1], comb[,2])
  )
  if (isTRUE(include_group)) {
    gv <- if (length(group_value)) as.character(group_value)[1] else NA_character_
    out <- out |> dplyr::mutate(group = gv, .before = method)
  }
  out
}

compute_all_methods <- function(df, label_type, label_val, wcol = NULL, include_group = TRUE) {
  dplyr::bind_rows(
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "pearson"),
                "pearson",  label_type, label_val, !is.null(wcol), include_group),
    mat_to_tidy(weighted_cor_mat(df, zvars, wcol = wcol, method = "spearman"),
                "spearman", label_type, label_val, !is.null(wcol), include_group)
  )
}

# Pretty printer (forces full width, shows key cols first)
pp <- function(x, title) {
  cat("\n", strrep("=", nchar(title)+4), "\n", "= ", title, " =\n",
      strrep("=", nchar(title)+4), "\n", sep = "")

  grpcol <- intersect(names(x),
                      c("reporting_type","ph_spend_quintile","income_quintile","group"))[1]
  x2 <- x %>%
    mutate(correlation = round(correlation, 3)) %>%
    arrange(desc(weighted), method, var1, var2)

  if (length(grpcol)) {
    x2 <- x2 %>% select(group_type, all_of(grpcol), method, weighted, n_used, var1, var2, correlation)
  } else {
    x2 <- x2 %>% select(group_type, method, weighted, n_used, var1, var2, correlation)
  }

  print(x2, n = Inf, width = Inf)
  invisible(NULL)
}

# ---- 1) OVERALL correlations (weighted & unweighted) ----
corr_overall <- bind_rows(
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = "sum_n_cert"),
  compute_all_methods(z_cluster, "overall", "All clusters", wcol = NULL)
)
pp(corr_overall, "Overall correlations (Pearson & Spearman; weighted & unweighted)")

# ---- 2) Build county weights for modal grouping at cluster×period ----
county_w <- cy %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(w = sum(n_cert, na.rm = TRUE), .groups = "drop") %>%
  mutate(w = ifelse(is.finite(w) & w > 0, w, 1))

modal_group <- function(lookup_df, value_col) {
  req_cols <- c("county_ihme", value_col)
  if (is.null(lookup_df) || !all(req_cols %in% names(lookup_df))) return(NULL)

  membership %>%
    left_join(lookup_df %>% select(county_ihme, !!rlang::sym(value_col)), by = "county_ihme") %>%
    left_join(county_w, by = c("county_ihme","period")) %>%
    filter(!is.na(.data[[value_col]])) %>%
    mutate(w = ifelse(is.finite(w) & w > 0, w, 1)) %>%
    group_by(period, cluster, .data[[value_col]]) %>%
    summarise(w = sum(w, na.rm = TRUE), .groups = "drop") %>%
    group_by(period, cluster) %>%
    slice_max(order_by = w, n = 1, with_ties = FALSE) %>%
    ungroup() %>%
    rename(group = !!rlang::sym(value_col))
}

# ---- 3a) By REPORTING TYPE (if available) ----
if (exists("rep_lookup") && is.data.frame(rep_lookup)) {
  cl_rep <- modal_group(rep_lookup %>% mutate(reporting_type = as.character(reporting_type)),
                        "reporting_type")
  if (!is.null(cl_rep) && nrow(cl_rep)) {
    corr_by_reporting <- bind_rows(
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_rep %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "reporting_type", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_reporting %>% rename(reporting_type = group),
       "By reporting type (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Reporting-type lookup present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Reporting-type lookup not found; skipping by-reporting correlations.\n")
}

# ---- 3b) By PH SPEND quintile (if available) ----
if (exists("ph_q") && is.data.frame(ph_q) && nrow(ph_q)) {
  cl_ph <- modal_group(ph_q %>% mutate(ph_quint = as.character(ph_quint)), "ph_quint")
  if (!is.null(cl_ph) && nrow(cl_ph)) {
    corr_by_ph <- bind_rows(
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_ph %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "ph_spend_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_ph %>% rename(ph_spend_quintile = group),
       "By PH-spend quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] PH spend quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] PH spend quintiles not available; skipping.\n")
}

# ---- 3c) By INCOME quintile (if available) ----
if (exists("inc_q") && is.data.frame(inc_q) && nrow(inc_q)) {
  cl_inc <- modal_group(inc_q %>% mutate(inc_quint = as.character(inc_quint)), "inc_quint")
  if (!is.null(cl_inc) && nrow(cl_inc)) {
    corr_by_inc <- bind_rows(
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = "sum_n_cert", include_group = FALSE)) %>%
        ungroup(),
      cl_inc %>%
        inner_join(z_cluster, by = c("period","cluster")) %>%
        group_by(group) %>%
        group_modify(~ compute_all_methods(.x, "income_quintile", .y$group[[1]], wcol = NULL, include_group = FALSE)) %>%
        ungroup()
    ) %>% relocate(group, .before = method)
    pp(corr_by_inc %>% rename(income_quintile = group),
       "By income quintile (Pearson & Spearman; weighted & unweighted)")
  } else {
    cat("\n[CORR] Income quintiles present but no modal groups could be formed.\n")
  }
} else {
  cat("\n[CORR] Income quintiles not available; skipping.\n")
}

```
Scores by reporting type and public health spending for diversity metrics
```{r}
# ──────────────────────────────────────────────────────────────
# Phillips detail metrics vs reporting type & PH spend — FINAL+
# (period normalization, de-dup membership, robust fin-year snapping)
# + One time series per metric with 5 lines for PH-spend quintiles
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(tidyr); library(stringr)
  library(purrr); library(ggplot2); library(scales); library(here)
})

dir.create(here("figures","phillips_detail"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)

# ---- helpers --------------------------------------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

norm_period <- function(x) {
  # normalize "1999–2005", "1999-2005", "1999 — 2005", etc. → "1999_2005"
  x <- gsub("\u2013|\u2014|—|-", "_", x)  # en/em dash/hyphen → underscore
  x <- gsub("\\s+", "", x)                # drop spaces
  re <- regmatches(x, gregexpr("\\d{4}", x))
  out <- mapply(function(lbl, yrs) {
    if (length(yrs) >= 2) {
      y1 <- min(as.integer(yrs[1]), as.integer(yrs[2]))
      y2 <- max(as.integer(yrs[1]), as.integer(yrs[2]))
      paste0(y1, "_", y2)
    } else lbl
  }, x, re, USE.NAMES = FALSE)
  out
}

get_years <- function(s) as.integer(stringr::str_extract_all(s, "\\d{4}")[[1]])
parse_period <- function(lbl) {
  yrs <- get_years(lbl)
  if (length(yrs) >= 2) {
    y1 <- min(yrs[1], yrs[2]); y2 <- max(yrs[1], yrs[2]); mid <- floor((y1 + y2)/2)
    tibble(period = lbl, start = y1, end = y2, mid = mid)
  } else tibble(period = lbl, start = NA_integer_, end = NA_integer_, mid = NA_integer_)
}
nearest_fin_year <- function(y, avail) if (!length(avail) || is.na(y)) NA_integer_ else avail[which.min(abs(avail - y))]

# ---- load cluster metrics + membership -----------------------
metrics_file_candidates <- c(
  here("output","cluster_metrics_ucr39_cstd.csv.gz"),
  here("output","cluster_metrics.csv.gz"),
  "output/cluster_metrics_ucr39_cstd.csv.gz",
  "output/cluster_metrics.csv.gz",
  "cluster_metrics_ucr39_cstd.csv.gz",
  "cluster_metrics.csv.gz"
)
membership_file_candidates <- c(
  here("output","county_cluster_membership.csv.gz"),
  "output/county_cluster_membership.csv.gz",
  "county_cluster_membership.csv.gz"
)
metrics_file    <- metrics_file_candidates[file.exists(metrics_file_candidates)][1]
membership_file <- membership_file_candidates[file.exists(membership_file_candidates)][1]
stopifnot(!is.na(metrics_file), !is.na(membership_file))

metrics <- readr::read_csv(metrics_file, show_col_types = FALSE) %>%
  mutate(cluster = as.character(cluster),
         period  = norm_period(as.character(period)))

membership <- readr::read_csv(membership_file, show_col_types = FALSE) %>%
  mutate(cluster     = as.character(cluster),
         period      = norm_period(as.character(period)),
         county_ihme = std_fips(if ("fips" %in% names(.)) fips else if ("GEOID" %in% names(.)) GEOID else fips)) %>%
  filter(grepl("^[0-9]{5}$", county_ihme)) %>%
  distinct(cluster, period, county_ihme, .keep_all = FALSE)    # one row per key

# ---- pick 4 Phillips metrics ---------------------------------
num_cols <- names(metrics)[vapply(metrics, is.numeric, logical(1))]
preferred <- c(
  "detail_mcod_root3_cstd","detail_mcod_icd4_cstd","detail_ucod_root3_cstd","detail_ucod_icd4_cstd",
  "detail_d95","detail_d2000","detail_2000","detail_ref2000",
  "cod_diversity_cstd","cod_diversity_std","cod_diversity",
  "neff_cause","richness_cause","richness_cstd","neff_cstd"
)
present_pref <- intersect(preferred, num_cols)
if (length(present_pref) < 4) {
  extra <- setdiff(num_cols, present_pref)
  cand  <- extra[grepl("detail|divers|rich|neff|d95", extra, ignore.case = TRUE)]
  present_pref <- unique(c(present_pref, cand))
}
detail_cols <- unique(present_pref)[1:min(4, length(unique(present_pref)))]
stopifnot(length(detail_cols) > 0)
message("Using Phillips detail metrics: ", paste(detail_cols, collapse = " | "))

# ---- diagnostics: period coverage BEFORE expansion -----------
cat("\n# Period counts (metrics):\n")
print(metrics %>% count(period, name = "clusters_in_metrics") %>% arrange(period))
cat("\n# Period counts (membership):\n")
print(membership %>% count(period, name = "counties_in_membership") %>% arrange(period))

# ---- expand cluster→county -----------------------------------
detail_long <- metrics %>%
  select(cluster, period, all_of(detail_cols)) %>%
  pivot_longer(cols = all_of(detail_cols), names_to = "metric", values_to = "value") %>%
  inner_join(membership %>% select(cluster, period, county_ihme),
             by = c("cluster","period"),
             relationship = "many-to-many") %>%
  filter(is.finite(value))

cat("\n# After expansion: rows by period & metric\n")
print(detail_long %>% count(period, metric, name = "rows") %>% arrange(metric, period))

# ---- reporting-type lookup (or build) ------------------------
if (!exists("rep_lu")) {
  reporting_path_opts <- c(
    here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    "/mnt/data/County-Death-Investigation-System-2018-1-9-2024.csv"
  )
  reporting_path <- reporting_path_opts[file.exists(reporting_path_opts)][1]
  stopifnot(!is.na(reporting_path))
  rep_raw <- readr::read_csv(reporting_path, show_col_types = FALSE)
  get_colname <- function(df, patterns) {
    nm <- names(df)
    hits <- which(Reduce(`|`, lapply(patterns, function(p) grepl(p, nm, ignore.case = TRUE))))
    if (!length(hits)) return(NA_character_) else nm[hits[1]]
  }
  fips_col <- get_colname(rep_raw, c("^fips$","^fips_?code$","geoid","county_?fips","countyrs","fips.*5"))
  type_col <- get_colname(rep_raw, c("reporting.*type","investigation.*type","death.*investigation.*system","^type$","system"))
  stopifnot(!is.na(fips_col), !is.na(type_col))
  rep_lu <- rep_raw %>%
    mutate(county_ihme = std_fips(.data[[fips_col]]),
           reporting_type = trimws(as.character(.data[[type_col]]))) %>%
    filter(grepl("^[0-9]{5}$", county_ihme), !is.na(reporting_type), reporting_type != "") %>%
    mutate(reporting_type = dplyr::recode(tolower(reporting_type),
      "medical examiner"="Medical Examiner","me"="Medical Examiner",
      "coroner"="Coroner","mixed"="Mixed","hybrid"="Mixed",
      .default = stringr::str_to_title(reporting_type))) %>%
    select(county_ihme, reporting_type) %>% distinct()
}
cat("\n# Reporting-type coverage (distinct counties):\n")
print(rep_lu %>% count(reporting_type) %>% mutate(total = sum(n)))

# ---- finance-year snapping (+ fallback) — ROBUST --------------
# Make sure fin_year is integer for joins; be tolerant if fin_all missing
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")

# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))

# Main PH-per-period using nearest AVAILABLE finance year
ph_period_main <- period_info %>%
  dplyr::select(period, fin_year) %>%
  dplyr::inner_join(
    ph_pc %>% dplyr::select(county_ihme, fin_year, ph_pc),
    by = "fin_year", relationship = "many-to-many"
  ) %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6))) %>%
  dplyr::select(county_ihme, period, ph_pc, log_ph_pc)

# Fallback (periods without a mapped fin_year row will use county median spend)
ph_any <- ph_pc %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(ph_pc, na.rm = TRUE), .groups = "drop") %>%
  dplyr::mutate(log_ph_pc = log10(pmax(ph_pc, 1e-6)))

need_fallback <- setdiff(period_info$period, unique(ph_period_main$period))
ph_period_fb <- if (length(need_fallback)) {
  tidyr::crossing(county_ihme = unique(membership$county_ihme), period = need_fallback) %>%
    dplyr::left_join(ph_any, by = "county_ihme")
} else tibble(county_ihme = character(), period = character(), ph_pc = numeric(), log_ph_pc = numeric())

ph_period <- dplyr::bind_rows(ph_period_main, ph_period_fb)

cat("\n# Period→finance-year map (forced to available years)\n")
print(period_info %>% dplyr::mutate(fin_year = as.character(fin_year)))
cat("\n# PH spend rows by period (should be large)\n")
print(ph_period %>% dplyr::count(period, name = "rows") %>% dplyr::arrange(period))
cat("\n# ph_pc rows by fin_year\n")
print(ph_pc %>% dplyr::count(fin_year, name = "rows") %>% dplyr::arrange(fin_year))

# ---- A) Means by reporting type across periods ----------------
detail_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, reporting_type, metric) %>%
  summarise(avg_value = mean(value, na.rm = TRUE),
            n = dplyr::n(), .groups = "drop") %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)]))

if (nrow(detail_rep) > 0) {
  g_detail_rep <- ggplot(detail_rep, aes(period_ord, avg_value, group = reporting_type, colour = reporting_type)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, scales = "free_y", ncol = 2) +
    labs(title = "Phillips detail metrics by reporting type (cluster→county, period means)",
         x = NULL, y = "Mean value", colour = "Reporting type") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_by_reporting_type_timeseries.png"),
         g_detail_rep, width = 9, height = 6.5, dpi = 300)
  print(g_detail_rep)
} else {
  message("No rows for reporting-type timeseries — skipping the plot.")
}

# ---- B) R²: metric ~ reporting_type (per period) --------------
r2_rep <- detail_long %>%
  left_join(rep_lu, by = "county_ihme") %>%
  filter(!is.na(reporting_type)) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || n_distinct(d$reporting_type) < 2) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ reporting_type, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ reporting_type (by period)\n")
print(r2_rep %>% arrange(metric, period))

# ---- C) R²: metric ~ log10(PH spend) (per period) -------------
r2_spend <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  group_by(period, metric) %>%
  group_modify(\(d, key) {
    nn <- nrow(d)
    if (nn < 50 || !any(is.finite(d$log_ph_pc))) return(tibble(r2 = NA_real_, n = nn))
    tibble(r2 = summary(lm(value ~ log_ph_pc, data = d))$r.squared, n = nn)
  }) %>% ungroup()

cat("\nR²: Phillips metric ~ log10(PH spend per capita) (by period)\n")
print(r2_spend %>% arrange(metric, period))

# ---- D) Scatter (guarded) ------------------------------------
scatter_sample <- detail_long %>%
  inner_join(ph_period, by = c("county_ihme","period")) %>%
  left_join(period_info %>% select(period, start), by = "period") %>%
  mutate(period_ord = factor(period, levels = period_info$period[order(period_info$start)])) %>%
  filter(is.finite(value), is.finite(log_ph_pc))

if (nrow(scatter_sample) > 0) {
  g_detail_spend <- ggplot(scatter_sample, aes(log_ph_pc, value)) +
    geom_point(alpha = 0.35, size = 1) +
    geom_smooth(method = "lm", se = FALSE, linewidth = 0.8) +
    facet_grid(metric ~ period_ord, scales = "free_y") +
    labs(title = "Phillips detail metrics vs log10(PH spend per capita)",
         x = "log10(PH spend per capita)", y = "Metric value") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_vs_ph_spend_scatter.png"),
         g_detail_spend, width = 12, height = 7.5, dpi = 300)
  print(g_detail_spend)
} else {
  message("No rows for spend vs metrics scatter — skipping the plot.")
}

# ---- E) NEW: Time series with multiple lines for PH-spend quintiles ----
# Quintiles computed GLOBALLY from each county's median PH spend (ph_any),
# so periods with sparse PH coverage still get full quintile lines.
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")

# Build monotone breaks even if there are ties
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]
  stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  # enforce strictly increasing breaks
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9
  qs[length(qs)] <- max(v) + 1e-9
  qs
}

quint_breaks <- make_quintile_breaks(ph_any$ph_pc)

county_quintile <- ph_any %>%
  mutate(spend_quintile = cut(ph_pc, breaks = quint_breaks, include.lowest = TRUE,
                              right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_quintile)

period_levels <- period_info$period[order(period_info$start)]

detail_with_quint <- detail_long %>%
  left_join(county_quintile, by = "county_ihme") %>%
  filter(!is.na(spend_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

# Summarize mean metric per period × quintile
ts_quint <- detail_with_quint %>%
  group_by(metric, period_ord, spend_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = dplyr::n(), .groups = "drop")

cat("\n# Rows per period × quintile (any metric):\n")
print(
  detail_with_quint %>%
    count(period_ord, spend_quintile, name = "rows") %>%
    tidyr::complete(period_ord = period_levels, spend_quintile = labs_quint, fill = list(rows = 0)) %>%
    arrange(period_ord, spend_quintile)
)

# Plot (guarded)
if (nrow(ts_quint) > 0) {
  g_quint <- ggplot(ts_quint,
                    aes(x = period_ord, y = avg_value,
                        group = spend_quintile, colour = spend_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(
      title = "Phillips detail metrics over time by public-health spend quintile",
      x = NULL, y = "Mean metric value", colour = "PH spend (per-capita) quintile"
    ) +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_spend_quintile.png"),
         g_quint, width = 10, height = 6.5, dpi = 300)
  print(g_quint)
} else {
  message("No rows for time-series-by-quintile — skipping the plot.")
}

# ---- F) Correlations with direction score (by period) ---------
assign_period <- function(y, info) {
  with(info, {
    p <- period[y >= start & y <= end]
    ifelse(length(p) >= 1, p[1], NA_character_)
  })
}
stopifnot(exists("direction_year"))
direction_period <- direction_year %>%
  mutate(period = vapply(year, assign_period, character(1), info = period_info)) %>%
  filter(!is.na(period)) %>%
  group_by(county_ihme, period) %>%
  summarise(direction_score = mean(direction_score, na.rm = TRUE), .groups = "drop")

detail_wide <- detail_long %>%
  select(county_ihme, period, metric, value) %>%
  distinct() %>%
  pivot_wider(names_from = metric, values_from = value)

corr_tbl <- direction_period %>%
  inner_join(detail_wide, by = c("county_ihme","period"))

cols_metrics <- setdiff(names(detail_wide), c("county_ihme","period"))
corr_out <- map_dfr(split(corr_tbl, corr_tbl$period), function(dd) {
  tibble(
    period = unique(dd$period),
    metric = cols_metrics,
    pearson_r = map_dbl(cols_metrics, ~ suppressWarnings(
      cor(dd$direction_score, dd[[.x]], use = "pairwise.complete.obs")
    )),
    n = nrow(dd)
  )
})
readr::write_csv(corr_out, here("output","correlation_direction_vs_phillips_by_period.csv"))
cat("\nSaved correlations to: ", here("output","correlation_direction_vs_phillips_by_period.csv"), "\n")
print(corr_out %>% arrange(metric, period))
```
Check by income
```{r}
ph_pc   <- ph_pc   %>% mutate(fin_year = suppressWarnings(as.integer(fin_year)))
fin_all <- if (exists("fin_all")) fin_all else tibble()
if (nrow(fin_all)) {
  year_col <- dplyr::case_when(
    "fin_year" %in% names(fin_all) ~ "fin_year",
    "year_fin" %in% names(fin_all) ~ "year_fin",
    "year"     %in% names(fin_all) ~ "year",
    TRUE ~ NA_character_
  )
  if (!is.na(year_col)) {
    fin_all <- fin_all %>% mutate(fin_year = suppressWarnings(as.integer(.data[[year_col]])))
  }
}

# Derive actual finance years to snap to (prefer fin_all; fallback to ph_pc)
fin_years_actual <- c(
  if (nrow(fin_all) && "fin_year" %in% names(fin_all)) fin_all$fin_year,
  if ("fin_year" %in% names(ph_pc)) ph_pc$fin_year
) %>%
  suppressWarnings(as.integer(.)) %>%
  { .[is.finite(.)] } %>%
  unique() %>%
  sort()

if (!length(fin_years_actual)) {
  stop("No finance years available. Re-run the finance builder to create fin_all/ph_pc with fin_years (e.g., 2017, 2022).")
}
fin_years_actual <- unique(fin_years_actual)
cat("\n# Using finance years for snapping:", paste(fin_years_actual, collapse = ", "), "\n")
# Build period_info from periods present in detail_long
period_info <- unique(detail_long$period) %>% sort() %>%
  purrr::map_dfr(parse_period) %>%
  dplyr::filter(!is.na(start), !is.na(end), !is.na(mid)) %>%
  dplyr::arrange(start) %>%
  dplyr::mutate(fin_year = vapply(mid, nearest_fin_year, integer(1), avail = fin_years_actual))
# ---- G) Time series by INCOME quintiles ------------------------
safe_quintile <- function(x) {
  labs <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
  v <- x[is.finite(x)]
  if (length(v) < 5L || length(unique(v)) < 5L) {
    return(factor(rep(NA_character_, length(x)), levels = labs))
  }
  qs <- quantile(v, probs = seq(0, 1, 0.2), na.rm = TRUE, names = FALSE, type = 7)
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9
  cut(x, breaks = qs, include.lowest = TRUE, right = FALSE, labels = labs)
}

period_levels <- period_info$period[order(period_info$start)]

# Join detail with ACS income
detail_with_income <- detail_long %>%
  inner_join(income_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(avg_income)) %>%
  group_by(period) %>%
  mutate(income_quintile = safe_quintile(avg_income)) %>%
  ungroup() %>%
  filter(!is.na(income_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_income <- detail_with_income %>%
  group_by(metric, period_ord, income_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_income) > 0) {
  g_income <- ggplot(ts_income,
                     aes(x = period_ord, y = avg_value,
                         group = income_quintile, colour = income_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by INCOME quintile",
         x = NULL, y = "Mean metric value", colour = "Income quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_income_quintile.png"),
         g_income, width = 10, height = 6.5, dpi = 300)
  print(g_income)
} else {
  message("Income quintile time-series empty after guards — skipping.")
}


# ---- H) Time series by BA+ quintiles ---------------------------
detail_with_ba <- detail_long %>%
  inner_join(ba_all %>% rename(fin_year = acs_year), by = "county_ihme") %>%
  inner_join(period_info %>% select(period, fin_year), by = "period") %>%
  filter(is.finite(value), is.finite(ba_share)) %>%
  group_by(period) %>%
  mutate(ba_quintile = safe_quintile(ba_share)) %>%
  ungroup() %>%
  filter(!is.na(ba_quintile)) %>%
  mutate(period_ord = factor(period, levels = period_levels))

ts_ba <- detail_with_ba %>%
  group_by(metric, period_ord, ba_quintile) %>%
  summarise(avg_value = mean(value, na.rm = TRUE), n = n(), .groups = "drop")

if (nrow(ts_ba) > 0) {
  g_ba <- ggplot(ts_ba,
                 aes(x = period_ord, y = avg_value,
                     group = ba_quintile, colour = ba_quintile)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    facet_wrap(~ metric, ncol = 2, scales = "free_y") +
    labs(title = "Phillips detail metrics over time by BA+ share quintile",
         x = NULL, y = "Mean metric value", colour = "BA+ quintile") +
    theme_bw()
  ggsave(here("figures","phillips_detail","detail_timeseries_by_ba_quintile.png"),
         g_ba, width = 10, height = 6.5, dpi = 300)
  print(g_ba)
} else {
  message("BA+ quintile time-series empty after guards — skipping.")
}

```
Pre-requisites
```{r}
# ---------- prerequisites ----------
if (!exists("prop_garbage_col") || !exists("overd_col")) {
  stop("Run the preamble that defines prop_garbage_col/overd_col and builds detail_year.")
}

# ---------- population weighting (robust & non-crashy) ----------
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) {
  as.character(pop_col)
} else NA_character_
pop_col_ok <- is.character(pop_col_name) && !is.na(pop_col_name)
message(if (pop_col_ok) paste0("Population weighting ON (", pop_col_name, ").")
        else "Population weighting OFF.")

# ---------- build base_sel (1999–2022), drop dummy FIPS ----------
base_sel <- cy %>%
  dplyr::mutate(
    county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0"),
    pg  = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    od  = suppressWarnings(as.numeric(.data[[overd_col]])),
    # create 'pop' ONLY if a population column is available; else NA
    pop = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  dplyr::filter(
    year >= 1999, year <= 2022,
    county_ihme != "00000", county_ihme != "0000"
  )

# ---------- temporally stable, safe weighted mean ----------
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(w))) return(mean(xx, na.rm = TRUE))
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
wmaybe <- function(x, w) if (pop_col_ok) safe_wmean(x, w) else mean(x, na.rm = TRUE)

# ---------- per-county temporally stable averages ----------
county_avg <- base_sel %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(
    prop_garbage = wmaybe(pg, pop),       # uses weights if present; else unweighted mean
    overd_unspec = wmaybe(od, pop),
    pop_wt       = if (pop_col_ok) mean(pop, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# ---------- detail averages from prebuilt detail_year ----------
detail_avg <- detail_year %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")

# PH spend quintiles (stable across finance years)
ph_any <- ph_pc %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000") %>%
  dplyr::group_by(county_ihme) %>%
  dplyr::summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  dplyr::filter(is.finite(ph_pc))

# Income quintiles (already pooled over time in your function)
income_quint <- income_quint %>%
  dplyr::mutate(county_ihme = stringr::str_pad(as.character(county_ihme), 5, pad = "0")) %>%
  dplyr::filter(county_ihme != "00000", county_ihme != "0000")


```
Validation: 4 metrics by public health spending
```{r}
# Validation: 4 metrics by public health spending (table output, unspecified overdoses removed/adjusted)
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(scales)
  library(here);  library(readr); library(stringr)
})

dir.create(here("figures","ph_spend_relationship"), recursive = TRUE, showWarnings = FALSE)

# ---------- helpers (as before) ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b

find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}

period_to_midyear <- function(p) {
  p <- as.character(p)
  m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}

safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (missing(w) || is.null(w) || all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("ph_pc"))     # needs cy (county-year), ph_pc (finance)
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# Detect metric columns
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) {
  stop("Need columns in `cy`: prop_garbage (auto-detected) AND pct_overd_miss.")
}
ri_label <- "Reassignability Index (RI)"
have_ri  <- !is.na(ri_col)

# Population weights (prefer explicit pop_col; else fall back to n_cert if present)
pop_col_name <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(pop_col_name)) pop_col_name <- if ("population" %in% names(cy)) "population" else NA_character_
weight_fallback <- NA_character_
if (is.na(pop_col_name)) {
  if ("n_cert" %in% names(cy)) { pop_col_name <- "n_cert"; weight_fallback <- "n_cert" }
}
pop_col_ok <- !is.na(pop_col_name)
message(
  if (pop_col_ok && is.na(weight_fallback)) paste0("Population weighting ON (", pop_col_name, ").")
  else if (pop_col_ok && weight_fallback == "n_cert") "Weighting by n_cert (fallback)."
  else "Population weighting OFF (no weights found)."
)

# ---------- PH spend quintiles (stable per county) ----------
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000", county_ihme != "0000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>%
  mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE, right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# ---------- detail_year (bring ICD-4 detail to year) ----------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit   <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year   <- "year"   %in% names(detail_long)
  has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric found in `detail_long`.")
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>%
    filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>%
    filter(county_ihme != "00000", county_ihme != "0000") %>%
    distinct()
}

# ---------- Attempt to find unspecified-overdose column ----------
unspec_patterns <- c("unspec","unspecified","unclass","not[_ ]specified","notspecified")
unspec_overd_col <- NA_character_
for (pat in unspec_patterns) {
  # find any column name containing both the pat and overdose/overd/poison
  cand <- names(cy)[grepl(pat, tolower(names(cy))) & grepl("overd|overdose|poison|opiate|opioid", tolower(names(cy)))]
  if (length(cand)) { unspec_overd_col <- cand[1]; break }
}
# Also check for more general unspecified overdose-like names if above fails
if (is.na(unspec_overd_col)) {
  cand2 <- names(cy)[grepl("unspec|unspecified|unclass|not[_ ]specified", tolower(names(cy)))]
  # see if any of these also mention 'overd' elsewhere in another column to match by context (fallback)
  if (length(cand2)) unspec_overd_col <- cand2[1]
}

if (!is.na(unspec_overd_col)) {
  message("Detected unspecified-overdose column: ", unspec_overd_col)
} else {
  message("No unspecified-overdose column detected. pct_overd_miss will be used as-is.")
}

# ---------- assemble county-year series (with weights) ----------
base_sel <- cy %>%
  mutate(
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_,
    weight         = if (pop_col_ok) suppressWarnings(as.numeric(.data[[pop_col_name]])) else NA_real_
  ) %>%
  filter(year >= 1999, year <= 2022,
         county_ihme != "00000", county_ihme != "0000") %>%
  select(county_ihme, year, prop_garbage, pct_overd_miss, ri, weight, everything()) %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(spend_quint,  by = "county_ihme")

# ---------- create adjusted overdose metric with unspecified removed (if detected) ----------
if (!is.na(unspec_overd_col)) {
  # Extract unspecified column from base_sel if present
  # We allow the detected column to be either percent or counts; try to disambiguate.
  base_sel <- base_sel %>%
    mutate(unspecified_raw = suppressWarnings(as.numeric(.data[[unspec_overd_col]])))
  
  # If unspecified values look like counts (>1.5), try to convert to percent by dividing by n_cert (if available)
  if ("n_cert" %in% names(base_sel)) {
    # create unspecified_pct: if raw looks like counts (max>1.5), compute percent = 100 * raw / n_cert
    suspect_counts <- max(base_sel$unspecified_raw, na.rm = TRUE) > 1.5
    if (isTRUE(suspect_counts)) {
      message("Unspecified-overdose column appears to be counts; converting to percent using n_cert.")
      base_sel <- base_sel %>%
        mutate(unspecified_pct = ifelse(is.finite(unspecified_raw) & is.finite(n_cert) & n_cert > 0,
                                        100 * unspecified_raw / n_cert, NA_real_))
    } else {
      # treat as percent already
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    }
  } else {
    # no n_cert: if raw values appear to be percent (<= 100) assume percent; otherwise keep raw but warn
    suspect_counts <- max(base_sel$unspecified_raw, na.rm = TRUE) > 100
    if (isTRUE(suspect_counts)) {
      warning("Unspecified-overdose column looks like large counts but n_cert is unavailable; using raw values. Consider providing n_cert for correct conversion.")
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    } else {
      base_sel <- base_sel %>% mutate(unspecified_pct = unspecified_raw)
    }
  }
  # Now compute adjusted pct_overd_miss (remove unspecified_pct)
  base_sel <- base_sel %>%
    mutate(
      pct_overd_miss_orig = pct_overd_miss,
      pct_overd_miss_adj  = case_when(
        !is.finite(pct_overd_miss) ~ NA_real_,
        !is.finite(unspecified_pct) ~ pct_overd_miss,          # no unspecified info for that row
        TRUE ~ pmax(0, pct_overd_miss - unspecified_pct)       # subtract and clamp at 0
      )
    )
} else {
  # no unspecified column found: keep original and duplicate column
  base_sel <- base_sel %>%
    mutate(
      pct_overd_miss_orig = pct_overd_miss,
      pct_overd_miss_adj  = pct_overd_miss
    )
}

# ---------- aggregate to year × PH-spend quintile (WEIGHTED) ----------
ts_spend <- base_sel %>%
  group_by(year, spend_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss_orig = safe_wmean(pct_overd_miss_orig, weight),
    pct_overd_miss_adj  = safe_wmean(pct_overd_miss_adj,  weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(spend_q = factor(spend_q, levels = labs_quint)) %>%
  arrange(year, spend_q)

# ---------- output table (CSV + print top rows) ----------
out_file <- here("figures","ph_spend_relationship","metrics_by_phspend_timeseries_table.csv")
readr::write_csv(ts_spend, out_file)
message("Wrote table to: ", out_file)

# Print a compact preview to console
print(utils::head(ts_spend, 20))

# Also return ts_spend invisibly if running interactively
invisible(ts_spend)

```
Validation: 4 metrics by reporting type
```{r}
# ─────────────────────────────────────────────────────────────
# Plot: reporting type vs. level of detail (UCOD, ICD-4)
# ─────────────────────────────────────────────────────────────
suppressPackageStartupMessages({ library(ggplot2); library(dplyr); library(scales); library(here) })

out_dir <- get0("out_dir", ifnotfound = here("figures","reporting_type_timeseries"))
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

if (!exists("agg_by_rt") || !("mean_detail_icd4" %in% names(agg_by_rt))) {
  stop("`agg_by_rt` with `mean_detail_icd4` not found. Run the aggregation block first.")
}

w_lab <- ifelse(exists("w_col") && !is.na(w_col), w_col, "UNWEIGHTED")

plot_df <- agg_by_rt %>%
  select(year, reporting_type, mean_detail_icd4) %>%
  filter(!is.na(mean_detail_icd4))

# Colors to match the example; includes 'Mixed' as a neutral tone if present
pal <- c(
  "Coroner"               = "#ef5350",
  "Other County Official" = "#43a047",
  "Medical Examiner"      = "#42a5f5",
  "Mixed"                 = "#8d6e63"
)
# keep only colors for types present
pal <- pal[names(pal) %in% unique(as.character(plot_df$reporting_type))]

p_detail_by_rt <- ggplot(plot_df,
                         aes(x = year, y = mean_detail_icd4,
                             color = reporting_type, group = reporting_type)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = pal, name = "Reporting type") +
  scale_x_continuous(breaks = pretty_breaks(6)) +
  labs(
    title = "Phillips detail (UCOD, ICD-4)",
    subtitle = paste0("Weighted by ", w_lab, " · County means by reporting type (1999–2022)"),
    x = NULL, y = "Mean value"
  ) +
  theme_minimal(base_size = 13) +
  theme(panel.grid.minor = element_blank(),
        legend.position = "right")

ggsave(file.path(out_dir, "detail_icd4_by_reporting_timeseries.png"),
       p_detail_by_rt, width = 10, height = 6, dpi = 150)

p_detail_by_rt

```
Validation: 4 metrics by income
```{r}
# ──────────────────────────────────────────────────────────────
# Metrics by INCOME — weighted everywhere (incl. RI)
#   A) x = income quintile; lines = PH-spend quintiles
#      • County-level metric averaged across years USING WEIGHTS
#      • Group means weighted by county SUM of weights across years
#   B) Time series: x = year; lines = income quintiles
#      • Weighted by year-specific weights
# Weights: pop_col > population > n_cert (fallback)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2); library(scales)
  library(readr); library(stringr); library(here); library(patchwork)
})

dir.create(here("figures","income_relationship"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("figures","income_timeseries"),   recursive = TRUE, showWarnings = FALSE)

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !is.na(a)) a else b
find_col <- function(df, patterns) {
  nms <- names(df); hit <- NULL
  for (pat in patterns) { m <- nms[grepl(pat, tolower(nms))]; if (length(m)) { hit <- m[1]; break } }
  hit %||% NA_character_
}
period_to_midyear <- function(p) {
  p <- as.character(p); m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
  if (is.na(m[1,1])) return(NA_integer_)
  s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
  as.integer(round((s + e)/2))
}
safe_wmean <- function(x, w) {
  xx <- ifelse(is.finite(x), x, NA_real_)
  ww <- ifelse(is.finite(w), w, NA_real_)
  if (all(is.na(xx))) return(NA_real_)
  if (all(is.na(ww)) || sum(ww, na.rm = TRUE) <= 0) return(mean(xx, na.rm = TRUE))
  sum(xx * ww, na.rm = TRUE) / sum(ww, na.rm = TRUE)
}
labs_quint <- c("Q1 lowest","Q2","Q3","Q4","Q5 highest")
make_quintile_breaks <- function(v) {
  v <- v[is.finite(v)]; stopifnot(length(v) > 0)
  qs <- quantile(v, probs = seq(0,1,0.2), na.rm = TRUE, names = FALSE, type = 7)
  for (i in 2:length(qs)) if (qs[i] <= qs[i-1]) qs[i] <- qs[i-1] + .Machine$double.eps
  qs[1] <- min(v) - 1e-9; qs[length(qs)] <- max(v) + 1e-9; qs
}
ri_label <- "Re-assignability Index (RI)"

# ---------- prerequisites ----------
stopifnot(exists("cy"), exists("detail_long"), exists("ph_pc"))
cy <- cy %>% mutate(county_ihme = std_fips(county_ihme))

# metrics
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_]?garbage\\b","garbage[_]?share","frac[_]?garbage",
        "dq_rec_ig_frac_mean_garbage","foreman[_]?garbage","\\bgarbage\\b")
)
overd_col <- if ("pct_overd_miss" %in% names(cy)) "pct_overd_miss" else NA_character_
ri_col    <- "RI_post_only"
if (is.na(prop_garbage_col) || is.na(overd_col)) stop("Need prop_garbage + pct_overd_miss in `cy`.")
have_ri <- !is.na(ri_col)

# weights (pop_col > population > n_cert)
w_col <- if (exists("pop_col") && !is.na(pop_col) && pop_col %in% names(cy)) as.character(pop_col) else NA_character_
if (is.na(w_col) && "population" %in% names(cy)) w_col <- "population"
if (is.na(w_col) && "n_cert"     %in% names(cy)) w_col <- "n_cert"
w_label <- ifelse(!is.na(w_col), w_col, "UNWEIGHTED")
message("Weighting by: ", w_label)

# income quintiles (county-level, stable)
get_income_quintiles <- function(cy_df) {
  income_candidates <- c("median_household_income","median_income","mhi","hh_income",
                         "income_pc","per_capita_income","pc_income","income")
  inc_col <- income_candidates[income_candidates %in% names(cy_df)][1]
  if (!is.na(inc_col)) {
    inc_any <- cy_df %>%
      transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
      group_by(county_ihme) %>% summarise(income = median(income_val, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(income))
  } else {
    if (!requireNamespace("tidycensus", quietly = TRUE)) stop("No income in `cy` and {tidycensus} not installed.")
    inc_acs <- tidycensus::get_acs(geography = "county", variables = "B19013_001",
                                   year = 2022, survey = "acs5", cache_table = TRUE, show_call = FALSE)
    inc_any <- inc_acs %>% transmute(county_ihme = std_fips(GEOID), income = as.numeric(estimate)) %>%
      filter(is.finite(income), county_ihme != "00000")
  }
  qb_inc <- make_quintile_breaks(inc_any$income)
  inc_any %>% mutate(income_q = cut(income, breaks = qb_inc, include.lowest = TRUE,
                                    right = FALSE, labels = labs_quint)) %>%
    transmute(county_ihme, income_q)
}
income_quint <- get_income_quintiles(cy)

# PH-spend quintiles (for panel A line colour)
ph_any <- ph_pc %>%
  mutate(county_ihme = std_fips(county_ihme)) %>%
  filter(county_ihme != "00000") %>%
  group_by(county_ihme) %>%
  summarise(ph_pc = median(suppressWarnings(as.numeric(ph_pc)), na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(ph_pc))
qb_spend <- make_quintile_breaks(ph_any$ph_pc)
spend_quint <- ph_any %>% mutate(spend_q = cut(ph_pc, breaks = qb_spend, include.lowest = TRUE,
                                               right = FALSE, labels = labs_quint)) %>%
  select(county_ihme, spend_q)

# detail_year (to year)
if (!exists("detail_year")) {
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))
  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1]
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)
  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]]))
    )
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% dplyr::filter(grepl(icd4_pat, tolower(metric)))
    if (!nrow(dl)) stop("No UCOD ICD-4 detail metric in `detail_long`.")
    detail_year <- dl %>% transmute(
      county_ihme, year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
      detail_icd4 = suppressWarnings(as.numeric(value))
    ) %>% group_by(county_ihme, year) %>% summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
  detail_year <- detail_year %>% filter(is.finite(year), is.finite(detail_icd4)) %>%
    mutate(year = as.integer(year)) %>% filter(county_ihme != "00000") %>% distinct()
}

# ---------- weights per county-year ----------
w_df <- cy %>%
  transmute(county_ihme, year,
            weight = if (!is.na(w_col)) suppressWarnings(as.numeric(.data[[w_col]])) else NA_real_) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-year series (with weights) ----------
base_sel <- cy %>%
  transmute(
    county_ihme = std_fips(county_ihme), year,
    prop_garbage   = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    pct_overd_miss = suppressWarnings(as.numeric(.data[[overd_col]])),
    ri             = if (have_ri) suppressWarnings(as.numeric(.data[[ri_col]])) else NA_real_
  ) %>%
  left_join(w_df, by = c("county_ihme","year")) %>%
  filter(year >= 1999, year <= 2022)

# ---------- county-level STABLE averages (weighted across years) ----------
county_avg <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  group_by(county_ihme) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    wt_sum         = sum(weight, na.rm = TRUE),
    .groups = "drop"
  )

# ============================================================
# A) Metrics vs INCOME quintile (x = income_q; lines = PH-spend quintiles)
#     Group means weighted by county wt_sum
# ============================================================
comb_A <- county_avg %>%
  inner_join(income_quint, by = "county_ihme") %>%
  inner_join(spend_quint,  by = "county_ihme")

metrics_cols_A <- intersect(c("prop_garbage","detail_icd4","ri"), names(comb_A))

by_q_income_x <- comb_A %>%
  pivot_longer(cols = all_of(metrics_cols_A), names_to = "metric", values_to = "value") %>%
  group_by(metric, income_q, spend_q) %>%
  summarise(mean_value = safe_wmean(value, wt_sum), n = dplyr::n(), .groups = "drop") %>%
  mutate(
    metric   = dplyr::recode(metric,
                  prop_garbage="Proportion garbage (UCOD)",
                  pct_overd_miss="Overdose % missing",
                  detail_icd4="Phillips detail (UCOD, ICD-4)",
                  ri=ri_label),
    income_q = factor(income_q, levels = labs_quint),
    spend_q  = factor(spend_q,  levels = labs_quint)
  )

plot_lines_income <- function(df, mname, title, file_out) {
  dd <- df %>% filter(metric == mname, is.finite(mean_value))
  if (!nrow(dd)) { message("Skipping (no data): ", mname); return(NULL) }
  p <- ggplot(dd, aes(x = income_q, y = mean_value, group = spend_q, colour = spend_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 2.2) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means (1999–2022) · Lines = PH-spend quintiles"),
      x = "Income quintile (median HH income)", y = "Mean metric", colour = "PH-spend quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_relationship", file_out), p, width = 8.8, height = 5.4, dpi = 320)
  p
}

pA_garb  <- plot_lines_income(by_q_income_x, "Proportion garbage (UCOD)", "Proportion garbage (UCOD)",       "prop_garbage_lines.png")
pA_overd <- plot_lines_income(by_q_income_x, "Overdose % missing",        "Overdose % missing",              "pct_overd_miss_lines.png")
pA_det   <- plot_lines_income(by_q_income_x, "Phillips detail (UCOD, ICD-4)", "Phillips detail (UCOD, ICD-4)", "detail_icd4_lines.png")
pA_ri    <- plot_lines_income(by_q_income_x, ri_label, ri_label, "ri_lines.png")

combined_A <- wrap_plots(pA_garb, pA_overd, pA_det, pA_ri, ncol = 1) + plot_layout(heights = rep(1,4))
ggsave(here("figures","income_relationship","metrics_vs_income_lines_4panel.png"),
       combined_A, width = 9.5, height = 16, dpi = 320)

# ============================================================
# B) Time series by INCOME quintile (x = year; lines = income quintiles)
#     Weighted by year-specific weights
# ============================================================
series_inc <- base_sel %>%
  left_join(detail_year, by = c("county_ihme","year")) %>%
  inner_join(income_quint, by = "county_ihme")

ts_income <- series_inc %>%
  group_by(year, income_q) %>%
  summarise(
    prop_garbage   = safe_wmean(prop_garbage,   weight),
    pct_overd_miss = safe_wmean(pct_overd_miss, weight),
    detail_icd4    = safe_wmean(detail_icd4,    weight),
    ri             = safe_wmean(ri,             weight),
    .groups = "drop"
  ) %>%
  mutate(income_q = factor(income_q, levels = labs_quint))

plot_metric_income_ts <- function(df, var, title, file_out) {
  dd <- df %>% filter(is.finite(.data[[var]]))
  if (!nrow(dd)) { message("Skipping (no data): ", var); return(NULL) }
  p <- ggplot(dd, aes(x = year, y = .data[[var]], colour = income_q)) +
    geom_line(linewidth = 1.2) + geom_point(size = 1.8) +
    scale_x_continuous(breaks = seq(2000, 2022, 2)) +
    labs(
      title = title,
      subtitle = paste0("Weighted by ", w_label, " · County means by income quintile (1999–2022)"),
      x = NULL, y = "Mean value", colour = "Income quintile"
    ) + theme_bw(base_size = 12)
  ggsave(here("figures","income_timeseries", file_out), p, width = 8.8, height = 5.2, dpi = 320)
  p
}

pB1 <- plot_metric_income_ts(ts_income, "prop_garbage",   "Proportion garbage (UCOD)",      "prop_garbage_by_income_timeseries.png")
pB3 <- plot_metric_income_ts(ts_income, "detail_icd4",    "Phillips detail (UCOD, ICD-4)",  "detail_icd4_by_income_timeseries.png")
pB4 <- plot_metric_income_ts(ts_income, "ri",             ri_label,                          "ri_by_income_timeseries.png")

combined_B <- wrap_plots(pB1, pB3, pB4, ncol = 1) + plot_layout(heights = rep(1,3))
ggsave(here("figures","income_timeseries","metrics_by_income_timeseries_4panel.png"),
       combined_B, width = 9.5, height = 16, dpi = 320)

pA_garb; pA_det; pA_ri; pB1; pB2; pB3; pB4

```
Validation: 4 metrics by excess COVID-19 deaths
```{r}
# Validation: 4 metrics by excess COVID-19 deaths (with LOD-by-cluster)
# ──────────────────────────────────────────────────────────────
# Builds in memory: est, pop_by_county, counts_by_county,
#                   metrics_by_county(garbage, ri, detail_icd4),
#                   county_avg, check_df (+ agg_index)
# Writes:           output/excess_percap_by_county.csv
# Correlations:     metrics vs relExcDeathsMean  (PRIMARY)
# ──────────────────────────────────────────────────────────────
suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(tidyr); library(here)
  options(dplyr.summarise.inform = FALSE)
})

# ---------- helpers ----------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")
safe_num <- function(x) suppressWarnings(as.numeric(x))
first_existing <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }
first_col_val <- function(df, candidates) { nm <- intersect(candidates, names(df)); if (length(nm)) df[[nm[1]]] else NA }
z_std <- function(v) { m <- mean(v, na.rm=TRUE); s <- sd(v, na.rm=TRUE); if (!is.finite(s) || s==0) rep(NA_real_, length(v)) else (v-m)/s }
make_fips5 <- function(fips_code, state_fips=NULL){
  fc <- str_replace_all(as.character(fips_code), "[^0-9]", "")
  if (!is.null(state_fips) && !all(is.na(state_fips))) {
    sf <- str_pad(as.character(state_fips), 2, pad="0")
    ifelse(nchar(fc) >= 5, str_pad(substr(fc,1,5),5,pad="0"),
           paste0(sf, str_pad(substr(fc, pmax(1, nchar(fc)-2), nchar(fc)), 3, pad="0")))
  } else str_pad(substr(fc,1,5), 5, pad="0")
}
w_pearson <- function(x,y,w=NULL){
  ok <- is.finite(x) & is.finite(y); if (!is.null(w)) ok <- ok & is.finite(w) & w>0
  x<-x[ok]; y<-y[ok]; w <- if (is.null(w)) rep(1,length(x)) else w[ok]
  if (length(x) < 3) return(c(r=NA_real_, p=NA_real_, lo=NA_real_, hi=NA_real_))
  wx <- sum(w*x)/sum(w); wy <- sum(w*y)/sum(w); xc <- x-wx; yc <- y-wy
  r <- (sum(w*xc*yc)/sum(w)) / sqrt((sum(w*xc^2)/sum(w))*(sum(w*yc^2)/sum(w)))
  n_eff <- (sum(w)^2)/sum(w^2); df <- max(1, n_eff-2)
  if (!is.finite(r) || abs(r)>=1 || !is.finite(df) || df<=0) return(c(r=r,p=NA,lo=NA,hi=NA))
  t <- r*sqrt(df/(1-r^2)); p <- 2*pt(-abs(t), df); z <- atanh(r); se <- 1/sqrt(max(4, n_eff-3))
  c(r=r, p=p, lo=tanh(z-1.96*se), hi=tanh(z+1.96*se))
}

# ---------- optional county-year (for metrics & weights) ----------
cy <- if (exists("cy") && is.data.frame(cy)) cy else {
  fp <- first_existing(c(here("data","county_year_quality_metrics.csv"),
                         here("data","county_year_quality_metrics.csv.gz")))
  if (!is.na(fp)) { message("Reading cy: ", fp); suppressMessages(readr::read_csv(fp, show_col_types = FALSE)) } else NULL
}
if (!is.null(cy)) {
  if ("county_ihme" %in% names(cy)) cy$county_ihme <- std_fips(cy$county_ihme)
  if (!"county_ihme" %in% names(cy) && "fips" %in% names(cy)) cy$county_ihme <- std_fips(cy$fips)
}

# ---------- load estimatesMonthly & build county_ihme ----------
read_estimates_monthly <- function(path){
  df <- suppressMessages(readr::read_csv(path, show_col_types = FALSE, progress = FALSE))
  if (ncol(df) == 1) df <- suppressMessages(readr::read_tsv(path, show_col_types = FALSE, progress = FALSE))
  df
}
est_path <- first_existing(c(here("data_raw","estimatesMonthly.csv"), "data_raw/estimatesMonthly.csv"))
stopifnot(!is.na(est_path))
raw_est <- read_estimates_monthly(est_path)

# Require relExcDeathsMean explicitly (as requested)
need <- c("year","month","FIPSCode","COVIDDeathsUCD","excDeathsMed","relExcDeathsMean")
miss <- setdiff(need, names(raw_est))
if (length(miss)) stop("Missing in estimatesMonthly.csv: ", paste(miss, collapse=", "))

raw_est <- raw_est %>% mutate(
  county_ihme = make_fips5(first_col_val(., c("FIPSCode","FIPS","fips","GEOID","geoid")),
                           if ("stateFIPS" %in% names(.)) .$stateFIPS else NULL)
)

est <- raw_est %>%
  transmute(
    county_ihme = county_ihme,
    year        = as.integer(year),
    month       = as.integer(month),
    excDeaths   = safe_num(excDeathsMed),
    COVIDDeaths = safe_num(COVIDDeathsUCD),
    relExc      = safe_num(relExcDeathsMean)  # <-- primary outcome (relative excess)
  )

# ---------- population (prefer cy → else ACS fallback) ----------
pop_by_county <- NULL
if (!is.null(cy)) {
  pop_col_cy <- names(cy)[tolower(names(cy)) %in% c("population","pop","pop_total","pop_estimate")][1]
  if (!is.na(pop_col_cy)) {
    pop_by_county <- cy %>%
      filter(!is.na(county_ihme)) %>%
      transmute(county_ihme = std_fips(county_ihme), pop = safe_num(.data[[pop_col_cy]])) %>%
      group_by(county_ihme) %>% summarise(pop = mean(pop, na.rm = TRUE), .groups = "drop") %>%
      filter(is.finite(pop))
  }
}
if (is.null(pop_by_county) || nrow(pop_by_county) == 0) {
  if (!requireNamespace("tidycensus", quietly = TRUE)) {
    stop("No population in `cy` and {tidycensus} not installed. Install tidycensus (set API key) or add a pop column to cy.")
  }
  message("Building pop_join from ACS (B01001_001, ACS5) …")
  suppressPackageStartupMessages(library(tidycensus))
  pop_by_county <- tidycensus::get_acs(
    geography = "county", variables = "B01001_001", year = 2017,
    survey = "acs5", geometry = FALSE, cache_table = TRUE
  ) %>% transmute(county_ihme = std_fips(GEOID), pop = as.numeric(estimate))
}
stopifnot(nrow(pop_by_county) > 0)

# ---------- excess window + county averages ----------
est_sub <- est %>% mutate(ym = year*100L + month) %>% filter(ym >= 202003L, ym <= 202208L)
counts_by_county <- est_sub %>%
  group_by(county_ihme) %>%
  summarise(
    exc_avg      = mean(excDeaths, na.rm = TRUE),
    covid_avg    = mean(COVIDDeaths, na.rm = TRUE),
    rel_exc_mean = mean(relExc,    na.rm = TRUE),   # <-- primary outcome
    .groups = "drop"
  )

# =================================================================
# LEVEL OF DETAIL (LOD) BY CLUSTER → map to counties
# =================================================================
pick_lod_period <- function(avail) {
  pref <- c("2013_2019","2006_2012","1999_2005","2020_2022")
  hit <- pref[pref %in% avail]; if (length(hit)) hit[1] else avail[1]
}
load_lod_cluster_metrics <- function() {
  metrics_path <- first_existing(c(
    here("output","cluster_metrics_ucr39_cstd.csv.gz"),
    here("output","cluster_metrics_ucr39_cstd.csv")
  ))
  if (is.na(metrics_path)) stop("Missing LOD metrics file (cluster_metrics_ucr39_cstd.*).")
  message("Reading LOD cluster metrics: ", metrics_path)
  met <- suppressMessages(readr::read_csv(metrics_path, show_col_types = FALSE))
  val_col <- intersect(c("detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4"), names(met))[1]
  if (is.na(val_col)) stop("No detail_* column found in LOD metrics file.")
  if (!all(c("cluster","period") %in% names(met))) stop("LOD metrics must have 'cluster' and 'period' columns.")
  met %>% transmute(cluster = as.character(cluster),
                    period  = as.character(period),
                    detail_icd4 = safe_num(.data[[val_col]]))
}
normalize_membership_lod <- function(df, target_period) {
  nms <- names(df); low <- tolower(nms)
  fips_col    <- nms[which(grepl("^(fips|geoid)$|^geoid|fips", low))[1]]
  cluster_col <- nms[which(grepl("^(cluster|group|cluster_id)$|cluster|group", low))[1]]
  period_col  <- nms[low == "period"]
  if (is.na(fips_col) || is.na(cluster_col)) stop("LOD membership needs FIPS & cluster/group column.")
  base <- df %>% transmute(county_ihme = std_fips(.data[[fips_col]]),
                           cluster     = as.character(.data[[cluster_col]])) %>% distinct()
  if (length(period_col)) {
    df %>% transmute(county_ihme = std_fips(.data[[fips_col]]),
                     cluster     = as.character(.data[[cluster_col]]),
                     period      = as.character(.data[[period_col]])) %>% distinct()
  } else {
    base %>% mutate(period = target_period)
  }
}
attach_lod_to_counties <- function(target_period = "2013_2019") {
  met <- load_lod_cluster_metrics()
  avail <- sort(unique(met$period))
  use_period <- pick_lod_period(avail)
  if (!identical(use_period, target_period))
    message("LOD target period ", target_period, " not found; using ", use_period, ".")
  met_use <- met %>% filter(period == use_period) %>% select(cluster, detail_icd4)

  membership_path <- first_existing(c(
    here("data","all_county_groupings.csv"),
    here("data","all_county_groupings.csv.gz"),
    here("output","county_cluster_membership.csv.gz"),
    here("output","county_cluster_membership.csv")
  ))
  if (is.na(membership_path)) stop("No county→cluster membership file found (looked for all_county_groupings.* or county_cluster_membership.*).")
  message("Reading LOD membership: ", membership_path)
  mem_raw  <- suppressMessages(readr::read_csv(membership_path, show_col_types = FALSE))
  mem_norm <- normalize_membership_lod(mem_raw, use_period) %>% filter(period == use_period)

  mem_norm %>% select(county_ihme, cluster) %>%
    distinct() %>%
    left_join(met_use, by = "cluster")
}

detail_by_county <- attach_lod_to_counties("2013_2019")
message("LOD rows mapped: ", nrow(detail_by_county), " (",
        sum(is.finite(detail_by_county$detail_icd4)), " with non-missing values).")

# ---------- metrics from cy (prop_garbage, ri averaged 2013–2019) ----------
metrics_by_county <- NULL
if (!is.null(cy)) {
  year_col <- names(cy)[tolower(names(cy)) %in% c("year","yr")][1]
  ri_col <- intersect(names(cy), c("RI_post_only"))[1]
  have_metrics <- c("prop_garbage", ri_col); have_metrics <- have_metrics[!is.na(have_metrics)]
  if (!is.na(year_col) && length(have_metrics) > 0) {
    metrics_by_county <- cy %>%
      mutate(year = as.integer(.data[[year_col]])) %>%
      filter(year %in% 2013:2019) %>%
      group_by(county_ihme) %>%
      summarise(across(all_of(have_metrics), ~ mean(safe_num(.), na.rm = TRUE)), .groups = "drop") %>%
      rename(ri = !!ri_col)
  }
}
if (is.null(metrics_by_county)) metrics_by_county <- tibble(county_ihme = character())

# add detail_icd4 (by cluster→county) to metrics_by_county
metrics_by_county <- metrics_by_county %>%
  full_join(detail_by_county %>% select(county_ihme, detail_icd4), by = "county_ihme")

# ---------- weights (certificates over 2013–2019; else population) ----------
county_avg <- {
  wt_tbl <- NULL
  if (!is.null(cy)) {
    ncert_col <- names(cy)[tolower(names(cy)) %in% c("n_cert","deaths","total","cert_count")][1]
    year_col  <- names(cy)[tolower(names(cy)) %in% c("year","yr")][1]
    if (!is.na(ncert_col) && !is.na(year_col)) {
      wt_tbl <- cy %>%
        transmute(county_ihme = std_fips(county_ihme),
                  year = as.integer(.data[[year_col]]),
                  n_cert = safe_num(.data[[ncert_col]])) %>%
        filter(is.finite(n_cert)) %>%
        mutate(use = ifelse(year %in% 2013:2019, 1L, 0L)) %>%
        group_by(county_ihme) %>%
        summarise(wt_sum = if (sum(use)>0) sum(n_cert[use==1], na.rm=TRUE) else sum(n_cert, na.rm=TRUE),
                  .groups = "drop")
    }
  }
  if (is.null(wt_tbl) || nrow(wt_tbl) == 0) wt_tbl <- pop_by_county %>% transmute(county_ihme, wt_sum = pop)
  wt_tbl %>% left_join(metrics_by_county, by = "county_ihme")
}

# ---------- per-capita outcomes & aggregate z-score ----------
check_df <- county_avg %>%
  full_join(counts_by_county, by = "county_ihme") %>%
  left_join(pop_by_county,     by = "county_ihme") %>%
  mutate(
    pop = ifelse(is.finite(pop) & pop > 0, pop, NA_real_),
    exc_per100k       = (exc_avg   / pop) * 1e5,
    covid_per100k     = (covid_avg / pop) * 1e5,
    nc_excess_per100k = ((exc_avg - covid_avg) / pop) * 1e5
  ) %>%
  mutate(
    z_garbage = z_std(-prop_garbage),  # lower is better
    z_detail  = z_std(detail_icd4),    # higher is better
    z_ri      = z_std(ri),             # higher is better
    n_comp    = rowSums(cbind(!is.na(z_garbage), !is.na(z_detail), !is.na(z_ri))),
    agg_index = ifelse(n_comp >= 2, rowMeans(cbind(z_garbage, z_detail, z_ri), na.rm = TRUE), NA_real_)
  ) %>%
  select(-n_comp)

# ---------- sanity print + export ----------
message("Rows with missing population will be omitted from per-capita checks.")
print(
  check_df %>%
    arrange(desc(wt_sum)) %>%
    select(county_ihme, wt_sum, pop, exc_avg, covid_avg, rel_exc_mean,
           exc_per100k, covid_per100k, nc_excess_per100k,
           prop_garbage, detail_icd4, ri, agg_index) %>%
    head(20),
  n = 20
)

dir.create(here("output"), showWarnings = FALSE, recursive = TRUE)
out_csv <- here("output","excess_percap_by_county.csv")
readr::write_csv(check_df, out_csv)
message("✓ Wrote: ", out_csv)

# ---------- correlations: metrics (incl aggregate) vs relExcDeathsMean (PRIMARY) ----------
metrics <- intersect(c("prop_garbage","detail_icd4","ri","agg_index"), names(check_df))
if (length(metrics) > 0) {
  out_list <- lapply(metrics, function(m) {
    dfm <- check_df %>% filter(is.finite(.data[[m]]), is.finite(rel_exc_mean))
    if (nrow(dfm) < 4) return(NULL)
    w_ok <- any(is.finite(dfm$wt_sum) & dfm$wt_sum > 0)

    # PRIMARY: correlation with relExcDeathsMean (averaged)
    corr_rel <- if (w_ok) w_pearson(dfm[[m]], dfm$rel_exc_mean, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$rel_exc_mean, NULL)

    # Optionally keep the others for reference
    corr_nc  <- if (w_ok) w_pearson(dfm[[m]], dfm$nc_excess_per100k, dfm$wt_sum) else w_pearson(dfm[[m]], dfm$nc_excess_per100k, NULL)
    corr_exc <- if (w_ok) w_pearson(dfm[[m]], dfm$exc_per100k,     dfm$wt_sum) else w_pearson(dfm[[m]], dfm$exc_per100k,     NULL)
    corr_cvd <- if (w_ok) w_pearson(dfm[[m]], dfm$covid_per100k,   dfm$wt_sum) else w_pearson(dfm[[m]], dfm$covid_per100k,   NULL)

    data.frame(
      metric = m,
      n_counties = nrow(dfm),
      # primary (relExcDeathsMean)
      cor_rel_r  = unname(corr_rel["r"]),  cor_rel_p  = unname(corr_rel["p"]),
      cor_rel_lo = unname(corr_rel["lo"]), cor_rel_hi = unname(corr_rel["hi"]),
      # optional extras
      cor_nc_r   = unname(corr_nc["r"]),
      cor_exc_r  = unname(corr_exc["r"]),
      cor_cvd_r  = unname(corr_cvd["r"])
    )
  }) %>% bind_rows()
  print(out_list)
} else {
  message("No metrics found to correlate.")
}

# --- read/augment estimatesMonthly with ratioMedUCD + excDeathsMean (per-capita) ---

# helper to read if not already present (reuses helpers from above: first_existing, read_estimates_monthly, make_fips5, safe_num)
if (!exists("raw_est")) {
  est_path <- first_existing(c(here("data_raw","estimatesMonthly.csv"), "data_raw/estimatesMonthly.csv"))
  stopifnot(!is.na(est_path))
  raw_est <- read_estimates_monthly(est_path)
  raw_est <- raw_est %>% mutate(
    county_ihme = make_fips5(
      first_existing(list(names(.)[match(TRUE, names(.) %in% c("FIPSCode","FIPS","fips","GEOID","geoid"))])),
      if ("stateFIPS" %in% names(.)) .$stateFIPS else NULL
    )
  )
}

need_core <- c("year","month","COVIDDeathsUCD","relExcDeathsMean")
miss_core <- setdiff(need_core, names(raw_est))
if (length(miss_core)) stop("Missing in estimatesMonthly.csv: ", paste(miss_core, collapse=", "))

has_excMed  <- "excDeathsMed"  %in% names(raw_est)
has_excMean <- "excDeathsMean" %in% names(raw_est)
has_ratio   <- "ratioMedUCD"   %in% names(raw_est)

est <- raw_est %>%
  transmute(
    county_ihme = county_ihme,
    year        = as.integer(year),
    month       = as.integer(month),
    COVIDDeaths = safe_num(COVIDDeathsUCD),
    relExc      = safe_num(relExcDeathsMean),
    excMed      = if (has_excMed)  safe_num(excDeathsMed)  else NA_real_,
    excMean     = if (has_excMean) safe_num(excDeathsMean) else NA_real_,
    ratioMedUCD = if (has_ratio)   safe_num(ratioMedUCD)   else NA_real_
  )

# Window: Mar 2020–Aug 2022
est_sub <- est %>%
  mutate(ym = year*100L + month) %>%
  filter(ym >= 202003L, ym <= 202208L)

# county-level averages in window
counts_by_county <- est_sub %>%
  group_by(county_ihme) %>%
  summarise(
    exc_avg              = if (has_excMed)  mean(excMed,  na.rm = TRUE) else NA_real_,
    covid_avg            = mean(COVIDDeaths, na.rm = TRUE),
    rel_exc_mean         = mean(relExc,      na.rm = TRUE),
    exc_mean_avg         = if (has_excMean) mean(excMean, na.rm = TRUE) else NA_real_,
    ratio_med_ucd_mean   = if (has_ratio)   mean(ratioMedUCD, na.rm = TRUE) else NA_real_,
    .groups = "drop"
  )

# join population + quality metrics and compute per-capita outcomes
check_df <- county_avg %>%
  full_join(counts_by_county, by = "county_ihme") %>%
  left_join(pop_by_county,     by = "county_ihme") %>%
  mutate(
    pop = ifelse(is.finite(pop) & pop > 0, pop, NA_real_),
    # per-capita (per 100k) outcomes
    exc_per100k        = if (has_excMed)  (exc_avg      / pop) * 1e5 else NA_real_,
    covid_per100k      =                     (covid_avg    / pop) * 1e5,
    nc_excess_per100k  = if (has_excMed)  ((exc_avg - covid_avg) / pop) * 1e5 else NA_real_,
    exc_mean_per100k   = if (has_excMean) (exc_mean_avg / pop) * 1e5 else NA_real_
  ) %>%
  # z-scores/aggregate index stay the same
  mutate(
    z_garbage = z_std(-prop_garbage),
    z_detail  = z_std(detail_icd4),
    z_ri      = z_std(ri),
    n_comp    = rowSums(cbind(!is.na(z_garbage), !is.na(z_detail), !is.na(z_ri))),
    agg_index = ifelse(n_comp >= 2, rowMeans(cbind(z_garbage, z_detail, z_ri), na.rm = TRUE), NA_real_)
  ) %>% select(-n_comp)

# (optional) quick peek
print(
  check_df %>% arrange(desc(wt_sum)) %>%
    select(county_ihme, wt_sum, pop,
           exc_avg, exc_mean_avg, covid_avg, rel_exc_mean,
           exc_per100k, exc_mean_per100k, covid_per100k, nc_excess_per100k,
           ratio_med_ucd_mean, prop_garbage, detail_icd4, ri, agg_index) %>% head(12),
  n = 12
)

# ---------------- correlations: add exc_mean_per100k and ratio_med_ucd_mean ----------------
metrics <- intersect(c("prop_garbage","detail_icd4","ri","agg_index"), names(check_df))

if (length(metrics) > 0) {
  out_list <- lapply(metrics, function(m) {
    dfm <- check_df %>% filter(is.finite(.data[[m]]), is.finite(rel_exc_mean))
    if (nrow(dfm) < 4) return(NULL)
    w_ok <- any(is.finite(dfm$wt_sum) & dfm$wt_sum > 0)

    w <- if (w_ok) dfm$wt_sum else NULL
    c_rel   <- w_pearson(dfm[[m]], dfm$rel_exc_mean,    w)   # primary
    c_nc    <- w_pearson(dfm[[m]], dfm$nc_excess_per100k, w)
    c_exc   <- w_pearson(dfm[[m]], dfm$exc_per100k,      w)  # using excDeathsMed per-capita (if present)
    c_cvd   <- w_pearson(dfm[[m]], dfm$covid_per100k,    w)
    c_excMn <- w_pearson(dfm[[m]], dfm$exc_mean_per100k, w)  # NEW: excDeathsMean per-capita
    c_ratio <- w_pearson(dfm[[m]], dfm$ratio_med_ucd_mean, w) # NEW: ratioMedUCD (dimensionless)

    data.frame(
      metric = m,
      n_counties = nrow(dfm),
      # primary
      cor_rel_r  = unname(c_rel["r"]),  cor_rel_p  = unname(c_rel["p"]),
      cor_rel_lo = unname(c_rel["lo"]), cor_rel_hi = unname(c_rel["hi"]),
      # extras
      cor_nc_r      = unname(c_nc["r"]),
      cor_exc_r     = unname(c_exc["r"]),
      cor_cvd_r     = unname(c_cvd["r"]),
      cor_excMean_r = unname(c_excMn["r"]),     # NEW
      cor_ratio_r   = unname(c_ratio["r"])      # NEW
    )
  }) %>% dplyr::bind_rows()
  print(out_list)
} else {
  message("No metrics found to correlate.")
}


```
Geographic variation number calculate (for main text)
```{r}
## ---- manuscript_support_summaries ------------------------------------------
library(dplyr)
library(tidyr)
library(rlang)

# Main data frame with county-year metrics
df <- cy_metrics
detail <- detail_cluster

gc_df <- cy_metrics %>%
  mutate(
    gc_pct = prop_garbage * 100,     # drop *100 if already in percent
    period = case_when(
      year >= 1999 & year <= 2005 ~ "1999-2005",
      year >= 2006 & year <= 2012 ~ "2006-2012",
      year >= 2013 & year <= 2019 ~ "2013-2019",
      year >= 2020 & year <= 2022 ~ "2020-2022",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(period))

## 1a. Year-by-year national means for Figure 1 (trend + COVID bump)
gc_yearly <- gc_df %>%
  group_by(year) %>%
  summarise(
    mean_gc_pct = mean(gc_pct, na.rm = TRUE),
    q25_gc_pct  = quantile(gc_pct, 0.25, na.rm = TRUE),
    q75_gc_pct  = quantile(gc_pct, 0.75, na.rm = TRUE),
    .groups = "drop"
  )

gc_yearly
# -> Use to describe the steady decline 1999–2019 and rise during COVID.

## 1b. Garbage-coded deaths by period (for “26% (24–29%) vs 33% (30–36%)”)
gc_period <- gc_df %>%
  group_by(period) %>%
  summarise(
    mean_gc_pct = mean(gc_pct, na.rm = TRUE),
    q25_gc_pct  = quantile(gc_pct, 0.25, na.rm = TRUE),
    q75_gc_pct  = quantile(gc_pct, 0.75, na.rm = TRUE),
    n           = sum(!is.na(gc_pct)),
    .groups = "drop"
  )

gc_period
# -> Read off 2013–2019 and 2020–2022 rows for the manuscript sentence.

## 1c. Geographic variation in the increase during COVID (county level)
# Assumed county ID column is `county_fips` – change if needed.
gc_change_by_county <- gc_df %>%
  filter(period %in% c("2013-2019", "2020-2022")) %>%
  group_by(county_ihme, period) %>%
  summarise(
    mean_gc_pct = mean(gc_pct, na.rm = TRUE),
    .groups = "drop_last"
  ) %>%
  pivot_wider(
    names_from  = period,
    values_from = mean_gc_pct
  ) %>%
  mutate(
    diff_2020_2022_vs_2013_2019 = `2020-2022` - `2013-2019`
  )

gc_change_summary <- gc_change_by_county %>%
  summarise(
    median_diff   = median(diff_2020_2022_vs_2013_2019, na.rm = TRUE),
    q25_diff      = quantile(diff_2020_2022_vs_2013_2019, 0.25, na.rm = TRUE),
    q75_diff      = quantile(diff_2020_2022_vs_2013_2019, 0.75, na.rm = TRUE),
    p10_diff      = quantile(diff_2020_2022_vs_2013_2019, 0.10, na.rm = TRUE),
    p90_diff      = quantile(diff_2020_2022_vs_2013_2019, 0.90, na.rm = TRUE),
    min_diff      = min(diff_2020_2022_vs_2013_2019, na.rm = TRUE),
    max_diff      = max(diff_2020_2022_vs_2013_2019, na.rm = TRUE),
    share_ge_10pp = mean(diff_2020_2022_vs_2013_2019 >= 10, na.rm = TRUE)
  )

gc_change_summary
# Example text this supports:
# “Across counties, the increase in the share of garbage-coded deaths
#  from 2013–2019 to 2020–2022 ranged from MIN to MAX percentage points
#  (10th–90th percentile P10 to P90), and SHARE_GE_10PP% of counties
#  experienced increases of ≥10 percentage points, indicating substantial
#  geographic variation in the impact of the pandemic on coding quality.”


### ---------------------------------------------------------------------------
### 2. DETAIL METRIC  (cluster-level data: detail_cluster)
### ---------------------------------------------------------------------------

# Assumed columns in detail_cluster:
#   - year
#   - cluster_id        : geographic cluster identifier
#   - detail            : detail / entropy metric
# If your columns differ, change the names in the mutate/rename below.


## 2a. Detail by period (means + IQRs for Figure 2 text)
detail_period <- detail_cluster %>%
  group_by(period) %>%
  summarise(
    mean_detail = mean(detail_ucod_icd4_cstd, na.rm = TRUE),
    q25_detail  = quantile(detail_ucod_icd4_cstd, 0.25, na.rm = TRUE),
    q75_detail  = quantile(detail_ucod_icd4_cstd, 0.75, na.rm = TRUE),
    iqr_detail  = q75_detail - q25_detail,
    .groups = "drop"
  )

detail_period

detail_change_by_cluster <- detail_cluster %>%
  filter(period %in% c("1999_2005", "2020_2022")) %>%
  group_by(cluster, period) %>%
  summarise(
    mean_detail = mean(detail, na.rm = TRUE),
    .groups = "drop_last"
  ) %>%
  pivot_wider(
    names_from  = period,
    values_from = mean_detail
  ) %>%
  mutate(
    diff_2020_2022_vs_1999_2005 = `2020_2022` - `1999_2005`
  )

detail_change_summary <- detail_change_by_cluster %>%
  summarise(
    median_diff = median(diff_2020_2022_vs_1999_2005, na.rm = TRUE),
    q25_diff    = quantile(diff_2020_2022_vs_1999_2005, 0.25, na.rm = TRUE),
    q75_diff    = quantile(diff_2020_2022_vs_1999_2005, 0.75, na.rm = TRUE),
    p10_diff    = quantile(diff_2020_2022_vs_1999_2005, 0.10, na.rm = TRUE),
    p90_diff    = quantile(diff_2020_2022_vs_1999_2005, 0.90, na.rm = TRUE),
    min_diff    = min(diff_2020_2022_vs_1999_2005, na.rm = TRUE),
    max_diff    = max(diff_2020_2022_vs_1999_2005, na.rm = TRUE)
  )

detail_change_summary
# Example “geographic variation” sentence this supports:
# “Improvements in detail were not uniform: cluster-level changes from
#  1999–2005 to 2020–2022 ranged from MIN to MAX (10th–90th percentile
#  P10 to P90), indicating that some regions saw much larger gains in
#  coding detail than others.”
```
NEW: Make plot of level of detail v.s. size to assess bias (DEC 22)
```{r}
# Sample-size sensitivity plot for Level-of-Detail (CSTD) metric
# - draws ONE large "national" sample from a chosen period (proxy population)
# - computes a reference ("truth") detail on that population draw
# - for each sample size n, takes B bootstrap-like subsamples (without replacement)
# - plots estimate (mean + 95% interval) and bias vs n
#
# Assumes your upstream objects already exist:
#   parquet_dir, county_var, UCR39_COL, garbage_root_set, threads, .clamp100, out_dir (or here())
# If not, this chunk is still mostly standalone: it re-loads needed libs and reconnects DuckDB.

suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(purrr); library(tibble)
  library(duckdb); library(DBI); library(glue)
  library(ggplot2); library(scales); library(here); library(fs)
})

# ---------------- user knobs ----------------
set.seed(1)

period_name <- "2020_2022"          # choose one: names(periods)
years_use   <- 2020:2022           # must match period_name (kept explicit for standalone use)
B           <- 1000L               # number of random subsamples per n
pop_draw_n  <- 200000L             # "proxy population" size drawn from national data for this period
sample_sizes <- c(200L, 500L, 1000L, 1500L, 2500L, 5000L, 10000L, 20000L)

# Output
out_dir_figs <- here("figures")
dir_create(out_dir_figs)

# ---------------- helpers ----------------
# Robust clean for ICD-10 strings inside DuckDB query:
# root3: first 3 alnum; icd4: first 4 alnum
# (We filter garbage by root3 using your garbage_root_set already.)
compute_detail_one_sample_icd4_cstd <- function(df_sample, std_ucr, us_within_icd4, maxH) {
  # df_sample columns: ucr39, icd4
  if (nrow(df_sample) == 0) return(NA_real_)

  # within-cause shares in sample
  w_k <- df_sample %>%
    count(ucr39, icd4, name = "n") %>%
    group_by(ucr39) %>%
    mutate(w = n / sum(n)) %>%
    ungroup()

  # expand over all (ucr39, icd4) pairs that exist nationally; fill missing with NA then fallback to w_us
  expanded <- us_within_icd4 %>%
    left_join(std_ucr, by = "ucr39") %>%                       # adds s (national cause weights)
    left_join(w_k, by = c("ucr39" = "ucr39", "icd4" = "icd4")) %>%
    mutate(w_eff = dplyr::coalesce(w, w_us))

  # aggregate within-cause to overall p*(icd4) using national cause weights s
  p_star <- expanded %>%
    group_by(icd4) %>%
    summarise(p = sum(s * w_eff, na.rm = TRUE), .groups = "drop")

  # entropy + scale to 0-100
  pp <- p_star$p
  pp <- pp / sum(pp, na.rm = TRUE)
  pp <- pp[is.finite(pp) & pp > 0]

  if (!length(pp) || is.na(maxH) || maxH <= 0) return(NA_real_)

  H <- -sum(pp * log(pp))
  .clamp100(100 * H / maxH)
}

# ---------------- pull a national "proxy population" draw ----------------
con <- dbConnect(duckdb::duckdb(), dbdir=":memory:")
on.exit(try(dbDisconnect(con, shutdown = TRUE), silent = TRUE), add = TRUE)
dbExecute(con, paste0("PRAGMA threads = ", max(1L, threads)))

# register garbage root3 set
duckdb::duckdb_register(con, "garbage", tibble(root3 = garbage_root_set))

# Create a temp table of valid (non-garbage) deaths for the selected years
yrs_range <- range(years_use)

dbExecute(con, glue("
  CREATE TEMP TABLE ucod_valid AS
  SELECT
    {UCR39_COL} AS ucr39,
    SUBSTR(UPPER(regexp_replace(ucod,'[^A-Za-z0-9]','')),1,3) AS root3,
    SUBSTR(UPPER(regexp_replace(ucod,'[^A-Za-z0-9]','')),1,4) AS icd4
  FROM parquet_scan('{normalizePath(parquet_dir, winslash = '/') }/*.parquet')
  WHERE year BETWEEN {yrs_range[1]} AND {yrs_range[2]}
    AND {UCR39_COL} IS NOT NULL
    AND ucod IS NOT NULL
"))

# Filter out garbage by root3
dbExecute(con, "
  CREATE TEMP TABLE ucod_valid_nongarbage AS
  SELECT ucr39, icd4
  FROM ucod_valid
  WHERE root3 NOT IN (SELECT root3 FROM garbage)
    AND icd4 IS NOT NULL
    AND LENGTH(icd4) = 4
")

n_available <- dbGetQuery(con, "SELECT COUNT(*) AS n FROM ucod_valid_nongarbage")$n
message("[", period_name, "] non-garbage UCOD rows available: ", format(n_available, big.mark=","))

pop_n_eff <- min(pop_draw_n, as.integer(n_available))
if (pop_n_eff < max(sample_sizes)) {
  warning("Proxy population draw (", pop_n_eff, ") is smaller than max(sample_sizes) (", max(sample_sizes), "). Truncating sample_sizes.")
  sample_sizes <- sample_sizes[sample_sizes <= pop_n_eff]
}

# Draw a large random subset once (cheap-ish) and do all resampling in-memory
message("Drawing proxy population of size ", format(pop_n_eff, big.mark=","), " ...")
pop_df <- dbGetQuery(con, glue("
  SELECT ucr39, icd4
  FROM ucod_valid_nongarbage
  USING SAMPLE {pop_n_eff}
")) %>% as_tibble()

# ---------------- compute national standardization pieces from proxy population ----------------
# national cause weights s = P(ucr39)
std_ucr <- pop_df %>%
  count(ucr39, name = "n") %>%
  mutate(s = n / sum(n)) %>%
  select(ucr39, s)

# national within-cause shares w_us = P(icd4 | ucr39)
us_within_icd4 <- pop_df %>%
  count(ucr39, icd4, name = "n") %>%
  group_by(ucr39) %>%
  mutate(w_us = n / sum(n)) %>%
  ungroup() %>%
  select(ucr39, icd4, w_us)

K_icd4 <- dplyr::n_distinct(us_within_icd4$icd4)
maxH_icd4 <- if (K_icd4 > 1) log(K_icd4) else NA_real_

# Reference ("truth") on full proxy population
ref_detail <- compute_detail_one_sample_icd4_cstd(pop_df, std_ucr, us_within_icd4, maxH_icd4)
message("Reference detail (proxy population): ", round(ref_detail, 2))

# ---------------- resampling experiment ----------------
# For each n, take B subsamples and compute detail
# (sampling without replacement within the proxy population; this isolates finite-sample effects cleanly)
res_df <- map_dfr(sample_sizes, function(n) {
  message("Resampling n = ", n, " (B = ", B, ") ...")
  est <- replicate(B, {
    idx <- sample.int(nrow(pop_df), size = n, replace = FALSE)
    compute_detail_one_sample_icd4_cstd(pop_df[idx, , drop=FALSE], std_ucr, us_within_icd4, maxH_icd4)
  })
  tibble(
    n = n,
    estimate = est,
    bias = est - ref_detail
  )
})

summ_df <- res_df %>%
  group_by(n) %>%
  summarise(
    ref_detail = ref_detail,
    mean_est   = mean(estimate, na.rm=TRUE),
    lo_est     = quantile(estimate, 0.025, na.rm=TRUE),
    hi_est     = quantile(estimate, 0.975, na.rm=TRUE),
    mean_bias  = mean(bias, na.rm=TRUE),
    lo_bias    = quantile(bias, 0.025, na.rm=TRUE),
    hi_bias    = quantile(bias, 0.975, na.rm=TRUE),
    .groups = "drop"
  )

# ---------------- plots ----------------
p_est <- ggplot(summ_df, aes(x = n, y = mean_est)) +
  geom_hline(aes(yintercept = ref_detail), linetype = "dashed") +
  geom_ribbon(aes(ymin = lo_est, ymax = hi_est), alpha = 0.2) +
  geom_line() +
  geom_point(size = 2) +
  scale_x_log10(labels = comma) +
  labs(
    x = "Sample size (log scale)",
    y = "Estimated level of detail (0–100)",
    title = paste0("Sample-size sensitivity of level of detail (", period_name, ")"),
    subtitle = paste0("Proxy population draw N = ", comma(pop_n_eff), "; dashed line = reference on proxy population")
  )

p_bias <- ggplot(summ_df, aes(x = n, y = mean_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_ribbon(aes(ymin = lo_bias, ymax = hi_bias), alpha = 0.2) +
  geom_line() +
  geom_point(size = 2) +
  scale_x_log10(labels = comma) +
  labs(
    x = "Sample size (log scale)",
    y = "Bias (estimate − reference)",
    title = paste0("Bias vs sample size (", period_name, ")"),
    subtitle = "Ribbon shows 2.5–97.5% across 1000 subsamples at each n"
  )

# Save
fn_est  <- file.path(out_dir_figs, paste0("detail_sensitivity_estimate_", period_name, ".png"))
fn_bias <- file.path(out_dir_figs, paste0("detail_sensitivity_bias_", period_name, ".png"))
ggsave(fn_est,  p_est,  width = 8.5, height = 5.2, dpi = 300)
ggsave(fn_bias, p_bias, width = 8.5, height = 5.2, dpi = 300)

print(p_est)
print(p_bias)

# Optional: save the summary table for appendix/debug
write_csv(summ_df, file.path(out_dir_figs, paste0("detail_sensitivity_summary_", period_name, ".csv")))

cat("\nSaved:\n- ", fn_est, "\n- ", fn_bias, "\n", sep="")
```
NEW: build covariates (run this before running next chunk)
```{r}
# ──────────────────────────────────────────────────────────────
# COVARIATES (FULL FIXED, COPY/PASTE)
# Builds everything you need downstream:
#   1) fin_all  : county_ihme × fin_year public-health expenditures (E32)
#   2) pop_join : county_ihme × fin_year population
#   3) ph_pc    : county_ihme × fin_year public-health spend per capita
#   4) income_all: county_ihme × acs_year median HH income (B19013_001)
#   5) ba_all    : county_ihme × acs_year BA+ share (DP02_0068PE)
# Also writes:
#   output/ph_pc.csv, output/income_all.csv, output/ba_all.csv
# ──────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr); library(here)
})

# ----------------------- helpers -----------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

pick_first <- function(paths) {
  p <- paths[file.exists(paths)]
  if (length(p)) p[1] else NA_character_
}

find_first <- function(fname) {
  pick_first(c(
    here("data_raw", "finance", fname),
    here("data_raw", fname),
    here("data", fname),
    fname
  ))
}

ensure_pkg <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) install.packages(pkg)
  invisible(TRUE)
}

# ----------------------- 1) Parse FinEstDAT fixed-width -----------------------
# Robust inference from RIGHT:
# [... govt_id (14)] [... item_code (3)] [... amount digits] [year(4)] [flag(1)]
parse_finest_fixed <- function(path) {
  stopifnot(file.exists(path))
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(tibble())

  year  <- suppressWarnings(as.integer(str_sub(lines, -5, -2)))
  flag  <- str_sub(lines, -1, -1)
  left1 <- str_sub(lines,  1, -6)

  m <- regexpr("(\\d+)\\s*$", left1, perl = TRUE)
  amt_str <- ifelse(m > 0, regmatches(left1, m), NA_character_)
  amount  <- suppressWarnings(as.numeric(amt_str))

  left2 <- ifelse(m > 0, substr(left1, 1, m - 1L), left1)
  left2 <- sub("\\s+$", "", left2)

  raw_item <- str_sub(left2, -3, -1)
  govt_id  <- str_sub(left2,  1, -4)

  item_code <- ifelse(grepl("^[A-Z][0-9]{2}$", raw_item, ignore.case = TRUE),
                      toupper(raw_item),
               ifelse(grepl("^[0-9]{2}[A-Z]$", raw_item, ignore.case = TRUE),
                      paste0(toupper(str_sub(raw_item, -1, -1)), str_sub(raw_item, 1, 2)),
                      toupper(raw_item)))

  tibble(
    govt_id   = govt_id,
    item_code = item_code,
    amount    = amount,
    year      = year,
    flag      = flag
  ) %>%
    filter(!is.na(amount), !is.na(year), nchar(govt_id) >= 10)
}

# ----------------------- 2) PID crosswalk (govt_id → county_ihme) -----------------------
# Extracts:
#   govt_id_raw = leading digits
#   code_99     = right-most token like 99### (e.g., 99003)
#   county_ihme = state_fips + last 3 digits of code_99
read_pid_xwalk <- function(path) {
  if (!file.exists(path)) return(NULL)
  lines <- readr::read_lines(path, progress = FALSE)
  lines <- lines[nzchar(lines)]
  if (!length(lines)) return(NULL)

  lead_digits <- function(x) sub("^([0-9]+).*$", "\\1", x)

  find_99_code <- function(x) {
    m <- gregexpr("\\b99\\d{3}\\b", x, perl = TRUE)
    if (m[[1]][1] == -1) return(NA_character_)
    ix <- tail(m[[1]], 1)
    ml <- attr(m[[1]], "match.length")
    substr(x, ix, ix + ml[length(ml)] - 1)
  }

  tib <- tibble(raw = lines) %>%
    mutate(
      govt_id_raw = lead_digits(raw),
      state_fips  = substr(govt_id_raw, 1, 2),
      code_99     = vapply(raw, find_99_code, character(1)),
      county_ihme = if_else(
        !is.na(code_99),
        paste0(state_fips, substr(code_99, 3, 5)),
        NA_character_
      )
    ) %>%
    filter(!is.na(county_ihme), nchar(county_ihme) == 5, nchar(govt_id_raw) >= 10) %>%
    transmute(
      govt_id    = govt_id_raw,
      county_ihme = std_fips(county_ihme)
    ) %>%
    distinct()

  if (!nrow(tib)) return(NULL)
  tib
}

# ----------------------- 3) Build fin_all (E32) -----------------------
fin2017_path <- find_first("2017FinEstDAT_09202024modp_pu.txt")
fin2022_path <- find_first("2022FinEstDAT_09202024modp_pu.txt")
pid2017_path <- find_first("Fin_PID_2017.txt")
pid2022_path <- find_first("Fin_PID_2022.txt")

fin_tbls <- list()
if (!is.na(fin2017_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2017_path)))
if (!is.na(fin2022_path)) fin_tbls <- append(fin_tbls, list(parse_finest_fixed(fin2022_path)))
stopifnot(length(fin_tbls) > 0)

fin_raw <- bind_rows(fin_tbls)

pid_xw <- bind_rows(list(
  read_pid_xwalk(pid2017_path),
  read_pid_xwalk(pid2022_path)
) |> purrr::compact()) %>% distinct()

if (!nrow(pid_xw)) {
  stop("PID crosswalk missing/empty. Provide Fin_PID_2017.txt / Fin_PID_2022.txt (or correct paths).")
}

fin_e32 <- fin_raw %>% filter(item_code == "E32")
if (!nrow(fin_e32)) {
  stop("Parsed finance files but found ZERO rows with item_code == 'E32'. ",
       "Print item_code counts to confirm the codebook.")
}

fin_all <- fin_e32 %>%
  left_join(pid_xw, by = "govt_id") %>%
  filter(!is.na(county_ihme)) %>%
  transmute(
    county_ihme   = std_fips(county_ihme),
    fin_year      = as.integer(year),
    ph_exp_total  = as.numeric(amount)
  ) %>%
  group_by(county_ihme, fin_year) %>%
  summarise(ph_exp_total = sum(ph_exp_total, na.rm = TRUE), .groups = "drop") %>%
  filter(is.finite(fin_year), is.finite(ph_exp_total))

message("[fin_all] rows: ", nrow(fin_all))
print(fin_all %>% count(fin_year, sort = TRUE))

# ----------------------- 4) Population (pop_join) + PH per-capita (ph_pc) -----------------------
as_county_ihme <- function(df) {
  nm <- names(df)
  id_col <- dplyr::case_when(
    "county_ihme" %in% nm ~ "county_ihme",
    "GEOID"       %in% nm ~ "GEOID",
    "fips"        %in% nm ~ "fips",
    "FIPS"        %in% nm ~ "FIPS",
    "countyrs"    %in% nm ~ "countyrs",
    TRUE ~ NA_character_
  )
  if (is.na(id_col)) stop("No county ID column found. Expect one of county_ihme/GEOID/fips/FIPS/countyrs.")
  df %>% mutate(county_ihme = std_fips(.data[[id_col]]))
}

build_pop_join <- function(fin_years) {
  fin_years <- sort(unique(stats::na.omit(as.integer(fin_years))))
  if (!length(fin_years)) stop("build_pop_join: fin_years empty")

  # reuse if already valid
  if (exists("pop_join", inherits = TRUE)) {
    pj <- get("pop_join", inherits = TRUE)
    if (is.data.frame(pj) && all(c("county_ihme","fin_year","pop") %in% names(pj))) return(pj)
  }

  # Try ACS via tidycensus
  if (ensure_pkg("tidycensus") && requireNamespace("tidycensus", quietly = TRUE)) {
    message("[pop_join] Building from ACS (B01001_001, acs5)…")
    out <- purrr::map_dfr(fin_years, function(y) {
      yy <- max(2009L, min(2023L, as.integer(y)))
      df <- tidycensus::get_acs(
        geography   = "county",
        variables   = "B01001_001",
        year        = yy,
        survey      = "acs5",
        cache_table = TRUE,
        geometry    = FALSE
      )
      tibble(
        county_ihme = std_fips(df$GEOID),
        fin_year    = as.integer(y),
        pop         = as.numeric(df$estimate)
      )
    })
    if (nrow(out)) return(out)
  }

  # Fallback (optional): pid_all if you have it
  if (exists("pid_all", inherits = TRUE)) {
    message("[pop_join] Falling back to pid_all…")
    pid <- get("pid_all", inherits = TRUE)
    stopifnot(all(c("county_ihme","year","pop") %in% names(pid)))
    return(pid %>% transmute(county_ihme = std_fips(county_ihme), fin_year = as.integer(year), pop = as.numeric(pop)))
  }

  stop("Could not build pop_join: tidycensus unavailable/failed and pid_all not found.")
}

fin_all <- as_county_ihme(fin_all)
avail_fin_years <- sort(unique(fin_all$fin_year))
pop_join <- build_pop_join(avail_fin_years)

ph_pc <- fin_all %>%
  left_join(pop_join, by = c("county_ihme","fin_year")) %>%
  mutate(
    pop  = suppressWarnings(as.numeric(pop)),
    ph_pc = ph_exp_total / pop
  ) %>%
  filter(is.finite(ph_pc), is.finite(fin_year), county_ihme != "00000", county_ihme != "0000") %>%
  select(county_ihme, fin_year, ph_exp_total, pop, ph_pc) %>%
  arrange(fin_year, county_ihme)

message("[ph_pc] rows: ", nrow(ph_pc))
print(ph_pc %>% count(fin_year, sort = TRUE))

# write for downstream scripts
dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)
readr::write_csv(ph_pc, here("output","ph_pc.csv"))

# ----------------------- 5) Income (income_all) -----------------------
# Median household income: ACS 5-year, B19013_001
acs_years <- sort(unique(avail_fin_years[is.finite(avail_fin_years) & avail_fin_years >= 2009L]))
if (!length(acs_years)) acs_years <- c(2017L, 2022L)

pull_income_tidycensus <- function(years) {
  purrr::map_dfr(years, function(y) {
    df <- tidycensus::get_acs(
      geography   = "county",
      variables   = "B19013_001",
      year        = y,
      survey      = "acs5",
      cache_table = TRUE,
      geometry    = FALSE
    )
    tibble(
      county_ihme = std_fips(df$GEOID),
      acs_year    = as.integer(y),
      avg_income  = suppressWarnings(as.numeric(df$estimate))
    )
  })
}

pull_income_censusapi <- function(years) {
  ensure_pkg("censusapi")
  purrr::map_dfr(years, function(y) {
    df <- censusapi::getCensus(
      name     = "acs/acs5",
      vintage  = y,
      vars     = c("NAME", "B19013_001E"),
      region   = "county:*",
      regionin = "state:*"
    )
    tibble(
      county_ihme = std_fips(paste0(df$state, df$county)),
      acs_year    = as.integer(y),
      avg_income  = suppressWarnings(as.numeric(df$B19013_001E))
    )
  })
}

income_all <- tryCatch(
  {
    if (ensure_pkg("tidycensus") && requireNamespace("tidycensus", quietly = TRUE)) {
      message("[income_all] Pulling via tidycensus…")
      pull_income_tidycensus(acs_years)
    } else {
      message("[income_all] Pulling via censusapi…")
      pull_income_censusapi(acs_years)
    }
  },
  error = function(e) {
    message("[income_all] tidycensus failed; trying censusapi…\n", conditionMessage(e))
    pull_income_censusapi(acs_years)
  }
) %>%
  mutate(
    county_ihme = std_fips(county_ihme),
    acs_year    = as.integer(acs_year),
    avg_income  = as.numeric(avg_income)
  ) %>%
  filter(is.finite(avg_income), county_ihme != "00000", county_ihme != "0000") %>%
  arrange(acs_year, county_ihme)

message("[income_all] years: ", paste(unique(income_all$acs_year), collapse = ", "),
        " | rows: ", nrow(income_all))
readr::write_csv(income_all, here("output","income_all.csv"))

# ----------------------- 6) BA+ share (ba_all) -----------------------
# Best practice: compute BA+ share from B15003 (education attainment, age 25+)
# BA+ = sum(B15003_022 ... B15003_025)
# Denominator (25+ total) = sum(B15003_001 ... B15003_025)

pull_ba_from_b15003_tidycensus <- function(years) {
  ensure_pkg("tidycensus")
  purrr::map_dfr(years, function(y) {

    # pull B15003_001 to B15003_025
    vars <- sprintf("B15003_%03d", 1:25)

    df <- tidycensus::get_acs(
      geography   = "county",
      variables   = vars,
      year        = y,
      survey      = "acs5",
      cache_table = TRUE,
      geometry    = FALSE
    )

    # wide: one row per county, cols per var estimate
    wide <- df %>%
      select(GEOID, variable, estimate) %>%
      tidyr::pivot_wider(names_from = variable, values_from = estimate)

    ba_num <- rowSums(dplyr::select(wide, B15003_022, B15003_023, B15003_024, B15003_025), na.rm = TRUE)
    denom  <- rowSums(dplyr::select(wide, dplyr::starts_with("B15003_")), na.rm = TRUE)

    tibble(
      county_ihme = std_fips(wide$GEOID),
      acs_year    = as.integer(y),
      ba_share    = ifelse(denom > 0, ba_num / denom, NA_real_)
    )
  })
}

ba_all <- pull_ba_from_b15003_tidycensus(acs_years) %>%
  mutate(
    county_ihme = std_fips(county_ihme),
    acs_year    = as.integer(acs_year),
    ba_share    = as.numeric(ba_share)
  ) %>%
  filter(is.finite(ba_share), ba_share >= 0, ba_share <= 1,
         county_ihme != "00000", county_ihme != "0000") %>%
  arrange(acs_year, county_ihme)

message("[ba_all] years: ", paste(unique(ba_all$acs_year), collapse = ", "),
        " | rows: ", nrow(ba_all))
readr::write_csv(ba_all, here("output","ba_all.csv"))

# ----------------------- done -----------------------
message("✅ Covariates built: fin_all, pop_join, ph_pc, income_all, ba_all")

```
Appendix: results plots
```{r}
# -----------------------------
# 1) Raw covariate plots (FULL FIXED for your current file)
# -----------------------------
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr)
  library(ggplot2); library(here)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# Your file's actual covariates (from the error message)
covariate_name_map <- list(
  excess_all_avg      = c("exc_avg"),
  covid_avg           = c("covid_avg"),
  rel_excess_mean     = c("rel_exc_mean"),
  population          = c("pop"),
  excess_per100k      = c("exc_per100k"),
  covid_per100k       = c("covid_per100k"),
  noncovid_excess_100k= c("nc_excess_per100k"),
  z_garbage           = c("z_garbage"),
  z_detail            = c("z_detail")
)

# -----------------------------
# load covariates
# -----------------------------
cov_path <- here("data", "county_covariates.csv.gz")
message("Reading covariates: ", cov_path)
stopifnot(file.exists(cov_path))

dq_cov <- readr::read_csv(cov_path, show_col_types = FALSE)

# ensure county id
id_col <- dplyr::case_when(
  "county_ihme" %in% names(dq_cov) ~ "county_ihme",
  "GEOID"       %in% names(dq_cov) ~ "GEOID",
  "fips"        %in% names(dq_cov) ~ "fips",
  "FIPS"        %in% names(dq_cov) ~ "FIPS",
  TRUE ~ NA_character_
)
if (is.na(id_col)) stop("No county id column found (need county_ihme/GEOID/fips/FIPS).")

dq_cov <- dq_cov %>% mutate(county_ihme = std_fips(.data[[id_col]]))

# year handling (your file DOES have year)
if ("year" %in% names(dq_cov)) {
  dq_cov <- dq_cov %>% mutate(year = as.integer(year))
} else {
  dq_cov <- dq_cov %>% mutate(year = NA_integer_)
}

# -----------------------------
# detect present covariates safely
# -----------------------------
present_covs <- purrr::imap_dfr(covariate_name_map, function(cands, std_name) {
  hit <- intersect(cands, names(dq_cov))
  if (length(hit)) tibble(std_name = std_name, raw_name = hit[1]) else tibble()
})

if (!nrow(present_covs)) {
  stop(
    "No recognized covariate columns found.\n",
    "Available columns: ", paste(names(dq_cov), collapse = ", "), "\n",
    "Edit covariate_name_map to match."
  )
}

message("Recognized covariates:\n",
        paste0("  - ", present_covs$std_name, " <= ", present_covs$raw_name, collapse = "\n"))

# -----------------------------
# long format + plots (NO group_walk; fixes 'covariate' warning)
# -----------------------------
out_dir_cov_plots <- here("output", "covariate_raw_plots")
dir.create(out_dir_cov_plots, recursive = TRUE, showWarnings = FALSE)

plot_covariate <- function(df, cov_name) {
  ggplot(df, aes(x = value)) +
    geom_histogram(bins = 40) +
    labs(
      title = paste0("Raw covariate distribution: ", cov_name),
      x = cov_name, y = "Count (county-years)"
    ) +
    theme_minimal(base_size = 12)
}

cov_names <- sort(unique(cov_long$covariate))

for (cov_name in cov_names) {
  df_sub <- cov_long %>% filter(covariate == cov_name)
  p <- plot_covariate(df_sub, cov_name)

  ggsave(
    filename = file.path(out_dir_cov_plots, paste0("raw_", cov_name, ".png")),
    plot = p, width = 8, height = 5, dpi = 300
  )
}

# write standardized wide file (useful for merges)
cov_wide <- cov_long %>% tidyr::pivot_wider(names_from = covariate, values_from = value)
readr::write_csv(cov_wide, here("output", "county_covariates_standardized.csv"))

message("✅ Saved raw covariate plots to: ", out_dir_cov_plots)
message("✅ Wrote standardized covariates: output/county_covariates_standardized.csv")

# =====================================================================
# RAW DISTRIBUTION PLOTS (FIXED) — garbage + RI from county-year file,
# and detail from COD diversity file (cluster_metrics_ucr39_cstd).
#
# Outputs (PNG) to: figures/dq_diagnostics_raw/
#   - hist_raw_prop_garbage.png
#   - hist_raw_RI.png
#   - hist_raw_detail.png
#
# Assumes you have:
#   1) data/county_year_quality_metrics.csv.gz
#   2) output/cluster_metrics_ucr39_cstd.csv.gz
#   3) output/county_cluster_membership.csv.gz
#
# IMPORTANT:
# - "detail" is NOT in county_year_quality_metrics.csv.gz (per your note),
#   so we compute county-level detail by:
#     membership (period+cluster -> fips) + cluster metrics (period+cluster -> detail)
#   then (optionally) map period -> representative year and plot distribution across counties.
# =====================================================================

suppressPackageStartupMessages({
  library(dplyr); library(readr); library(stringr); library(purrr); library(tidyr)
  library(ggplot2); library(here); library(scales)
})

# -----------------------------
# config
# -----------------------------
dq_path        <- here("data",   "county_year_quality_metrics.csv.gz")
metrics_path   <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
member_path    <- here("output", "county_cluster_membership.csv.gz")

stopifnot(file.exists(dq_path))
stopifnot(file.exists(metrics_path))
stopifnot(file.exists(member_path))

fig_dir <- here("figures", "dq_diagnostics_raw")
dir.create(fig_dir, recursive = TRUE, showWarnings = FALSE)

period_to_year <- c("1999_2005"=2002L, "2006_2012"=2009L, "2013_2019"=2016L, "2020_2022"=2021L)

normalize_id <- function(x) {
  x %>% as.character() %>% stringr::str_trim() %>%
    stringr::str_replace_all("[^A-Za-z0-9]+", "_") %>%
    stringr::str_replace_all("^_+|_+$", "") %>%
    tolower()
}
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

pick_col <- function(df, candidates) {
  hit <- intersect(candidates, names(df))
  if (length(hit)) hit[1] else NA_character_
}

plot_hist <- function(x, title, xlab, bins = 40) {
  ggplot(data.frame(x = x), aes(x = x)) +
    geom_histogram(bins = bins) +
    labs(title = title, x = xlab, y = "Count") +
    theme_minimal(base_size = 12)
}

# -----------------------------
# 1) Garbage + RI from county-year file (dq)
# -----------------------------
dq <- readr::read_csv(dq_path, show_col_types = FALSE) %>%
  mutate(county_ihme = std_fips(.data[["county_ihme"]]),
         year = as.integer(.data[["year"]]))

garbage_candidates <- c("prop_garbage", "garbage_prop", "pct_garbage", "p_garbage", "DQ_prop_garbage")
ri_candidates      <- c("RI", "DQ_overall", "ri", "RI_cluster", "DQ_RI", "RI_post_only", "RI_jsd")

raw_cols <- c(
  garbage = pick_col(dq, garbage_candidates),
  RI      = pick_col(dq, ri_candidates)
)

if (is.na(raw_cols["garbage"])) {
  stop("Could not find garbage column in dq. Available columns: ", paste(names(dq), collapse = ", "))
}
if (is.na(raw_cols["RI"])) {
  stop("Could not find RI column in dq. Available columns: ", paste(names(dq), collapse = ", "))
}

garb <- dq %>% pull(.data[[raw_cols["garbage"]]]) %>% as.numeric()
garb <- garb[is.finite(garb)]

ri <- dq %>% pull(.data[[raw_cols["RI"]]]) %>% as.numeric()
ri <- ri[is.finite(ri)]

p_garb <- plot_hist(
  x     = garb,
  title = "Proportion garbage-coded deaths",
  xlab  = raw_cols["garbage"]
)
ggsave(file.path(fig_dir, "hist_raw_prop_garbage.png"), p_garb, width = 8, height = 5, dpi = 300)

# -----------------------------
# RI histogram — trimmed for visualization
# -----------------------------

# Extract RI
ri <- dq %>% pull(.data[[raw_cols["RI"]]]) %>% as.numeric()
ri <- ri[is.finite(ri)]

# Define trimming bounds (adjust if needed)
ri_lo <- quantile(ri, 0.01, na.rm = TRUE)
ri_hi <- quantile(ri, 0.99, na.rm = TRUE)

# Trim ONLY for plotting
ri_trim <- ri[ri >= ri_lo & ri <= ri_hi]

p_ri <- ggplot(data.frame(x = ri_trim), aes(x = x)) +
  geom_histogram(bins = 40) +
  labs(
    title = "Reassignability index (RI) distribution",
    x = raw_cols["RI"],
    y = "Count"
  ) +
  theme_minimal(base_size = 12)

ggsave(
  file.path(fig_dir, "hist_raw_RI.png"),
  p_ri, width = 8, height = 5, dpi = 300
)

message(
  "ℹ️ RI histogram trimmed to [",
  round(ri_lo, 3), ", ", round(ri_hi, 3),
  "] for visualization only"
)


# -----------------------------
# 2) Detail from COD diversity file (cluster metrics) + membership expansion
# -----------------------------
metrics <- readr::read_csv(metrics_path, show_col_types = FALSE) %>%
  mutate(
    period  = as.character(period),
    cluster = normalize_id(cluster)
  )

membership <- readr::read_csv(member_path, show_col_types = FALSE) %>%
  mutate(
    period  = as.character(period),
    cluster = normalize_id(cluster),
    fips    = std_fips(fips)
  )

# Choose a "detail" column from cluster metrics (edit candidates if your column is named differently)
detail_candidates <- c(
  "detail_ucod_icd4_cstd"
)
detail_col <- pick_col(metrics, detail_candidates)
if (is.na(detail_col)) {
  stop(
    "Could not find a detail/diversity column in cluster metrics.\n",
    "Tried: ", paste(detail_candidates, collapse = ", "), "\n",
    "Available numeric columns include: ",
    paste(names(metrics)[vapply(metrics, is.numeric, logical(1))], collapse = ", ")
  )
}

# Expand cluster-level detail -> county rows
detail_county_period <- membership %>%
  select(period, cluster, fips) %>%
  left_join(metrics %>% select(period, cluster, !!detail_col), by = c("period","cluster")) %>%
  transmute(
    county_ihme = fips,
    period      = period,
    detail      = as.numeric(.data[[detail_col]])
  ) %>%
  filter(is.finite(detail), nchar(county_ihme) == 5, county_ihme != "00000")

if (!nrow(detail_county_period)) {
  stop("Detail expansion produced 0 rows. Check that membership(period,cluster) matches metrics(period,cluster).")
}

# Option A (default): plot pooled across all periods (county-period distribution)
detail_vals <- detail_county_period$detail
detail_vals <- detail_vals[is.finite(detail_vals)]

p_detail <- plot_hist(
  x     = detail_vals,
  title = paste0("Level of detail distribution"),
  xlab  = detail_col
)
ggsave(file.path(fig_dir, "hist_raw_detail.png"), p_detail, width = 8, height = 5, dpi = 300)

# Option B: if you want a single cross-section, map period -> representative year and sample one period
# (uncomment to use)
# detail_cross <- detail_county_period %>%
#   mutate(year = unname(period_to_year[period])) %>%
#   filter(!is.na(year)) %>%
#   group_by(county_ihme) %>%
#   summarise(detail = mean(detail, na.rm = TRUE), .groups = "drop")
# p_detail2 <- plot_hist(detail_cross$detail[is.finite(detail_cross$detail)],
#                        "Raw distribution: Detail (county avg across available periods)",
#                        detail_col)
# ggsave(file.path(fig_dir, "hist_raw_detail_countyavg.png"), p_detail2, width = 8, height = 5, dpi = 300)

message("✅ Saved detail histogram to: ", fig_dir)
message("✅ Detail column used: ", detail_col)
```
FIGURE APPENDIX: raw covariate distributions
```{r}
# =====================================================================
# Covariate figure (4 panels, cross-sectional) with:
#   - Population capped at 97.5th percentile (plotting only)
#   - PH spend per capita trimmed 2.5th–97.5th percentile (plotting only)
#   - Higher resolution histograms (more bins)
#
# Panels:
#   1) Population (latest fin_year per county, capped)
#   2) Public health spend per capita (latest fin_year per county, trimmed)
#   3) Median household income (latest acs_year per county)
#   4) COVID excess deaths (county_covariates.csv.gz; no year -> median per county)
#
# Output:
#   figures/dq_diagnostics_raw/covariates_4panel_income_pop_phpc_covid.png
# =====================================================================

suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(ggplot2); library(here)
  library(patchwork)
})

std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

get_or_read <- function(obj_name, csv_path) {
  if (exists(obj_name, inherits = TRUE)) {
    get(obj_name, inherits = TRUE)
  } else {
    stopifnot(file.exists(csv_path))
    readr::read_csv(csv_path, show_col_types = FALSE)
  }
}

pick_col <- function(df, candidates) {
  hit <- intersect(candidates, names(df))
  if (length(hit)) hit[1] else NA_character_
}

# -----------------------------
# Inputs
# -----------------------------
ph_path  <- here("output", "ph_pc.csv")
inc_path <- here("output", "income_all.csv")
cov_path <- here("data",   "county_covariates.csv.gz")

ph_pc      <- get_or_read("ph_pc",      ph_path)
income_all <- get_or_read("income_all", inc_path)
stopifnot(file.exists(cov_path))
dq_cov <- readr::read_csv(cov_path, show_col_types = FALSE)

# -----------------------------
# Panel 1 + 2: population + PH per-capita (latest fin_year per county)
# -----------------------------
stopifnot(all(c("county_ihme","fin_year","pop","ph_pc") %in% names(ph_pc)))

ph_xs <- ph_pc %>%
  transmute(
    county_ihme = std_fips(county_ihme),
    fin_year    = as.integer(fin_year),
    pop         = suppressWarnings(as.numeric(pop)),
    ph_pc       = suppressWarnings(as.numeric(ph_pc))
  ) %>%
  filter(
    nchar(county_ihme) == 5,
    county_ihme != "00000",
    is.finite(fin_year)
  ) %>%
  group_by(county_ihme) %>%
  slice_max(order_by = fin_year, n = 1, with_ties = FALSE) %>%
  ungroup()

# ---- population: cap at 97.5th percentile (plotting only)
pop_vals <- ph_xs$pop
pop_vals <- pop_vals[is.finite(pop_vals)]
pop_p975 <- unname(quantile(pop_vals, 0.975, na.rm = TRUE))

pop_xs <- ph_xs %>%
  filter(is.finite(pop)) %>%
  mutate(pop_capped = pmin(pop, pop_p975)) %>%
  transmute(covariate = "Population (capped at 97.5th pctile)", value = pop_capped)

message("ℹ️ Population capped at 97.5th percentile = ",
        format(round(pop_p975, 0), big.mark = ","), " (plotting only).")

# ---- PH per-capita: trim 2.5th–97.5th percentile (plotting only)
phpc_vals <- ph_xs$ph_pc
phpc_vals <- phpc_vals[is.finite(phpc_vals)]
phpc_p025 <- unname(quantile(phpc_vals, 0.025, na.rm = TRUE))
phpc_p975 <- unname(quantile(phpc_vals, 0.975, na.rm = TRUE))

phpc_xs <- ph_xs %>%
  filter(is.finite(ph_pc)) %>%
  filter(ph_pc >= phpc_p025, ph_pc <= phpc_p975) %>%
  transmute(covariate = "Public health spend per capita (trimmed 2.5th–97.5th pctile)", value = ph_pc)

message("ℹ️ PH per-capita trimmed to [",
        signif(phpc_p025, 4), ", ", signif(phpc_p975, 4),
        "] (plotting only).")

if (!nrow(pop_xs))  stop("Population panel empty after filtering. Check ph_pc$pop.")
if (!nrow(phpc_xs)) stop("PH per-capita panel empty after trimming. Check ph_pc$ph_pc.")

# -----------------------------
# Panel 3: median income (latest acs_year per county)
# -----------------------------
stopifnot(all(c("county_ihme","acs_year","avg_income") %in% names(income_all)))

inc_xs <- income_all %>%
  transmute(
    county_ihme = std_fips(county_ihme),
    acs_year    = as.integer(acs_year),
    income_med  = suppressWarnings(as.numeric(avg_income))
  ) %>%
  filter(
    nchar(county_ihme) == 5,
    county_ihme != "00000",
    is.finite(acs_year),
    is.finite(income_med)
  ) %>%
  group_by(county_ihme) %>%
  slice_max(order_by = acs_year, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  transmute(covariate = "Median household income (ACS B19013_001)", value = income_med)

if (!nrow(inc_xs)) stop("Income panel empty after filtering. Check income_all columns/values.")

# -----------------------------
# Panel 4: COVID excess deaths (no year; median per county)
# -----------------------------
id_col <- dplyr::case_when(
  "county_ihme" %in% names(dq_cov) ~ "county_ihme",
  "GEOID"       %in% names(dq_cov) ~ "GEOID",
  "fips"        %in% names(dq_cov) ~ "fips",
  "FIPS"        %in% names(dq_cov) ~ "FIPS",
  TRUE ~ NA_character_
)
if (is.na(id_col)) stop("No county id column found in county_covariates (need county_ihme/GEOID/fips/FIPS).")

covid_candidates <- c(
  "covid_per100k", "covid_per_100k", "covid_excess_per100k", "covid_excess_per_100k",
  "covid_avg", "covid"
)
covid_col <- pick_col(dq_cov, covid_candidates)
if (is.na(covid_col)) {
  stop(
    "Could not find a COVID excess-deaths column in county_covariates.csv.gz.\n",
    "Tried: ", paste(covid_candidates, collapse = ", "), "\n",
    "Available columns: ", paste(names(dq_cov), collapse = ", ")
  )
}
covid_label <- if (grepl("per", covid_col, ignore.case = TRUE)) "COVID excess deaths (per 100k)" else "COVID excess deaths"

covid_xs <- dq_cov %>%
  transmute(
    county_ihme = std_fips(.data[[id_col]]),
    covid_val   = suppressWarnings(as.numeric(.data[[covid_col]]))
  ) %>%
  filter(
    nchar(county_ihme) == 5,
    county_ihme != "00000",
    is.finite(covid_val)
  ) %>%
  group_by(county_ihme) %>%
  summarise(covid_val = median(covid_val, na.rm = TRUE), .groups = "drop") %>%
  transmute(covariate = covid_label, value = covid_val)

if (!nrow(covid_xs)) stop("COVID panel empty after filtering. Check covid column contents.")
message("ℹ️ COVID column used from county_covariates: ", covid_col)

# -----------------------------
# Plot + save (4 panels stacked) with higher resolution
# -----------------------------
fig_dir <- here("figures", "dq_diagnostics_raw")
dir.create(fig_dir, recursive = TRUE, showWarnings = FALSE)

# Higher resolution: more bins (and you can change these)
bins_pop   <- 70
bins_phpc  <- 70
bins_inc   <- 70
bins_covid <- 70

plot_hist <- function(df, title, bins = 60) {
  ggplot(df, aes(x = value)) +
    geom_histogram(bins = bins) +
    labs(title = title, x = NULL, y = "Count (counties)") +
    theme_minimal(base_size = 12)
}

p_pop   <- plot_hist(pop_xs,  "Population (capped at 97.5th pctile)", bins = bins_pop)
p_phpc  <- plot_hist(phpc_xs, "Public health spend per capita (trimmed 2.5th–97.5th pctile)", bins = bins_phpc)
p_inc   <- plot_hist(inc_xs,  "Median household income (ACS B19013_001)", bins = bins_inc)
p_covid <- plot_hist(covid_xs, covid_label, bins = bins_covid)

p_combined <- (p_pop / p_phpc / p_inc / p_covid) +
  plot_annotation(title = "Raw covariate distributions (cross-sectional)")

out_file <- file.path(fig_dir, "covariates_4panel_income_pop_phpc_covid.png")
ggsave(out_file, p_combined, width = 8, height = 12, dpi = 450)

message("✅ Saved 4-panel covariate figure: ", out_file)

```
FIGURE APPENDIX: each metric overtime
```{r}
# =====================================================================
# STANDALONE APPENDIX CHUNK: Results plots (COPY/PASTE)
# Creates TWO figures:
#   (1) Raw distributions (ONE FIGURE): Proportion garbage + RI + Level of detail
#   (2) Indices over time (ONE FIGURE): median line + IQR ribbon + middle-95% ribbon
#
# Inputs (assumed):
#   1) data/county_year_quality_metrics.csv.gz
#   2) output/cluster_metrics_ucr39_cstd.csv.gz
#   3) output/county_cluster_membership.csv.gz
#
# Outputs (PNG) to:
#   figures/dq_diagnostics_raw/
#     - hist_raw_indices_combined.png
#     - indices_over_time_median_iqr_95.png
# =====================================================================

suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tidyr); library(purrr)
  library(ggplot2); library(here); library(scales)
  library(patchwork)
})

# -----------------------------
# helpers
# -----------------------------
std_fips <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

normalize_id <- function(x) {
  x %>% as.character() %>% stringr::str_trim() %>%
    stringr::str_replace_all("[^A-Za-z0-9]+", "_") %>%
    stringr::str_replace_all("^_+|_+$", "") %>%
    tolower()
}

pick_col <- function(df, candidates) {
  hit <- intersect(candidates, names(df))
  if (length(hit)) hit[1] else NA_character_
}

# -----------------------------
# paths + output dir
# -----------------------------
dq_path        <- here("data",   "county_year_quality_metrics.csv.gz")
metrics_path   <- here("output", "cluster_metrics_ucr39_cstd.csv.gz")
member_path    <- here("output", "county_cluster_membership.csv.gz")

stopifnot(file.exists(dq_path))
stopifnot(file.exists(metrics_path))
stopifnot(file.exists(member_path))

fig_dir <- here("figures", "dq_diagnostics_raw")
dir.create(fig_dir, recursive = TRUE, showWarnings = FALSE)

# Higher-resolution histograms
bins_hist <- 70

# =============================
# (1) RAW DISTRIBUTIONS (one figure)
#   - Prop garbage + RI from county-year
#   - Detail from cluster metrics expanded to counties via membership
# =============================

dq <- readr::read_csv(dq_path, show_col_types = FALSE) %>%
  mutate(
    county_ihme = std_fips(.data[["county_ihme"]]),
    year        = as.integer(.data[["year"]])
  )

garbage_candidates <- c("prop_garbage", "garbage_prop", "pct_garbage", "p_garbage", "DQ_prop_garbage")
ri_candidates      <- c("RI_post_only", "RI_jsd")

garbage_col <- pick_col(dq, garbage_candidates)
ri_col      <- pick_col(dq, ri_candidates)

if (is.na(garbage_col)) stop("Could not find garbage column in dq. Available: ", paste(names(dq), collapse = ", "))
if (is.na(ri_col))      stop("Could not find RI column in dq. Available: ", paste(names(dq), collapse = ", "))

garb <- suppressWarnings(as.numeric(dq[[garbage_col]]))
garb <- garb[is.finite(garb)]

ri <- suppressWarnings(as.numeric(dq[[ri_col]]))
ri <- ri[is.finite(ri)]

# Trim RI for visualization ONLY (center the distribution)
ri_lo <- unname(quantile(ri, 0.01, na.rm = TRUE))
ri_hi <- unname(quantile(ri, 0.99, na.rm = TRUE))
ri_trim <- ri[ri >= ri_lo & ri <= ri_hi]

message("ℹ️ RI histogram trimmed to [", signif(ri_lo,4), ", ", signif(ri_hi,4), "] for visualization only.")

# Detail from cluster metrics + membership expansion
metrics <- readr::read_csv(metrics_path, show_col_types = FALSE) %>%
  mutate(period = as.character(period), cluster = normalize_id(cluster))

membership <- readr::read_csv(member_path, show_col_types = FALSE) %>%
  mutate(period = as.character(period), cluster = normalize_id(cluster), fips = std_fips(fips))

detail_candidates <- c("detail_ucod_icd4_cstd")
detail_col <- pick_col(metrics, detail_candidates)
if (is.na(detail_col)) {
  stop(
    "Could not find detail column in cluster metrics. Tried: ",
    paste(detail_candidates, collapse = ", "),
    "\nAvailable numeric cols: ",
    paste(names(metrics)[vapply(metrics, is.numeric, logical(1))], collapse = ", ")
  )
}

detail_county_period <- membership %>%
  select(period, cluster, fips) %>%
  left_join(metrics %>% select(period, cluster, !!detail_col), by = c("period","cluster")) %>%
  transmute(
    county_ihme = fips,
    period      = period,
    detail      = suppressWarnings(as.numeric(.data[[detail_col]]))
  ) %>%
  filter(is.finite(detail), nchar(county_ihme) == 5, county_ihme != "00000")

if (!nrow(detail_county_period)) {
  stop("Detail expansion produced 0 rows. Check that membership(period,cluster) matches metrics(period,cluster).")
}

detail_vals <- detail_county_period$detail
detail_vals <- detail_vals[is.finite(detail_vals)]

idx_long_hist <- bind_rows(
  tibble(index = "Proportion garbage-coded deaths", value = garb),
  tibble(index = "Reassignability index (RI)",     value = ri_trim),
  tibble(index = "Level of detail",                value = detail_vals)
) %>%
  filter(is.finite(value))

p_hist <- ggplot(idx_long_hist, aes(x = value)) +
  geom_histogram(bins = bins_hist) +
  facet_wrap(~ index, scales = "free_x", ncol = 1) +
  labs(
    title = "Raw distributions of data quality indices",
    subtitle = paste0(
      "RI trimmed to 1st–99th percentile for visualization only [",
      signif(ri_lo,4), ", ", signif(ri_hi,4), "]"
    ),
    x = NULL,
    y = "Count"
  ) +
  theme_minimal(base_size = 12)

ggsave(
  filename = file.path(fig_dir, "hist_raw_indices_combined.png"),
  plot = p_hist,
  width = 8, height = 10, dpi = 450
)

message("✅ Saved: ", file.path(fig_dir, "hist_raw_indices_combined.png"))

# =============================
# (2) INDICES OVER TIME (one figure)
#   - Prop garbage + RI: county-year (dq)
#   - Detail: county-period mapped to representative year (midpoint)
#   - Summaries: median + IQR + middle 95%
# =============================

period_to_year <- c("1999_2005"=2002L, "2006_2012"=2009L, "2013_2019"=2016L, "2020_2022"=2021L)

detail_year <- detail_county_period %>%
  mutate(year = unname(period_to_year[period])) %>%
  filter(is.finite(year)) %>%
  transmute(year = as.integer(year), value = detail, index = "Level of detail")

idx_time_long <- bind_rows(
  dq %>%
    transmute(
      year  = as.integer(year),
      value = suppressWarnings(as.numeric(.data[[garbage_col]])),
      index = "Proportion garbage-coded deaths"
    ),
  dq %>%
    transmute(
      year  = as.integer(year),
      value = suppressWarnings(as.numeric(.data[[ri_col]])),
      index = "Reassignability index (RI)"
    ),
  detail_year
) %>%
  filter(is.finite(year), is.finite(value))

idx_time_summ <- idx_time_long %>%
  group_by(index, year) %>%
  summarise(
    n     = sum(is.finite(value)),
    p02_5 = unname(quantile(value, 0.025, na.rm = TRUE)),
    p25   = unname(quantile(value, 0.25,  na.rm = TRUE)),
    p50   = unname(quantile(value, 0.50,  na.rm = TRUE)),
    p75   = unname(quantile(value, 0.75,  na.rm = TRUE)),
    p97_5 = unname(quantile(value, 0.975, na.rm = TRUE)),
    .groups = "drop"
  )

p_time <- ggplot(idx_time_summ, aes(x = year, y = p50)) +
  geom_ribbon(aes(ymin = p02_5, ymax = p97_5), alpha = 0.15) +
  geom_ribbon(aes(ymin = p25,   ymax = p75),   alpha = 0.25) +
  geom_line(linewidth = 0.6) +
  facet_wrap(~ index, scales = "free_y", ncol = 1) +
  scale_x_continuous(breaks = pretty_breaks(n = 8)) +
  labs(
    title = "Data quality indices over time",
    subtitle = "Line = median; darker ribbon = IQR; lighter ribbon = middle 95%",
    x = "Year",
    y = NULL
  ) +
  theme_minimal(base_size = 12)

ggsave(
  filename = file.path(fig_dir, "indices_over_time_median_iqr_95.png"),
  plot = p_time,
  width = 8, height = 10, dpi = 450
)

message("✅ Saved: ", file.path(fig_dir, "indices_over_time_median_iqr_95.png"))
```
STATISTICAL ANALYSIS (DEC 23)
```{r}
# ============================================================
# STATISTICAL ANALYSIS + VERIFICATION PACK (FULL FIXED VERSION)
#   + ADDS COVID-19 SEVERITY / IMPLIED COVID UNDERCOUNT (PER 100k)
#     - pulls county population from US Census PEP (cached to data_raw/)
#   - Builds county×year analysis frame (metrics + covariates)
#   - Computes: period means, pre/post signed-rank (HL + CI)
#               correlations (overall + by-period) incl. severity covariates
#               reporting-type KW + eps^2
#               metric–metric correlations (weighted + unweighted)
#               optional yearly correlation time series (stable covariates only)
#   - Writes CSVs + verification manifest + report to output/
#   - No plots
# ============================================================

suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(readr); library(stringr)
  library(purrr); library(broom); library(here); library(tibble)
  library(jsonlite)
})

dir.create(here("output"), recursive = TRUE, showWarnings = FALSE)
dir.create(here("data_raw"), recursive = TRUE, showWarnings = FALSE)

# -------------------- toggles --------------------
DO_BOOT_CORR_CI   <- TRUE
BOOT_B            <- 1000
BOOT_SEED         <- 12345
MIN_N_CORR        <- 25
MIN_N_KW          <- 50
MIN_N_PAIR        <- 25

# COVID severity window (monthly estimates): Mar 2020–Aug 2022
SEV_START_YM <- 202003L
SEV_END_YM   <- 202208L

# Census population vintage for per-100k scaling (single-year cross-section)
CENSUS_POP_YEAR <- 2022L

# -------------------- helpers --------------------
std_fips <- function(x) str_pad(as.character(x), 5, pad = "0")
`%||%` <- function(a,b) if (!is.null(a) && length(a) && !all(is.na(a))) a else b
safe_num <- function(x) suppressWarnings(as.numeric(x))

find_col <- function(df, patterns) {
  nms <- names(df)
  low <- tolower(nms)
  for (pat in patterns) {
    hit <- nms[grepl(pat, low)]
    if (length(hit)) return(hit[1])
  }
  NA_character_
}

safe_z <- function(x) {
  x <- as.numeric(x)
  if (all(is.na(x))) return(rep(NA_real_, length(x)))
  mu <- mean(x, na.rm = TRUE); sdv <- sd(x, na.rm = TRUE)
  if (!is.finite(sdv) || sdv == 0) return(rep(0, length(x)))
  (x - mu) / sdv
}

safe_wmean <- function(x, w) {
  x <- as.numeric(x); w <- as.numeric(w)
  okx <- is.finite(x); okw <- is.finite(w) & w > 0
  if (sum(okx) == 0) return(NA_real_)
  if (sum(okw) == 0) return(mean(x[okx], na.rm = TRUE))
  w2 <- w; w2[!okw] <- NA_real_
  sum(x * w2, na.rm = TRUE) / sum(w2, na.rm = TRUE)
}

# correlation with p-value + n (no CI)
corr_test <- function(x, y, method = c("spearman","pearson"), min_n = MIN_N_CORR) {
  method <- match.arg(method)
  x <- as.numeric(x); y <- as.numeric(y)
  ok <- is.finite(x) & is.finite(y)
  if (sum(ok) < min_n) return(tibble(n = sum(ok), r = NA_real_, p_value = NA_real_))
  r <- suppressWarnings(cor(x[ok], y[ok], method = method))
  p <- suppressWarnings(cor.test(x[ok], y[ok], method = method)$p.value)
  tibble(n = sum(ok), r = unname(r), p_value = unname(p))
}

# bootstrap CI for correlation (percentile CI)
boot_corr_ci <- function(x, y, method = c("spearman","pearson"),
                         B = BOOT_B, seed = BOOT_SEED, min_n = MIN_N_CORR) {
  method <- match.arg(method)
  x <- as.numeric(x); y <- as.numeric(y)
  ok <- is.finite(x) & is.finite(y)
  x <- x[ok]; y <- y[ok]
  n <- length(x)
  if (n < min_n) return(tibble(ci_lo = NA_real_, ci_hi = NA_real_, boot_n = n))

  set.seed(seed)
  rs <- replicate(B, {
    idx <- sample.int(n, size = n, replace = TRUE)
    suppressWarnings(cor(x[idx], y[idx], method = method))
  })
  rs <- rs[is.finite(rs)]
  if (!length(rs)) return(tibble(ci_lo = NA_real_, ci_hi = NA_real_, boot_n = n))
  tibble(
    ci_lo = unname(quantile(rs, 0.025, na.rm = TRUE)),
    ci_hi = unname(quantile(rs, 0.975, na.rm = TRUE)),
    boot_n = n
  )
}

corr_row <- function(x, y, method) {
  ct <- corr_test(x, y, method = method, min_n = MIN_N_CORR)
  if (!isTRUE(DO_BOOT_CORR_CI)) return(bind_cols(ct, tibble(ci_lo = NA_real_, ci_hi = NA_real_, boot_n = ct$n)))
  ci <- boot_corr_ci(x, y, method = method, B = BOOT_B, seed = BOOT_SEED, min_n = MIN_N_CORR)
  bind_cols(ct, ci)
}

# Kruskal–Wallis epsilon^2
eps2_kw <- function(kw_stat, k, n) {
  if (!is.finite(kw_stat) || !is.finite(k) || !is.finite(n) || n <= k || k < 2) return(NA_real_)
  (kw_stat - k + 1) / (n - k)
}

# weighted correlation matrix (Pearson/Spearman), listwise complete
weighted_cor_mat <- function(df, vars, wcol = NULL, method = c("pearson","spearman")) {
  method <- match.arg(method)
  X <- df %>% dplyr::select(dplyr::all_of(vars))
  w <- if (!is.null(wcol) && wcol %in% names(df)) as.numeric(df[[wcol]]) else NULL

  keep <- stats::complete.cases(X)
  if (!is.null(w)) keep <- keep & is.finite(w) & w > 0
  X <- as.matrix(X[keep, , drop = FALSE])
  if (!is.null(w)) w <- w[keep]

  n_used <- nrow(X)
  R <- matrix(NA_real_, ncol = length(vars), nrow = length(vars),
              dimnames = list(vars, vars))
  if (n_used < 3) return(list(cor = R, n = n_used))

  if (method == "spearman") X <- apply(X, 2, rank, ties.method = "average")

  if (is.null(w)) {
    C <- stats::cov(X)
  } else {
    w <- w / sum(w)
    C <- stats::cov.wt(X, wt = w, method = "ML")$cov
  }
  s <- sqrt(diag(C)); s[!is.finite(s) | s == 0] <- NA_real_
  R <- C / (s %o% s)
  dimnames(R) <- list(colnames(X), colnames(X))
  list(cor = R, n = n_used)
}

mat_to_tidy <- function(corlst, group_type, group, method, weighted_flag) {
  R <- corlst$cor; n_used <- corlst$n
  vars <- colnames(R)
  comb <- t(combn(vars, 2))
  tibble(
    group_type = group_type,
    group      = as.character(group),
    method     = method,
    weighted   = weighted_flag,
    n_used     = n_used,
    var1       = comb[,1],
    var2       = comb[,2],
    correlation = mapply(function(a,b) R[a,b], comb[,1], comb[,2])
  )
}

first_existing <- function(paths) { p <- paths[file.exists(paths)]; if (length(p)) p[1] else NA_character_ }

# FIPS builder robust to “FIPSCode” formats
make_fips5 <- function(fips_code, state_fips=NULL){
  fc <- str_replace_all(as.character(fips_code), "[^0-9]", "")
  if (!is.null(state_fips) && !all(is.na(state_fips))) {
    sf <- str_pad(as.character(state_fips), 2, pad="0")
    ifelse(nchar(fc) >= 5, str_pad(substr(fc,1,5),5,pad="0"),
           paste0(sf, str_pad(substr(fc, pmax(1, nchar(fc)-2), nchar(fc)), 3, pad="0")))
  } else str_pad(substr(fc,1,5), 5, pad="0")
}

# -------------------- required inputs --------------------
stopifnot(exists("cy"), is.data.frame(cy))
cy <- cy %>%
  mutate(county_ihme = std_fips(county_ihme),
         year = suppressWarnings(as.integer(year))) %>%
  filter(is.finite(year), year >= 1999, year <= 2022, county_ihme != "00000")

# -------------------- detect metric columns in cy --------------------
prop_garbage_col <- get0("prop_garbage_col") %||% find_col(
  cy, c("\\bprop[_ ]?garbage\\b","garbage[_ ]share","frac[_ ]garbage","\\bgarbage\\b")
)
if (is.na(prop_garbage_col)) stop("Could not detect prop_garbage column in `cy`.")

ri_main_col <- {
  cand <- c(get0("ri_col"), "RI", "RI_jsd", "ri")
  cand <- cand[!is.na(cand)]
  cand[cand %in% names(cy)][1] %||% NA_character_
}
ri_post_col <- c("RI_post_only","ri_post_only","RI_post","ri_post")[
  c("RI_post_only","ri_post_only","RI_post","ri_post") %in% names(cy)
][1] %||% NA_character_

# weights
w_col <- {
  cand <- c(get0("pop_col"), "n_cert", "population")
  cand <- cand[!is.na(cand)]
  cand[cand %in% names(cy)][1] %||% NA_character_
}
if (is.na(w_col)) warning("No weight column found (expected n_cert/population). Using unweighted means.")

message("Using weight column: ", ifelse(is.na(w_col), "NONE", w_col))
message("Using prop_garbage: ", prop_garbage_col)
message("Using RI main: ", ifelse(is.na(ri_main_col), "NONE", ri_main_col))
message("Using RI_post_only: ", ifelse(is.na(ri_post_col), "NONE", ri_post_col))

# -------------------- build / detect detail_year --------------------
if (!exists("detail_year")) {
  stopifnot(exists("detail_long"), is.data.frame(detail_long))
  detail_long <- detail_long %>% mutate(county_ihme = std_fips(county_ihme))

  ucod_icd4_candidates <- c("detail_icd4_ucod","detail_ucod_icd4_cstd","detail_ucod_icd4","detail_icd4")
  wide_hit <- intersect(ucod_icd4_candidates, names(detail_long))[1] %||% NA_character_
  has_year <- "year" %in% names(detail_long); has_period <- "period" %in% names(detail_long)

  period_to_midyear <- function(p) {
    p <- as.character(p)
    m <- stringr::str_match(p, "([0-9]{4})\\D+([0-9]{4})")
    if (is.na(m[1,1])) return(NA_integer_)
    s <- suppressWarnings(as.integer(m[,2])); e <- suppressWarnings(as.integer(m[,3]))
    as.integer(round((s + e)/2))
  }

  if (!is.na(wide_hit)) {
    detail_year <- detail_long %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(.data[[wide_hit]])))
  } else {
    stopifnot(all(c("metric","value") %in% names(detail_long)))
    icd4_pat <- "(detail|diversity).*ucod.*icd\\s*[-_ ]?4|icd\\s*[-_ ]?4.*ucod"
    dl <- detail_long %>% filter(grepl(icd4_pat, tolower(metric)))
    detail_year <- dl %>%
      transmute(county_ihme,
                year = if (has_year) suppressWarnings(as.integer(year)) else period_to_midyear(period),
                detail_icd4 = suppressWarnings(as.numeric(value))) %>%
      group_by(county_ihme, year) %>%
      summarise(detail_icd4 = mean(detail_icd4, na.rm = TRUE), .groups = "drop")
  }
}
detail_year <- detail_year %>%
  mutate(county_ihme = std_fips(county_ihme),
         year = suppressWarnings(as.integer(year))) %>%
  filter(is.finite(year), is.finite(detail_icd4), year >= 1999, year <= 2022)

# -------------------- reporting type lookup (optional) --------------------
get_reporting_lookup <- function() {
  if (exists("rep_lu") && is.data.frame(rep_lu) &&
      all(c("county_ihme","reporting_type") %in% names(rep_lu))) {
    return(rep_lu %>% transmute(county_ihme = std_fips(county_ihme),
                                reporting_type = as.character(reporting_type)))
  }

  candidates <- c(
    here("data_raw","County-Death-Investigation-System-2018-1-9-2024.csv"),
    here("data_raw","County-Death-Investigation-System-2018.csv"),
    here("data_raw","County-Death-Investigation-System.csv")
  )
  path <- candidates[file.exists(candidates)][1] %||% NA_character_
  if (is.na(path)) return(tibble(county_ihme = character(0), reporting_type = character(0)))

  rep_raw <- readr::read_csv(path, show_col_types = FALSE)
  exact_col <- names(rep_raw)[tolower(names(rep_raw)) == tolower("Medicolegal Death Investigation Type")]
  type_col <- if (length(exact_col) == 1) exact_col else find_col(rep_raw, c("medicolegal","reporting.*type","investigation.*type","death.*investigation"))
  fips_col <- find_col(rep_raw, c("^fips$","geoid","county_?fips","fips.*5"))
  if (is.na(fips_col) || is.na(type_col)) return(tibble(county_ihme = character(0), reporting_type = character(0)))

  rep_raw %>%
    transmute(county_ihme = std_fips(.data[[fips_col]]),
              rt_raw = trimws(as.character(.data[[type_col]]))) %>%
    mutate(rt_lower = tolower(replace_na(rt_raw,"")),
           reporting_type = case_when(
             grepl("medical", rt_lower) | grepl("\\bme\\b", rt_lower) | grepl("examiner", rt_lower) ~ "Medical Examiner",
             grepl("coroner", rt_lower) ~ "Coroner",
             grepl("mixed", rt_lower) ~ "Mixed",
             TRUE ~ "Other County Official"
           )) %>%
    select(county_ihme, reporting_type) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000") %>%
    distinct()
}

rep_lookup <- get_reporting_lookup() %>%
  mutate(reporting_type = factor(reporting_type,
                                 levels = c("Coroner","Other County Official","Mixed","Medical Examiner")))

rep_bin <- rep_lookup %>%
  mutate(reporting_bin = case_when(
    reporting_type == "Medical Examiner" ~ 1,
    reporting_type == "Coroner" ~ 0,
    TRUE ~ NA_real_
  )) %>%
  select(county_ihme, reporting_bin)

# -------------------- income + PH spend predictors (optional) --------------------
income_pred <- {
  if (exists("income_all") && is.data.frame(income_all)) {
    inc_col <- find_col(income_all, c("^avg[_ ]?income$","median[_ ]?household[_ ]?income","median[_ ]?income","b19013_001","income"))
    if (!is.na(inc_col)) {
      income_all %>%
        transmute(county_ihme = std_fips(county_ihme),
                  income_val = suppressWarnings(as.numeric(.data[[inc_col]]))) %>%
        filter(is.finite(income_val)) %>%
        group_by(county_ihme) %>%
        summarise(income_med = median(income_val, na.rm = TRUE), .groups = "drop")
    } else tibble(county_ihme = character(0), income_med = numeric(0))
  } else {
    inc_cy <- find_col(cy, c("median[_ ]?income","medianhousehold","b19013","income"))
    if (!is.na(inc_cy)) {
      cy %>%
        transmute(county_ihme, income_val = suppressWarnings(as.numeric(.data[[inc_cy]]))) %>%
        filter(is.finite(income_val)) %>%
        group_by(county_ihme) %>%
        summarise(income_med = median(income_val, na.rm = TRUE), .groups = "drop")
    } else tibble(county_ihme = character(0), income_med = numeric(0))
  }
}

ph_pred <- {
  if (exists("ph_pc") && is.data.frame(ph_pc)) {
    ph_col <- find_col(ph_pc, c("^ph[_ ]?pc$","ph[_ ]?per[_ ]?capita","per[_ ]?capita","phpc"))
    if (!is.na(ph_col)) {
      ph_pc %>%
        transmute(county_ihme = std_fips(county_ihme),
                  ph_val = suppressWarnings(as.numeric(.data[[ph_col]]))) %>%
        filter(is.finite(ph_val)) %>%
        group_by(county_ihme) %>%
        summarise(ph_pc_med = median(ph_val, na.rm = TRUE), .groups = "drop")
    } else tibble(county_ihme = character(0), ph_pc_med = numeric(0))
  } else {
    ph_cy <- find_col(cy, c("\\bph[_ ]?pc\\b","ph[_ ]?per[_ ]?capita","phpc","public health"))
    if (!is.na(ph_cy)) {
      cy %>%
        transmute(county_ihme, ph_val = suppressWarnings(as.numeric(.data[[ph_cy]]))) %>%
        filter(is.finite(ph_val)) %>%
        group_by(county_ihme) %>%
        summarise(ph_pc_med = median(ph_val, na.rm = TRUE), .groups = "drop")
    } else tibble(county_ihme = character(0), ph_pc_med = numeric(0))
  }
}

if (nrow(income_pred) == 0) warning("Income predictor not found. Income correlations will be NA.")
if (nrow(ph_pred) == 0) warning("PH spend predictor not found. PH correlations will be NA.")
if (nrow(rep_lookup) == 0) warning("Reporting-type lookup not found. Reporting-type tests/correlations will be NA.")

# ============================================================
# POPULATION LOOKUP FROM CENSUS PEP (REQUIRED FOR PER-100k)
#   - cached to data_raw/census_pep_county_pop_<YEAR>.csv
#   - no API key required; if you have one, set Sys.getenv("CENSUS_API_KEY")
# ============================================================

get_census_county_pop_pep <- function(year = 2022L, api_key = NULL) {
  base <- sprintf("https://api.census.gov/data/%d/pep/population", year)
  q <- "get=POP,NAME&for=county:*&in=state:*"
  url <- paste0(base, "?", q, if (!is.null(api_key)) paste0("&key=", api_key) else "")
  dat <- jsonlite::fromJSON(url)

  hdr <- dat[1, ]
  body <- dat[-1, , drop = FALSE]
  df <- as.data.frame(body, stringsAsFactors = FALSE)
  names(df) <- hdr

  out <- df %>%
    transmute(
      state = .data[["state"]],
      county = .data[["county"]],
      county_ihme = std_fips(paste0(str_pad(state, 2, "left", "0"),
                                   str_pad(county, 3, "left", "0"))),
      pop = safe_num(.data[["POP"]])
    ) %>%
    filter(nchar(county_ihme) == 5, county_ihme != "00000", is.finite(pop), pop > 0) %>%
    select(county_ihme, pop)

  out
}

pop_cache <- here("data_raw", sprintf("census_pep_county_pop_%d.csv", CENSUS_POP_YEAR))
if (file.exists(pop_cache)) {
  pop_by_county <- readr::read_csv(pop_cache, show_col_types = FALSE) %>%
    transmute(county_ihme = std_fips(county_ihme), pop = safe_num(pop)) %>%
    filter(is.finite(pop), pop > 0)
} else {
  api_key <- Sys.getenv("CENSUS_API_KEY")
  api_key <- if (nzchar(api_key)) api_key else NULL
  pop_by_county <- get_census_county_pop_pep(year = CENSUS_POP_YEAR, api_key = api_key)
  readr::write_csv(pop_by_county, pop_cache)
}
message("Loaded Census county population rows: ", nrow(pop_by_county), " (", basename(pop_cache), ")")

# ============================================================
# COVID-19 SEVERITY / IMPLIED COVID UNDERCOUNT (PER 100k)
#   Source: IHME estimatesMonthly.csv
#   Window: Mar 2020–Aug 2022
#
#   PRIMARY:
#     covid_undercount_per100k = mean(max(excDeathsMean - COVIDDeathsUCD, 0)) / pop * 1e5
# ============================================================

build_covid_severity <- function(cy_df, pop_by_county) {

  if (missing(pop_by_county) || !is.data.frame(pop_by_county) ||
      !all(c("county_ihme","pop") %in% names(pop_by_county))) {
    stop("pop_by_county must be provided with columns county_ihme and pop.")
  }

  est_path <- first_existing(c(
    here("data_raw","estimatesMonthly.csv"),
    here("data_raw","estimatesMonthly.csv.gz")
  ))
  if (is.na(est_path)) stop("estimatesMonthly.csv not found")

  raw_est <- suppressMessages(readr::read_csv(est_path, show_col_types = FALSE))
  if (ncol(raw_est) == 1)
    raw_est <- suppressMessages(readr::read_tsv(est_path, show_col_types = FALSE))

  need <- c("year","month","FIPSCode","COVIDDeathsUCD","excDeathsMean")
  miss <- setdiff(need, names(raw_est))
  if (length(miss))
    stop("Missing required columns in estimatesMonthly: ",
         paste(miss, collapse = ", "))

  raw_est <- raw_est %>%
    mutate(
      county_ihme = make_fips5(
        FIPSCode,
        if ("stateFIPS" %in% names(raw_est)) stateFIPS else NULL
      )
    )

  est <- raw_est %>%
    transmute(
      county_ihme = std_fips(county_ihme),
      year  = as.integer(year),
      month = as.integer(month),
      covid = safe_num(COVIDDeathsUCD),
      excess = safe_num(excDeathsMean)
    ) %>%
    mutate(ym = year * 100L + month) %>%
    filter(
      is.finite(ym),
      ym >= SEV_START_YM, ym <= SEV_END_YM,
      is.finite(covid), is.finite(excess)
    ) %>%
    mutate(
      covid_undercount = pmax(excess - covid, 0)
    )

  sev <- est %>%
    group_by(county_ihme) %>%
    summarise(
      covid_undercount_avg = mean(covid_undercount, na.rm = TRUE),
      exc_mean_avg         = mean(excess, na.rm = TRUE),
      covid_avg            = mean(covid, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    left_join(pop_by_county %>% transmute(county_ihme = std_fips(county_ihme), pop = safe_num(pop)),
              by = "county_ihme") %>%
    filter(is.finite(pop), pop > 0) %>%
    mutate(
      covid_undercount_per100k = (covid_undercount_avg / pop) * 1e5,
      exc_mean_per100k         = (exc_mean_avg / pop) * 1e5,
      covid_per100k            = (covid_avg / pop) * 1e5
    )

  sev
}

severity_by_county <- build_covid_severity(cy, pop_by_county)
out_sev <- here("output","covid_severity_by_county.csv")
write_csv(severity_by_county, out_sev)

message("COVID severity covariates written: ", out_sev)
message("Severity cols: ", paste(setdiff(names(severity_by_county), "county_ihme"), collapse = ", "))

# -------------------- build base county×year frame --------------------
base <- cy %>%
  transmute(
    county_ihme,
    year,
    weight = if (!is.na(w_col)) suppressWarnings(as.numeric(.data[[w_col]])) else NA_real_,
    prop_garbage = suppressWarnings(as.numeric(.data[[prop_garbage_col]])),
    ri_main      = if (!is.na(ri_main_col)) suppressWarnings(as.numeric(.data[[ri_main_col]])) else NA_real_,
    ri_post_only = if (!is.na(ri_post_col)) suppressWarnings(as.numeric(.data[[ri_post_col]])) else NA_real_
  ) %>%
  left_join(detail_year %>% select(county_ihme, year, detail_icd4), by = c("county_ihme","year")) %>%
  left_join(rep_lookup, by = "county_ihme") %>%
  left_join(rep_bin, by = "county_ihme") %>%
  left_join(income_pred, by = "county_ihme") %>%
  left_join(ph_pred, by = "county_ihme") %>%
  left_join(severity_by_county, by = "county_ihme")

# -------------------- aggregate indices (BOTH variants) --------------------
# agg_global_*: z across all county-years (best for time-trend statements)
# agg_year_*  : z within year (best for within-year spatial comparisons / mapping)
base <- base %>%
  mutate(
    z_garbage_global = safe_z(-prop_garbage),
    z_detail_global  = safe_z(detail_icd4),
    z_ri_main_global = safe_z(ri_main),
    z_ri_post_global = safe_z(ri_post_only),
    agg_global_main  = z_garbage_global + z_detail_global + z_ri_main_global,
    agg_global_post  = z_garbage_global + z_detail_global + z_ri_post_global
  ) %>%
  group_by(year) %>%
  mutate(
    z_garbage_year = safe_z(-prop_garbage),
    z_detail_year  = safe_z(detail_icd4),
    z_ri_main_year = safe_z(ri_main),
    z_ri_post_year = safe_z(ri_post_only),
    agg_year_main  = z_garbage_year + z_detail_year + z_ri_main_year,
    agg_year_post  = z_garbage_year + z_detail_year + z_ri_post_year
  ) %>%
  ungroup()

# -------------------- define periods --------------------
period_of_year <- function(y) {
  case_when(
    y %in% 1999:2005 ~ "1999_2005",
    y %in% 2006:2012 ~ "2006_2012",
    y %in% 2013:2019 ~ "2013_2019",
    y %in% 2020:2022 ~ "2020_2022",
    TRUE ~ NA_character_
  )
}
base <- base %>% mutate(period = period_of_year(year)) %>% filter(!is.na(period))

# -------------------- choose metrics + covariates --------------------
metric_cols <- c(
  "prop_garbage","detail_icd4","ri_main","ri_post_only",
  "agg_global_main","agg_global_post",
  "agg_year_main","agg_year_post"
)
metric_cols <- metric_cols[metric_cols %in% names(base)]

covar_cols <- c("income_med","ph_pc_med","reporting_bin")
covar_cols <- covar_cols[covar_cols %in% names(base)]

# -------------------- severity covariates (PRIMARY first) --------------------
severity_cols <- intersect(
  c(
    # PRIMARY (use in main text)
    "covid_undercount_per100k",
    # supporting / robustness
    "exc_mean_per100k",
    "covid_per100k",
    "covid_undercount_avg",
    "exc_mean_avg",
    "covid_avg"
  ),
  names(base)
)
severity_cols <- severity_cols[!vapply(base[severity_cols], function(x) all(is.na(x)), logical(1))]

if (!("covid_undercount_per100k" %in% severity_cols)) {
  warning("PRIMARY undercount variable (covid_undercount_per100k) missing from base. Check joins + pop_by_county.")
}

# -------------------- county×period means --------------------
df_period <- base %>%
  group_by(county_ihme, period) %>%
  summarise(
    across(all_of(metric_cols),    ~ safe_wmean(.x, weight)),
    across(all_of(severity_cols),  ~ .x[which(!is.na(.x))[1]] %||% NA_real_), # time-invariant, keep as-is
    across(all_of(covar_cols),     ~ .x[which(!is.na(.x))[1]] %||% NA_real_),
    reporting_type = reporting_type[which(!is.na(reporting_type))[1]] %||% NA,
    sum_weight = sum(weight, na.rm = TRUE),
    .groups = "drop"
  )

# -------------------- (1) Paired signed-rank pre/post tests --------------------
run_signedrank <- function(dat, metric, pre_period, post_period, label) {
  w <- dat %>%
    select(county_ihme, period, value = all_of(metric)) %>%
    filter(period %in% c(pre_period, post_period)) %>%
    pivot_wider(names_from = period, values_from = value)

  pre <- w[[pre_period]]; post <- w[[post_period]]
  ok <- is.finite(pre) & is.finite(post)
  diffs <- (post - pre)[ok]

  if (length(diffs) < MIN_N_PAIR) {
    return(tibble(
      comparison = label, metric = metric, n_pairs = length(diffs),
      median_diff = NA_real_, q25_diff = NA_real_, q75_diff = NA_real_,
      share_increase = NA_real_, hl_est = NA_real_, hl_lo = NA_real_, hl_hi = NA_real_,
      p_value = NA_real_
    ))
  }

  wt <- suppressWarnings(stats::wilcox.test(diffs, mu = 0, conf.int = TRUE,
                                           conf.level = 0.95, exact = FALSE))
  ci <- wt$conf.int
  tibble(
    comparison = label,
    metric = metric,
    n_pairs = length(diffs),
    median_diff = median(diffs, na.rm = TRUE),
    q25_diff = unname(quantile(diffs, 0.25, na.rm = TRUE)),
    q75_diff = unname(quantile(diffs, 0.75, na.rm = TRUE)),
    share_increase = mean(diffs > 0, na.rm = TRUE),
    hl_est = unname(wt$estimate),
    hl_lo = unname(ci[1]),
    hl_hi = unname(ci[2]),
    p_value = unname(wt$p.value)
  )
}

comparisons <- tribble(
  ~pre,        ~post,       ~label,
  "2013_2019",  "2020_2022", "COVID-era change: 2013–2019 vs 2020–2022",
  "1999_2005",  "2020_2022", "Long-run change: 1999–2005 vs 2020–2022"
)

signedrank_tbl <- expand_grid(metric = metric_cols, comparisons) %>%
  mutate(out = pmap(list(pre, post, label, metric),
                    ~ run_signedrank(df_period, metric = ..4, pre_period = ..1, post_period = ..2, label = ..3))) %>%
  select(out) %>% unnest(out) %>%
  group_by(comparison) %>% mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>% ungroup()

out_signedrank <- here("output","stats_prepost_signedrank_county_verified.csv")
write_csv(signedrank_tbl, out_signedrank)

# -------------------- (2) Correlations: overall + by period --------------------
df_county_overall <- base %>%
  group_by(county_ihme) %>%
  summarise(
    across(all_of(metric_cols),   ~ mean(as.numeric(.x), na.rm = TRUE)),
    across(all_of(severity_cols), ~ .x[which(!is.na(.x))[1]] %||% NA_real_),  # stable by county
    across(all_of(covar_cols),    ~ .x[which(!is.na(.x))[1]] %||% NA_real_),
    reporting_type = reporting_type[which(!is.na(reporting_type))[1]] %||% NA,
    .groups = "drop"
  )

corr_overall_stable <- expand_grid(
  metric = metric_cols,
  covariate = covar_cols,
  method = c("spearman","pearson")
) %>%
  mutate(out = pmap(list(metric, covariate, method), function(metric, covariate, method) {
    corr_row(df_county_overall[[metric]], df_county_overall[[covariate]], method)
  })) %>%
  unnest(out) %>%
  group_by(method) %>% mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>% ungroup() %>%
  mutate(scope = "overall_county_mean")

corr_overall_severity <- tibble()
if (length(severity_cols)) {
  corr_overall_severity <- expand_grid(
    metric = metric_cols,
    covariate = severity_cols,
    method = c("spearman","pearson")
  ) %>%
    mutate(out = pmap(list(metric, covariate, method), function(metric, covariate, method) {
      corr_row(df_county_overall[[metric]], df_county_overall[[covariate]], method)
    })) %>%
    unnest(out) %>%
    group_by(method) %>% mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>% ungroup() %>%
    mutate(scope = "overall_county_mean_severity")
}

corr_overall <- bind_rows(corr_overall_stable, corr_overall_severity)
out_corr_overall <- here("output","stats_correlations_county_overall_verified.csv")
write_csv(corr_overall, out_corr_overall)

corr_by_period_stable <- expand_grid(
  period = sort(unique(df_period$period)),
  metric = metric_cols,
  covariate = covar_cols,
  method = c("spearman","pearson")
) %>%
  mutate(out = pmap(list(period, metric, covariate, method), function(period, metric, covariate, method) {
    d <- df_period %>% filter(.data$period == .env$period)
    corr_row(d[[metric]], d[[covariate]], method)
  })) %>%
  unnest(out) %>%
  group_by(period, method) %>% mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>% ungroup() %>%
  mutate(scope = "by_period_county_period_mean")

corr_by_period_severity <- tibble()
if (length(severity_cols)) {
  corr_by_period_severity <- expand_grid(
    period = sort(unique(df_period$period)),
    metric = metric_cols,
    covariate = severity_cols,
    method = c("spearman","pearson")
  ) %>%
    mutate(out = pmap(list(period, metric, covariate, method), function(period, metric, covariate, method) {
      d <- df_period %>% filter(.data$period == .env$period)
      corr_row(d[[metric]], d[[covariate]], method)
    })) %>%
    unnest(out) %>%
    group_by(period, method) %>% mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>% ungroup() %>%
    mutate(scope = "by_period_county_period_mean_severity")
}

corr_by_period <- bind_rows(corr_by_period_stable, corr_by_period_severity)
out_corr_by_period <- here("output","stats_correlations_county_by_period_verified.csv")
write_csv(corr_by_period, out_corr_by_period)

# -------------------- (3) Reporting-type differences: Kruskal–Wallis + eps^2 --------------------
run_kw <- function(d, metric) {
  dd <- d %>% filter(is.finite(.data[[metric]]), !is.na(reporting_type))
  if (nrow(dd) < MIN_N_KW) return(tibble(metric = metric, n = nrow(dd), k = NA_integer_,
                                        kw_stat = NA_real_, p_value = NA_real_, eps2 = NA_real_))
  k <- n_distinct(dd$reporting_type)
  if (k < 2) return(tibble(metric = metric, n = nrow(dd), k = k,
                          kw_stat = NA_real_, p_value = NA_real_, eps2 = NA_real_))
  kt <- suppressWarnings(kruskal.test(dd[[metric]] ~ dd$reporting_type))
  tibble(metric = metric, n = nrow(dd), k = k,
         kw_stat = unname(kt$statistic),
         p_value = unname(kt$p.value),
         eps2 = eps2_kw(unname(kt$statistic), k, nrow(dd)))
}

kw_overall <- bind_rows(lapply(metric_cols, function(m) run_kw(df_county_overall, m))) %>%
  mutate(scope = "overall_county_mean", period = "ALL")

kw_by_period <- df_period %>%
  group_by(period) %>%
  group_modify(~ bind_rows(lapply(metric_cols, function(m) run_kw(.x, m)))) %>%
  ungroup() %>%
  mutate(scope = "by_period_county_period_mean") %>%
  mutate(period = as.character(period))

kw_all <- bind_rows(kw_overall, kw_by_period) %>%
  group_by(scope, period) %>%
  mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>%
  ungroup()

out_kw <- here("output","stats_reportingtype_kw_eps2_verified.csv")
write_csv(kw_all, out_kw)

# -------------------- (4) Metric–metric correlations (weighted + unweighted; overall + by period) --------------------
metric_for_mm <- metric_cols

mm_overall <- {
  d <- df_period %>% filter(if_all(all_of(metric_for_mm), ~ is.finite(.x)))
  bind_rows(
    mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = "sum_weight", method = "pearson"),
                "overall", "ALL", "pearson", TRUE),
    mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = "sum_weight", method = "spearman"),
                "overall", "ALL", "spearman", TRUE),
    mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = NULL, method = "pearson"),
                "overall", "ALL", "pearson", FALSE),
    mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = NULL, method = "spearman"),
                "overall", "ALL", "spearman", FALSE)
  )
}

mm_by_period <- df_period %>%
  group_by(period) %>%
  group_modify(~ {
    d <- .x %>% filter(if_all(all_of(metric_for_mm), ~ is.finite(.x)))
    bind_rows(
      mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = "sum_weight", method = "pearson"),
                  "period", .y$period[[1]], "pearson", TRUE),
      mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = "sum_weight", method = "spearman"),
                  "period", .y$period[[1]], "spearman", TRUE),
      mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = NULL, method = "pearson"),
                  "period", .y$period[[1]], "pearson", FALSE),
      mat_to_tidy(weighted_cor_mat(d, metric_for_mm, wcol = NULL, method = "spearman"),
                  "period", .y$period[[1]], "spearman", FALSE)
    )
  }) %>% ungroup()

metric_corrs <- bind_rows(mm_overall, mm_by_period)
out_mm <- here("output","stats_metric_correlations_verified.csv")
write_csv(metric_corrs, out_mm)

# -------------------- (5) Yearly correlation time series (optional; stable covariates only) --------------------
do_yearly_correlations <- TRUE
yearly_corrs <- tibble()

if (isTRUE(do_yearly_correlations) && length(covar_cols)) {
  yearly_corrs <- base %>%
    group_by(year) %>%
    group_modify(~{
      dfg <- .x
      expand_grid(metric = metric_cols, covariate = covar_cols, method = c("pearson","spearman")) %>%
        mutate(out = pmap(
          list(metric, covariate, method),
          function(metric, covariate, method) corr_row(dfg[[metric]], dfg[[covariate]], method)
        )) %>%
        unnest(out)
    }) %>%
    ungroup() %>%
    group_by(year, method) %>%
    mutate(p_adj_fdr = p.adjust(p_value, method = "BH")) %>%
    ungroup()

  out_yearly <- here("output","stats_correlations_time_series_long_verified.csv")
  write_csv(yearly_corrs, out_yearly)
}

# -------------------- VERIFICATION MANIFEST + REPORT --------------------
manifest <- bind_rows(
  signedrank_tbl %>%
    transmute(section = "signedrank",
              key = paste(comparison, metric, sep = " | "),
              value = sprintf("HL=%.6f (%.6f, %.6f); p=%.3g; n=%d",
                              hl_est, hl_lo, hl_hi, p_value, n_pairs),
              file = basename(out_signedrank)),
  corr_overall %>%
    transmute(section = "corr_overall",
              key = paste(scope, metric, "vs", covariate, method, sep = " | "),
              value = sprintf("r=%.6f; CI=(%.6f, %.6f); p=%.3g; n=%d",
                              r, ci_lo, ci_hi, p_value, n),
              file = basename(out_corr_overall)),
  corr_by_period %>%
    transmute(section = "corr_by_period",
              key = paste(scope, period, metric, "vs", covariate, method, sep = " | "),
              value = sprintf("r=%.6f; CI=(%.6f, %.6f); p=%.3g; n=%d",
                              r, ci_lo, ci_hi, p_value, n),
              file = basename(out_corr_by_period)),
  kw_all %>%
    transmute(section = "kw",
              key = paste(scope, period, metric, sep = " | "),
              value = sprintf("KW=%.6f; eps2=%.6f; p=%.3g; n=%d; k=%s",
                              kw_stat, eps2, p_value, n, ifelse(is.na(k),"NA",as.character(k))),
              file = basename(out_kw))
)

out_manifest <- here("output","verification_manifest.csv")
write_csv(manifest, out_manifest)

report_lines <- c(
  "STATISTICAL ANALYSIS VERIFICATION REPORT",
  paste0("Generated: ", format(Sys.time(), "%Y-%m-%d %H:%M:%S")),
  "",
  "[INPUTS DETECTED]",
  paste0("  prop_garbage_col = ", prop_garbage_col),
  paste0("  ri_main_col      = ", ifelse(is.na(ri_main_col), "NONE", ri_main_col)),
  paste0("  ri_post_col      = ", ifelse(is.na(ri_post_col), "NONE", ri_post_col)),
  paste0("  weight_col       = ", ifelse(is.na(w_col), "NONE", w_col)),
  paste0("  severity_cols    = ", ifelse(length(severity_cols), paste(severity_cols, collapse=", "), "NONE")),
  paste0("  severity_source  = ", out_sev),
  paste0("  severity_window  = ", SEV_START_YM, "–", SEV_END_YM),
  paste0("  census_pop_year  = ", CENSUS_POP_YEAR),
  paste0("  pop_cache_file   = ", pop_cache),
  "",
  "[OUTPUTS WRITTEN]",
  paste0("  - ", out_signedrank),
  paste0("  - ", out_corr_overall),
  paste0("  - ", out_corr_by_period),
  paste0("  - ", out_kw),
  paste0("  - ", out_mm),
  if (exists("out_yearly")) paste0("  - ", out_yearly) else NULL,
  paste0("  - ", out_manifest),
  paste0("  - ", out_sev),
  "",
  "[NOTES]",
  paste0("  * Correlations include bootstrap percentile 95% CI: ", DO_BOOT_CORR_CI,
         " (B=", BOOT_B, ", seed=", BOOT_SEED, ")."),
  "  * Two aggregate indices are produced:",
  "      - agg_year_*   : z-scored within year (best for within-year spatial comparisons / mapping).",
  "      - agg_global_* : z-scored across all county-years (best for time-trend statements).",
  "  * COVID severity covariates are time-invariant county-level summaries from estimatesMonthly (Mar 2020–Aug 2022).",
  "    PRIMARY: covid_undercount_per100k = mean(max(excDeathsMean - COVIDDeathsUCD, 0)) / pop * 1e5, using Census PEP county population."
)

out_report <- here("output","verification_report.txt")
writeLines(report_lines, out_report)

# -------------------- console summary --------------------
message("\n[WROTE]")
message(" - ", out_signedrank)
message(" - ", out_corr_overall)
message(" - ", out_corr_by_period)
message(" - ", out_kw)
message(" - ", out_mm)
if (exists("out_yearly")) message(" - ", out_yearly)
message(" - ", out_manifest)
message(" - ", out_report)
message(" - ", out_sev)

message("\n[CHECKS]")
message("Income rows present? ", nrow(income_pred) > 0)
message("PH spend rows present? ", nrow(ph_pred) > 0)
message("Reporting type rows present? ", nrow(rep_lookup) > 0)
message("detail_year rows present? ", nrow(detail_year) > 0)
message("COVID severity rows present? ", nrow(severity_by_county) > 0)
message("Census population rows present? ", exists("pop_by_county") && nrow(pop_by_county) > 0)

invisible(list(
  signedrank = signedrank_tbl,
  corr_overall = corr_overall,
  corr_by_period = corr_by_period,
  kw = kw_all,
  metric_corrs = metric_corrs,
  yearly_corrs = yearly_corrs,
  manifest = manifest,
  covid_severity = severity_by_county,
  pop_by_county = pop_by_county
))

```


